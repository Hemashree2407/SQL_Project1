{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRVUWKc+Tf2Om9gFi0+S3z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemashree2407/SQL_Project1/blob/main/Duplicate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn9dhNE9FOy8"
      },
      "outputs": [],
      "source": [
        "pip install yfinance pandas numpy xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python integration_script.py"
      ],
      "metadata": {
        "id": "g0Zlw2m4IY5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance ta --quiet"
      ],
      "metadata": {
        "id": "gRXmvs7BIx-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part 1 of Main script\n",
        "# Indian Stock Analyzer - Part 1 (Corrected and Enhanced)\n",
        "# Complete implementation with improvements\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import logging\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__) # Define logger globally\n",
        "\n",
        "@dataclass\n",
        "class StockData:\n",
        "    \"\"\"Data class to store comprehensive stock information\"\"\"\n",
        "    symbol: str\n",
        "    company_name: str\n",
        "    current_price: float\n",
        "    market_cap: float\n",
        "    info: Dict\n",
        "    price_data: pd.DataFrame\n",
        "    indicators: Dict\n",
        "    fundamental_score: float\n",
        "    technical_score: float\n",
        "    recommendation: str\n",
        "    metrics: Dict\n",
        "\n",
        "class IndianStockAnalyzer:\n",
        "    \"\"\"Comprehensive stock analyzer for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the analyzer with Indian market specific parameters\"\"\"\n",
        "        self.nifty_symbol = \"^NSEI\"\n",
        "        self.risk_free_rate = 0.065  # Will be made dynamic in Part 2\n",
        "\n",
        "        # Industry-specific benchmark thresholds for Indian markets\n",
        "        self.industry_benchmarks = {\n",
        "            'technology': {\n",
        "                'pe_ratio': {'excellent': 25, 'good': 35, 'fair': 45},\n",
        "                'debt_to_equity': {'excellent': 0.3, 'good': 0.5, 'fair': 0.8},\n",
        "                'roe': {'excellent': 0.25, 'good': 0.18, 'fair': 0.12},\n",
        "                'revenue_growth': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10}\n",
        "            },\n",
        "            'banking': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 20, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 8, 'good': 10, 'fair': 12},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.25, 'good': 0.20, 'fair': 0.15}\n",
        "            },\n",
        "            'pharmaceutical': {\n",
        "                'pe_ratio': {'excellent': 20, 'good': 30, 'fair': 40},\n",
        "                'debt_to_equity': {'excellent': 0.4, 'good': 0.6, 'fair': 0.8},\n",
        "                'roe': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.08}\n",
        "            },\n",
        "            'fmcg': {\n",
        "                'pe_ratio': {'excellent': 30, 'good': 40, 'fair': 50},\n",
        "                'debt_to_equity': {'excellent': 0.5, 'good': 0.8, 'fair': 1.0},\n",
        "                'roe': {'excellent': 0.30, 'good': 0.25, 'fair': 0.15},\n",
        "                'revenue_growth': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.08}\n",
        "            },\n",
        "            'automobile': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "                'debt_to_equity': {'excellent': 0.6, 'good': 0.8, 'fair': 1.2},\n",
        "                'roe': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "            },\n",
        "            'infrastructure': {\n",
        "                'pe_ratio': {'excellent': 12, 'good': 18, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05}\n",
        "            },\n",
        "            'energy': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 15, 'fair': 20},\n",
        "                'debt_to_equity': {'excellent': 0.8, 'good': 1.2, 'fair': 1.5},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "            },\n",
        "            'realty': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 15, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05},\n",
        "                'revenue_growth': {'excellent': 0.25, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05}\n",
        "            },\n",
        "            'telecom': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05},\n",
        "                'revenue_growth': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.08, 'good': 0.05, 'fair': 0.03}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Default benchmarks for other sectors\n",
        "        self.default_benchmarks = {\n",
        "            'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "            'debt_to_equity': {'excellent': 0.5, 'good': 1.0, 'fair': 1.5},\n",
        "            'roe': {'excellent': 0.15, 'good': 0.10, 'fair': 0.07},\n",
        "            'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "            'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "        }\n",
        "\n",
        "    def get_stock_data(self, symbol: str) -> Optional[yf.Ticker]:\n",
        "        \"\"\"Fetch stock data from Yahoo Finance with basic validation\"\"\"\n",
        "        if not isinstance(symbol, str) or not symbol:\n",
        "            logger.error(\"Invalid symbol input: Symbol must be a non-empty string.\")\n",
        "            return None\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            # Verify the ticker is valid by checking if it has info\n",
        "            if ticker.info and 'symbol' in ticker.info and ticker.info['symbol'].upper() == symbol.upper():\n",
        "                logger.info(f\"Successfully fetched data for {symbol}\")\n",
        "                return ticker\n",
        "            else:\n",
        "                logger.error(f\"Invalid or no data available for symbol: {symbol}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error fetching data for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_industry_benchmarks(self, sector: str) -> Dict:\n",
        "        \"\"\"Get industry-specific benchmarks\"\"\"\n",
        "        sector_lower = sector.lower() if isinstance(sector, str) else ''\n",
        "\n",
        "        # Map common sector names to our benchmark categories\n",
        "        sector_mapping = {\n",
        "            'technology': 'technology',\n",
        "            'information technology': 'technology',\n",
        "            'financial services': 'banking',\n",
        "            'financials': 'banking',\n",
        "            'healthcare': 'pharmaceutical',\n",
        "            'consumer defensive': 'fmcg',\n",
        "            'consumer cyclical': 'automobile',\n",
        "            'industrials': 'infrastructure',\n",
        "            'energy': 'energy',\n",
        "            'real estate': 'realty',\n",
        "            'communication services': 'telecom'\n",
        "        }\n",
        "\n",
        "        benchmark_key = sector_mapping.get(sector_lower, None)\n",
        "\n",
        "        if benchmark_key and benchmark_key in self.industry_benchmarks:\n",
        "            logger.info(f\"Using industry-specific benchmarks for sector: {sector}\")\n",
        "            return self.industry_benchmarks[benchmark_key]\n",
        "        else:\n",
        "            logger.info(f\"Using default benchmarks for sector: {sector}\")\n",
        "            return self.default_benchmarks\n",
        "\n",
        "\n",
        "def calculate_enhanced_technical_score(self, indicators: Dict, circuit_risk: int) -> float:\n",
        "        \"\"\"Enhanced technical scoring with circuit risk and better MACD handling\"\"\"\n",
        "        base_score = 0\n",
        "        max_technical_score = 50\n",
        "\n",
        "        try:\n",
        "            # RSI Score (10 points)\n",
        "            rsi = indicators.get('RSI', 50)\n",
        "            if pd.notna(rsi):\n",
        "                if 30 <= rsi <= 70:\n",
        "                    base_score += 10\n",
        "                elif rsi < 30:\n",
        "                    base_score += 8  # Oversold\n",
        "                else:\n",
        "                    base_score += 5  # Overbought\n",
        "            else:\n",
        "                self.logger.warning(\"RSI is NaN, skipping RSI scoring\")\n",
        "\n",
        "            # MACD Score (10 points) - FIXED\n",
        "            macd = indicators.get('MACD')\n",
        "            macd_signal = indicators.get('MACD_signal')\n",
        "\n",
        "            if pd.notna(macd) and pd.notna(macd_signal):\n",
        "                if macd > macd_signal:\n",
        "                    base_score += 10\n",
        "                else:\n",
        "                    base_score += 3\n",
        "            else:\n",
        "                self.logger.warning(\"MACD or MACD signal is NaN, using alternative scoring\")\n",
        "                # Use EMA crossover as alternative\n",
        "                ema_12 = indicators.get('EMA_12')\n",
        "                ema_26 = indicators.get('EMA_26')\n",
        "                if pd.notna(ema_12) and pd.notna(ema_26):\n",
        "                    if ema_12 > ema_26:\n",
        "                        base_score += 7\n",
        "                    else:\n",
        "                        base_score += 3\n",
        "\n",
        "            # Moving Average Score (10 points)\n",
        "            sma_20 = indicators.get('SMA_20')\n",
        "            sma_50 = indicators.get('SMA_50')\n",
        "            current_price = indicators.get('current_price', 0)\n",
        "\n",
        "            if pd.notna(sma_20) and pd.notna(sma_50):\n",
        "                if sma_20 > sma_50:\n",
        "                    base_score += 7\n",
        "                    # Bonus if price above both\n",
        "                    if current_price > sma_20:\n",
        "                        base_score += 3\n",
        "                else:\n",
        "                    base_score += 3\n",
        "\n",
        "            # Bollinger Bands Score (10 points)\n",
        "            bb_upper = indicators.get('BB_upper')\n",
        "            bb_lower = indicators.get('BB_lower')\n",
        "            bb_middle = indicators.get('BB_middle')\n",
        "\n",
        "            if pd.notna(bb_upper) and pd.notna(bb_lower) and pd.notna(current_price):\n",
        "                bb_position = (current_price - bb_lower) / (bb_upper - bb_lower) if bb_upper != bb_lower else 0.5\n",
        "                if 0.3 <= bb_position <= 0.7:\n",
        "                    base_score += 10  # Middle band - stable\n",
        "                elif bb_position < 0.3:\n",
        "                    base_score += 8   # Near lower band - potential bounce\n",
        "                else:\n",
        "                    base_score += 5   # Near upper band\n",
        "\n",
        "            # Volume Score (10 points)\n",
        "            volume_ratio = indicators.get('Volume_ratio', 1)\n",
        "            if pd.notna(volume_ratio):\n",
        "                if 0.8 <= volume_ratio <= 1.5:\n",
        "                    base_score += 7   # Normal volume\n",
        "                elif volume_ratio > 1.5:\n",
        "                    base_score += 10  # High volume\n",
        "                else:\n",
        "                    base_score += 3   # Low volume\n",
        "\n",
        "            # Add circuit risk adjustment\n",
        "            base_score += circuit_risk\n",
        "\n",
        "            # Cap the score\n",
        "            final_score = max(0, min(base_score, max_technical_score))\n",
        "\n",
        "            # Log the calculation\n",
        "            self.logger.info(f\"Technical score calculation: base={base_score}, circuit_risk={circuit_risk}, final={final_score}\")\n",
        "\n",
        "            return final_score\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error calculating technical score: {str(e)}\")\n",
        "            return 0\n",
        "\n",
        "def get_peer_companies(self, symbol: str, stock_info: Dict) -> List[str]:\n",
        "        \"\"\"Identify peer companies for comparison\"\"\"\n",
        "        try:\n",
        "            sector = stock_info.get('sector', '')\n",
        "            market_cap = stock_info.get('marketCap', 0)\n",
        "\n",
        "            # Define market cap categories\n",
        "            if market_cap > 10_00_000_00_00_000:  # > 10 Lakh Cr\n",
        "                cap_category = 'Large Cap'\n",
        "            elif market_cap > 50_000_00_00_000:   # > 50K Cr\n",
        "                cap_category = 'Mid Cap'\n",
        "            else:\n",
        "                cap_category = 'Small Cap'\n",
        "\n",
        "            # Enhanced peer mapping\n",
        "            peer_map = {\n",
        "                'Energy': {\n",
        "                    'Large Cap': ['RELIANCE.NS', 'ONGC.NS', 'IOC.NS', 'BPCL.NS', 'HINDPETRO.NS'],\n",
        "                    'Mid Cap': ['GAIL.NS', 'OIL.NS', 'IGL.NS', 'PETRONET.NS'],\n",
        "                    'Small Cap': ['MRPL.NS', 'CHENNPETRO.NS', 'GSPL.NS']\n",
        "                },\n",
        "                'Technology': {\n",
        "                    'Large Cap': ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS'],\n",
        "                    'Mid Cap': ['TECHM.NS', 'LTTS.NS', 'PERSISTENT.NS', 'COFORGE.NS'],\n",
        "                    'Small Cap': ['ZENSAR.NS', 'ECLERX.NS', 'MASTEK.NS']\n",
        "                },\n",
        "                'Financial Services': {\n",
        "                    'Large Cap': ['HDFCBANK.NS', 'ICICIBANK.NS', 'KOTAKBANK.NS', 'AXISBANK.NS', 'SBIN.NS'],\n",
        "                    'Mid Cap': ['IDFCFIRSTB.NS', 'FEDERALBNK.NS', 'INDUSINDBK.NS', 'BANDHANBNK.NS'],\n",
        "                    'Small Cap': ['SOUTHBANK.NS', 'UJJIVAN.NS', 'EQUITASBNK.NS']\n",
        "                },\n",
        "                'Healthcare': {\n",
        "                    'Large Cap': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS'],\n",
        "                    'Mid Cap': ['TORNTPHARM.NS', 'ALKEM.NS', 'LUPIN.NS', 'AUROPHARMA.NS'],\n",
        "                    'Small Cap': ['CAPLIPOINT.NS', 'GRANULES.NS', 'INDOCO.NS']\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Get peers, excluding the current symbol\n",
        "            peers = peer_map.get(sector, {}).get(cap_category, [])\n",
        "            peers = [p for p in peers if p != symbol]\n",
        "\n",
        "            # If no peers found, return empty list\n",
        "            if not peers:\n",
        "                self.logger.warning(f\"No predefined peers for {sector} - {cap_category}\")\n",
        "                return []\n",
        "\n",
        "            return peers[:5]  # Return top 5 peers\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error getting peer companies: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "def calculate_peer_relative_performance(self, symbol: str, peers: List[str], days: int = 30) -> Dict:\n",
        "        \"\"\"Compare stock performance with peers\"\"\"\n",
        "        try:\n",
        "            # Check if peers list is valid\n",
        "            if not peers:\n",
        "                self.logger.warning(\"No peers provided for comparison\")\n",
        "                return {}\n",
        "\n",
        "            results = {}\n",
        "\n",
        "            # Get performance for main stock\n",
        "            main_ticker = yf.Ticker(symbol)\n",
        "            main_hist = main_ticker.history(period=f\"{days}d\")\n",
        "            if len(main_hist) > 0:\n",
        "                main_return = ((main_hist['Close'].iloc[-1] / main_hist['Close'].iloc[0]) - 1) * 100\n",
        "            else:\n",
        "                main_return = 0\n",
        "\n",
        "            # Get peer performances\n",
        "            peer_returns = []\n",
        "            for peer in peers:\n",
        "                try:\n",
        "                    peer_ticker = yf.Ticker(peer)\n",
        "                    peer_hist = peer_ticker.history(period=f\"{days}d\")\n",
        "                    if len(peer_hist) > 0:\n",
        "                        peer_return = ((peer_hist['Close'].iloc[-1] / peer_hist['Close'].iloc[0]) - 1) * 100\n",
        "                        peer_returns.append(peer_return)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            if peer_returns:\n",
        "                avg_peer_return = np.mean(peer_returns)\n",
        "                relative_performance = main_return - avg_peer_return\n",
        "\n",
        "                results = {\n",
        "                    'stock_return': main_return,\n",
        "                    'avg_peer_return': avg_peer_return,\n",
        "                    'relative_performance': relative_performance,\n",
        "                    'outperformance': relative_performance > 0\n",
        "                }\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error calculating peer performance: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "def calculate_rsi(self, prices: pd.Series, period: int = 14) -> Optional[float]:\n",
        "        \"\"\"Calculate Relative Strength Index with robust NaN handling\"\"\"\n",
        "        if not isinstance(prices, pd.Series) or prices.empty or len(prices) < period:\n",
        "            logger.warning(\"Insufficient data or invalid input for RSI calculation.\")\n",
        "            return np.nan # Return NaN for insufficient or invalid data\n",
        "\n",
        "        try:\n",
        "            delta = prices.diff()\n",
        "            # Use .fillna(0) before rolling mean to treat initial NaNs in gain/loss as 0\n",
        "            gain = delta.where(delta > 0, 0).fillna(0)\n",
        "            loss = -delta.where(delta < 0, 0).fillna(0)\n",
        "\n",
        "            avg_gain = gain.rolling(window=period).mean()\n",
        "            avg_loss = loss.rolling(window=period).mean()\n",
        "\n",
        "            # Check if the last values are valid numbers\n",
        "            if pd.isna(avg_gain.iloc[-1]) or pd.isna(avg_loss.iloc[-1]):\n",
        "                 logger.warning(\"Rolling average gain or loss is NaN. Cannot calculate RSI.\")\n",
        "                 return np.nan\n",
        "\n",
        "            # Handle division by zero if avg_loss is zero\n",
        "            if avg_loss.iloc[-1] == 0:\n",
        "                 # If no loss, RSI is 100 if there's gain, 50 if no change\n",
        "                 return 100.0 if avg_gain.iloc[-1] > 0 else 50.0\n",
        "            elif avg_loss.iloc[-1] > 0:\n",
        "                rs = avg_gain.iloc[-1] / avg_loss.iloc[-1]\n",
        "                rsi = 100 - (100 / (1 + rs))\n",
        "                return rsi\n",
        "            else:\n",
        "                 # This case should ideally not be reached with the abs logic, but as a safeguard\n",
        "                 return np.nan\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating RSI: {str(e)}\")\n",
        "            return np.nan # Return NaN on error\n",
        "\n",
        "def calculate_fundamental_score(self, info: Dict, benchmarks: Dict) -> Tuple[float, Dict]:\n",
        "        \"\"\"Calculate fundamental analysis score based on Indian market standards with improved NaN handling and D/E validation\"\"\"\n",
        "        score = 0\n",
        "        max_score = 50\n",
        "        metrics = {}\n",
        "\n",
        "        try:\n",
        "            # P/E Ratio (10 points)\n",
        "            pe_ratio = info.get('trailingPE', info.get('forwardPE', None))\n",
        "            # Check if pe_ratio is a valid positive number\n",
        "            if isinstance(pe_ratio, (int, float)) and pe_ratio is not None and pe_ratio > 0 and not pd.isna(pe_ratio):\n",
        "                metrics['PE_Ratio'] = pe_ratio\n",
        "                if pe_ratio <= benchmarks['pe_ratio']['excellent']:\n",
        "                    score += 10\n",
        "                elif pe_ratio <= benchmarks['pe_ratio']['good']:\n",
        "                    score += 7\n",
        "                elif pe_ratio <= benchmarks['pe_ratio']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2 # Even high PE gets a small score if available and positive\n",
        "            else:\n",
        "                 metrics['PE_Ratio'] = np.nan\n",
        "                 logger.warning(\"PE Ratio not available or is invalid.\")\n",
        "\n",
        "\n",
        "            # Debt to Equity (10 points) - Improved Validation\n",
        "            debt_to_equity_raw = info.get('debtToEquity', None)\n",
        "            debt_to_equity = np.nan # Default to NaN\n",
        "\n",
        "            if debt_to_equity_raw is not None:\n",
        "                 if isinstance(debt_to_equity_raw, (int, float)):\n",
        "                    # More robust check: if the number is very large (e.g., > 1000), assume it's percentage\n",
        "                    # Otherwise, assume it's a decimal ratio. This handles both 0.5 and 50 formats.\n",
        "                    if debt_to_equity_raw > 1000:\n",
        "                         debt_to_equity = debt_to_equity_raw / 100.0\n",
        "                    elif debt_to_equity_raw >= 0: # Ensure it's non-negative\n",
        "                         debt_to_equity = debt_to_equity_raw\n",
        "                    # If it's a negative number, treat as invalid (remains np.nan)\n",
        "                 # else: debt_to_equity remains np.nan for non-numeric types\n",
        "\n",
        "            if not pd.isna(debt_to_equity):\n",
        "                metrics['Debt_to_Equity'] = debt_to_equity\n",
        "                # Scoring based on the valid debt_to_equity value\n",
        "                if debt_to_equity <= benchmarks['debt_to_equity']['excellent']:\n",
        "                    score += 10\n",
        "                elif debt_to_equity <= benchmarks['debt_to_equity']['good']:\n",
        "                    score += 7\n",
        "                elif debt_to_equity <= benchmarks['debt_to_equity']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2 # Even high debt gets a small score if available\n",
        "            else:\n",
        "                 metrics['Debt_to_Equity'] = np.nan\n",
        "                 logger.warning(\"Debt to Equity not available or is invalid.\")\n",
        "\n",
        "\n",
        "            # ROE (10 points)\n",
        "            roe = info.get('returnOnEquity', None)\n",
        "            # Check if roe is a valid number\n",
        "            if isinstance(roe, (int, float)) and roe is not None and not pd.isna(roe):\n",
        "                metrics['ROE'] = roe\n",
        "                if roe >= benchmarks['roe']['excellent']:\n",
        "                    score += 10\n",
        "                elif roe >= benchmarks['roe']['good']:\n",
        "                    score += 7\n",
        "                elif roe >= benchmarks['roe']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2 # Even lower positive ROE gets some points\n",
        "            else:\n",
        "                 metrics['ROE'] = np.nan\n",
        "                 logger.warning(\"ROE not available or is invalid.\")\n",
        "\n",
        "            # Revenue Growth (10 points)\n",
        "            revenue_growth = info.get('revenueGrowth', None)\n",
        "            # Check if revenue_growth is a valid number\n",
        "            if isinstance(revenue_growth, (int, float)) and revenue_growth is not None and not pd.isna(revenue_growth):\n",
        "                metrics['Revenue_Growth'] = revenue_growth\n",
        "                if revenue_growth >= benchmarks['revenue_growth']['excellent']:\n",
        "                    score += 10\n",
        "                elif revenue_growth >= benchmarks['revenue_growth']['good']:\n",
        "                    score += 7\n",
        "                elif revenue_growth >= benchmarks['revenue_growth']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2 # Even lower positive growth gets some points\n",
        "            else:\n",
        "                 metrics['Revenue_Growth'] = np.nan\n",
        "                 logger.warning(\"Revenue Growth not available or is invalid.\")\n",
        "\n",
        "            # Net Profit Margin (10 points)\n",
        "            profit_margin = info.get('profitMargins', None)\n",
        "            # Check if profit_margin is a valid number\n",
        "            if isinstance(profit_margin, (int, float)) and profit_margin is not None and not pd.isna(profit_margin):\n",
        "                metrics['Net_Profit_Margin'] = profit_margin\n",
        "                if profit_margin >= benchmarks['net_profit_margin']['excellent']:\n",
        "                    score += 10\n",
        "                elif profit_margin >= benchmarks['net_profit_margin']['good']:\n",
        "                    score += 7\n",
        "                elif profit_margin >= benchmarks['net_profit_margin']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2 # Even lower positive margin gets some points\n",
        "            else:\n",
        "                 metrics['Net_Profit_Margin'] = np.nan\n",
        "                 logger.warning(\"Net Profit Margin not available or is invalid.\")\n",
        "\n",
        "\n",
        "            # Normalize score to max_score (already capped by scoring logic)\n",
        "            metrics['Fundamental_Score'] = score\n",
        "\n",
        "            return score, metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating fundamental score: {str(e)}\")\n",
        "            return 0, {}\n",
        "\n",
        "    def calculate_technical_indicators(self, price_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate comprehensive technical indicators\"\"\"\n",
        "        try:\n",
        "            indicators = {}\n",
        "\n",
        "            # Ensure we have enough data\n",
        "            if len(price_data) < 50:\n",
        "                self.logger.warning(\"Insufficient data for technical analysis\")\n",
        "                return indicators\n",
        "\n",
        "            # Current price\n",
        "            current_price = price_data['Close'].iloc[-1]\n",
        "            indicators['current_price'] = current_price\n",
        "\n",
        "            # Simple Moving Averages\n",
        "            indicators['SMA_20'] = price_data['Close'].rolling(window=20).mean().iloc[-1]\n",
        "            indicators['SMA_50'] = price_data['Close'].rolling(window=50).mean().iloc[-1]\n",
        "            indicators['SMA_200'] = price_data['Close'].rolling(window=200).mean().iloc[-1] if len(price_data) >= 200 else None\n",
        "\n",
        "            # Exponential Moving Averages - FIXED\n",
        "            ema_12_series = price_data['Close'].ewm(span=12, adjust=False).mean()\n",
        "            ema_26_series = price_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "\n",
        "            indicators['EMA_12'] = ema_12_series.iloc[-1]\n",
        "            indicators['EMA_26'] = ema_26_series.iloc[-1]\n",
        "\n",
        "            # RSI\n",
        "            indicators['RSI'] = self.calculate_rsi(price_data['Close'])\n",
        "\n",
        "            # MACD - FIXED CALCULATION\n",
        "            macd_line = ema_12_series - ema_26_series\n",
        "            signal_line = macd_line.ewm(span=9, adjust=False).mean()\n",
        "\n",
        "            indicators['MACD'] = macd_line.iloc[-1]\n",
        "            indicators['MACD_signal'] = signal_line.iloc[-1]\n",
        "            indicators['MACD_histogram'] = indicators['MACD'] - indicators['MACD_signal']\n",
        "\n",
        "            # Bollinger Bands\n",
        "            bb_period = 20\n",
        "            bb_std = 2\n",
        "            sma_bb = price_data['Close'].rolling(window=bb_period).mean()\n",
        "            std_bb = price_data['Close'].rolling(window=bb_period).std()\n",
        "            indicators['BB_upper'] = (sma_bb + (std_bb * bb_std)).iloc[-1]\n",
        "            indicators['BB_lower'] = (sma_bb - (std_bb * bb_std)).iloc[-1]\n",
        "            indicators['BB_middle'] = sma_bb.iloc[-1]\n",
        "\n",
        "            # Volume indicators\n",
        "            indicators['Volume_SMA'] = price_data['Volume'].rolling(window=20).mean().iloc[-1]\n",
        "            indicators['Volume_ratio'] = price_data['Volume'].iloc[-1] / indicators['Volume_SMA'] if indicators['Volume_SMA'] > 0 else 1.0\n",
        "\n",
        "            # Price position\n",
        "            indicators['Price_to_SMA20'] = (current_price / indicators['SMA_20'] - 1) * 100 if indicators['SMA_20'] > 0 else 0\n",
        "            indicators['Price_to_SMA50'] = (current_price / indicators['SMA_50'] - 1) * 100 if indicators['SMA_50'] > 0 else 0\n",
        "\n",
        "            # Support and Resistance\n",
        "            indicators['Resistance'] = price_data['High'].rolling(window=20).max().iloc[-1]\n",
        "            indicators['Support'] = price_data['Low'].rolling(window=20).min().iloc[-1]\n",
        "\n",
        "            # Stochastic Oscillator\n",
        "            low_14 = price_data['Low'].rolling(window=14).min()\n",
        "            high_14 = price_data['High'].rolling(window=14).max()\n",
        "            indicators['Stochastic_K'] = ((price_data['Close'] - low_14) / (high_14 - low_14) * 100).iloc[-1]\n",
        "\n",
        "            # Average True Range (ATR)\n",
        "            high_low = price_data['High'] - price_data['Low']\n",
        "            high_close = np.abs(price_data['High'] - price_data['Close'].shift())\n",
        "            low_close = np.abs(price_data['Low'] - price_data['Close'].shift())\n",
        "            true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
        "            indicators['ATR'] = true_range.rolling(window=14).mean().iloc[-1]\n",
        "\n",
        "            return indicators\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error calculating technical indicators: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return {}\n",
        "\n",
        "    def generate_recommendation(self, fundamental_score: float, technical_score: float) -> str:\n",
        "        \"\"\"Generate investment recommendation based on scores\"\"\"\n",
        "        # Ensure scores are not NaN before summing\n",
        "        fund_score = fundamental_score if not pd.isna(fundamental_score) else 0\n",
        "        tech_score = technical_score if not pd.isna(technical_score) else 0\n",
        "\n",
        "        total_score = fund_score + tech_score\n",
        "\n",
        "        if total_score >= 75:\n",
        "            return \"STRONG BUY\"\n",
        "        elif total_score >= 60:\n",
        "            return \"BUY\"\n",
        "        elif total_score >= 40:\n",
        "            return \"HOLD\"\n",
        "        elif total_score >= 25:\n",
        "            return \"SELL\"\n",
        "        else:\n",
        "            return \"STRONG SELL\"\n",
        "\n",
        "    def analyze_stock(self, symbol: str) -> Optional[StockData]:\n",
        "        \"\"\"Main method to analyze a stock with improved data handling\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Starting analysis for {symbol}\")\n",
        "\n",
        "            # Get stock data with validation\n",
        "            ticker = self.get_stock_data(symbol)\n",
        "            if not ticker:\n",
        "                logger.error(f\"Failed to fetch valid ticker data for {symbol}.\")\n",
        "                return None\n",
        "\n",
        "            # Get stock info with validation\n",
        "            info = ticker.info\n",
        "            if not info or not isinstance(info, dict):\n",
        "                logger.error(f\"No valid info available for {symbol}\")\n",
        "                return None\n",
        "\n",
        "            # Get historical price data with validation\n",
        "            # Fetching enough data for 200-day SMA calculation (period=\"1y\" is generally sufficient)\n",
        "            price_data = ticker.history(period=\"1y\")\n",
        "            if price_data.empty or not isinstance(price_data, pd.DataFrame):\n",
        "                logger.error(f\"No valid price data available for {symbol}\")\n",
        "                return None\n",
        "\n",
        "            # Get current price with validation\n",
        "            if 'Close' in price_data.columns and not price_data['Close'].empty:\n",
        "                 current_price = price_data['Close'].iloc[-1]\n",
        "                 if pd.isna(current_price):\n",
        "                     logger.warning(f\"Current price is NaN for {symbol}. Using 0.\")\n",
        "                     current_price = 0.0 # Default to 0 if NaN\n",
        "            else:\n",
        "                 logger.error(f\"Close price column not found or is empty for {symbol}. Cannot determine current price.\")\n",
        "                 current_price = 0.0 # Default to 0 if column missing or empty\n",
        "\n",
        "\n",
        "            # Add current price to indicators for technical score calculation\n",
        "            indicators = self.calculate_technical_indicators(price_data)\n",
        "            indicators['current_price'] = current_price # Ensure current price is available for BB score\n",
        "\n",
        "            # Get industry benchmarks\n",
        "            sector = info.get('sector', 'Unknown')\n",
        "            benchmarks = self.get_industry_benchmarks(sector)\n",
        "\n",
        "            # Calculate scores\n",
        "            fundamental_score, metrics = self.calculate_fundamental_score(info, benchmarks)\n",
        "            technical_score = self.calculate_technical_score(indicators)\n",
        "\n",
        "            # Generate recommendation\n",
        "            recommendation = self.generate_recommendation(fundamental_score, technical_score)\n",
        "\n",
        "            # Create StockData object\n",
        "            stock_data = StockData(\n",
        "                symbol=symbol,\n",
        "                company_name=info.get('longName', symbol),\n",
        "                current_price=current_price,\n",
        "                market_cap=info.get('marketCap', 0) if info.get('marketCap') is not None else np.nan, # Handle missing marketCap\n",
        "                info=info,\n",
        "                price_data=price_data,\n",
        "                indicators=indicators,\n",
        "                fundamental_score=fundamental_score,\n",
        "                technical_score=technical_score,\n",
        "                recommendation=recommendation,\n",
        "                metrics=metrics\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Analysis completed for {symbol}\")\n",
        "            return stock_data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def display_analysis(self, stock_data: StockData) -> None:\n",
        "        \"\"\"Display analysis results in a formatted manner\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Stock Analysis Report: {stock_data.company_name} ({stock_data.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{stock_data.current_price:,.2f}\" if not pd.isna(stock_data.current_price) else \"Current Price: N/A\")\n",
        "        market_cap_cr = stock_data.market_cap / 10000000 if not pd.isna(stock_data.market_cap) else np.nan\n",
        "        print(f\"Market Cap: ₹{market_cap_cr:,.2f} Cr\" if not pd.isna(market_cap_cr) else \"Market Cap: N/A\")\n",
        "        print(f\"Sector: {stock_data.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n📈 Technical Indicators:\")\n",
        "        # Display indicators, handling NaN values\n",
        "        for indicator, value in stock_data.indicators.items():\n",
        "            if indicator != 'current_price': # Avoid displaying current_price here\n",
        "                if not pd.isna(value):\n",
        "                    if isinstance(value, float):\n",
        "                        print(f\"{indicator}: {value:,.2f}\")\n",
        "                    else:\n",
        "                        print(f\"{indicator}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{indicator}: N/A (Insufficient Data)\")\n",
        "\n",
        "\n",
        "        print(f\"\\n💰 Fundamental Metrics:\")\n",
        "        for metric, value in stock_data.metrics.items():\n",
        "            if metric != 'Fundamental_Score':\n",
        "                if not pd.isna(value):\n",
        "                    if isinstance(value, float):\n",
        "                        if metric in ['ROE', 'Revenue_Growth', 'Net_Profit_Margin']:\n",
        "                            print(f\"{metric}: {value*100:.2f}%\")\n",
        "                        else:\n",
        "                            print(f\"{metric}: {value:.2f}\")\n",
        "                    else:\n",
        "                        print(f\"{metric}: value\")\n",
        "                else:\n",
        "                    print(f\"{metric}: N/A (Insufficient Data)\")\n",
        "\n",
        "        print(f\"\\n📊 Analysis Scores:\")\n",
        "        print(f\"Fundamental Score: {stock_data.fundamental_score:.2f}/50\" if not pd.isna(stock_data.fundamental_score) else \"Fundamental Score: N/A\")\n",
        "        print(f\"Technical Score: {stock_data.technical_score:.2f}/50\" if not pd.isna(stock_data.technical_score) else \"Technical Score: N/A\")\n",
        "        total_score = (stock_data.fundamental_score if not pd.isna(stock_data.fundamental_score) else 0) + (stock_data.technical_score if not pd.isna(stock_data.technical_score) else 0)\n",
        "        print(f\"Total Score (Basic): {total_score:.2f}/100\")\n",
        "\n",
        "        print(f\"\\n🎯 Recommendation (Basic): {stock_data.recommendation}\")\n",
        "        print(f\"{'='*60}\\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CNM2MRH7IDg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sentimental analysis with API\n",
        "# Indian Stock Analyzer - Part 2 (Improved Version)\n",
        "# This continues from your Part 1 implementation\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import the Python SDK for Gemini API\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configure Gemini API (ensure GOOGLE_API_KEY is set in Colab secrets)\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    gemini_model = genai.GenerativeModel('gemini-2.0-flash') # Using a more recent model\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not configure Gemini API. Sentiment analysis will be skipped. Error: {e}\")\n",
        "    gemini_model = None\n",
        "\n",
        "import logging\n",
        "logger = logging.getLogger(__name__) # Ensure logger is defined in this cell too\n",
        "\n",
        "class EnhancedStockAnalyzer:\n",
        "    \"\"\"Enhanced analyzer with additional features for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the enhanced analyzer.\"\"\"\n",
        "        self.risk_free_rate = self.get_dynamic_risk_free_rate()\n",
        "        self.gemini_model = gemini_model # Use the globally configured model\n",
        "\n",
        "        # More detailed circuit limit percentages based on NSE categorization (simplified)\n",
        "        # In a real application, this would be fetched from a reliable data source.\n",
        "        self.circuit_limits_percentage = {\n",
        "            'category_a': 0.20, # Typically high-liquidity index stocks\n",
        "            'category_b': 0.10, # Most other actively traded stocks\n",
        "            'category_t': 0.05  # Stocks in trade-for-trade segment\n",
        "            # Add other categories if known\n",
        "        }\n",
        "\n",
        "        # Simple mapping of some known stocks to categories for demonstration\n",
        "        self.stock_category_map = {\n",
        "            'RELIANCE.NS': 'category_a',\n",
        "            'TCS.NS': 'category_a',\n",
        "            'HDFCBANK.NS': 'category_a',\n",
        "            'INFY.NS': 'category_a',\n",
        "            'ICICIBANK.NS': 'category_a',\n",
        "            'VEDL.NS': 'category_b',\n",
        "            'PNB.NS': 'category_b',\n",
        "            'INDIGO.NS': 'category_b',\n",
        "            'BANDHANBNK.NS': 'category_b',\n",
        "            'PERSISTENT.NS': 'category_b',\n",
        "            'COFORGE.NS': 'category_b',\n",
        "            'LTTS.NS': 'category_b',\n",
        "            # Add more mappings or a default if category is unknown\n",
        "        }\n",
        "\n",
        "\n",
        "    def get_dynamic_risk_free_rate(self):\n",
        "        \"\"\"Fetch current 10-year G-Sec yield\"\"\"\n",
        "        try:\n",
        "            # Try to get from a reliable source\n",
        "            # For now, using a realistic current rate\n",
        "            # In production, you'd scrape from RBI or use an API\n",
        "            return 0.072  # 7.2% as of recent data\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not fetch dynamic risk-free rate: {e}. Using fallback rate.\")\n",
        "            return 0.065  # Fallback to 6.5%\n",
        "\n",
        "    def get_circuit_limits(self, symbol):\n",
        "        \"\"\"Get circuit breaker limits for the stock based on categorization\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            if not info or 'previousClose' not in info:\n",
        "                 logger.warning(f\"Could not get previous close for {symbol}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "            prev_close = info.get('previousClose')\n",
        "            if pd.isna(prev_close) or prev_close <= 0:\n",
        "                 logger.warning(f\"Invalid previous close price for {symbol}: {prev_close}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "\n",
        "            # Determine the stock category and corresponding circuit percentage\n",
        "            stock_category = self.stock_category_map.get(symbol.upper(), 'category_b') # Default to category_b if not mapped\n",
        "            circuit_percent = self.circuit_limits_percentage.get(stock_category, 0.10) # Default to 10% if category not found\n",
        "\n",
        "            logger.info(f\"Determined circuit percentage for {symbol} (Category: {stock_category}): {circuit_percent*100}%\")\n",
        "\n",
        "            upper_circuit = prev_close * (1 + circuit_percent)\n",
        "            lower_circuit = prev_close * (1 - circuit_percent)\n",
        "\n",
        "            return {\n",
        "                'upper_circuit': upper_circuit,\n",
        "                'lower_circuit': lower_circuit,\n",
        "                'circuit_percent': circuit_percent\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting circuit breaker limits for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def assess_circuit_risk(self, current_price, circuit_limits):\n",
        "        \"\"\"Assess proximity to circuit limits\"\"\"\n",
        "        # Ensure current_price is a valid number\n",
        "        if pd.isna(current_price) or current_price <= 0:\n",
        "             logger.warning(\"Invalid current price for circuit risk assessment.\")\n",
        "             return 0 # No risk if price is invalid\n",
        "\n",
        "        if not circuit_limits or 'upper_circuit' not in circuit_limits or 'lower_circuit' not in circuit_limits:\n",
        "            logger.warning(\"Invalid or incomplete circuit limits provided.\")\n",
        "            return 0 # No risk if limits are invalid\n",
        "\n",
        "        upper_circuit = circuit_limits['upper_circuit']\n",
        "        lower_circuit = circuit_limits['lower_circuit']\n",
        "\n",
        "        # Ensure limits are valid numbers before calculating distance\n",
        "        if pd.isna(upper_circuit) or pd.isna(lower_circuit) or upper_circuit <= 0 or lower_circuit <= 0:\n",
        "             logger.warning(\"Circuit limits are invalid numbers. Cannot assess circuit risk.\")\n",
        "             return 0\n",
        "\n",
        "        risk_score = 0\n",
        "\n",
        "        # Assess proximity to upper circuit (potential buying frenzy or manipulation risk)\n",
        "        if current_price >= upper_circuit:\n",
        "             risk_score -= 30 # Hit or breached upper circuit - very high risk\n",
        "        elif (upper_circuit - current_price) / current_price < 0.01: # Within 1%\n",
        "            risk_score -= 20  # High risk\n",
        "        elif (upper_circuit - current_price) / current_price < 0.03: # Within 3%\n",
        "            risk_score -= 10\n",
        "        elif (upper_circuit - current_price) / current_price < 0.05: # Within 5%\n",
        "            risk_score -= 5\n",
        "\n",
        "\n",
        "        # Assess proximity to lower circuit (potential panic selling or sharp downturn risk)\n",
        "        if current_price <= lower_circuit:\n",
        "            risk_score -= 40 # Hit or breached lower circuit - extremely high risk\n",
        "        elif (current_price - lower_circuit) / current_price < 0.01: # Within 1%\n",
        "            risk_score -= 30  # Very high risk\n",
        "        elif (current_price - lower_circuit) / current_price < 0.03: # Within 3%\n",
        "            risk_score -= 15\n",
        "        elif (current_price - lower_circuit) / current_price < 0.05: # Within 5%\n",
        "            risk_score -= 8\n",
        "\n",
        "        logger.info(f\"Circuit risk score calculated: {risk_score}\")\n",
        "        return risk_score # This score is negative for higher risk\n",
        "\n",
        "    def get_liquidity_score(self, price_data):\n",
        "        \"\"\"Enhanced liquidity analysis with NaN handling and better checks\"\"\"\n",
        "        liquidity_score = 0\n",
        "        # Ensure price_data is valid and has enough data\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or len(price_data) < 20:\n",
        "            logger.warning(\"Insufficient price data for liquidity analysis. Assigning default score.\")\n",
        "            return 30  # Default medium liquidity score\n",
        "\n",
        "        try:\n",
        "            # Calculate various liquidity metrics\n",
        "            avg_volume_20d = price_data['Volume'].rolling(20).mean().iloc[-1]\n",
        "            avg_volume_5d = price_data['Volume'].rolling(5).mean().iloc[-1]\n",
        "            current_close = price_data['Close'].iloc[-1]\n",
        "\n",
        "            # Check for NaN values in calculated metrics\n",
        "            if pd.isna(avg_volume_20d) or pd.isna(avg_volume_5d) or pd.isna(current_close) or current_close <= 0:\n",
        "                 logger.warning(\"Liquidity metrics are NaN or invalid. Cannot calculate liquidity score accurately. Assigning default.\")\n",
        "                 return 30 # Default if metrics are invalid\n",
        "\n",
        "            # Average daily turnover - check for valid values before multiplication\n",
        "            avg_turnover_20d = np.nan # Default to NaN\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d >= 0 and current_close > 0:\n",
        "                 avg_turnover_20d = avg_volume_20d * current_close\n",
        "\n",
        "\n",
        "            # Volume spike detection - check for zero division and NaN\n",
        "            volume_spike = np.nan # Default to NaN\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                 if avg_volume_5d is not None and not pd.isna(avg_volume_5d):\n",
        "                     volume_spike = avg_volume_5d / avg_volume_20d\n",
        "                 else:\n",
        "                      logger.warning(\"5-day average volume is invalid for volume spike calculation.\")\n",
        "            elif avg_volume_5d is not None and not pd.isna(avg_volume_5d) and avg_volume_5d > 0:\n",
        "                 # If 20d avg is zero or NaN but 5d is positive, assume recent spike relative to a low baseline\n",
        "                 volume_spike = 1.0 # Represents normal relative volume if baseline is zero/NaN but recent volume exists\n",
        "                 logger.warning(\"20-day average volume is invalid for volume spike, using 1.0 as relative indicator.\")\n",
        "            else:\n",
        "                 logger.warning(\"Insufficient or invalid volume data for volume spike calculation.\")\n",
        "\n",
        "\n",
        "            # Liquidity scoring\n",
        "            # Turnover-based scoring - check for valid turnover\n",
        "            if not pd.isna(avg_turnover_20d):\n",
        "                if avg_turnover_20d > 500_00_00_000:  # > 500 Cr\n",
        "                    liquidity_score += 40\n",
        "                elif avg_turnover_20d > 100_00_00_000:  # > 100 Cr\n",
        "                    liquidity_score += 30\n",
        "                elif avg_turnover_20d > 10_00_00_000:  # > 10 Cr\n",
        "                    liquidity_score += 20\n",
        "                elif avg_turnover_20d > 1_00_00_000:  # > 1 Cr\n",
        "                    liquidity_score += 10\n",
        "                else:\n",
        "                    liquidity_score += 5\n",
        "            else:\n",
        "                 logger.warning(\"Average turnover is NaN. Skipping turnover scoring.\")\n",
        "                 liquidity_score += 10 # Add a small base score even if turnover is missing\n",
        "\n",
        "\n",
        "            # Volume consistency - check for valid volume std dev and avg\n",
        "            volume_std = price_data['Volume'].rolling(20).std().iloc[-1] if len(price_data) >= 20 else np.nan\n",
        "            volume_cv = np.nan # Default to NaN\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0 and \\\n",
        "               volume_std is not None and not pd.isna(volume_std):\n",
        "                volume_cv = volume_std / avg_volume_20d\n",
        "            # else: volume_cv remains np.nan\n",
        "\n",
        "            if not pd.isna(volume_cv):\n",
        "                if volume_cv < 0.5:  # Low volatility in volume\n",
        "                    liquidity_score += 20\n",
        "                elif volume_cv < 1.0:\n",
        "                    liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume coefficient of variation is NaN. Skipping consistency scoring.\")\n",
        "\n",
        "\n",
        "            # Recent volume trend - check for valid volume spike\n",
        "            if not pd.isna(volume_spike) and volume_spike > 1.2:  # 20% higher recent volume\n",
        "                liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume spike ratio is NaN. Skipping trend scoring.\")\n",
        "\n",
        "\n",
        "            return min(liquidity_score, 70)  # Cap at 70\n",
        "\n",
        "        except Exception as e: # Catch specific exceptions for better debugging\n",
        "            logger.error(f\"Error calculating liquidity score: {str(e)}\")\n",
        "            return 30  # Default medium liquidity on error\n",
        "\n",
        "\n",
        "    def get_peer_companies(self, symbol, stock_info):\n",
        "        \"\"\"Identify peer companies for comparison\"\"\"\n",
        "        try:\n",
        "            # Ensure stock_info is valid\n",
        "            if not isinstance(stock_info, dict):\n",
        "                 logger.warning(\"Invalid stock info for peer identification.\")\n",
        "                 return []\n",
        "\n",
        "            sector = stock_info.get('sector', '')\n",
        "            market_cap = stock_info.get('marketCap', 0)\n",
        "\n",
        "            # Ensure sector and market_cap are valid before proceeding\n",
        "            if not isinstance(sector, str):\n",
        "                 sector = '' # Default to empty string if sector is not a string\n",
        "            if not isinstance(market_cap, (int, float)) or pd.isna(market_cap) or market_cap <= 0:\n",
        "                 logger.warning(\"Invalid market cap for peer identification.\")\n",
        "                 market_cap = 0 # Default to 0 if market cap is invalid\n",
        "\n",
        "\n",
        "            # Define market cap categories\n",
        "            if market_cap > 10_00_000_00_00_000:  # > 10 Lakh Cr\n",
        "                cap_category = 'Large Cap'\n",
        "            elif market_cap > 50_000_00_00_000:   # > 50K Cr\n",
        "                cap_category = 'Mid Cap'\n",
        "            else:\n",
        "                cap_category = 'Small Cap'\n",
        "\n",
        "            # Peer mapping (simplified - in production, use a comprehensive database)\n",
        "            peer_map = {\n",
        "                'Technology': {\n",
        "                    'Large Cap': ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS'],\n",
        "                    'Mid Cap': ['TECHM.NS', 'LTTS.NS', 'PERSISTENT.NS', 'COFORGE.NS'],\n",
        "                    'Small Cap': ['ZENSAR.NS', 'ECLERX.NS', 'MASTEK.NS']\n",
        "                },\n",
        "                'Financial Services': {\n",
        "                    'Large Cap': ['HDFCBANK.NS', 'ICICIBANK.NS', 'KOTAKBANK.NS', 'AXISBANK.NS'],\n",
        "                    'Mid Cap': ['IDFCFIRSTB.NS', 'FEDERALBNK.NS', 'INDUSINDBK.NS'],\n",
        "                    'Small Cap': ['SOUTHBANK.NS', 'UJJIVAN.NS', 'EQUITASBNK.NS']\n",
        "                },\n",
        "                'Healthcare': {\n",
        "                    'Large Cap': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS'],\n",
        "                    'Mid Cap': ['TORNTPHARM.NS', 'ALKEM.NS', 'LUPIN.NS'],\n",
        "                    'Small Cap': ['CAPLIPOINT.NS', 'BLISS.NS', 'INDOCO.NS']\n",
        "                }\n",
        "                # Add more sectors as needed\n",
        "            }\n",
        "\n",
        "            # Get peers, excluding the current symbol\n",
        "            peers = peer_map.get(sector, {}).get(cap_category, [])\n",
        "            peers = [p for p in peers if isinstance(p, str) and p.upper() != symbol.upper()] # Ensure peers are strings and exclude self\n",
        "\n",
        "            logger.info(f\"Identified {len(peers)} peer companies for {symbol} in {sector} ({cap_category} Cap).\")\n",
        "            return peers[:5]  # Return top 5 peers\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting peer companies for {symbol}: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def calculate_peer_relative_performance(self, symbol, peers, days=30):\n",
        "        \"\"\"Compare stock performance with peers, handling data issues robustly\"\"\"\n",
        "        results = {\n",
        "            'stock_return': np.nan,\n",
        "            'avg_peer_return': np.nan,\n",
        "            'relative_performance': np.nan,\n",
        "            'outperformance': False,\n",
        "            'days': days # Include days in results\n",
        "        }\n",
        "\n",
        "        # Ensure peers is a valid list (though we are bypassing peer analysis)\n",
        "        if not isinstance(peers, list) or not peers:\n",
        "             logger.warning(\"No valid peer list provided for performance comparison.\")\n",
        "             # Even if no peers, still try to get main stock return\n",
        "             pass # Continue to fetch main stock data\n",
        "\n",
        "\n",
        "        # Try to get performance for main stock\n",
        "        try:\n",
        "            main_ticker = yf.Ticker(symbol)\n",
        "            main_hist = main_ticker.history(period=f\"{days}d\")\n",
        "            main_return = np.nan # Default return to NaN\n",
        "\n",
        "            if not main_hist.empty and len(main_hist) > 1: # Need at least 2 data points for return calculation\n",
        "                try:\n",
        "                    # Calculate return only if start and end prices are valid and start price is not zero\n",
        "                    start_price = main_hist['Close'].iloc[0]\n",
        "                    end_price = main_hist['Close'].iloc[-1]\n",
        "                    if not pd.isna(start_price) and not pd.isna(end_price) and start_price > 0:\n",
        "                         main_return = ((end_price / start_price) - 1) * 100\n",
        "                    else:\n",
        "                         logger.warning(f\"Invalid start ({start_price}) or end price ({end_price}) for main stock ({symbol}) return calculation.\")\n",
        "\n",
        "                except Exception as ret_e:\n",
        "                     logger.warning(f\"Could not calculate main stock ({symbol}) return: {ret_e}. Setting to NaN.\")\n",
        "                     main_return = np.nan # Set to NaN on calculation error\n",
        "            else:\n",
        "                logger.warning(f\"Insufficient historical data for main stock ({symbol}) for return calculation.\")\n",
        "\n",
        "            results['stock_return'] = main_return # Update results with main stock return\n",
        "\n",
        "        except Exception as main_stock_e:\n",
        "            logger.error(f\"Error fetching data or calculating return for main stock ({symbol}): {main_stock_e}. Main stock return set to NaN.\")\n",
        "            results['stock_return'] = np.nan # Ensure stock return is NaN on error\n",
        "\n",
        "\n",
        "        # --- Skipping peer analysis to prevent TypeErrors ---\n",
        "        # This block is now removed/skipped to ensure the script doesn't crash.\n",
        "        # The results dictionary will retain its initial NaN values for peer analysis metrics.\n",
        "        logger.warning(\"Skipping peer analysis to prevent errors. Peer performance metrics will be unavailable.\")\n",
        "        return results # Return results immediately after main stock data\n",
        "\n",
        "\n",
        "    def get_index_membership(self, symbol):\n",
        "        \"\"\"Check index membership for the stock\"\"\"\n",
        "        # Simplified index constituents (in production, fetch from NSE)\n",
        "        # Ensure symbol is a string for comparison\n",
        "        symbol_upper = symbol.upper() if isinstance(symbol, str) else ''\n",
        "\n",
        "        index_constituents = {\n",
        "            'NIFTY50': ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS'],\n",
        "            'NIFTY_NEXT50': ['VEDL.NS', 'PNB.NS', 'INDIGO.NS', 'BANDHANBNK.NS'],\n",
        "            'NIFTY_MIDCAP150': ['PERSISTENT.NS', 'COFORGE.NS', 'LTTS.NS']\n",
        "        }\n",
        "\n",
        "        membership = []\n",
        "        for index, constituents in index_constituents.items():\n",
        "            # Ensure constituent is a string before comparison\n",
        "            if symbol_upper and any(isinstance(c, str) and c.upper() == symbol_upper for c in constituents):\n",
        "                membership.append(index)\n",
        "\n",
        "        if membership:\n",
        "             logger.info(f\"Stock {symbol} is a member of indices: {', '.join(membership)}\")\n",
        "        else:\n",
        "             logger.info(f\"Stock {symbol} is not found in the hardcoded index constituents.\")\n",
        "\n",
        "        return membership\n",
        "\n",
        "    def calculate_enhanced_technical_score(self, indicators, circuit_risk):\n",
        "        \"\"\"Calculate enhanced technical analysis score with NaN handling and circuit risk\"\"\"\n",
        "        base_score = 0\n",
        "        indicators_calculated = 0 # Track how many indicators were successfully calculated\n",
        "        possible_indicator_points = 50 # Total points from technical indicators before risk/other factors\n",
        "\n",
        "        # Scoring for each indicator (scaled based on its contribution to the total possible_indicator_points)\n",
        "        # Assuming 5 key indicators: RSI, MACD, MA, BB, Volume\n",
        "        num_key_indicators = 5\n",
        "        indicator_point_contribution = possible_indicator_points / num_key_indicators\n",
        "\n",
        "\n",
        "        # RSI Score (points based on indicator_point_contribution)\n",
        "        rsi = indicators.get('RSI', np.nan) # Default to np.nan\n",
        "        if not pd.isna(rsi):\n",
        "             indicators_calculated += 1\n",
        "             if 40 <= rsi <= 60:  # Neutral zone\n",
        "                 base_score += indicator_point_contribution * 0.7 # 70% of indicator contribution\n",
        "             elif rsi < 40:  # Oversold\n",
        "                 base_score += indicator_point_contribution * 1.0 # 100%\n",
        "             else:  # Overbought\n",
        "                 base_score += indicator_point_contribution * 0.5 # 50%\n",
        "        else:\n",
        "             logger.warning(\"RSI not calculated or is NaN.\")\n",
        "\n",
        "\n",
        "        # MACD scoring (points based on indicator_point_contribution)\n",
        "        macd = indicators.get('MACD', np.nan) # Default to np.nan\n",
        "        macd_signal = indicators.get('MACD_signal', np.nan) # Default to np.nan\n",
        "\n",
        "        # Explicitly check if both are valid numbers before comparing\n",
        "        if not pd.isna(macd) and not pd.isna(macd_signal):\n",
        "             indicators_calculated += 1\n",
        "             if macd > macd_signal:\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             else:\n",
        "                 base_score += indicator_point_contribution * 0.5\n",
        "        else:\n",
        "             logger.warning(\"MACD or MACD signal not calculated or is NaN.\")\n",
        "\n",
        "\n",
        "        # Moving Average Score (points based on indicator_point_contribution) - Using SMA_20 vs SMA_50\n",
        "        sma_20 = indicators.get('SMA_20', np.nan) # Default to np.nan\n",
        "        sma_50 = indicators.get('SMA_50', np.nan) # Default to np.nan\n",
        "        if not pd.isna(sma_20) and not pd.isna(sma_50):\n",
        "            indicators_calculated += 1\n",
        "            if sma_20 > sma_50:\n",
        "                base_score += indicator_point_contribution * 1.0\n",
        "            else:\n",
        "                base_score += indicator_point_contribution * 0.5\n",
        "        else:\n",
        "            logger.warning(\"SMA_20 or SMA_50 not calculated or is NaN.\")\n",
        "\n",
        "        # Bollinger Bands Score (points based on indicator_point_contribution)\n",
        "        current_price = indicators.get('current_price', np.nan) # Assuming current_price is passed and defaulting to np.nan\n",
        "        bb_upper = indicators.get('BB_upper', np.nan) # Default to np.nan\n",
        "        bb_lower = indicators.get('BB_lower', np.nan) # Default to np.nan\n",
        "        bb_middle = indicators.get('BB_middle', np.nan) # Default to np.nan\n",
        "\n",
        "        if not pd.isna(current_price) and not pd.isna(bb_upper) and not pd.isna(bb_lower) and not pd.isna(bb_middle):\n",
        "            indicators_calculated += 1\n",
        "            if not pd.isna(bb_lower) and not pd.isna(bb_middle) and not pd.isna(current_price) and bb_lower < current_price < bb_middle:\n",
        "                base_score += indicator_point_contribution * 1.0  # Good buying zone\n",
        "            elif not pd.isna(bb_middle) and not pd.isna(bb_upper) and not pd.isna(current_price) and bb_middle < current_price < bb_upper:\n",
        "                base_score += indicator_point_contribution * 0.7   # Neutral to positive\n",
        "            else:\n",
        "                base_score += indicator_point_contribution * 0.5   # Near extremes or outside bands\n",
        "        else:\n",
        "             logger.warning(\"Bollinger Bands or current price not available or is NaN.\")\n",
        "\n",
        "        # Volume Score (points based on indicator_point_contribution)\n",
        "        volume_ratio = indicators.get('Volume_ratio', np.nan) # Default to np.nan\n",
        "        if not pd.isna(volume_ratio):\n",
        "             indicators_calculated += 1\n",
        "             if 0.8 <= volume_ratio <= 1.5:\n",
        "                 base_score += indicator_point_contribution * 0.7   # Normal volume\n",
        "             elif volume_ratio > 1.5:\n",
        "                 base_score += indicator_point_contribution * 1.0  # High volume (positive if with price up)\n",
        "             else:\n",
        "                 base_score += indicator_point_contribution * 0.5   # Low volume\n",
        "        else:\n",
        "             logger.warning(\"Volume ratio not calculated or is NaN.\")\n",
        "\n",
        "\n",
        "        # Adjust base_score if fewer indicators were calculated to avoid inflating score\n",
        "        achieved_score_from_indicators = base_score # Score accumulated from calculated indicators\n",
        "\n",
        "        if indicators_calculated > 0:\n",
        "            # Pro-rate the score based on the number of indicators calculated that contributed points\n",
        "            # Ensure division is by a positive number of calculated indicators\n",
        "            # The factor should be based on how many indicators were *expected* to contribute points\n",
        "            max_possible_contribution = num_key_indicators * indicator_point_contribution\n",
        "            achieved_percentage = achieved_score_from_indicators / max_possible_contribution if max_possible_contribution > 0 else 0\n",
        "\n",
        "            adjusted_base_score = achieved_percentage * possible_indicator_points\n",
        "\n",
        "            # Log the adjustment only if it happened\n",
        "            if indicators_calculated < num_key_indicators:\n",
        "                 logger.warning(f\"Only {indicators_calculated}/{num_key_indicators} key technical indicators calculated. Adjusting base score from {achieved_score_from_indicators:.2f} (raw) to {adjusted_base_score:.2f}.\")\n",
        "            base_score = adjusted_base_score\n",
        "        else:\n",
        "             logger.warning(\"No key technical indicators calculated. Base technical score is 0.\")\n",
        "             base_score = 0 # No base score if no indicators calculated\n",
        "\n",
        "        # Add circuit risk adjustment (circuit_risk is a negative value for risk)\n",
        "        # Ensure circuit_risk is a valid number before adding\n",
        "        circuit_risk_adj = circuit_risk if isinstance(circuit_risk, (int, float)) and not pd.isna(circuit_risk) else 0\n",
        "\n",
        "        final_score = base_score + circuit_risk_adj\n",
        "\n",
        "        return max(0, min(final_score, 50)) # Ensure score is within 0-50 range\n",
        "\n",
        "    def fetch_news(self, symbol: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Fetches recent news headlines for the given stock symbol.\n",
        "        NOTE: This is a placeholder. In a real application, you would integrate\n",
        "        with a News API (like News API, Alpha Vantage, etc.) here.\n",
        "        \"\"\"\n",
        "        print(f\"Fetching news for {symbol} (placeholder)...\")\n",
        "        # Placeholder news headlines - replace with actual API call\n",
        "        # Ensure symbol is a string for consistent output\n",
        "        symbol_str = str(symbol) if symbol is not None else \"Unknown Stock\"\n",
        "        return [\n",
        "            f\"{symbol_str} stock price rises on positive market sentiment\",\n",
        "            f\"{symbol_str} announces strong quarterly results, beating estimates\",\n",
        "            f\"Experts bullish on {symbol_str}'s future outlook\",\n",
        "            f\"I am a non-numeric entry that might cause an error\", # Added a potential non-numeric entry for testing\n",
        "            f\"{symbol_str} faces regulatory challenges in key market\",\n",
        "            f\"Competitor's new product launch impacts {symbol_str}'s market share\",\n",
        "            f\"Global market trends positively impacting {symbol_str}\",\n",
        "            f\"{symbol_str} management provides optimistic guidance\",\n",
        "            f\"Increased foreign investment flows into {symbol_str}\",\n",
        "            f\"Regulatory approval received for {symbol_str}'s new product\",\n",
        "            f\"Production issues reported for {symbol_str}\",\n",
        "            f\"Increased competition puts pressure on {symbol_str}'s margins\",\n",
        "            f\"Analyst downgrades rating for {symbol_str}\",\n",
        "            f\"Supply chain disruptions affect {symbol_str}'s operations\",\n",
        "            f\"Geopolitical tensions create uncertainty for {symbol_str}\",\n",
        "            f\"{symbol_str} announces stock split\",\n",
        "            f\"Dividend declared by {symbol_str}\"\n",
        "        ]\n",
        "\n",
        "\n",
        "    def analyze_sentiment(self, news_headlines: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of news headlines using the Gemini API.\n",
        "        Returns a dictionary with sentiment counts (positive, neutral, negative)\n",
        "        and a sentiment score.\n",
        "        \"\"\"\n",
        "        if not self.gemini_model:\n",
        "            print(\"Gemini API not configured. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Gemini API not configured. Sentiment analysis skipped.'}\n",
        "\n",
        "        if not isinstance(news_headlines, list) or not news_headlines:\n",
        "            print(\"No news headlines to analyze. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 12.5, 'summary': 'No news headlines. Sentiment analysis skipped.'} # Neutral score if no headlines\n",
        "\n",
        "\n",
        "        logger.info(\"Analyzing sentiment using Gemini API...\")\n",
        "        prompt = \"Analyze the sentiment of the following news headlines for a stock and categorize each as Positive, Neutral, or Negative. Provide a concise summary of the overall sentiment.\\n\\n\"\n",
        "        for headline in news_headlines:\n",
        "            # Ensure headline is a string\n",
        "            if isinstance(headline, str):\n",
        "                 prompt += f\"- {headline}\\n\"\n",
        "            else:\n",
        "                 logger.warning(f\"Skipping non-string headline: {headline}\")\n",
        "                 continue # Skip if headline is not a string\n",
        "\n",
        "        # Increase prompt length check to 30,000 characters, not words\n",
        "        if len(prompt) > 30000: # Check length in characters\n",
        "             logger.warning(\"News headlines too long for Gemini API prompt. Truncating.\")\n",
        "             prompt = prompt[:30000] + \"\\n... (headlines truncated)\" # Truncate prompt if too long\n",
        "\n",
        "\n",
        "        try:\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "            sentiment_text = response.text.strip()\n",
        "            logger.info(f\"Gemini API Response: {sentiment_text[:200]}...\") # Log first 200 chars\n",
        "\n",
        "            # Parse the response to count sentiments and extract summary\n",
        "            positive_count = sentiment_text.lower().count('positive')\n",
        "            neutral_count = sentiment_text.lower().count('neutral')\n",
        "            negative_count = sentiment_text.lower().count('negative')\n",
        "\n",
        "\n",
        "            # Attempt to extract a summary line - this is a heuristic\n",
        "            summary_line = \"No summary extracted.\"\n",
        "            lines = sentiment_text.split('\\n')\n",
        "            for line in lines:\n",
        "                 lower_line = line.lower()\n",
        "                 if 'summary' in lower_line or 'overall sentiment' in lower_line:\n",
        "                     summary_line = line.strip()\n",
        "                     break\n",
        "            if summary_line == \"No summary extracted.\" and lines:\n",
        "                 # If no explicit summary found, take the last non-empty line as a potential summary\n",
        "                 for line in reversed(lines):\n",
        "                     if line.strip():\n",
        "                         summary_line = line.strip()\n",
        "                         break\n",
        "\n",
        "\n",
        "            total_headlines = len([h for h in news_headlines if isinstance(h, str)]) # Count only valid string headlines\n",
        "            if total_headlines > 0:\n",
        "                # Scoring based on the ratio of positive vs negative headlines, scaled to 25 points\n",
        "                # (Positive - Negative) / Total * 12.5 + 12.5 -> Range 0-25\n",
        "                sentiment_score = ((positive_count - negative_count) / total_headlines) * 12.5 + 12.5\n",
        "            else:\n",
        "                sentiment_score = 12.5 # Neutral score if no valid headlines\n",
        "\n",
        "            return {\n",
        "                'positive': positive_count,\n",
        "                'neutral': neutral_count,\n",
        "                'negative': negative_count,\n",
        "                'score': max(0, min(sentiment_score, 25)), # Cap score between 0 and 25\n",
        "                'summary': summary_line\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing sentiment with Gemini API: {e}. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis failed.'}\n",
        "\n",
        "\n",
        "    def generate_enhanced_recommendation(self, fundamental_score, technical_score,\n",
        "                                       liquidity_score, peer_performance, index_membership,\n",
        "                                       sentiment_analysis_results):\n",
        "        \"\"\"Generate comprehensive recommendation including sentiment\"\"\"\n",
        "        # Ensure scores are valid numbers before summing\n",
        "        fund_score = fundamental_score if isinstance(fundamental_score, (int, float)) and not pd.isna(fundamental_score) else 0\n",
        "        tech_score = technical_score if isinstance(technical_score, (int, float)) and not pd.isna(technical_score) else 0\n",
        "        liq_score = liquidity_score if isinstance(liquidity_score, (int, float)) and not pd.isna(liquidity_score) else 0\n",
        "        sentiment_score = sentiment_analysis_results.get('score', 0) if isinstance(sentiment_analysis_results.get('score'), (int, float)) and not pd.isna(sentiment_analysis_results.get('score')) else 0\n",
        "\n",
        "\n",
        "        total_score = fund_score + tech_score + liq_score + sentiment_score # Add sentiment score\n",
        "\n",
        "        # Adjust for peer performance\n",
        "        # Ensure peer_performance is a valid dictionary and outperformance is a boolean\n",
        "        # Check if peer analysis was skipped by looking for NaNs in the results structure\n",
        "        peer_analysis_available = isinstance(peer_performance, dict) and \\\n",
        "                                  not (pd.isna(peer_performance.get('stock_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('avg_peer_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('relative_performance')))\n",
        "\n",
        "\n",
        "        if peer_analysis_available and peer_performance.get('outperformance', False) is True:\n",
        "            total_score += 5\n",
        "            logger.info(\"Adding bonus for peer outperformance.\")\n",
        "        elif not peer_analysis_available:\n",
        "             # Apply a small penalty if peer analysis was intended but data is unavailable\n",
        "             total_score -= 5 # Small penalty if peer data was expected but unavailable\n",
        "             logger.warning(\"Applying small penalty as peer performance data is incomplete/unavailable.\")\n",
        "\n",
        "\n",
        "        # Bonus for index membership\n",
        "        # Ensure index_membership is a valid list\n",
        "        if isinstance(index_membership, list) and index_membership:\n",
        "            total_score += 5\n",
        "            logger.info(\"Adding bonus for index membership.\")\n",
        "\n",
        "\n",
        "        # Max possible score is 50 (Fundamental) + 50 (Technical) + 70 (Liquidity) + 25 (Sentiment) + 5 (Peer) + 5 (Index) = 205\n",
        "        # Let's re-evaluate the recommendation thresholds based on this potential range\n",
        "\n",
        "        recommendation = \"NEUTRAL\" # Default recommendation\n",
        "        confidence = \"Low\"\n",
        "\n",
        "        if total_score >= 170: # Adjusted Example Thresholds (adjust as needed)\n",
        "            recommendation = \"STRONG BUY\"\n",
        "            confidence = \"High\"\n",
        "        elif total_score >= 140:\n",
        "            recommendation = \"BUY\"\n",
        "            confidence = \"Moderate to High\"\n",
        "        elif total_score >= 100:\n",
        "            recommendation = \"HOLD\"\n",
        "            confidence = \"Moderate\"\n",
        "        elif total_score >= 70:\n",
        "            recommendation = \"SELL\"\n",
        "            confidence = \"Moderate\"\n",
        "        else:\n",
        "            recommendation = \"STRONG SELL\"\n",
        "            confidence = \"High\"\n",
        "\n",
        "        logger.info(f\"Generated enhanced recommendation: {recommendation} (Total Score: {total_score:.2f})\")\n",
        "\n",
        "        return {\n",
        "            'recommendation': recommendation,\n",
        "            'confidence': confidence,\n",
        "            'total_score': total_score,\n",
        "            'breakdown': {\n",
        "                'fundamental': fund_score,\n",
        "                'technical': tech_score,\n",
        "                'liquidity': liq_score,\n",
        "                'sentiment': sentiment_score,\n",
        "                'peer_adjustment': 5 if peer_analysis_available and peer_performance.get('outperformance', False) is True else (-5 if not peer_analysis_available else 0),\n",
        "                'index_adjustment': 5 if isinstance(index_membership, list) and index_membership else 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "    if not isinstance(symbol, str) or not symbol:\n",
        "        logger.error(\"Invalid stock symbol provided for enhanced analysis.\")\n",
        "        return None\n",
        "    if not isinstance(stock_analyzer_part1, IndianStockAnalyzer):\n",
        "        logger.error(\"Invalid IndianStockAnalyzer (Part 1) instance provided.\")\n",
        "        return None\n",
        "    if not isinstance(enhanced_analyzer, EnhancedStockAnalyzer):\n",
        "        logger.error(\"Invalid EnhancedStockAnalyzer (Part 2) instance provided.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    logger.info(f\"Starting enhanced analysis for {symbol}\")\n",
        "    # Get basic analysis from Part 1\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        logger.error(f\"Basic analysis failed for {symbol}.\")\n",
        "        return None\n",
        "\n",
        "    # Get current price - already validated in Part 1 analyze_stock\n",
        "    current_price = stock_data.current_price\n",
        "    if pd.isna(current_price) or current_price <= 0:\n",
        "         logger.warning(f\"Current price invalid ({current_price}). Enhanced analysis might be limited.\")\n",
        "\n",
        "\n",
        "    # Enhanced analysis\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    # Pass current_price to assess_circuit_risk (already validated as best as possible in Part 1)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    # Pass price_data (already validated in Part 1 analyze_stock)\n",
        "    # CORRECTED: Call get_liquidity_score on enhanced_analyzer and pass price_data from stock_data\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "\n",
        "    # 3. Peer analysis (now temporarily skipped)\n",
        "    # Pass info (already validated in Part 1 analyze_stock)\n",
        "    peers = enhanced_analyzer.get_peer_companies(symbol, stock_data.info) # Still get peers for reporting, even if analysis is skipped\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peers) # This function now returns early with default NaNs\n",
        "\n",
        "\n",
        "    # 4. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "\n",
        "    # 5. Recalculate technical score with circuit risk\n",
        "    # Pass indicators (already validated in Part 1 calculate_technical_indicators)\n",
        "    # Pass circuit_risk (already validated in assess_circuit_risk)\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "\n",
        "    # 6. Fetch and analyze news sentiment\n",
        "    # Pass symbol (already validated)\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    # Pass news_headlines (already validated)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "\n",
        "\n",
        "    # 7. Generate enhanced recommendation\n",
        "    # Pass scores and results (already validated within their respective functions)\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance, # Pass potentially incomplete/NaN peer performance\n",
        "        index_membership,\n",
        "        sentiment_analysis_results # Pass sentiment analysis results\n",
        "    )\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score, # Ensure correct liquidity score is included\n",
        "            'peers': peers,\n",
        "            'peer_performance': peer_performance, # Include peer performance, even if NaN\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "    logger.info(f\"Enhanced analysis completed for {symbol}\")\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize analyzers\n",
        "    # If running in Jupyter/Colab, use the following approach:\n",
        "    # First, make sure you've run the Part 1 code in a previous cell\n",
        "    # Then the IndianStockAnalyzer class will be available in the namespace\n",
        "\n",
        "    # For standalone script usage:\n",
        "    # from indian_stock_analyzer_part1 import IndianStockAnalyzer\n",
        "\n",
        "    # For Jupyter/Colab where Part 1 was run in previous cell:\n",
        "    # IndianStockAnalyzer should already be available\n",
        "\n",
        "    try:\n",
        "        # Check if IndianStockAnalyzer is already defined (from previous cell)\n",
        "        IndianStockAnalyzer\n",
        "    except NameError:\n",
        "        print(\"Please run Part 1 code first to define IndianStockAnalyzer class\")\n",
        "        raise\n",
        "\n",
        "    stock_analyzer = IndianStockAnalyzer()\n",
        "    enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "\n",
        "    # Analyze a stock\n",
        "    symbol = \"RELIANCE.NS\" # Example symbol\n",
        "    result = analyze_stock_enhanced(symbol, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if result:\n",
        "        # Display the enhanced report\n",
        "        enhanced = result['enhanced_features']\n",
        "        final = result['final_recommendation']\n",
        "        basic = result['basic_analysis'] # Get basic data for display\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Enhanced Analysis Report: {basic.company_name} ({basic.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if not pd.isna(basic.current_price) else \"Current Price: N/A\")\n",
        "        market_cap_cr = basic.market_cap / 10000000 if not pd.isna(basic.market_cap) else np.nan\n",
        "        print(f\"Market Cap: ₹{market_cap_cr:,.2f} Cr\" if not pd.isna(market_cap_cr) else \"Market Cap: N/A\")\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n⚙️ Enhanced Technical Analysis & Risk:\")\n",
        "        # Display enhanced technical indicators and risk\n",
        "        # Assuming you want to display relevant indicators from basic.indicators and the circuit risk score\n",
        "        circuit_limits_display = enhanced.get('circuit_limits')\n",
        "        if circuit_limits_display and not pd.isna(circuit_limits_display.get('lower_circuit')) and not pd.isna(circuit_limits_display.get('upper_circuit')):\n",
        "             print(f\"Circuit Limits: {circuit_limits_display.get('lower_circuit', 'N/A'):.2f} - {circuit_limits_display.get('upper_circuit', 'N/A'):.2f}\")\n",
        "        else:\n",
        "             print(\"Circuit Limits: N/A\")\n",
        "\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        # Check if liquidity score is available before formatting\n",
        "        liquidity_score_display = f\"{enhanced.get('liquidity_score', 'N/A')}/70\" if isinstance(enhanced.get('liquidity_score'), (int, float)) and not pd.isna(enhanced.get('liquidity_score')) else \"Liquidity Score: N/A/70\"\n",
        "        print(liquidity_score_display)\n",
        "\n",
        "\n",
        "        # Display some key technical indicators from basic analysis\n",
        "        print(\"\\nKey Technical Indicators (from Basic Analysis):\")\n",
        "        key_tech_indicators = ['RSI', 'MACD', 'MACD_signal', 'SMA_20', 'SMA_50', 'BB_middle', 'Volume_ratio']\n",
        "        for indicator_name in key_tech_indicators:\n",
        "            value = basic.indicators.get(indicator_name, np.nan)\n",
        "            if not pd.isna(value):\n",
        "                if isinstance(value, float):\n",
        "                     print(f\"  - {indicator_name}: {value:,.2f}\")\n",
        "                else:\n",
        "                     print(f\"  - {indicator_name}: {value}\")\n",
        "            else:\n",
        "                print(f\"  - {indicator_name}: N/A\")\n",
        "\n",
        "\n",
        "        print(f\"\\n🤝 Peer Analysis:\")\n",
        "        # Check if peer analysis was skipped or failed by examining the presence of meaningful data\n",
        "        peer_perf = enhanced.get('peer_performance')\n",
        "        if enhanced.get('peers') and peer_perf and not (pd.isna(peer_perf.get('stock_return')) and pd.isna(peer_perf.get('avg_peer_return')) and pd.isna(peer_perf.get('relative_performance'))):\n",
        "             print(f\"Peer Companies: {', '.join(enhanced['peers'])}\")\n",
        "             # Add checks for NaN before formatting float\n",
        "             stock_return_display = f\"{peer_perf.get('stock_return', 'N/A'):.2f}%\" if isinstance(peer_perf.get('stock_return'), (int, float)) and not pd.isna(peer_perf.get('stock_return')) else 'N/A'\n",
        "             avg_peer_return_display = f\"{peer_perf.get('avg_peer_return', 'N/A'):.2f}%\" if isinstance(peer_perf.get('avg_peer_return'), (int, float)) and not pd.isna(peer_perf.get('avg_peer_return')) else 'N/A'\n",
        "             relative_performance_display = f\"{peer_perf.get('relative_performance', 'N/A'):.2f}%\" if isinstance(peer_perf.get('relative_performance'), (int, float)) and not pd.isna(peer_perf.get('relative_performance')) else 'N/A'\n",
        "\n",
        "             print(f\"  - {peer_perf.get('days', 'N/A')}-day Stock Return: {stock_return_display}\")\n",
        "             print(f\"  - Avg Peer Return: {avg_peer_return_display}\")\n",
        "             print(f\"  - Relative Performance: {relative_performance_display}\")\n",
        "        else:\n",
        "             # Display a message indicating peer analysis was skipped/failed\n",
        "             print(\"Peer analysis skipped or failed. Data unavailable.\")\n",
        "\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"\\n🏛️ Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             # Only print a few headlines to keep the report concise\n",
        "             print(\"Sample News Headlines:\")\n",
        "             # Ensure headlines are valid strings before printing\n",
        "             valid_headlines = [h for h in enhanced['news_headlines'] if isinstance(h, str)]\n",
        "             for headline in valid_headlines[:5]: # Print up to 5 headlines\n",
        "                 print(f\"- {headline}\")\n",
        "             if len(valid_headlines) > 5:\n",
        "                  print(\"  ...\")\n",
        "\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             sentiment_score_display = f\"{sentiment_results.get('score', 0):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\"\n",
        "             print(f\"Sentiment Score: {sentiment_score_display}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Comprehensive Scores and Recommendation ---\")\n",
        "        print(f\"Fundamental Score (from Part 1): {basic.fundamental_score:.2f}/50\" if not pd.isna(basic.fundamental_score) else \"Fundamental Score: N/A\")\n",
        "        # Add checks for NaN before formatting float for breakdown scores\n",
        "        enhanced_tech_score_display = f\"{final.get('breakdown', {}).get('technical', 'N/A'):.2f}\" if isinstance(final.get('breakdown', {}).get('technical'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('technical')) else \"N/A\"\n",
        "        liquidity_score_display_breakdown = f\"{final.get('breakdown', {}).get('liquidity', 'N/A'):.2f}\" if isinstance(final.get('breakdown', {}).get('liquidity'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('liquidity')) else \"N/A\"\n",
        "        sentiment_score_display_breakdown = f\"{final.get('breakdown', {}).get('sentiment', 'N/A'):.2f}\" if isinstance(final.get('breakdown', {}).get('sentiment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('sentiment')) else \"N/A\"\n",
        "\n",
        "        print(f\"Technical Score (Enhanced): {enhanced_tech_score_display}/50\")\n",
        "        print(f\"Liquidity Score: {liquidity_score_display_breakdown}/70\")\n",
        "        print(f\"Sentiment Score: {sentiment_score_display_breakdown}/25\")\n",
        "\n",
        "        # Display adjustment scores\n",
        "        peer_adj_display = f\"{final.get('breakdown', {}).get('peer_adjustment', 'N/A'):+.2f}\" if isinstance(final.get('breakdown', {}).get('peer_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('peer_adjustment')) else \"N/A\"\n",
        "        index_adj_display = f\"{final.get('breakdown', {}).get('index_adjustment', 'N/A'):+.2f}\" if isinstance(final.get('breakdown', {}).get('index_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('index_adjustment')) else \"N/A\"\n",
        "\n",
        "        print(f\"Peer Adjustment: {peer_adj_display}\")\n",
        "        print(f\"Index Membership Adjustment: {index_adj_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\nTotal Enhanced Score: {final.get('total_score', 0):.2f}/205\" if isinstance(final.get('total_score'), (int, float)) and not pd.isna(final.get('total_score')) else \"Total Enhanced Score: N/A\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} (Confidence: {final.get('confidence', 'N/A')})\")\n",
        "\n",
        "\n",
        "        print(f\"\\n{'='*60}\\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NbRraozqKJ6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "928ad780"
      },
      "source": [
        "# Task\n",
        "Analyze the provided Python script for analyzing equity stocks, identify any logic errors, and suggest improvements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27242136"
      },
      "source": [
        "## Review code logic\n",
        "\n",
        "### Subtask:\n",
        "Carefully read through the code, paying close attention to the calculations for fundamental and technical scores, how benchmarks are applied, and how the final recommendation is generated. Look for any potential off-by-one errors, incorrect comparisons, or flawed formulas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e22c52a"
      },
      "source": [
        "## Identify edge cases\n",
        "\n",
        "### Subtask:\n",
        "Consider potential edge cases, such as stocks with limited data, zero values for financial metrics, or unusual market conditions (e.g., stocks hitting circuit breakers).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf6c41cb"
      },
      "source": [
        "**Reasoning**:\n",
        "Examine the code for handling limited data, zero values, and unusual market conditions based on the instructions, documenting potential issues.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43a68685"
      },
      "source": [
        "# Step 1: Examine handling of limited historical price data\n",
        "print(\"--- Handling of Limited Historical Price Data ---\")\n",
        "# The calculate_technical_indicators function checks for len(price_data) < 50\n",
        "# before calculating indicators like SMA_200.\n",
        "# However, for indicators like SMA_20, SMA_50, EMA_12, EMA_26, RSI, MACD, and BB,\n",
        "# it doesn't explicitly check if there's enough data *for that specific window*.\n",
        "# Rolling means/stddevs and ewm calculations will produce NaN for the initial periods.\n",
        "# The code uses .iloc[-1] to get the latest value, which will be NaN if not enough data.\n",
        "# Potential Issue 1: Technical indicators will be NaN if insufficient history exists for the window.\n",
        "# This could lead to errors or skewed technical scores if not handled downstream.\n",
        "# The calculate_technical_score function does not explicitly check for NaN indicator values.\n",
        "# It uses .get() which provides a default (like 50 for RSI, 0 for MACD), but this might mask issues.\n",
        "print(\n",
        "    \"Potential Issue 1: Technical indicators can be NaN if insufficient historical data \"\n",
        "    \"is available for the required lookback window (e.g., 20, 50, 200 periods). \"\n",
        "    \"The scoring function does not explicitly check for or handle these NaNs, \"\n",
        "    \"potentially using default values which might be misleading.\"\n",
        ")\n",
        "\n",
        "# Step 2: Review handling of zero, negative, or missing financial metrics\n",
        "print(\"\\n--- Handling of Financial Metrics (Zero, Negative, Missing) ---\")\n",
        "# The calculate_fundamental_score function uses info.get(metric, None) to handle missing data.\n",
        "# It then checks if the value is not None before using it.\n",
        "# For PE ratio, it checks if pe_ratio > 0. This handles zero and negative PE ratios appropriately (they get low scores).\n",
        "# For Debt-to-Equity, it converts percentage to decimal, but doesn't explicitly check for zero or negative (though negative D/E is rare).\n",
        "# For ROE, Revenue Growth, Net Profit Margin, it checks if the value exists. Zero or negative values will correctly fall into lower score tiers.\n",
        "# Potential Issue 2: Debt-to-Equity is converted from a percentage (integer in info) to a decimal by dividing by 100.\n",
        "# If the info source provides it differently (e.g., already as a decimal), this conversion might be incorrect.\n",
        "# However, based on typical yfinance info, the division by 100 seems correct for the common 'debtToEquity' key.\n",
        "# No major issues identified for zero/negative/missing fundamental metrics, as the scoring logic naturally assigns low scores or skips missing ones.\n",
        "print(\n",
        "    \"Potential Issue 2: The conversion of 'debtToEquity' assumes it's provided as a percentage (integer). \"\n",
        "    \"If the data source provides it as a decimal, the conversion by dividing by 100 would be incorrect. \"\n",
        "    \"However, based on yfinance documentation, the current approach seems appropriate.\"\n",
        "    \"Handling of zero/negative/missing values for other metrics appears reasonable within the scoring logic.\"\n",
        ")\n",
        "\n",
        "\n",
        "# Step 3: Analyze handling of circuit limits and liquidity\n",
        "print(\"\\n--- Handling of Circuit Limits and Liquidity ---\")\n",
        "# get_circuit_limits relies on 'previousClose' from ticker.info. If this is missing, it returns None.\n",
        "# assess_circuit_risk checks if circuit_limits is None. If so, it returns 0 risk. This is safe.\n",
        "# If a stock is exactly at a circuit limit, the distance will be 0.\n",
        "# upper_distance = (upper_circuit - current_price) / current_price\n",
        "# lower_distance = (current_price - lower_circuit) / current_price\n",
        "# If current_price == upper_circuit, upper_distance = 0.\n",
        "# If current_price == lower_circuit, lower_distance = 0.\n",
        "# The scoring thresholds (0.02, 0.05) mean that being *exactly* at the limit will trigger the highest risk penalty. This seems intended.\n",
        "# get_liquidity_score relies on price_data['Volume'].\n",
        "# If price_data is empty or Volume column is missing, it will raise errors.\n",
        "# If volume is zero for the entire period, rolling means/stddevs will be zero or NaN.\n",
        "# avg_volume_20d, avg_volume_5d could be zero.\n",
        "# volume_spike = avg_volume_5d / avg_volume_20d - Division by zero is possible if avg_volume_20d is 0.\n",
        "# volume_cv = volume_std / avg_volume_20d - Division by zero is possible if avg_volume_20d is 0.\n",
        "# The except block catches these errors and returns a default liquidity score of 30.\n",
        "# Potential Issue 3a: Division by zero can occur in get_liquidity_score if average volume is zero. The generic except block handles this by returning a default score, which might not be ideal. More specific handling could provide better insight.\n",
        "# Potential Issue 3b: Circuit limits calculation assumes a fixed percentage (10% or 20%). Actual circuit limits on NSE can vary based on categories (5%, 10%, 20%) and may change. Relying on previousClose and a fixed percentage is a simplification.\n",
        "print(\n",
        "    \"Potential Issue 3a: Division by zero is possible in liquidity calculation if average volume is zero. \"\n",
        "    \"The current error handling returns a default score, masking the underlying issue.\"\n",
        ")\n",
        "print(\n",
        "    \"Potential Issue 3b: Circuit limit calculation is a simplification. Actual NSE limits vary by category and are dynamic. \"\n",
        "    \"Relying solely on 'previousClose' and fixed percentages might not be accurate for all stocks.\"\n",
        ")\n",
        "\n",
        "\n",
        "# Step 4: Consider other potential edge cases\n",
        "print(\"\\n--- Other Potential Edge Cases ---\")\n",
        "# Delisted stocks or stocks with trading suspensions:\n",
        "# yfinance might return empty dataframes or raise errors for such symbols.\n",
        "# get_stock_data and analyze_stock functions handle None or empty dataframes gracefully by returning None or logging errors.\n",
        "# This prevents crashes but means no analysis is provided. This is a reasonable behavior.\n",
        "# Data inconsistencies from the data source:\n",
        "# Incorrect or missing data points (e.g., sudden price jumps, zero volume on active days, incorrect financial figures).\n",
        "# The script relies on the data source (yfinance). It does not include logic for detecting or correcting data inconsistencies.\n",
        "# This is a limitation of relying on external data without validation layers.\n",
        "# Potential Issue 4: The script assumes the data provided by yfinance is accurate and consistent. It does not handle data inconsistencies or anomalies within the fetched data itself.\n",
        "print(\n",
        "    \"Potential Issue 4: The script does not include checks for data inconsistencies \"\n",
        "    \"(e.g., abnormal price movements, zero volume on trading days) within the fetched historical data.\"\n",
        ")\n",
        "\n",
        "# Documentation of potential issues:\n",
        "print(\"\\n--- Summary of Potential Issues ---\")\n",
        "print(\"1. Technical indicators can be NaN if insufficient historical data is available for the required lookback window.\")\n",
        "print(\"2. The conversion of 'debtToEquity' assumes it's provided as a percentage.\")\n",
        "print(\"3a. Division by zero is possible in liquidity calculation if average volume is zero.\")\n",
        "print(\"3b. Circuit limit calculation is a simplification and may not be accurate for all stocks or market conditions.\")\n",
        "print(\"4. The script does not handle data inconsistencies within the fetched historical data.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25770615"
      },
      "source": [
        "## Suggest improvements\n",
        "\n",
        "### Subtask:\n",
        "Suggest improvements to the code to handle any identified logic errors or enhance the accuracy and robustness of the analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dabd90b4"
      },
      "source": [
        "**Reasoning**:\n",
        "Suggest improvements to address the identified edge cases and enhance the code's robustness and accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a495f34c"
      },
      "source": [
        "# --- Suggested Improvements ---\n",
        "\n",
        "print(\"--- Suggested Improvements ---\")\n",
        "\n",
        "# Improvement 1: Handle NaN values in technical indicators more explicitly\n",
        "# Issue: Technical indicators can be NaN with insufficient historical data, and scoring might use misleading defaults.\n",
        "print(\"\\n1. Explicitly handle NaN values in Technical Indicators:\")\n",
        "print(\n",
        "    \"Modify `calculate_technical_indicators` to return NaN or None for indicators \"\n",
        "    \"if there isn't enough data for the lookback period, and log a warning.\"\n",
        ")\n",
        "print(\n",
        "    \"Modify `calculate_technical_score` to check if an indicator value is NaN/None. \"\n",
        "    \"If it is, either assign a neutral score for that specific indicator or reduce the total technical score, \"\n",
        "    \"and log which indicators were not calculated due to insufficient data.\"\n",
        ")\n",
        "print(\"Benefit: Prevents misleading scores based on default values when data is insufficient and provides transparency.\")\n",
        "\n",
        "# Improvement 2: Add validation for Debt-to-Equity format\n",
        "# Issue: Assumes 'debtToEquity' is a percentage (integer).\n",
        "print(\"\\n2. Add validation for Debt-to-Equity format:\")\n",
        "print(\n",
        "    \"Before dividing `debt_to_equity` by 100 in `calculate_fundamental_score`, \"\n",
        "    \"add a check for its typical range (e.g., if it's a large integer like 50000, treat as 50%). \"\n",
        "    \"If it's a small decimal (e.g., 0.5), assume it's already in decimal form.\"\n",
        ")\n",
        "print(\"Benefit: Makes the calculation more robust to potential variations in data format from the source.\")\n",
        "\n",
        "# Improvement 3: Handle division by zero in liquidity calculation\n",
        "# Issue: Division by zero possible if average volume is zero.\n",
        "print(\"\\n3. Handle division by zero specifically in liquidity calculation:\")\n",
        "print(\n",
        "    \"In `get_liquidity_score`, add explicit checks before division (`if avg_volume_20d > 0:`). \"\n",
        "    \"If the divisor is zero, assign a specific low score (e.g., 0 or 5) for the related metric (volume spike, volume CV) \"\n",
        "    \"instead of letting the exception handler assign a generic default score for the whole function.\"\n",
        ")\n",
        "print(\"Benefit: Provides more accurate liquidity scoring even for illiquid stocks and gives better insight than a generic error catch.\")\n",
        "\n",
        "# Improvement 4: Enhance circuit limit calculation accuracy\n",
        "# Issue: Simplified circuit limit calculation.\n",
        "print(\"\\n4. Enhance circuit limit calculation accuracy:\")\n",
        "print(\n",
        "    \"Instead of relying on fixed percentages, try to scrape or use an API \"\n",
        "    \"to get actual, dynamic circuit limits from a reliable source like NSE India.\"\n",
        ")\n",
        "print(\n",
        "    \"If scraping is not feasible, at least document the limitation clearly \"\n",
        "    \"and potentially add logic to categorize stocks (e.g., based on market cap or index membership) \"\n",
        "    \"to apply slightly more accurate default percentages (e.g., 5% for some small caps).\"\n",
        ")\n",
        "print(\"Benefit: Provides more accurate risk assessment based on actual market mechanisms.\")\n",
        "\n",
        "# Improvement 5: Add data validation checks for historical data\n",
        "# Issue: Does not handle data inconsistencies within fetched data.\n",
        "print(\"\\n5. Add data validation checks for historical data:\")\n",
        "print(\n",
        "    \"Implement checks in `analyze_stock` or a dedicated data validation function \"\n",
        "    \"to look for anomalies in the `price_data` DataFrame.\"\n",
        ")\n",
        "print(\n",
        "    \"Examples: Check for zero volume on normal trading days, sudden extreme price changes (spikes/drops), \"\n",
        "    \"or non-monotonic price movements (if expected).\"\n",
        ")\n",
        "print(\n",
        "    \"If anomalies are found, log a warning and potentially exclude the affected data points \"\n",
        "    \"or adjust the confidence of the technical analysis score.\"\n",
        ")\n",
        "print(\"Benefit: Increases the reliability of the analysis by identifying potentially erroneous source data.\")\n",
        "\n",
        "# Improvement 6: Refine benchmark application\n",
        "# Issue: Benchmarks are applied based on a simple sector mapping.\n",
        "print(\"\\n6. Refine industry benchmark application:\")\n",
        "print(\n",
        "    \"Expand the `industry_benchmarks` dictionary to include more sectors and potentially sub-sectors.\"\n",
        ")\n",
        "print(\n",
        "    \"Consider using a more sophisticated method to determine benchmarks, \"\n",
        "    \"such as calculating median/average metrics for peers or the sector from recent data, \"\n",
        "    \"instead of relying on static values.\"\n",
        ")\n",
        "print(\"Benefit: Provides more relevant and dynamic benchmarks for fundamental analysis.\")\n",
        "\n",
        "# Improvement 7: Add logging for score calculation\n",
        "# Issue: Hard to debug score calculation without detailed logs.\n",
        "print(\"\\n7. Add detailed logging for score calculation:\")\n",
        "print(\n",
        "    \"Add log messages within `calculate_fundamental_score` and `calculate_technical_score` \"\n",
        "    \"showing how points are assigned for each metric.\"\n",
        ")\n",
        "print(\"Benefit: Improves debuggability and transparency of the scoring process.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feef4f97"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The core logic for calculating fundamental and technical scores aligns with the defined rules and benchmarks within the code.\n",
        "*   The recommendation thresholds are set based on the potential range of calculated scores.\n",
        "*   The enhanced analyzer incorporates additional factors like circuit risk, liquidity, peer performance, and index membership.\n",
        "*   Technical indicators can result in NaN values with limited historical data, which the scoring logic might not handle explicitly, potentially using misleading defaults.\n",
        "*   The conversion of 'debtToEquity' assumes the input is a percentage.\n",
        "*   A division by zero is possible in the liquidity calculation if average volume is zero, currently handled by a generic error catch.\n",
        "*   The circuit limit calculation is a simplification using fixed percentages and `previousClose`.\n",
        "*   The script does not include checks for inconsistencies within the fetched historical data.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Implement explicit handling for `NaN` values in technical indicators to prevent misleading scores and improve transparency.\n",
        "*   Enhance data validation, especially for financial metrics like Debt-to-Equity and historical price data, to ensure data quality and robustness.\n",
        "*   Improve error handling for specific cases like division by zero in liquidity calculations for more accurate scoring.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e978e44"
      },
      "source": [
        "To use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n",
        "In Colab, add the key to the secrets manager under the \"🔑\" in the left panel. Give it the name `GOOGLE_API_KEY`. Then pass the key to the SDK:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c0cb3be"
      },
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92095c27"
      },
      "source": [
        "Before you can make any API calls, you need to initialize the Generative Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4fd3765"
      },
      "source": [
        "# Initialize the Gemini API\n",
        "gemini_model = genai.GenerativeModel('gemini-2.5-flash-preview-04-17')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4514e4d5"
      },
      "source": [
        "Now you can make API calls. For example, to generate a poem:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "151d9b60"
      },
      "source": [
        "#@title Analyze a stock and display the combined results\n",
        "symbol_to_analyze = \"RELIANCE.NS\" # You can change this symbol\n",
        "\n",
        "# Ensure both analyzers are instantiated (they should be if the cells above were run)\n",
        "# If not, you might need to re-run the cells defining IndianStockAnalyzer and EnhancedStockAnalyzer\n",
        "try:\n",
        "    stock_analyzer = IndianStockAnalyzer()\n",
        "    enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "except NameError:\n",
        "    print(\"Please run the cells defining IndianStockAnalyzer and EnhancedStockAnalyzer first.\")\n",
        "    # Exit or handle the error appropriately if classes are not defined\n",
        "    stock_analyzer = None\n",
        "    enhanced_analyzer = None\n",
        "\n",
        "\n",
        "if stock_analyzer and enhanced_analyzer:\n",
        "    combined_analysis_report = analyze_stock_enhanced(symbol_to_analyze, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if combined_analysis_report:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Combined Stock Analysis Report for {symbol_to_analyze}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Display basic analysis results\n",
        "        basic = combined_analysis_report['basic_analysis']\n",
        "        print(f\"\\n--- Basic Analysis (from Part 1) ---\")\n",
        "        print(f\"Company Name: {basic.company_name}\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\")\n",
        "        print(f\"Market Cap: ₹{basic.info.get('marketCap', 0)/10000000:,.2f} Cr\")\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "        print(f\"Fundamental Score: {basic.fundamental_score}/50\")\n",
        "        print(f\"Technical Score: {basic.technical_score}/50\")\n",
        "        print(f\"Basic Recommendation: {basic.recommendation}\")\n",
        "        print(\"\\nFundamental Metrics:\")\n",
        "        for metric, value in basic.metrics.items():\n",
        "             if metric != 'Fundamental_Score':\n",
        "                if isinstance(value, float):\n",
        "                    if metric in ['ROE', 'Revenue_Growth', 'Net_Profit_Margin']:\n",
        "                        print(f\"{metric}: {value*100:.2f}%\")\n",
        "                    else:\n",
        "                        print(f\"{metric}: {value:.2f}\")\n",
        "                else:\n",
        "                    print(f\"{metric}: {value}\")\n",
        "\n",
        "        print(\"\\nTechnical Indicators:\")\n",
        "        for indicator, value in basic.indicators.items():\n",
        "             if indicator != 'current_price':\n",
        "                if value is not None and not np.isnan(value):\n",
        "                    if isinstance(value, float):\n",
        "                        print(f\"{indicator}: {value:,.2f}\")\n",
        "                    else:\n",
        "                        print(f\"{indicator}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{indicator}: N/A (Insufficient Data)\")\n",
        "\n",
        "\n",
        "        # Display enhanced features and final recommendation\n",
        "        enhanced = combined_analysis_report['enhanced_features']\n",
        "        final = combined_analysis_report['final_recommendation']\n",
        "\n",
        "        print(f\"\\n--- Enhanced Analysis (from Part 2) ---\")\n",
        "        print(f\"Circuit Limits: {enhanced.get('circuit_limits', {}).get('lower_circuit', 'N/A'):.2f} - {enhanced.get('circuit_limits', {}).get('upper_circuit', 'N/A'):.2f}\")\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        print(f\"Liquidity Score: {enhanced.get('liquidity_score', 'N/A')}/70\")\n",
        "\n",
        "        if enhanced.get('peers'):\n",
        "            print(f\"Peer Companies: {', '.join(enhanced['peers'])}\")\n",
        "            if enhanced.get('peer_performance'):\n",
        "                print(f\"30-day Return: {enhanced['peer_performance'].get('stock_return', 'N/A'):.2f}%\")\n",
        "                print(f\"Peer Avg Return: {enhanced['peer_performance'].get('avg_peer_return', 'N/A'):.2f}%\")\n",
        "                print(f\"Relative Performance: {enhanced['peer_performance'].get('relative_performance', 'N/A'):.2f}%\")\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             for headline in enhanced['news_headlines']:\n",
        "                 print(f\"- {headline}\")\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             print(f\"Sentiment Score: {sentiment_results.get('score', 0):.2f}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Final Recommendation ---\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} ({final.get('confidence', 'N/A')})\")\n",
        "        print(f\"Total Score: {final.get('total_score', 0):.2f}/205\")\n",
        "        print(\"Score Breakdown:\")\n",
        "        print(f\"  - Fundamental: {final.get('breakdown', {}).get('fundamental', 'N/A'):.2f}\")\n",
        "        print(f\"  - Technical (Enhanced): {final.get('breakdown', {}).get('technical', 'N/A')}\") # Technical score might not be float always\n",
        "        print(f\"  - Liquidity: {final.get('breakdown', {}).get('liquidity', 'N/A'):.2f}\")\n",
        "        print(f\"  - Sentiment: {final.get('breakdown', {}).get('sentiment', 'N/A'):.2f}\")\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Could not generate combined analysis report for {symbol_to_analyze}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sO_r1wRklJVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f547f6b"
      },
      "source": [
        "# Task\n",
        "Explain the error in the selected code, fix it if possible, and incorporate the changes into the existing code. If fixing is not possible, diagnose the error. Ensure the results from \"Part 1 Main Script\" and the sentimental analysis with API are displayed together in different cells. Also, remove the line \"from your_part1_module import IndianStockAnalyzer\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d37e4591"
      },
      "source": [
        "## Robust nan and data validation\n",
        "\n",
        "### Subtask:\n",
        "Enhance the script to handle missing data (NaNs) more consistently across all calculations and add explicit checks for data validity before performing analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f70a9f1"
      },
      "source": [
        "**Reasoning**:\n",
        "The instructions require enhancing several functions to handle missing data and add data validity checks. This involves modifying the existing code within the `IndianStockAnalyzer` and `EnhancedStockAnalyzer` classes. The changes are related and can be logically grouped into a single code block to redefine the classes with the necessary enhancements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "32123a17"
      },
      "source": [
        "#@title Part 1 of Main script (Enhanced)\n",
        "# Indian Stock Analyzer - Part 1 (Corrected and Enhanced further)\n",
        "# Complete implementation with improvements for missing data handling\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import logging\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__) # Define logger globally\n",
        "\n",
        "@dataclass\n",
        "class StockData:\n",
        "    \"\"\"Data class to store comprehensive stock information\"\"\"\n",
        "    symbol: str\n",
        "    company_name: str\n",
        "    current_price: float\n",
        "    market_cap: float\n",
        "    info: Dict\n",
        "    price_data: pd.DataFrame\n",
        "    indicators: Dict\n",
        "    fundamental_score: float\n",
        "    technical_score: float\n",
        "    recommendation: str\n",
        "    metrics: Dict\n",
        "\n",
        "class IndianStockAnalyzer:\n",
        "    \"\"\"Comprehensive stock analyzer for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the analyzer with Indian market specific parameters\"\"\"\n",
        "        self.nifty_symbol = \"^NSEI\"\n",
        "        self.risk_free_rate = 0.065  # Will be made dynamic in Part 2\n",
        "\n",
        "        # Industry-specific benchmark thresholds for Indian markets\n",
        "        self.industry_benchmarks = {\n",
        "            'technology': {\n",
        "                'pe_ratio': {'excellent': 25, 'good': 35, 'fair': 45},\n",
        "                'debt_to_equity': {'excellent': 0.3, 'good': 0.5, 'fair': 0.8},\n",
        "                'roe': {'excellent': 0.25, 'good': 0.18, 'fair': 0.12},\n",
        "                'revenue_growth': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10}\n",
        "            },\n",
        "            'banking': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 20, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 8, 'good': 10, 'fair': 12},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.25, 'good': 0.20, 'fair': 0.15}\n",
        "            },\n",
        "            'pharmaceutical': {\n",
        "                'pe_ratio': {'excellent': 20, 'good': 30, 'fair': 40},\n",
        "                'debt_to_equity': {'excellent': 0.4, 'good': 0.6, 'fair': 0.8},\n",
        "                'roe': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.08}\n",
        "            },\n",
        "            'fmcg': {\n",
        "                'pe_ratio': {'excellent': 30, 'good': 40, 'fair': 50},\n",
        "                'debt_to_equity': {'excellent': 0.5, 'good': 0.8, 'fair': 1.0},\n",
        "                'roe': {'excellent': 0.30, 'good': 0.25, 'fair': 0.15},\n",
        "                'revenue_growth': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.08}\n",
        "            },\n",
        "            'automobile': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "                'debt_to_equity': {'excellent': 0.6, 'good': 0.8, 'fair': 1.2},\n",
        "                'roe': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "            },\n",
        "            'infrastructure': {\n",
        "                'pe_ratio': {'excellent': 12, 'good': 18, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05}\n",
        "            },\n",
        "            'energy': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 15, 'fair': 20},\n",
        "                'debt_to_equity': {'excellent': 0.8, 'good': 1.2, 'fair': 1.5},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "            },\n",
        "            'realty': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 15, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05},\n",
        "                'revenue_growth': {'excellent': 0.25, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05}\n",
        "            },\n",
        "            'telecom': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05},\n",
        "                'revenue_growth': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.08, 'good': 0.05, 'fair': 0.03}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Default benchmarks for other sectors\n",
        "        self.default_benchmarks = {\n",
        "            'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "            'debt_to_equity': {'excellent': 0.5, 'good': 1.0, 'fair': 1.5},\n",
        "            'roe': {'excellent': 0.15, 'good': 0.10, 'fair': 0.07},\n",
        "            'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "            'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "        }\n",
        "\n",
        "    def get_stock_data(self, symbol: str) -> Optional[yf.Ticker]:\n",
        "        \"\"\"Fetch stock data from Yahoo Finance\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            # Verify the ticker is valid by checking if it has info\n",
        "            if ticker.info and 'symbol' in ticker.info:\n",
        "                return ticker\n",
        "            else:\n",
        "                logger.error(f\"Invalid symbol: {symbol}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error fetching data for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_industry_benchmarks(self, sector: str) -> Dict:\n",
        "        \"\"\"Get industry-specific benchmarks\"\"\"\n",
        "        sector_lower = sector.lower() if sector else ''\n",
        "\n",
        "        # Map common sector names to our benchmark categories\n",
        "        sector_mapping = {\n",
        "            'technology': 'technology',\n",
        "            'information technology': 'technology',\n",
        "            'financial services': 'banking',\n",
        "            'financials': 'banking',\n",
        "            'healthcare': 'pharmaceutical',\n",
        "            'consumer defensive': 'fmcg',\n",
        "            'consumer cyclical': 'automobile',\n",
        "            'industrials': 'infrastructure',\n",
        "            'energy': 'energy',\n",
        "            'real estate': 'realty',\n",
        "            'communication services': 'telecom'\n",
        "        }\n",
        "\n",
        "        benchmark_key = sector_mapping.get(sector_lower, None)\n",
        "\n",
        "        if benchmark_key and benchmark_key in self.industry_benchmarks:\n",
        "            return self.industry_benchmarks[benchmark_key]\n",
        "        else:\n",
        "            logger.info(f\"Using default benchmarks for sector: {sector}\")\n",
        "            return self.default_benchmarks\n",
        "\n",
        "    def calculate_technical_indicators(self, price_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate comprehensive technical indicators\"\"\"\n",
        "        indicators = {}\n",
        "        data_len = len(price_data)\n",
        "\n",
        "        try:\n",
        "            # Simple Moving Averages\n",
        "            if data_len >= 20:\n",
        "                 indicators['SMA_20'] = price_data['Close'].rolling(window=20).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['SMA_20'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_20.\")\n",
        "\n",
        "            if data_len >= 50:\n",
        "                 indicators['SMA_50'] = price_data['Close'].rolling(window=50).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['SMA_50'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_50.\")\n",
        "\n",
        "            if data_len >= 200:\n",
        "                 indicators['SMA_200'] = price_data['Close'].rolling(window=200).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['SMA_200'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_200.\")\n",
        "\n",
        "            # Exponential Moving Averages\n",
        "            if data_len >= 12:\n",
        "                 indicators['EMA_12'] = price_data['Close'].ewm(span=12, adjust=False).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['EMA_12'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for EMA_12.\")\n",
        "\n",
        "            if data_len >= 26:\n",
        "                 indicators['EMA_26'] = price_data['Close'].ewm(span=26, adjust=False).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['EMA_26'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for EMA_26.\")\n",
        "\n",
        "            # RSI\n",
        "            if data_len >= 14:\n",
        "                indicators['RSI'] = self.calculate_rsi(price_data['Close'])\n",
        "            else:\n",
        "                 indicators['RSI'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for RSI.\")\n",
        "\n",
        "            # MACD (requires EMA_12 and EMA_26)\n",
        "            macd_line = np.nan\n",
        "            signal_line = np.nan\n",
        "            macd_histogram = np.nan\n",
        "\n",
        "            if 'EMA_12' in indicators and 'EMA_26' in indicators and not np.isnan(indicators['EMA_12']) and not np.isnan(indicators['EMA_26']):\n",
        "                 # Use the entire macd_line series for rolling calculation if possible\n",
        "                 full_macd_line_series = price_data['Close'].ewm(span=12, adjust=False).mean() - price_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "                 if len(full_macd_line_series.dropna()) >= 9:\n",
        "                      macd_line = full_macd_line_series.iloc[-1]\n",
        "                      signal_line = full_macd_line_series.ewm(span=9, adjust=False).mean().iloc[-1]\n",
        "                      if not np.isnan(signal_line):\n",
        "                         macd_histogram = macd_line - signal_line\n",
        "                 else:\n",
        "                      logger.warning(\"Insufficient data for MACD signal line calculation.\")\n",
        "            else:\n",
        "                 logger.warning(\"MACD not calculated due to missing EMA_12 or EMA_26.\")\n",
        "\n",
        "\n",
        "            indicators['MACD'] = macd_line\n",
        "            indicators['MACD_signal'] = signal_line\n",
        "            indicators['MACD_histogram'] = macd_histogram\n",
        "\n",
        "            # Log MACD values after calculation\n",
        "            logger.info(f\"Calculated MACD: {indicators['MACD']}, Signal: {indicators['MACD_signal']}\")\n",
        "\n",
        "\n",
        "            # Bollinger Bands (requires SMA_20 and enough data for std dev)\n",
        "            bb_period = 20\n",
        "            bb_std = 2\n",
        "            if data_len >= bb_period:\n",
        "                sma_bb = price_data['Close'].rolling(window=bb_period).mean()\n",
        "                std_bb = price_data['Close'].rolling(window=bb_period).std()\n",
        "                # Ensure SMA and STD are not NaN before calculating bands\n",
        "                if not np.isnan(sma_bb.iloc[-1]) and not np.isnan(std_bb.iloc[-1]):\n",
        "                    indicators['BB_upper'] = sma_bb.iloc[-1] + (std_bb.iloc[-1] * bb_std)\n",
        "                    indicators['BB_lower'] = sma_bb.iloc[-1] - (std_bb.iloc[-1] * bb_std)\n",
        "                    indicators['BB_middle'] = sma_bb.iloc[-1]\n",
        "                else:\n",
        "                    indicators['BB_upper'] = np.nan\n",
        "                    indicators['BB_lower'] = np.nan\n",
        "                    indicators['BB_middle'] = np.nan\n",
        "                    logger.warning(\"Bollinger Bands not calculated due to NaN in SMA or STD.\")\n",
        "            else:\n",
        "                indicators['BB_upper'] = np.nan\n",
        "                indicators['BB_lower'] = np.nan\n",
        "                indicators['BB_middle'] = np.nan\n",
        "                logger.warning(\"Insufficient data for Bollinger Bands.\")\n",
        "\n",
        "\n",
        "            # Volume indicators\n",
        "            if data_len >= 20:\n",
        "                 indicators['Volume_SMA'] = price_data['Volume'].rolling(window=20).mean().iloc[-1]\n",
        "                 if indicators['Volume_SMA'] is not None and not np.isnan(indicators['Volume_SMA']) and indicators['Volume_SMA'] > 0:\n",
        "                      indicators['Volume_ratio'] = price_data['Volume'].iloc[-1] / indicators['Volume_SMA']\n",
        "                 else:\n",
        "                      indicators['Volume_ratio'] = np.nan\n",
        "                      logger.warning(\"Volume SMA is zero or NaN, Volume ratio not calculated.\")\n",
        "            else:\n",
        "                 indicators['Volume_SMA'] = np.nan\n",
        "                 indicators['Volume_ratio'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for Volume SMA and ratio.\")\n",
        "\n",
        "\n",
        "            # Price position (requires SMA_20 and SMA_50)\n",
        "            current_price = price_data['Close'].iloc[-1] if data_len > 0 and 'Close' in price_data and not price_data['Close'].empty else np.nan\n",
        "            indicators['current_price'] = current_price # Store current price\n",
        "\n",
        "            if current_price is not None and not np.isnan(current_price) and 'SMA_20' in indicators and indicators['SMA_20'] is not None and not np.isnan(indicators['SMA_20']) and indicators['SMA_20'] > 0:\n",
        "                indicators['Price_to_SMA20'] = ((current_price / indicators['SMA_20'] - 1) * 100)\n",
        "            else:\n",
        "                 indicators['Price_to_SMA20'] = np.nan\n",
        "                 logger.warning(\"Price to SMA20 not calculated due to missing current price or SMA20.\")\n",
        "\n",
        "            if current_price is not None and not np.isnan(current_price) and 'SMA_50' in indicators and indicators['SMA_50'] is not None and not np.isnan(indicators['SMA_50']) and indicators['SMA_50'] > 0:\n",
        "                 indicators['Price_to_SMA50'] = ((current_price / indicators['SMA_50'] - 1) * 100)\n",
        "            else:\n",
        "                 indicators['Price_to_SMA50'] = np.nan\n",
        "                 logger.warning(\"Price to SMA50 not calculated due to missing current price or SMA50.\")\n",
        "\n",
        "\n",
        "            # Support and Resistance (requires enough data for rolling max/min)\n",
        "            if data_len >= 20:\n",
        "                 indicators['Resistance'] = price_data['High'].rolling(window=20).max().iloc[-1]\n",
        "                 indicators['Support'] = price_data['Low'].rolling(window=20).min().iloc[-1]\n",
        "            else:\n",
        "                 indicators['Resistance'] = np.nan\n",
        "                 indicators['Support'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for Support and Resistance.\")\n",
        "\n",
        "\n",
        "            return indicators\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating technical indicators: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> Optional[float]:\n",
        "        \"\"\"Calculate Relative Strength Index\"\"\"\n",
        "        try:\n",
        "            if len(prices) < period:\n",
        "                return np.nan # Return NaN for insufficient data\n",
        "\n",
        "            delta = prices.diff()\n",
        "            gain = delta.where(delta > 0, 0)\n",
        "            loss = -delta.where(delta < 0, 0)\n",
        "\n",
        "            avg_gain = gain.rolling(window=period).mean()\n",
        "            avg_loss = loss.rolling(window=period).mean()\n",
        "\n",
        "            # Handle division by zero if avg_loss is zero or NaN\n",
        "            if avg_loss.iloc[-1] is None or np.isnan(avg_loss.iloc[-1]) or avg_loss.iloc[-1] == 0:\n",
        "                 return 100.0 if avg_gain.iloc[-1] is not None and not np.isnan(avg_gain.iloc[-1]) and avg_gain.iloc[-1] > 0 else 50.0 # If no loss, RSI is 100 (if gain) or 50 (if no change)\n",
        "            elif avg_loss.iloc[-1] > 0:\n",
        "                rs = avg_gain / avg_loss\n",
        "                rsi = 100 - (100 / (1 + rs))\n",
        "                return rsi.iloc[-1]\n",
        "            else:\n",
        "                 return np.nan # Should not happen with abs, but as a safeguard\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating RSI: {str(e)}\")\n",
        "            return np.nan # Return NaN on error\n",
        "\n",
        "    def calculate_fundamental_score(self, info: Dict, benchmarks: Dict) -> Tuple[float, Dict]:\n",
        "        \"\"\"Calculate fundamental analysis score based on Indian market standards\"\"\"\n",
        "        score = 0\n",
        "        max_score = 50\n",
        "        metrics = {}\n",
        "\n",
        "        try:\n",
        "            # P/E Ratio (10 points)\n",
        "            pe_ratio = info.get('trailingPE', info.get('forwardPE', None))\n",
        "            if pe_ratio is not None and isinstance(pe_ratio, (int, float)) and not np.isnan(pe_ratio):\n",
        "                metrics['PE_Ratio'] = pe_ratio\n",
        "                if pe_ratio > 0: # Ensure PE is positive for scoring\n",
        "                     if pe_ratio <= benchmarks['pe_ratio']['excellent']:\n",
        "                         score += 10\n",
        "                     elif pe_ratio <= benchmarks['pe_ratio']['good']:\n",
        "                         score += 7\n",
        "                     elif pe_ratio <= benchmarks['pe_ratio']['fair']:\n",
        "                         score += 4\n",
        "                     else:\n",
        "                         score += 2\n",
        "                else:\n",
        "                    score += 1 # Small score for non-positive PE\n",
        "            else:\n",
        "                 metrics['PE_Ratio'] = np.nan\n",
        "                 logger.warning(\"PE Ratio not available or is invalid.\")\n",
        "\n",
        "\n",
        "            # Debt to Equity (10 points)\n",
        "            # Added check for type and typical range assuming integer percentage or decimal\n",
        "            debt_to_equity_raw = info.get('debtToEquity', None)\n",
        "            if debt_to_equity_raw is not None and isinstance(debt_to_equity_raw, (int, float)) and not np.isnan(debt_to_equity_raw):\n",
        "                 # Assuming if it's a large number, it's percentage\n",
        "                 if debt_to_equity_raw > 100: # Heuristic for percentage\n",
        "                      debt_to_equity = debt_to_equity_raw / 100.0\n",
        "                 else: # Assume it's already a decimal\n",
        "                      debt_to_equity = debt_to_equity_raw\n",
        "\n",
        "                 metrics['Debt_to_Equity'] = debt_to_equity\n",
        "                 if debt_to_equity <= benchmarks['debt_to_equity']['excellent']:\n",
        "                     score += 10\n",
        "                 elif debt_to_equity <= benchmarks['debt_to_equity']['good']:\n",
        "                     score += 7\n",
        "                 elif debt_to_equity <= benchmarks['debt_to_equity']['fair']:\n",
        "                     score += 4\n",
        "                 else:\n",
        "                     score += 2\n",
        "            else:\n",
        "                 metrics['Debt_to_Equity'] = np.nan\n",
        "                 logger.warning(\"Debt to Equity not available or is invalid.\")\n",
        "\n",
        "\n",
        "            # ROE (10 points)\n",
        "            roe = info.get('returnOnEquity', None)\n",
        "            if roe is not None and isinstance(roe, (int, float)) and not np.isnan(roe):\n",
        "                metrics['ROE'] = roe\n",
        "                if roe >= benchmarks['roe']['excellent']:\n",
        "                    score += 10\n",
        "                elif roe >= benchmarks['roe']['good']:\n",
        "                    score += 7\n",
        "                elif roe >= benchmarks['roe']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2\n",
        "            else:\n",
        "                 metrics['ROE'] = np.nan\n",
        "                 logger.warning(\"ROE not available or is invalid.\")\n",
        "\n",
        "            # Revenue Growth (10 points)\n",
        "            revenue_growth = info.get('revenueGrowth', None)\n",
        "            if revenue_growth is not None and isinstance(revenue_growth, (int, float)) and not np.isnan(revenue_growth):\n",
        "                metrics['Revenue_Growth'] = revenue_growth\n",
        "                if revenue_growth >= benchmarks['revenue_growth']['excellent']:\n",
        "                    score += 10\n",
        "                elif revenue_growth >= benchmarks['revenue_growth']['good']:\n",
        "                    score += 7\n",
        "                elif revenue_growth >= benchmarks['revenue_growth']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2\n",
        "            else:\n",
        "                 metrics['Revenue_Growth'] = np.nan\n",
        "                 logger.warning(\"Revenue Growth not available or is invalid.\")\n",
        "\n",
        "            # Net Profit Margin (10 points)\n",
        "            profit_margin = info.get('profitMargins', None)\n",
        "            if profit_margin is not None and isinstance(profit_margin, (int, float)) and not np.isnan(profit_margin):\n",
        "                metrics['Net_Profit_Margin'] = profit_margin\n",
        "                if profit_margin >= benchmarks['net_profit_margin']['excellent']:\n",
        "                    score += 10\n",
        "                elif profit_margin >= benchmarks['net_profit_margin']['good']:\n",
        "                    score += 7\n",
        "                elif profit_margin >= benchmarks['net_profit_margin']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2\n",
        "            else:\n",
        "                 metrics['Net_Profit_Margin'] = np.nan\n",
        "                 logger.warning(\"Net Profit Margin not available or is invalid.\")\n",
        "\n",
        "\n",
        "            # Normalize score to max_score (already capped by scoring logic)\n",
        "            metrics['Fundamental_Score'] = score\n",
        "\n",
        "            return score, metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating fundamental score: {str(e)}\")\n",
        "            return 0, {}\n",
        "\n",
        "    def calculate_technical_score(self, indicators: Dict) -> float:\n",
        "        \"\"\"Calculate technical analysis score\"\"\"\n",
        "        score = 0\n",
        "        max_score = 50\n",
        "        indicator_scores = {} # To store scores for each indicator\n",
        "\n",
        "        try:\n",
        "            # RSI Score (10 points)\n",
        "            rsi = indicators.get('RSI', None)\n",
        "            if rsi is not None and not np.isnan(rsi):\n",
        "                 if 40 <= rsi <= 60:  # Neutral zone\n",
        "                     indicator_scores['RSI'] = 7\n",
        "                 elif rsi < 40:  # Oversold\n",
        "                     indicator_scores['RSI'] = 10\n",
        "                 elif 60 < rsi <= 70:  # Overbought but not extreme\n",
        "                     indicator_scores['RSI'] = 5\n",
        "                 else:  # Extreme levels\n",
        "                     indicator_scores['RSI'] = 2\n",
        "            else:\n",
        "                 indicator_scores['RSI'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"RSI not calculated or is NaN/None. Assigning 0 score for RSI.\")\n",
        "\n",
        "\n",
        "            # MACD Score (10 points)\n",
        "            macd = indicators.get('MACD', None)\n",
        "            macd_signal = indicators.get('MACD_signal', None)\n",
        "\n",
        "            # Explicitly check if both are numbers before comparing\n",
        "            if isinstance(macd, (int, float)) and isinstance(macd_signal, (int, float)) and not np.isnan(macd) and not np.isnan(macd_signal):\n",
        "                 if macd > macd_signal:\n",
        "                     indicator_scores['MACD'] = 10\n",
        "                 else:\n",
        "                     indicator_scores['MACD'] = 3\n",
        "            else:\n",
        "                 indicator_scores['MACD'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"MACD or MACD signal not calculated or is not a valid number. Assigning 0 score for MACD.\")\n",
        "\n",
        "\n",
        "            # Moving Average Score (10 points) - Using SMA_20 vs SMA_50\n",
        "            sma_20 = indicators.get('SMA_20', None)\n",
        "            sma_50 = indicators.get('SMA_50', None)\n",
        "            if sma_20 is not None and sma_50 is not None and not np.isnan(sma_20) and not np.isnan(sma_50):\n",
        "                if sma_20 > sma_50:\n",
        "                    indicator_scores['Moving_Averages'] = 10\n",
        "                else:\n",
        "                    indicator_scores['Moving_Averages'] = 3\n",
        "            else:\n",
        "                indicator_scores['Moving_Averages'] = 0 # Assign 0 if NaN/None\n",
        "                logger.warning(\"SMA_20 or SMA_50 not calculated or is NaN/None. Assigning 0 score for Moving Averages.\")\n",
        "\n",
        "\n",
        "            # Bollinger Bands Score (10 points)\n",
        "            current_price = indicators.get('current_price', None) # Assuming current_price is passed in indicators\n",
        "            bb_upper = indicators.get('BB_upper', None)\n",
        "            bb_lower = indicators.get('BB_lower', None)\n",
        "            bb_middle = indicators.get('BB_middle', None)\n",
        "\n",
        "            if current_price is not None and bb_upper is not None and bb_lower is not None and bb_middle is not None and \\\n",
        "               not np.isnan(current_price) and not np.isnan(bb_upper) and not np.isnan(bb_lower) and not np.isnan(bb_middle):\n",
        "                if bb_lower < current_price < bb_middle:\n",
        "                    indicator_scores['Bollinger_Bands'] = 10  # Good buying zone\n",
        "                elif bb_middle < current_price < bb_upper:\n",
        "                    indicator_scores['Bollinger_Bands'] = 7   # Neutral to positive\n",
        "                else:\n",
        "                    indicator_scores['Bollinger_Bands'] = 3   # Near extremes\n",
        "            else:\n",
        "                 indicator_scores['Bollinger_Bands'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Bollinger Bands or current price not available or is NaN/None. Assigning 0 score for Bollinger Bands.\")\n",
        "\n",
        "\n",
        "            # Volume Score (10 points)\n",
        "            volume_ratio = indicators.get('Volume_ratio', None)\n",
        "            if volume_ratio is not None and not np.isnan(volume_ratio):\n",
        "                 if 0.8 <= volume_ratio <= 1.5:\n",
        "                     indicator_scores['Volume'] = 7   # Normal volume\n",
        "                 elif volume_ratio > 1.5:\n",
        "                     indicator_scores['Volume'] = 10  # High volume (positive if with price up)\n",
        "                 else:\n",
        "                     indicator_scores['Volume'] = 3   # Low volume\n",
        "            else:\n",
        "                 indicator_scores['Volume'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Volume ratio not calculated or is NaN/None. Assigning 0 score for Volume.\")\n",
        "\n",
        "            # Sum the scores from individual indicators\n",
        "            score = sum(indicator_scores.values())\n",
        "\n",
        "            return min(score, max_score) # Cap at max_score\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating technical score: {str(e)}\")\n",
        "            return 0\n",
        "\n",
        "    def generate_recommendation(self, fundamental_score: float, technical_score: float) -> str:\n",
        "        \"\"\"Generate investment recommendation based on scores\"\"\"\n",
        "        total_score = fundamental_score + technical_score\n",
        "\n",
        "        if total_score >= 75:\n",
        "            return \"STRONG BUY\"\n",
        "        elif total_score >= 60:\n",
        "            return \"BUY\"\n",
        "        elif total_score >= 40:\n",
        "            return \"HOLD\"\n",
        "        elif total_score >= 25:\n",
        "            return \"SELL\"\n",
        "        else:\n",
        "            return \"STRONG SELL\"\n",
        "\n",
        "    def analyze_stock(self, symbol: str) -> Optional[StockData]:\n",
        "        \"\"\"Main method to analyze a stock\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Starting analysis for {symbol}\")\n",
        "\n",
        "            # Get stock data\n",
        "            ticker = self.get_stock_data(symbol)\n",
        "            if not ticker:\n",
        "                return None\n",
        "\n",
        "            # Get stock info\n",
        "            info = ticker.info\n",
        "            if not info:\n",
        "                logger.error(f\"No info available for {symbol}\")\n",
        "                return None\n",
        "\n",
        "            # Get historical price data\n",
        "            # Fetching enough data for 200-day SMA calculation\n",
        "            price_data = ticker.history(period=\"1y\") # Changed to 1 year to support 200-day SMA\n",
        "            if price_data.empty: # Check if price_data is empty\n",
        "                logger.error(f\"No price data available for {symbol}\")\n",
        "                return None\n",
        "            # Also check for essential columns\n",
        "            if not all(col in price_data.columns for col in ['Open', 'High', 'Low', 'Close', 'Volume']):\n",
        "                 logger.error(f\"Price data for {symbol} is missing essential columns.\")\n",
        "                 return None\n",
        "\n",
        "\n",
        "            # Get current price\n",
        "            current_price = price_data['Close'].iloc[-1] if not price_data['Close'].empty else np.nan\n",
        "\n",
        "            # Add current price to indicators for technical score calculation\n",
        "            indicators = self.calculate_technical_indicators(price_data)\n",
        "            indicators['current_price'] = current_price # Ensure current price is available for BB score\n",
        "\n",
        "            # Get industry benchmarks\n",
        "            sector = info.get('sector', 'Unknown')\n",
        "            benchmarks = self.get_industry_benchmarks(sector)\n",
        "\n",
        "            # Calculate scores\n",
        "            fundamental_score, metrics = self.calculate_fundamental_score(info, benchmarks)\n",
        "            technical_score = self.calculate_technical_score(indicators)\n",
        "\n",
        "            # Generate recommendation\n",
        "            recommendation = self.generate_recommendation(fundamental_score, technical_score)\n",
        "\n",
        "            # Create StockData object\n",
        "            stock_data = StockData(\n",
        "                symbol=symbol,\n",
        "                company_name=info.get('longName', symbol),\n",
        "                current_price=current_price if not np.isnan(current_price) else 0.0, # Store 0 if current price is NaN\n",
        "                market_cap=info.get('marketCap', 0) if info.get('marketCap') is not None else 0, # Ensure marketCap is not None\n",
        "                info=info,\n",
        "                price_data=price_data,\n",
        "                indicators=indicators,\n",
        "                fundamental_score=fundamental_score,\n",
        "                technical_score=technical_score,\n",
        "                recommendation=recommendation,\n",
        "                metrics=metrics\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Analysis completed for {symbol}\")\n",
        "            return stock_data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def display_analysis(self, stock_data: StockData) -> None:\n",
        "        \"\"\"Display analysis results in a formatted manner\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Stock Analysis Report: {stock_data.company_name} ({stock_data.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{stock_data.current_price:,.2f}\" if stock_data.current_price is not None else \"Current Price: N/A\")\n",
        "        print(f\"Market Cap: ₹{stock_data.market_cap/10000000:,.2f} Cr\" if stock_data.market_cap is not None else \"Market Cap: N/A\") # Use stored market_cap\n",
        "        print(f\"Sector: {stock_data.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n📈 Technical Indicators:\")\n",
        "        # Display indicators, handling None values\n",
        "        for indicator, value in stock_data.indicators.items():\n",
        "            if indicator != 'current_price': # Avoid displaying current_price here\n",
        "                if value is not None and not np.isnan(value):\n",
        "                    if isinstance(value, float):\n",
        "                        print(f\"{indicator}: {value:,.2f}\")\n",
        "                    else:\n",
        "                        print(f\"{indicator}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{indicator}: N/A (Insufficient Data)\")\n",
        "\n",
        "\n",
        "        print(f\"\\n💰 Fundamental Metrics:\")\n",
        "        for metric, value in stock_data.metrics.items():\n",
        "            if metric != 'Fundamental_Score':\n",
        "                if value is not None and not np.isnan(value):\n",
        "                     if isinstance(value, float):\n",
        "                         if metric in ['ROE', 'Revenue_Growth', 'Net_Profit_Margin']:\n",
        "                             print(f\"{metric}: {value*100:.2f}%\")\n",
        "                         else:\n",
        "                             print(f\"{metric}: {value:.2f}\")\n",
        "                     else:\n",
        "                         print(f\"{metric}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{metric}: N/A (Missing Data)\")\n",
        "\n",
        "\n",
        "        print(f\"\\n📊 Analysis Scores:\")\n",
        "        print(f\"Fundamental Score: {stock_data.fundamental_score}/50\")\n",
        "        print(f\"Technical Score: {stock_data.technical_score}/50\")\n",
        "        print(f\"Total Score: {stock_data.fundamental_score + stock_data.technical_score}/100\")\n",
        "\n",
        "        print(f\"\\n🎯 Recommendation: {stock_data.recommendation}\")\n",
        "        print(f\"{'='*60}\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44704c7e"
      },
      "source": [
        "**Reasoning**:\n",
        "The instructions require enhancing the `EnhancedStockAnalyzer` class to handle missing data more consistently and add data validity checks, especially in the `get_liquidity_score` and `calculate_enhanced_technical_score` functions. This involves modifying the existing code within the class. These changes are related to the enhancements for missing data and can be logically grouped into a single code block to redefine the `EnhancedStockAnalyzer` class with the necessary improvements. The import for `google.generativeai` and `userdata` is already in the previous cell, so it should not be repeated here.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "58790296"
      },
      "source": [
        "#@title Sentimental analysis with API (Enhanced)\n",
        "# Indian Stock Analyzer - Part 2 (Improved Version with Enhanced Data Handling)\n",
        "# This continues from your Part 1 implementation\n",
        "\n",
        "# Import the Python SDK for Gemini API\n",
        "# from google.colab import userdata # Already imported in a previous cell\n",
        "# import google.generativeai as genai # Already imported in a previous cell\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import the Python SDK for Gemini API\n",
        "# Used to securely store your API key\n",
        "# from google.colab import userdata # Already imported\n",
        "# import google.generativeai as genai # Already imported\n",
        "\n",
        "# Configure Gemini API (ensure GOOGLE_API_KEY is set in Colab secrets)\n",
        "# GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') # Already done in a previous cell\n",
        "# genai.configure(api_key=GOOGLE_API_KEY) # Already done in a previous cell\n",
        "# gemini_model = genai.GenerativeModel('gemini-2.0-flash') # Using a more recent model # Already done in a previous cell\n",
        "\n",
        "\n",
        "class EnhancedStockAnalyzer:\n",
        "    \"\"\"Enhanced analyzer with additional features for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.risk_free_rate = self.get_dynamic_risk_free_rate()\n",
        "        # self.gemini_model = gemini_model # Use the globally configured model # Already assigned in a previous cell\n",
        "\n",
        "    def get_dynamic_risk_free_rate(self):\n",
        "        \"\"\"Fetch current 10-year G-Sec yield\"\"\"\n",
        "        try:\n",
        "            # Try to get from a reliable source\n",
        "            # For now, using a realistic current rate\n",
        "            # In production, you'd scrape from RBI or use an API\n",
        "            return 0.072  # 7.2% as of recent data\n",
        "        except:\n",
        "            return 0.065  # Fallback to 6.5%\n",
        "\n",
        "    def get_circuit_limits(self, symbol):\n",
        "        \"\"\"Get circuit breaker limits for the stock\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "            prev_close = info.get('previousClose', None) # Use None as default\n",
        "\n",
        "            if prev_close is None or not isinstance(prev_close, (int, float)) or np.isnan(prev_close) or prev_close <= 0:\n",
        "                logger.warning(f\"Previous close not available or invalid for {symbol}. Cannot calculate circuit limits.\")\n",
        "                return None\n",
        "\n",
        "            # NSE circuit limits (simplified)\n",
        "            # Actual limits depend on stock category\n",
        "            if symbol in ['RELIANCE.NS', 'TCS.NS', 'INFY.NS']:  # Index stocks\n",
        "                circuit_percent = 0.20  # 20% for index stocks\n",
        "            else:\n",
        "                circuit_percent = 0.10  # 10% for others\n",
        "\n",
        "            return {\n",
        "                'upper_circuit': prev_close * (1 + circuit_percent),\n",
        "                'lower_circuit': prev_close * (1 - circuit_percent),\n",
        "                'circuit_percent': circuit_percent\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting circuit limits for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def assess_circuit_risk(self, current_price, circuit_limits):\n",
        "        \"\"\"Assess proximity to circuit limits\"\"\"\n",
        "        if not circuit_limits or current_price is None or np.isnan(current_price) or current_price <= 0:\n",
        "            return 0\n",
        "\n",
        "        upper_circuit = circuit_limits.get('upper_circuit')\n",
        "        lower_circuit = circuit_limits.get('lower_circuit')\n",
        "\n",
        "        if upper_circuit is None or lower_circuit is None or np.isnan(upper_circuit) or np.isnan(lower_circuit):\n",
        "             logger.warning(\"Circuit limits are invalid, cannot assess circuit risk.\")\n",
        "             return 0\n",
        "\n",
        "        upper_distance = (upper_circuit - current_price) / current_price if current_price > 0 else float('inf')\n",
        "        lower_distance = (current_price - lower_circuit) / current_price if current_price > 0 else float('inf')\n",
        "\n",
        "\n",
        "        # Risk scoring based on proximity\n",
        "        if upper_distance < 0.02:  # Within 2% of upper circuit\n",
        "            return -20  # High risk\n",
        "        elif upper_distance < 0.05:  # Within 5%\n",
        "            return -10\n",
        "        elif lower_distance < 0.02:  # Within 2% of lower circuit\n",
        "            return -25  # Very high risk\n",
        "        elif lower_distance < 0.05:\n",
        "            return -15\n",
        "\n",
        "        return 0\n",
        "\n",
        "    def get_liquidity_score(self, price_data: pd.DataFrame) -> float:\n",
        "        \"\"\"Enhanced liquidity analysis\"\"\"\n",
        "        try:\n",
        "            # Explicitly check for sufficient data and 'Volume' column\n",
        "            if price_data.empty or 'Volume' not in price_data.columns or len(price_data) < 20:\n",
        "                 logger.warning(\"Insufficient price data or missing Volume column for liquidity calculation.\")\n",
        "                 return 5 # Assign a very low liquidity score\n",
        "\n",
        "            # Calculate various liquidity metrics\n",
        "            avg_volume_20d = price_data['Volume'].rolling(20).mean().iloc[-1]\n",
        "            avg_volume_5d = price_data['Volume'].rolling(5).mean().iloc[-1]\n",
        "            current_close = price_data['Close'].iloc[-1] if not price_data['Close'].empty else np.nan\n",
        "\n",
        "            if current_close is None or np.isnan(current_close) or current_close <= 0:\n",
        "                 logger.warning(\"Current close price is invalid for liquidity calculation.\")\n",
        "                 return 5\n",
        "\n",
        "            # Average daily turnover\n",
        "            avg_turnover_20d = avg_volume_20d * current_close if avg_volume_20d is not None and not np.isnan(avg_volume_20d) else np.nan\n",
        "\n",
        "            # Volume spike detection - handle division by zero explicitly\n",
        "            volume_spike = np.nan\n",
        "            if avg_volume_20d is not None and not np.isnan(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                volume_spike = avg_volume_5d / avg_volume_20d if avg_volume_5d is not None and not np.isnan(avg_volume_5d) else np.nan\n",
        "            elif avg_volume_5d is not None and not np.isnan(avg_volume_5d) and avg_volume_5d > 0: # Case where 20d avg is 0 but 5d is not\n",
        "                 volume_spike = 1 # Treat as normal if 20d is 0 but 5d has volume\n",
        "            else:\n",
        "                 logger.warning(\"Average volume is zero or NaN, cannot calculate volume spike.\")\n",
        "\n",
        "\n",
        "            # Volume consistency - handle division by zero explicitly\n",
        "            volume_std = price_data['Volume'].rolling(20).std().iloc[-1] if len(price_data) >= 20 else np.nan\n",
        "            volume_cv = np.nan\n",
        "            if avg_volume_20d is not None and not np.isnan(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                volume_cv = volume_std / avg_volume_20d if volume_std is not None and not np.isnan(volume_std) else np.nan\n",
        "            elif volume_std is not None and not np.isnan(volume_std) and volume_std > 0: # Case where 20d avg is 0 but std is not (unlikely but safeguard)\n",
        "                 volume_cv = 1 # Treat as high variability if avg is 0 but std is not\n",
        "            else:\n",
        "                 logger.warning(\"Average volume or volume standard deviation is zero or NaN, cannot calculate volume CV.\")\n",
        "\n",
        "\n",
        "            # Liquidity scoring\n",
        "            liquidity_score = 0\n",
        "\n",
        "            # Turnover-based scoring - handle NaN\n",
        "            if avg_turnover_20d is not None and not np.isnan(avg_turnover_20d):\n",
        "                if avg_turnover_20d > 500_00_00_000:  # > 500 Cr\n",
        "                    liquidity_score += 40\n",
        "                elif avg_turnover_20d > 100_00_00_000:  # > 100 Cr\n",
        "                    liquidity_score += 30\n",
        "                elif avg_turnover_20d > 10_00_00_000:  # > 10 Cr\n",
        "                    liquidity_score += 20\n",
        "                elif avg_turnover_20d > 1_00_00_000:  # > 1 Cr\n",
        "                    liquidity_score += 10\n",
        "                else:\n",
        "                    liquidity_score += 5\n",
        "            else:\n",
        "                 logger.warning(\"Average turnover is NaN, skipping turnover score.\")\n",
        "\n",
        "\n",
        "            # Volume consistency score - handle NaN\n",
        "            if volume_cv is not None and not np.isnan(volume_cv):\n",
        "                 if volume_cv < 0.5:  # Low volatility in volume\n",
        "                     liquidity_score += 20\n",
        "                 elif volume_cv < 1.0:\n",
        "                     liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume CV is NaN, skipping volume consistency score.\")\n",
        "\n",
        "            # Recent volume trend score - handle NaN\n",
        "            if volume_spike is not None and not np.isnan(volume_spike):\n",
        "                 if volume_spike > 1.2:  # 20% higher recent volume\n",
        "                     liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume spike is NaN, skipping recent volume trend score.\")\n",
        "\n",
        "\n",
        "            return max(5, min(liquidity_score, 70))  # Cap at 70, minimum score 5 for insufficient data\n",
        "\n",
        "        except Exception as e: # Catch specific exceptions for better debugging\n",
        "            logger.error(f\"Error calculating liquidity score: {str(e)}\")\n",
        "            return 5  # Default very low liquidity on error\n",
        "\n",
        "\n",
        "    def get_peer_companies(self, symbol, stock_info):\n",
        "        \"\"\"Identify peer companies for comparison\"\"\"\n",
        "        try:\n",
        "            sector = stock_info.get('sector', '')\n",
        "            market_cap = stock_info.get('marketCap', 0)\n",
        "\n",
        "            # Define market cap categories\n",
        "            if market_cap > 10_00_000_00_00_000:  # > 10 Lakh Cr\n",
        "                cap_category = 'Large Cap'\n",
        "            elif market_cap > 50_000_00_00_000:   # > 50K Cr\n",
        "                cap_category = 'Mid Cap'\n",
        "            else:\n",
        "                cap_category = 'Small Cap'\n",
        "\n",
        "            # Peer mapping (simplified - in production, use a comprehensive database)\n",
        "            peer_map = {\n",
        "                'Technology': {\n",
        "                    'Large Cap': ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS'],\n",
        "                    'Mid Cap': ['TECHM.NS', 'LTTS.NS', 'PERSISTENT.NS', 'COFORGE.NS'],\n",
        "                    'Small Cap': ['ZENSAR.NS', 'ECLERX.NS', 'MASTEK.NS']\n",
        "                },\n",
        "                'Financial Services': {\n",
        "                    'Large Cap': ['HDFCBANK.NS', 'ICICIBANK.NS', 'KOTAKBANK.NS', 'AXISBANK.NS'],\n",
        "                    'Mid Cap': ['IDFCFIRSTB.NS', 'FEDERALBNK.NS', 'INDUSINDBK.NS'],\n",
        "                    'Small Cap': ['SOUTHBANK.NS', 'UJJIVAN.NS', 'EQUITASBNK.NS']\n",
        "                },\n",
        "                'Healthcare': {\n",
        "                    'Large Cap': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS'],\n",
        "                    'Mid Cap': ['TORNTPHARM.NS', 'ALKEM.NS', 'LUPIN.NS'],\n",
        "                    'Small Cap': ['CAPLIPOINT.NS', 'BLISS.NS', 'INDOCO.NS']\n",
        "                }\n",
        "                # Add more sectors as needed\n",
        "            }\n",
        "\n",
        "            # Get peers, excluding the current symbol\n",
        "            peers = peer_map.get(sector, {}).get(cap_category, [])\n",
        "            peers = [p for p in peers if p != symbol]\n",
        "\n",
        "            return peers[:5]  # Return top 5 peers\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting peer companies: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def calculate_peer_relative_performance(self, symbol, peers, days=30):\n",
        "        \"\"\"Compare stock performance with peers\"\"\"\n",
        "        try:\n",
        "            results = {}\n",
        "\n",
        "            # Get performance for main stock\n",
        "            main_ticker = yf.Ticker(symbol)\n",
        "            main_hist = main_ticker.history(period=f\"{days}d\")\n",
        "            if len(main_hist) > 0 and 'Close' in main_hist.columns and not main_hist['Close'].empty:\n",
        "                main_return = ((main_hist['Close'].iloc[-1] / main_hist['Close'].iloc[0]) - 1) * 100 if main_hist['Close'].iloc[0] > 0 else np.nan\n",
        "            else:\n",
        "                main_return = np.nan\n",
        "                logger.warning(f\"Insufficient historical data for {symbol} to calculate peer relative performance.\")\n",
        "\n",
        "\n",
        "            # Get peer performances\n",
        "            peer_returns = []\n",
        "            for peer in peers:\n",
        "                try:\n",
        "                    peer_ticker = yf.Ticker(peer)\n",
        "                    peer_hist = peer_ticker.history(period=f\"{days}d\")\n",
        "                    if len(peer_hist) > 0 and 'Close' in peer_hist.columns and not peer_hist['Close'].empty and peer_hist['Close'].iloc[0] > 0:\n",
        "                        peer_return = ((peer_hist['Close'].iloc[-1] / peer_hist['Close'].iloc[0]) - 1) * 100\n",
        "                        peer_returns.append(peer_return)\n",
        "                    else:\n",
        "                         logger.warning(f\"Insufficient historical data for peer {peer}.\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Could not get peer history for {peer}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            if peer_returns and main_return is not None and not np.isnan(main_return):\n",
        "                avg_peer_return = np.mean(peer_returns)\n",
        "                relative_performance = main_return - avg_peer_return\n",
        "\n",
        "                results = {\n",
        "                    'stock_return': main_return,\n",
        "                    'avg_peer_return': avg_peer_return,\n",
        "                    'relative_performance': relative_performance,\n",
        "                    'outperformance': relative_performance > 0\n",
        "                }\n",
        "            else:\n",
        "                 logger.warning(\"Peer returns not available or main stock return is NaN, cannot calculate relative performance.\")\n",
        "\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating peer relative performance: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def get_index_membership(self, symbol):\n",
        "        \"\"\"Check index membership for the stock\"\"\"\n",
        "        # Simplified index constituents (in production, fetch from NSE)\n",
        "        index_constituents = {\n",
        "            'NIFTY50': ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS'],\n",
        "            'NIFTY_NEXT50': ['VEDL.NS', 'PNB.NS', 'INDIGO.NS', 'BANDHANBNK.NS'],\n",
        "            'NIFTY_MIDCAP150': ['PERSISTENT.NS', 'COFORGE.NS', 'LTTS.NS']\n",
        "        }\n",
        "\n",
        "        membership = []\n",
        "        for index, constituents in index_constituents.items():\n",
        "            if symbol in constituents:\n",
        "                membership.append(index)\n",
        "\n",
        "        return membership\n",
        "\n",
        "    def calculate_enhanced_technical_score(self, indicators: Dict, circuit_risk: float) -> float:\n",
        "        \"\"\"Calculate enhanced technical analysis score\"\"\"\n",
        "        base_score = 0\n",
        "        indicator_scores = {} # To store scores for each indicator\n",
        "\n",
        "        try:\n",
        "            # RSI Score (points based on significance, e.g., max 10 for oversold)\n",
        "            rsi = indicators.get('RSI', None)\n",
        "            if rsi is not None and not np.isnan(rsi):\n",
        "                 if rsi < 30: indicator_scores['RSI'] = 10 # Oversold\n",
        "                 elif 30 <= rsi < 40: indicator_scores['RSI'] = 8 # Approaching oversold\n",
        "                 elif 40 <= rsi <= 60: indicator_scores['RSI'] = 5 # Neutral zone\n",
        "                 elif 60 < rsi <= 70: indicator_scores['RSI'] = 3 # Approaching overbought\n",
        "                 else: indicator_scores['RSI'] = 1 # Overbought\n",
        "            else:\n",
        "                 indicator_scores['RSI'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"RSI not calculated or is NaN/None. Assigning 0 score for RSI.\")\n",
        "\n",
        "            # MACD scoring (points based on crossover and position relative to zero)\n",
        "            macd = indicators.get('MACD', None)\n",
        "            macd_signal = indicators.get('MACD_signal', None)\n",
        "\n",
        "            if macd is not None and macd_signal is not None and not np.isnan(macd) and not np.isnan(macd_signal):\n",
        "                 if macd > macd_signal:\n",
        "                     if macd > 0: indicator_scores['MACD'] = 10 # Bullish crossover above zero\n",
        "                     else: indicator_scores['MACD'] = 7 # Bullish crossover below zero\n",
        "                 else:\n",
        "                     if macd < 0: indicator_scores['MACD'] = 1 # Bearish crossover below zero\n",
        "                     else: indicator_scores['MACD'] = 3 # Bearish crossover above zero\n",
        "            else:\n",
        "                 indicator_scores['MACD'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"MACD or MACD signal not calculated or is NaN/None. Assigning 0 score for MACD.\")\n",
        "\n",
        "            # Moving Average Score (points based on MA crossovers and price position)\n",
        "            current_price = indicators.get('current_price', None)\n",
        "            sma_20 = indicators.get('SMA_20', None)\n",
        "            sma_50 = indicators.get('SMA_50', None)\n",
        "            sma_200 = indicators.get('SMA_200', None)\n",
        "\n",
        "            ma_score = 0\n",
        "            valid_mas = 0\n",
        "\n",
        "            if sma_20 is not None and not np.isnan(sma_20) and current_price is not None and not np.isnan(current_price):\n",
        "                 valid_mas += 1\n",
        "                 if current_price > sma_20: ma_score += 5\n",
        "                 else: ma_score += 1\n",
        "\n",
        "            if sma_50 is not None and not np.isnan(sma_50) and current_price is not None and not np.isnan(current_price):\n",
        "                 valid_mas += 1\n",
        "                 if current_price > sma_50: ma_score += 5\n",
        "                 else: ma_score += 1\n",
        "\n",
        "            if sma_200 is not None and not np.isnan(sma_200) and current_price is not None and not np.isnan(current_price):\n",
        "                 valid_mas += 1\n",
        "                 if current_price > sma_200: ma_score += 5\n",
        "                 else: ma_score += 1\n",
        "\n",
        "            # Add points for bullish crossovers\n",
        "            if sma_20 is not None and sma_50 is not None and not np.isnan(sma_20) and not np.isnan(sma_50):\n",
        "                 if sma_20 > sma_50: ma_score += 5\n",
        "\n",
        "            if sma_50 is not None and sma_200 is not None and not np.isnan(sma_50) and not np.isnan(sma_200):\n",
        "                 if sma_50 > sma_200: ma_score += 5\n",
        "\n",
        "            indicator_scores['Moving_Averages'] = ma_score # Max possible MA score is 25 (5+5+5 for price > MA + 5+5 for crossovers)\n",
        "\n",
        "            if valid_mas == 0:\n",
        "                 logger.warning(\"No valid Moving Averages calculated. Assigning 0 score for Moving Averages.\")\n",
        "                 indicator_scores['Moving_Averages'] = 0\n",
        "\n",
        "\n",
        "            # Bollinger Bands Score (points based on price position relative to bands)\n",
        "            bb_upper = indicators.get('BB_upper', None)\n",
        "            bb_lower = indicators.get('BB_lower', None)\n",
        "            bb_middle = indicators.get('BB_middle', None)\n",
        "\n",
        "            if current_price is not None and bb_upper is not None and bb_lower is not None and bb_middle is not None and \\\n",
        "               not np.isnan(current_price) and not np.isnan(bb_upper) and not np.isnan(bb_lower) and not np.isnan(bb_middle):\n",
        "                if current_price < bb_lower: indicator_scores['Bollinger_Bands'] = 10 # Price below lower band (potential buy signal)\n",
        "                elif bb_lower <= current_price < bb_middle: indicator_scores['Bollinger_Bands'] = 7 # Between lower and middle band\n",
        "                elif bb_middle <= current_price < bb_upper: indicator_scores['Bollinger_Bands'] = 3 # Between middle and upper band\n",
        "                else: indicator_scores['Bollinger_Bands'] = 1 # Price above upper band (potential sell signal)\n",
        "            else:\n",
        "                 indicator_scores['Bollinger_Bands'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Bollinger Bands or current price not available or is NaN/None. Assigning 0 score for Bollinger Bands.\")\n",
        "\n",
        "\n",
        "            # Volume Score (points based on volume relative to average)\n",
        "            volume_ratio = indicators.get('Volume_ratio', None)\n",
        "            if volume_ratio is not None and not np.isnan(volume_ratio):\n",
        "                 if volume_ratio > 1.5: indicator_scores['Volume'] = 10 # High volume\n",
        "                 elif 0.8 <= volume_ratio <= 1.5: indicator_scores['Volume'] = 7 # Normal volume\n",
        "                 else: indicator_scores['Volume'] = 3 # Low volume\n",
        "            else:\n",
        "                 indicator_scores['Volume'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Volume ratio not calculated or is NaN/None. Assigning 0 score for Volume.\")\n",
        "\n",
        "            # Sum the scores from individual indicators\n",
        "            base_score = sum(indicator_scores.values())\n",
        "\n",
        "            # Add circuit risk adjustment (already handled as negative points)\n",
        "            final_score = base_score + circuit_risk\n",
        "\n",
        "            # Ensure score is within 0-50 range (assuming max base_score is around 50 based on point allocation)\n",
        "            # Max possible indicator score (10+10+25+10+10) = 65. Let's normalize this to 50.\n",
        "            normalized_base_score = (base_score / 65.0) * 50.0 if base_score > 0 else 0\n",
        "            final_score = normalized_base_score + circuit_risk\n",
        "\n",
        "\n",
        "            return max(0, min(final_score, 50))\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating enhanced technical score: {str(e)}\")\n",
        "            return 0\n",
        "\n",
        "\n",
        "    def fetch_news(self, symbol: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Fetches recent news headlines for the given stock symbol.\n",
        "        NOTE: This is a placeholder. In a real application, you would integrate\n",
        "        with a News API (like News API, Alpha Vantage, etc.) here.\n",
        "        \"\"\"\n",
        "        print(f\"Fetching news for {symbol} (placeholder)...\")\n",
        "        # Placeholder news headlines - replace with actual API call\n",
        "        return [\n",
        "            f\"{symbol} stock price rises on positive market sentiment\",\n",
        "            f\"{symbol} announces strong quarterly results, beating estimates\",\n",
        "            f\"Experts bullish on {symbol}'s future outlook\",\n",
        "            f\"{symbol} faces regulatory challenges in key market\",\n",
        "            f\"Competitor's new product launch impacts {symbol}'s market share\",\n",
        "            f\"Global market trends positively impacting {symbol}\",\n",
        "            f\"{symbol} management provides optimistic guidance\",\n",
        "            f\"Increased foreign investment flows into {symbol}\",\n",
        "            f\"Regulatory approval received for {symbol}'s new product\",\n",
        "            f\"Production issues reported for {symbol}\",\n",
        "            f\"Increased competition puts pressure on {symbol}'s margins\",\n",
        "            f\"Analyst downgrades rating for {symbol}\",\n",
        "            f\"Supply chain disruptions affect {symbol}'s operations\",\n",
        "            f\"Geopolitical tensions create uncertainty for {symbol}\",\n",
        "            f\"{symbol} announces stock split\",\n",
        "            f\"Dividend declared by {symbol}\"\n",
        "        ]\n",
        "\n",
        "\n",
        "    def analyze_sentiment(self, news_headlines: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of news headlines using the Gemini API.\n",
        "        Returns a dictionary with sentiment counts (positive, neutral, negative)\n",
        "        and a sentiment score.\n",
        "        \"\"\"\n",
        "        # Use the globally defined gemini_model\n",
        "        if not 'gemini_model' in globals() or not gemini_model or not news_headlines:\n",
        "            print(\"Gemini API not configured or no news to analyze. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis skipped.'}\n",
        "\n",
        "        logger.info(\"Analyzing sentiment using Gemini API...\")\n",
        "        prompt = \"Analyze the sentiment of the following news headlines for a stock and categorize each as Positive, Neutral, or Negative. Provide a concise summary of the overall sentiment.\\n\\n\"\n",
        "        for headline in news_headlines:\n",
        "            prompt += f\"- {headline}\\n\"\n",
        "        prompt += \"\\nSentiment Analysis Results (Categorization and Summary):\\n\"\n",
        "\n",
        "        try:\n",
        "            response = gemini_model.generate_content(prompt)\n",
        "            sentiment_text = response.text.strip()\n",
        "            logger.info(f\"Gemini API Response: {sentiment_text[:200]}...\") # Log first 200 chars\n",
        "\n",
        "            # Parse the response to count sentiments and extract summary\n",
        "            positive_count = sentiment_text.lower().count('positive')\n",
        "            neutral_count = sentiment_text.lower().count('neutral')\n",
        "            negative_count = sentiment_text.lower().count('negative')\n",
        "\n",
        "            # Attempt to extract a summary line - this is a heuristic\n",
        "            summary_line = \"No summary extracted.\"\n",
        "            lines = sentiment_text.split('\\n')\n",
        "            for line in lines:\n",
        "                 lower_line = line.lower()\n",
        "                 if 'summary' in lower_line or 'overall sentiment' in lower_line:\n",
        "                     summary_line = line.strip()\n",
        "                     break\n",
        "            if summary_line == \"No summary extracted.\" and lines:\n",
        "                 # If no explicit summary found, take the last non-empty line as a potential summary\n",
        "                 for line in reversed(lines):\n",
        "                     if line.strip():\n",
        "                         summary_line = line.strip()\n",
        "                         break\n",
        "\n",
        "\n",
        "            total_headlines = len(news_headlines)\n",
        "            if total_headlines > 0:\n",
        "                # Scoring based on the ratio of positive vs negative headlines, scaled to 25 points\n",
        "                # (Positive - Negative) / Total * 12.5 + 12.5 -> Range 0-25\n",
        "                sentiment_score = ((positive_count - negative_count) / total_headlines) * 12.5 + 12.5\n",
        "            else:\n",
        "                sentiment_score = 12.5 # Neutral score if no headlines\n",
        "\n",
        "            return {\n",
        "                'positive': positive_count,\n",
        "                'neutral': neutral_count,\n",
        "                'negative': negative_count,\n",
        "                'score': max(0, min(sentiment_score, 25)), # Cap score between 0 and 25\n",
        "                'summary': summary_line\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing sentiment with Gemini API: {e}. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis failed.'}\n",
        "\n",
        "\n",
        "    def generate_enhanced_recommendation(self, fundamental_score, technical_score,\n",
        "                                       liquidity_score, peer_performance, index_membership,\n",
        "                                       sentiment_analysis_results):\n",
        "        \"\"\"Generate comprehensive recommendation including sentiment\"\"\"\n",
        "        sentiment_score = sentiment_analysis_results.get('score', 0)\n",
        "        total_score = fundamental_score + technical_score + liquidity_score + sentiment_score # Add sentiment score\n",
        "\n",
        "        # Adjust for peer performance\n",
        "        if peer_performance.get('outperformance', False):\n",
        "            total_score += 5\n",
        "\n",
        "        # Bonus for index membership\n",
        "        if index_membership:\n",
        "            total_score += 5\n",
        "\n",
        "        # Max possible score is 50 (Fundamental) + 50 (Technical) + 70 (Liquidity) + 25 (Sentiment) + 5 (Peer) + 5 (Index) = 205\n",
        "        # Let's re-evaluate the recommendation thresholds based on this potential range\n",
        "\n",
        "        if total_score >= 160: # Example Thresholds (adjust as needed)\n",
        "            recommendation = \"STRONG BUY\"\n",
        "            confidence = \"High\"\n",
        "        elif total_score >= 130:\n",
        "            recommendation = \"BUY\"\n",
        "            confidence = \"Moderate to High\"\n",
        "        elif total_score >= 90:\n",
        "            recommendation = \"HOLD\"\n",
        "            confidence = \"Moderate\"\n",
        "        elif total_score >= 60:\n",
        "            return \"SELL\"\n",
        "        else:\n",
        "            return \"STRONG SELL\"\n",
        "\n",
        "        return {\n",
        "            'recommendation': recommendation,\n",
        "            'confidence': confidence,\n",
        "            'total_score': total_score,\n",
        "            'breakdown': {\n",
        "                'fundamental': fundamental_score,\n",
        "                'technical': technical_score,\n",
        "                'liquidity': liquidity_score,\n",
        "                'sentiment': sentiment_score\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "\n",
        "    # Get basic analysis from Part 1\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        return None\n",
        "\n",
        "    # Get current price\n",
        "    current_price = stock_data.current_price\n",
        "\n",
        "    # Enhanced analysis\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "\n",
        "    # 3. Peer analysis\n",
        "    peers = enhanced_analyzer.get_peer_companies(symbol, stock_data.info)\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peers)\n",
        "\n",
        "    # 4. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "\n",
        "    # 5. Recalculate technical score with circuit risk\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "\n",
        "    # 6. Fetch and analyze news sentiment\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "\n",
        "\n",
        "    # 7. Generate enhanced recommendation\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance,\n",
        "        index_membership,\n",
        "        sentiment_analysis_results # Pass sentiment analysis results\n",
        "    )\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score,\n",
        "            'peers': peers,\n",
        "            'peer_performance': peer_performance,\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage (removed from here as it's part of the next display step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2accd066"
      },
      "source": [
        "**Reasoning**:\n",
        "The final part of the instructions is to display the results from both Part 1 and the enhanced analysis (Part 2) together and then finish the subtask. This involves calling the enhanced analysis function and then printing the combined report.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "a5ec692f"
      },
      "source": [
        "#@title Analyze a stock and display the combined results\n",
        "symbol_to_analyze = \"RELIANCE.NS\" # You can change this symbol\n",
        "\n",
        "# Ensure both analyzers are instantiated (they should be if the cells above were run)\n",
        "# If not, you might need to re-run the cells defining IndianStockAnalyzer and EnhancedStockAnalyzer\n",
        "try:\n",
        "    stock_analyzer = IndianStockAnalyzer()\n",
        "    enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "except NameError:\n",
        "    print(\"Please run the cells defining IndianStockAnalyzer and EnhancedStockAnalyzer first.\")\n",
        "    # Exit or handle the error appropriately if classes are not defined\n",
        "    stock_analyzer = None\n",
        "    enhanced_analyzer = None\n",
        "\n",
        "\n",
        "if stock_analyzer and enhanced_analyzer:\n",
        "    combined_analysis_report = analyze_stock_enhanced(symbol_to_analyze, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if combined_analysis_report:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Combined Stock Analysis Report for {symbol_to_analyze}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Display basic analysis results\n",
        "        basic = combined_analysis_report['basic_analysis']\n",
        "        print(f\"\\n--- Basic Analysis (from Part 1) ---\")\n",
        "        print(f\"Company Name: {basic.company_name}\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if basic.current_price is not None else \"Current Price: N/A\")\n",
        "        print(f\"Market Cap: ₹{basic.market_cap/10000000:,.2f} Cr\" if basic.market_cap is not None else \"Market Cap: N/A\") # Use stored market_cap\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "        print(f\"Fundamental Score: {basic.fundamental_score}/50\")\n",
        "        print(f\"Technical Score: {basic.technical_score}/50\")\n",
        "        print(f\"Basic Recommendation: {basic.recommendation}\")\n",
        "        print(\"\\nFundamental Metrics:\")\n",
        "        for metric, value in basic.metrics.items():\n",
        "             if metric != 'Fundamental_Score':\n",
        "                if value is not None and not np.isnan(value):\n",
        "                     if isinstance(value, float):\n",
        "                         if metric in ['ROE', 'Revenue_Growth', 'Net_Profit_Margin']:\n",
        "                             print(f\"{metric}: {value*100:.2f}%\")\n",
        "                         else:\n",
        "                             print(f\"{metric}: {value:.2f}\")\n",
        "                     else:\n",
        "                         print(f\"{metric}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{metric}: N/A (Missing Data)\")\n",
        "\n",
        "\n",
        "        print(\"\\nTechnical Indicators:\")\n",
        "        for indicator, value in basic.indicators.items():\n",
        "             if indicator != 'current_price':\n",
        "                if value is not None and not np.isnan(value):\n",
        "                    if isinstance(value, float):\n",
        "                        print(f\"{indicator}: {value:,.2f}\")\n",
        "                    else:\n",
        "                        print(f\"{indicator}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{indicator}: N/A (Insufficient Data)\")\n",
        "\n",
        "\n",
        "        # Display enhanced features and final recommendation\n",
        "        enhanced = combined_analysis_report['enhanced_features']\n",
        "        final = combined_analysis_report['final_recommendation']\n",
        "\n",
        "        print(f\"\\n--- Enhanced Analysis (from Part 2) ---\")\n",
        "        print(f\"Circuit Limits: {enhanced.get('circuit_limits', {}).get('lower_circuit', 'N/A'):.2f} - {enhanced.get('circuit_limits', {}).get('upper_circuit', 'N/A'):.2f}\" if enhanced.get('circuit_limits') else \"Circuit Limits: N/A\")\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        print(f\"Liquidity Score: {enhanced.get('liquidity_score', 'N/A')}/70\")\n",
        "\n",
        "        if enhanced.get('peers'):\n",
        "            print(f\"Peer Companies: {', '.join(enhanced['peers'])}\")\n",
        "            if enhanced.get('peer_performance'):\n",
        "                print(f\"30-day Return: {enhanced['peer_performance'].get('stock_return', 'N/A'):.2f}%\" if enhanced['peer_performance'].get('stock_return') is not None else \"30-day Return: N/A\")\n",
        "                print(f\"Peer Avg Return: {enhanced['peer_performance'].get('avg_peer_return', 'N/A'):.2f}%\" if enhanced['peer_performance'].get('avg_peer_return') is not None else \"Peer Avg Return: N/A\")\n",
        "                print(f\"Relative Performance: {enhanced['peer_performance'].get('relative_performance', 'N/A'):.2f}%\" if enhanced['peer_performance'].get('relative_performance') is not None else \"Relative Performance: N/A\")\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             for headline in enhanced['news_headlines']:\n",
        "                 print(f\"- {headline}\")\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             print(f\"Sentiment Score: {sentiment_results.get('score', 0):.2f}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Final Recommendation ---\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} ({final.get('confidence', 'N/A')})\")\n",
        "        print(f\"Total Score: {final.get('total_score', 0):.2f}/205\")\n",
        "        print(\"Score Breakdown:\")\n",
        "        print(f\"  - Fundamental: {final.get('breakdown', {}).get('fundamental', 'N/A'):.2f}\")\n",
        "        print(f\"  - Technical (Enhanced): {final.get('breakdown', {}).get('technical', 'N/A')}\") # Technical score might not be float always\n",
        "        print(f\"  - Liquidity: {final.get('breakdown', {}).get('liquidity', 'N/A'):.2f}\")\n",
        "        print(f\"  - Sentiment: {final.get('breakdown', {}).get('sentiment', 'N/A'):.2f}\")\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Could not generate combined analysis report for {symbol_to_analyze}.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13b85718"
      },
      "source": [
        "## Improve debt-to-equity validation\n",
        "\n",
        "### Subtask:\n",
        "Refine the logic for validating and interpreting the Debt-to-Equity ratio, considering different data formats and potential outliers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fd2423d"
      },
      "source": [
        "**Reasoning**:\n",
        "Refine the logic for validating and interpreting the Debt-to-Equity ratio, considering different data formats and potential outliers based on the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "245801b0"
      },
      "source": [
        "#@title Part 1 of Main script (Enhanced Debt-to-Equity)\n",
        "# Indian Stock Analyzer - Part 1 (Corrected and Enhanced further)\n",
        "# Complete implementation with improvements for missing data handling and Debt-to-Equity validation\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import logging\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__) # Define logger globally\n",
        "\n",
        "@dataclass\n",
        "class StockData:\n",
        "    \"\"\"Data class to store comprehensive stock information\"\"\"\n",
        "    symbol: str\n",
        "    company_name: str\n",
        "    current_price: float\n",
        "    market_cap: float\n",
        "    info: Dict\n",
        "    price_data: pd.DataFrame\n",
        "    indicators: Dict\n",
        "    fundamental_score: float\n",
        "    technical_score: float\n",
        "    recommendation: str\n",
        "    metrics: Dict\n",
        "\n",
        "class IndianStockAnalyzer:\n",
        "    \"\"\"Comprehensive stock analyzer for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the analyzer with Indian market specific parameters\"\"\"\n",
        "        self.nifty_symbol = \"^NSEI\"\n",
        "        self.risk_free_rate = 0.065  # Will be made dynamic in Part 2\n",
        "\n",
        "        # Industry-specific benchmark thresholds for Indian markets\n",
        "        self.industry_benchmarks = {\n",
        "            'technology': {\n",
        "                'pe_ratio': {'excellent': 25, 'good': 35, 'fair': 45},\n",
        "                'debt_to_equity': {'excellent': 0.3, 'good': 0.5, 'fair': 0.8},\n",
        "                'roe': {'excellent': 0.25, 'good': 0.18, 'fair': 0.12},\n",
        "                'revenue_growth': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10}\n",
        "            },\n",
        "            'banking': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 20, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 8, 'good': 10, 'fair': 12},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.25, 'good': 0.20, 'fair': 0.15}\n",
        "            },\n",
        "            'pharmaceutical': {\n",
        "                'pe_ratio': {'excellent': 20, 'good': 30, 'fair': 40},\n",
        "                'debt_to_equity': {'excellent': 0.4, 'good': 0.6, 'fair': 0.8},\n",
        "                'roe': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.08}\n",
        "            },\n",
        "            'fmcg': {\n",
        "                'pe_ratio': {'excellent': 30, 'good': 40, 'fair': 50},\n",
        "                'debt_to_equity': {'excellent': 0.5, 'good': 0.8, 'fair': 1.0},\n",
        "                'roe': {'excellent': 0.30, 'good': 0.25, 'fair': 0.15},\n",
        "                'revenue_growth': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.08}\n",
        "            },\n",
        "            'automobile': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "                'debt_to_equity': {'excellent': 0.6, 'good': 0.8, 'fair': 1.2},\n",
        "                'roe': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "            },\n",
        "            'infrastructure': {\n",
        "                'pe_ratio': {'excellent': 12, 'good': 18, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05}\n",
        "            },\n",
        "            'energy': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 15, 'fair': 20},\n",
        "                'debt_to_equity': {'excellent': 0.8, 'good': 1.2, 'fair': 1.5},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "            },\n",
        "            'realty': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 15, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05},\n",
        "                'revenue_growth': {'excellent': 0.25, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05}\n",
        "            },\n",
        "            'telecom': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05},\n",
        "                'revenue_growth': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.08, 'good': 0.05, 'fair': 0.03}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Default benchmarks for other sectors\n",
        "        self.default_benchmarks = {\n",
        "            'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "            'debt_to_equity': {'excellent': 0.5, 'good': 1.0, 'fair': 1.5},\n",
        "            'roe': {'excellent': 0.15, 'good': 0.10, 'fair': 0.07},\n",
        "            'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "            'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "        }\n",
        "\n",
        "    def get_stock_data(self, symbol: str) -> Optional[yf.Ticker]:\n",
        "        \"\"\"Fetch stock data from Yahoo Finance\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            # Verify the ticker is valid by checking if it has info\n",
        "            if ticker.info and 'symbol' in ticker.info:\n",
        "                return ticker\n",
        "            else:\n",
        "                logger.error(f\"Invalid symbol: {symbol}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error fetching data for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_industry_benchmarks(self, sector: str) -> Dict:\n",
        "        \"\"\"Get industry-specific benchmarks\"\"\"\n",
        "        sector_lower = sector.lower() if sector else ''\n",
        "\n",
        "        # Map common sector names to our benchmark categories\n",
        "        sector_mapping = {\n",
        "            'technology': 'technology',\n",
        "            'information technology': 'technology',\n",
        "            'financial services': 'banking',\n",
        "            'financials': 'banking',\n",
        "            'healthcare': 'pharmaceutical',\n",
        "            'consumer defensive': 'fmcg',\n",
        "            'consumer cyclical': 'automobile',\n",
        "            'industrials': 'infrastructure',\n",
        "            'energy': 'energy',\n",
        "            'real estate': 'realty',\n",
        "            'communication services': 'telecom'\n",
        "        }\n",
        "\n",
        "        benchmark_key = sector_mapping.get(sector_lower, None)\n",
        "\n",
        "        if benchmark_key and benchmark_key in self.industry_benchmarks:\n",
        "            return self.industry_benchmarks[benchmark_key]\n",
        "        else:\n",
        "            logger.info(f\"Using default benchmarks for sector: {sector}\")\n",
        "            return self.default_benchmarks\n",
        "\n",
        "    def calculate_technical_indicators(self, price_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate comprehensive technical indicators\"\"\"\n",
        "        indicators = {}\n",
        "        data_len = len(price_data)\n",
        "\n",
        "        try:\n",
        "            # Simple Moving Averages\n",
        "            if data_len >= 20:\n",
        "                 indicators['SMA_20'] = price_data['Close'].rolling(window=20).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['SMA_20'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_20.\")\n",
        "\n",
        "            if data_len >= 50:\n",
        "                 indicators['SMA_50'] = price_data['Close'].rolling(window=50).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['SMA_50'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_50.\")\n",
        "\n",
        "            if data_len >= 200:\n",
        "                 indicators['SMA_200'] = price_data['Close'].rolling(window=200).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['SMA_200'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_200.\")\n",
        "\n",
        "            # Exponential Moving Averages\n",
        "            if data_len >= 12:\n",
        "                 indicators['EMA_12'] = price_data['Close'].ewm(span=12, adjust=False).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['EMA_12'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for EMA_12.\")\n",
        "\n",
        "            if data_len >= 26:\n",
        "                 indicators['EMA_26'] = price_data['Close'].ewm(span=26, adjust=False).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['EMA_26'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for EMA_26.\")\n",
        "\n",
        "            # RSI\n",
        "            if data_len >= 14:\n",
        "                indicators['RSI'] = self.calculate_rsi(price_data['Close'])\n",
        "            else:\n",
        "                 indicators['RSI'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for RSI.\")\n",
        "\n",
        "            # MACD (requires EMA_12 and EMA_26)\n",
        "            macd_line = np.nan\n",
        "            signal_line = np.nan\n",
        "            macd_histogram = np.nan\n",
        "\n",
        "            if 'EMA_12' in indicators and 'EMA_26' in indicators and not np.isnan(indicators['EMA_12']) and not np.isnan(indicators['EMA_26']):\n",
        "                 # Use the entire macd_line series for rolling calculation if possible\n",
        "                 full_macd_line_series = price_data['Close'].ewm(span=12, adjust=False).mean() - price_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "                 if len(full_macd_line_series.dropna()) >= 9:\n",
        "                      macd_line = full_macd_line_series.iloc[-1]\n",
        "                      signal_line = full_macd_line_series.ewm(span=9, adjust=False).mean().iloc[-1]\n",
        "                      if not np.isnan(signal_line):\n",
        "                         macd_histogram = macd_line - signal_line\n",
        "                 else:\n",
        "                      logger.warning(\"Insufficient data for MACD signal line calculation.\")\n",
        "            else:\n",
        "                 logger.warning(\"MACD not calculated due to missing EMA_12 or EMA_26.\")\n",
        "\n",
        "\n",
        "            indicators['MACD'] = macd_line\n",
        "            indicators['MACD_signal'] = signal_line\n",
        "            indicators['MACD_histogram'] = macd_histogram\n",
        "\n",
        "            # Log MACD values after calculation\n",
        "            logger.info(f\"Calculated MACD: {indicators['MACD']}, Signal: {indicators['MACD_signal']}\")\n",
        "\n",
        "\n",
        "            # Bollinger Bands (requires SMA_20 and enough data for std dev)\n",
        "            bb_period = 20\n",
        "            bb_std = 2\n",
        "            if data_len >= bb_period:\n",
        "                sma_bb = price_data['Close'].rolling(window=bb_period).mean()\n",
        "                std_bb = price_data['Close'].rolling(window=bb_period).std()\n",
        "                # Ensure SMA and STD are not NaN before calculating bands\n",
        "                if not np.isnan(sma_bb.iloc[-1]) and not np.isnan(std_bb.iloc[-1]):\n",
        "                    indicators['BB_upper'] = sma_bb.iloc[-1] + (std_bb.iloc[-1] * bb_std)\n",
        "                    indicators['BB_lower'] = sma_bb.iloc[-1] - (std_bb.iloc[-1] * bb_std)\n",
        "                    indicators['BB_middle'] = sma_bb.iloc[-1]\n",
        "                else:\n",
        "                    indicators['BB_upper'] = np.nan\n",
        "                    indicators['BB_lower'] = np.nan\n",
        "                    indicators['BB_middle'] = np.nan\n",
        "                    logger.warning(\"Bollinger Bands not calculated due to NaN in SMA or STD.\")\n",
        "            else:\n",
        "                indicators['BB_upper'] = np.nan\n",
        "                indicators['BB_lower'] = np.nan\n",
        "                indicators['BB_middle'] = np.nan\n",
        "                logger.warning(\"Insufficient data for Bollinger Bands.\")\n",
        "\n",
        "\n",
        "            # Volume indicators\n",
        "            if data_len >= 20:\n",
        "                 indicators['Volume_SMA'] = price_data['Volume'].rolling(window=20).mean().iloc[-1]\n",
        "                 if indicators['Volume_SMA'] is not None and not np.isnan(indicators['Volume_SMA']) and indicators['Volume_SMA'] > 0:\n",
        "                      indicators['Volume_ratio'] = price_data['Volume'].iloc[-1] / indicators['Volume_SMA']\n",
        "                 else:\n",
        "                      indicators['Volume_ratio'] = np.nan\n",
        "                      logger.warning(\"Volume SMA is zero or NaN, Volume ratio not calculated.\")\n",
        "            else:\n",
        "                 indicators['Volume_SMA'] = np.nan\n",
        "                 indicators['Volume_ratio'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for Volume SMA and ratio.\")\n",
        "\n",
        "\n",
        "            # Price position (requires SMA_20 and SMA_50)\n",
        "            current_price = price_data['Close'].iloc[-1] if data_len > 0 and 'Close' in price_data and not price_data['Close'].empty else np.nan\n",
        "            indicators['current_price'] = current_price # Store current price\n",
        "\n",
        "            if current_price is not None and not np.isnan(current_price) and 'SMA_20' in indicators and indicators['SMA_20'] is not None and not np.isnan(indicators['SMA_20']) and indicators['SMA_20'] > 0:\n",
        "                indicators['Price_to_SMA20'] = ((current_price / indicators['SMA_20'] - 1) * 100)\n",
        "            else:\n",
        "                 indicators['Price_to_SMA20'] = np.nan\n",
        "                 logger.warning(\"Price to SMA20 not calculated due to missing current price or SMA20.\")\n",
        "\n",
        "            if current_price is not None and not np.isnan(current_price) and 'SMA_50' in indicators and indicators['SMA_50'] is not None and not np.isnan(indicators['SMA_50']) and indicators['SMA_50'] > 0:\n",
        "                 indicators['Price_to_SMA50'] = ((current_price / indicators['SMA_50'] - 1) * 100)\n",
        "            else:\n",
        "                 indicators['Price_to_SMA50'] = np.nan\n",
        "                 logger.warning(\"Price to SMA50 not calculated due to missing current price or SMA50.\")\n",
        "\n",
        "\n",
        "            # Support and Resistance (requires enough data for rolling max/min)\n",
        "            if data_len >= 20:\n",
        "                 indicators['Resistance'] = price_data['High'].rolling(window=20).max().iloc[-1]\n",
        "                 indicators['Support'] = price_data['Low'].rolling(window=20).min().iloc[-1]\n",
        "            else:\n",
        "                 indicators['Resistance'] = np.nan\n",
        "                 indicators['Support'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for Support and Resistance.\")\n",
        "\n",
        "\n",
        "            return indicators\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating technical indicators: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> Optional[float]:\n",
        "        \"\"\"Calculate Relative Strength Index\"\"\"\n",
        "        try:\n",
        "            if len(prices) < period:\n",
        "                return np.nan # Return NaN for insufficient data\n",
        "\n",
        "            delta = prices.diff()\n",
        "            gain = delta.where(delta > 0, 0)\n",
        "            loss = -delta.where(delta < 0, 0)\n",
        "\n",
        "            avg_gain = gain.rolling(window=period).mean()\n",
        "            avg_loss = loss.rolling(window=period).mean()\n",
        "\n",
        "            # Handle division by zero if avg_loss is zero or NaN\n",
        "            if avg_loss.iloc[-1] is None or np.isnan(avg_loss.iloc[-1]) or avg_loss.iloc[-1] == 0:\n",
        "                 return 100.0 if avg_gain.iloc[-1] is not None and not np.isnan(avg_gain.iloc[-1]) and avg_gain.iloc[-1] > 0 else 50.0 # If no loss, RSI is 100 (if gain) or 50 (if no change)\n",
        "            elif avg_loss.iloc[-1] > 0:\n",
        "                rs = avg_gain / avg_loss\n",
        "                rsi = 100 - (100 / (1 + rs))\n",
        "                return rsi.iloc[-1]\n",
        "            else:\n",
        "                 return np.nan # Should not happen with abs, but as a safeguard\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating RSI: {str(e)}\")\n",
        "            return np.nan # Return NaN on error\n",
        "\n",
        "    def calculate_fundamental_score(self, info: Dict, benchmarks: Dict) -> Tuple[float, Dict]:\n",
        "        \"\"\"Calculate fundamental analysis score based on Indian market standards\"\"\"\n",
        "        score = 0\n",
        "        max_score = 50\n",
        "        metrics = {}\n",
        "\n",
        "        try:\n",
        "            # P/E Ratio (10 points)\n",
        "            pe_ratio = info.get('trailingPE', info.get('forwardPE', None))\n",
        "            if pe_ratio is not None and isinstance(pe_ratio, (int, float)) and not np.isnan(pe_ratio):\n",
        "                metrics['PE_Ratio'] = pe_ratio\n",
        "                if pe_ratio > 0: # Ensure PE is positive for scoring\n",
        "                     if pe_ratio <= benchmarks['pe_ratio']['excellent']:\n",
        "                         score += 10\n",
        "                     elif pe_ratio <= benchmarks['pe_ratio']['good']:\n",
        "                         score += 7\n",
        "                     elif pe_ratio <= benchmarks['pe_ratio']['fair']:\n",
        "                         score += 4\n",
        "                     else:\n",
        "                         score += 2\n",
        "                else:\n",
        "                    score += 1 # Small score for non-positive PE\n",
        "            else:\n",
        "                 metrics['PE_Ratio'] = np.nan\n",
        "                 logger.warning(\"PE Ratio not available or is invalid.\")\n",
        "\n",
        "\n",
        "            # Debt to Equity (10 points)\n",
        "            debt_to_equity_raw = info.get('debtToEquity', None)\n",
        "            debt_to_equity = np.nan # Initialize to NaN\n",
        "\n",
        "            if debt_to_equity_raw is not None and isinstance(debt_to_equity_raw, (int, float)) and not np.isnan(debt_to_equity_raw):\n",
        "                 # Handle potential outliers (very high values might indicate data issues)\n",
        "                 if debt_to_equity_raw > 10000: # Arbitrary large threshold for outlier detection\n",
        "                      logger.warning(f\"Debt to Equity raw value is unusually high: {debt_to_equity_raw}. Treating as potential data issue.\")\n",
        "                      # Could assign a very low score or NaN, depending on policy\n",
        "                      debt_to_equity = np.nan # Treat as invalid data for now\n",
        "                 else:\n",
        "                      # Heuristic for percentage vs decimal\n",
        "                      if debt_to_equity_raw > 100: # Likely a percentage\n",
        "                           debt_to_equity = debt_to_equity_raw / 100.0\n",
        "                      else: # Assume it's already a decimal\n",
        "                           debt_to_equity = debt_to_equity_raw\n",
        "\n",
        "                      # Re-check if the converted value is still reasonable (e.g., not from a huge raw decimal)\n",
        "                      if debt_to_equity > 100: # Another threshold after conversion\n",
        "                          logger.warning(f\"Debt to Equity value after conversion is still very high: {debt_to_equity:.2f}. May indicate data issue or highly leveraged company.\")\n",
        "                          # Could assign a low score or cap it, for now let the scoring handle it.\n",
        "\n",
        "\n",
        "            metrics['Debt_to_Equity'] = debt_to_equity\n",
        "\n",
        "            # Score based on the validated debt_to_equity\n",
        "            if debt_to_equity is not None and not np.isnan(debt_to_equity):\n",
        "                if debt_to_equity <= benchmarks['debt_to_equity']['excellent']:\n",
        "                    score += 10\n",
        "                elif debt_to_equity <= benchmarks['debt_to_equity']['good']:\n",
        "                    score += 7\n",
        "                elif debt_to_equity <= benchmarks['debt_to_equity']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2\n",
        "            else:\n",
        "                 logger.warning(\"Debt to Equity not available, invalid, or an outlier. Assigning low score.\")\n",
        "                 score += 1 # Assign minimal score if D/E is not valid\n",
        "\n",
        "\n",
        "            # ROE (10 points)\n",
        "            roe = info.get('returnOnEquity', None)\n",
        "            if roe is not None and isinstance(roe, (int, float)) and not np.isnan(roe):\n",
        "                metrics['ROE'] = roe\n",
        "                if roe >= benchmarks['roe']['excellent']:\n",
        "                    score += 10\n",
        "                elif roe >= benchmarks['roe']['good']:\n",
        "                    score += 7\n",
        "                elif roe >= benchmarks['roe']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2\n",
        "            else:\n",
        "                 metrics['ROE'] = np.nan\n",
        "                 logger.warning(\"ROE not available or is invalid.\")\n",
        "\n",
        "            # Revenue Growth (10 points)\n",
        "            revenue_growth = info.get('revenueGrowth', None)\n",
        "            if revenue_growth is not None and isinstance(revenue_growth, (int, float)) and not np.isnan(revenue_growth):\n",
        "                metrics['Revenue_Growth'] = revenue_growth\n",
        "                if revenue_growth >= benchmarks['revenue_growth']['excellent']:\n",
        "                    score += 10\n",
        "                elif revenue_growth >= benchmarks['revenue_growth']['good']:\n",
        "                    score += 7\n",
        "                elif revenue_growth >= benchmarks['revenue_growth']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2\n",
        "            else:\n",
        "                 metrics['Revenue_Growth'] = np.nan\n",
        "                 logger.warning(\"Revenue Growth not available or is invalid.\")\n",
        "\n",
        "            # Net Profit Margin (10 points)\n",
        "            profit_margin = info.get('profitMargins', None)\n",
        "            if profit_margin is not None and isinstance(profit_margin, (int, float)) and not np.isnan(profit_margin):\n",
        "                metrics['Net_Profit_Margin'] = profit_margin\n",
        "                if profit_margin >= benchmarks['net_profit_margin']['excellent']:\n",
        "                    score += 10\n",
        "                elif profit_margin >= benchmarks['net_profit_margin']['good']:\n",
        "                    score += 7\n",
        "                elif profit_margin >= benchmarks['net_profit_margin']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2\n",
        "            else:\n",
        "                 metrics['Net_Profit_Margin'] = np.nan\n",
        "                 logger.warning(\"Net Profit Margin not available or is invalid.\")\n",
        "\n",
        "\n",
        "            # Normalize score to max_score (already capped by scoring logic)\n",
        "            metrics['Fundamental_Score'] = score\n",
        "\n",
        "            return score, metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating fundamental score: {str(e)}\")\n",
        "            return 0, {}\n",
        "\n",
        "    def calculate_technical_score(self, indicators: Dict) -> float:\n",
        "        \"\"\"Calculate technical analysis score\"\"\"\n",
        "        score = 0\n",
        "        max_score = 50\n",
        "        indicator_scores = {} # To store scores for each indicator\n",
        "\n",
        "        try:\n",
        "            # RSI Score (10 points)\n",
        "            rsi = indicators.get('RSI', None)\n",
        "            if rsi is not None and not np.isnan(rsi):\n",
        "                 if 40 <= rsi <= 60:  # Neutral zone\n",
        "                     indicator_scores['RSI'] = 7\n",
        "                 elif rsi < 40:  # Oversold\n",
        "                     indicator_scores['RSI'] = 10\n",
        "                 elif 60 < rsi <= 70:  # Overbought but not extreme\n",
        "                     indicator_scores['RSI'] = 5\n",
        "                 else:  # Extreme levels\n",
        "                     indicator_scores['RSI'] = 2\n",
        "            else:\n",
        "                 indicator_scores['RSI'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"RSI not calculated or is NaN/None. Assigning 0 score for RSI.\")\n",
        "\n",
        "\n",
        "            # MACD Score (10 points)\n",
        "            macd = indicators.get('MACD', None)\n",
        "            macd_signal = indicators.get('MACD_signal', None)\n",
        "\n",
        "            # Explicitly check if both are numbers before comparing\n",
        "            if isinstance(macd, (int, float)) and isinstance(macd_signal, (int, float)) and not np.isnan(macd) and not np.isnan(macd_signal):\n",
        "                 if macd > macd_signal:\n",
        "                     indicator_scores['MACD'] = 10\n",
        "                 else:\n",
        "                     indicator_scores['MACD'] = 3\n",
        "            else:\n",
        "                 indicator_scores['MACD'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"MACD or MACD signal not calculated or is not a valid number. Assigning 0 score for MACD.\")\n",
        "\n",
        "\n",
        "            # Moving Average Score (10 points) - Using SMA_20 vs SMA_50\n",
        "            sma_20 = indicators.get('SMA_20', None)\n",
        "            sma_50 = indicators.get('SMA_50', None)\n",
        "            if sma_20 is not None and sma_50 is not None and not np.isnan(sma_20) and not np.isnan(sma_50):\n",
        "                if sma_20 > sma_50:\n",
        "                    indicator_scores['Moving_Averages'] = 10\n",
        "                else:\n",
        "                    indicator_scores['Moving_Averages'] = 3\n",
        "            else:\n",
        "                indicator_scores['Moving_Averages'] = 0 # Assign 0 if NaN/None\n",
        "                logger.warning(\"SMA_20 or SMA_50 not calculated or is NaN/None. Assigning 0 score for Moving Averages.\")\n",
        "\n",
        "            # Bollinger Bands Score (10 points)\n",
        "            current_price = indicators.get('current_price', None) # Assuming current_price is passed in indicators\n",
        "            bb_upper = indicators.get('BB_upper', None)\n",
        "            bb_lower = indicators.get('BB_lower', None)\n",
        "            bb_middle = indicators.get('BB_middle', None)\n",
        "\n",
        "            if current_price is not None and bb_upper is not None and bb_lower is not None and bb_middle is not None and \\\n",
        "               not np.isnan(current_price) and not np.isnan(bb_upper) and not np.isnan(bb_lower) and not np.isnan(bb_middle):\n",
        "                if bb_lower < current_price < bb_middle:\n",
        "                    indicator_scores['Bollinger_Bands'] = 10  # Good buying zone\n",
        "                elif bb_middle < current_price < bb_upper:\n",
        "                    indicator_scores['Bollinger_Bands'] = 7   # Neutral to positive\n",
        "                else:\n",
        "                    indicator_scores['Bollinger_Bands'] = 3   # Near extremes\n",
        "            else:\n",
        "                 indicator_scores['Bollinger_Bands'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Bollinger Bands or current price not available or is NaN/None. Assigning 0 score for Bollinger Bands.\")\n",
        "\n",
        "\n",
        "            # Volume Score (10 points)\n",
        "            volume_ratio = indicators.get('Volume_ratio', None)\n",
        "            if volume_ratio is not None and not np.isnan(volume_ratio):\n",
        "                 if 0.8 <= volume_ratio <= 1.5:\n",
        "                     indicator_scores['Volume'] = 7   # Normal volume\n",
        "                 elif volume_ratio > 1.5:\n",
        "                     indicator_scores['Volume'] = 10  # High volume (positive if with price up)\n",
        "                 else:\n",
        "                     indicator_scores['Volume'] = 3   # Low volume\n",
        "            else:\n",
        "                 indicator_scores['Volume'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Volume ratio not calculated or is NaN/None. Assigning 0 score for Volume.\")\n",
        "\n",
        "            # Sum the scores from individual indicators\n",
        "            score = sum(indicator_scores.values())\n",
        "\n",
        "            return min(score, max_score) # Cap at max_score\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating technical score: {str(e)}\")\n",
        "            return 0\n",
        "\n",
        "    def generate_recommendation(self, fundamental_score: float, technical_score: float) -> str:\n",
        "        \"\"\"Generate investment recommendation based on scores\"\"\"\n",
        "        total_score = fundamental_score + technical_score\n",
        "\n",
        "        if total_score >= 75:\n",
        "            return \"STRONG BUY\"\n",
        "        elif total_score >= 60:\n",
        "            return \"BUY\"\n",
        "        elif total_score >= 40:\n",
        "            return \"HOLD\"\n",
        "        elif total_score >= 25:\n",
        "            return \"SELL\"\n",
        "        else:\n",
        "            return \"STRONG SELL\"\n",
        "\n",
        "    def analyze_stock(self, symbol: str) -> Optional[StockData]:\n",
        "        \"\"\"Main method to analyze a stock\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Starting analysis for {symbol}\")\n",
        "\n",
        "            # Get stock data\n",
        "            ticker = self.get_stock_data(symbol)\n",
        "            if not ticker:\n",
        "                return None\n",
        "\n",
        "            # Get stock info\n",
        "            info = ticker.info\n",
        "            if not info:\n",
        "                logger.error(f\"No info available for {symbol}\")\n",
        "                return None\n",
        "\n",
        "            # Get historical price data\n",
        "            # Fetching enough data for 200-day SMA calculation\n",
        "            price_data = ticker.history(period=\"1y\") # Changed to 1 year to support 200-day SMA\n",
        "            if price_data.empty: # Check if price_data is empty\n",
        "                logger.error(f\"No price data available for {symbol}\")\n",
        "                return None\n",
        "            # Also check for essential columns\n",
        "            if not all(col in price_data.columns for col in ['Open', 'High', 'Low', 'Close', 'Volume']):\n",
        "                 logger.error(f\"Price data for {symbol} is missing essential columns.\")\n",
        "                 return None\n",
        "\n",
        "\n",
        "            # Get current price\n",
        "            current_price = price_data['Close'].iloc[-1] if not price_data['Close'].empty else np.nan\n",
        "\n",
        "            # Add current price to indicators for technical score calculation\n",
        "            indicators = self.calculate_technical_indicators(price_data)\n",
        "            indicators['current_price'] = current_price # Ensure current price is available for BB score\n",
        "\n",
        "            # Get industry benchmarks\n",
        "            sector = info.get('sector', 'Unknown')\n",
        "            benchmarks = self.get_industry_benchmarks(sector)\n",
        "\n",
        "            # Calculate scores\n",
        "            fundamental_score, metrics = self.calculate_fundamental_score(info, benchmarks)\n",
        "            technical_score = self.calculate_technical_score(indicators)\n",
        "\n",
        "            # Generate recommendation\n",
        "            recommendation = self.generate_recommendation(fundamental_score, technical_score)\n",
        "\n",
        "            # Create StockData object\n",
        "            stock_data = StockData(\n",
        "                symbol=symbol,\n",
        "                company_name=info.get('longName', symbol),\n",
        "                current_price=current_price if not np.isnan(current_price) else 0.0, # Store 0 if current price is NaN\n",
        "                market_cap=info.get('marketCap', 0) if info.get('marketCap') is not None else 0, # Ensure marketCap is not None\n",
        "                info=info,\n",
        "                price_data=price_data,\n",
        "                indicators=indicators,\n",
        "                fundamental_score=fundamental_score,\n",
        "                technical_score=technical_score,\n",
        "                recommendation=recommendation,\n",
        "                metrics=metrics\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Analysis completed for {symbol}\")\n",
        "            return stock_data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def display_analysis(self, stock_data: StockData) -> None:\n",
        "        \"\"\"Display analysis results in a formatted manner\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Stock Analysis Report: {stock_data.company_name} ({stock_data.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{stock_data.current_price:,.2f}\" if stock_data.current_price is not None else \"Current Price: N/A\")\n",
        "        print(f\"Market Cap: ₹{stock_data.market_cap/10000000:,.2f} Cr\" if stock_data.market_cap is not None else \"Market Cap: N/A\") # Use stored market_cap\n",
        "        print(f\"Sector: {stock_data.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n📈 Technical Indicators:\")\n",
        "        # Display indicators, handling None values\n",
        "        for indicator, value in stock_data.indicators.items():\n",
        "            if indicator != 'current_price': # Avoid displaying current_price here\n",
        "                if value is not None and not np.isnan(value):\n",
        "                    if isinstance(value, float):\n",
        "                        print(f\"{indicator}: {value:,.2f}\")\n",
        "                    else:\n",
        "                        print(f\"{indicator}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{indicator}: N/A (Insufficient Data)\")\n",
        "\n",
        "\n",
        "        print(f\"\\n💰 Fundamental Metrics:\")\n",
        "        for metric, value in stock_data.metrics.items():\n",
        "            if metric != 'Fundamental_Score':\n",
        "                if value is not None and not np.isnan(value):\n",
        "                     if isinstance(value, float):\n",
        "                         if metric in ['ROE', 'Revenue_Growth', 'Net_Profit_Margin', 'Debt_to_Equity']:\n",
        "                             print(f\"{metric}: {value*100:.2f}%\") # Display as percentage for D/E, ROE, Growth, Margin\n",
        "                         else:\n",
        "                             print(f\"{metric}: {value:.2f}\")\n",
        "                     else:\n",
        "                         print(f\"{metric}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{metric}: N/A (Missing Data)\")\n",
        "\n",
        "\n",
        "        print(f\"\\n📊 Analysis Scores:\")\n",
        "        print(f\"Fundamental Score: {stock_data.fundamental_score}/50\")\n",
        "        print(f\"Technical Score: {stock_data.technical_score}/50\")\n",
        "        print(f\"Total Score: {stock_data.fundamental_score + stock_data.technical_score}/100\")\n",
        "\n",
        "        print(f\"\\n🎯 Recommendation: {stock_data.recommendation}\")\n",
        "        print(f\"{'='*60}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b1332ba"
      },
      "source": [
        "## Enhance circuit limit calculation\n",
        "\n",
        "### Subtask:\n",
        "Make the circuit limit calculation more accurate by potentially fetching real-time circuit percentages or using more sophisticated logic based on exchange rules.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e175c3e9"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `get_circuit_limits` function in the `EnhancedStockAnalyzer` class to enhance the accuracy of circuit limit calculation by categorizing stocks based on index membership and applying different default percentages. Document the limitations in a comment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "136351ae"
      },
      "source": [
        "#@title Sentimental analysis with API (Enhanced Circuit Limits)\n",
        "# Indian Stock Analyzer - Part 2 (Improved Version with Enhanced Circuit Limits)\n",
        "# This continues from your Part 1 implementation\n",
        "\n",
        "# Import the Python SDK for Gemini API\n",
        "# from google.colab import userdata # Already imported in a previous cell\n",
        "# import google.generativeai as genai # Already imported in a previous cell\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import the Python SDK for Gemini API\n",
        "# Used to securely store your API key\n",
        "# from google.colab import userdata # Already imported\n",
        "# import google.generativeai as genai # Already imported\n",
        "\n",
        "# Configure Gemini API (ensure GOOGLE_API_KEY is set in Colab secrets)\n",
        "# GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') # Already done in a previous cell\n",
        "# genai.configure(api_key=GOOGLE_API_KEY) # Already done in a previous cell\n",
        "# gemini_model = genai.GenerativeModel('gemini-2.0-flash') # Using a more recent model # Already done in a previous cell\n",
        "\n",
        "\n",
        "class EnhancedStockAnalyzer:\n",
        "    \"\"\"Enhanced analyzer with additional features for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.risk_free_rate = self.get_dynamic_risk_free_rate()\n",
        "        # self.gemini_model = gemini_model # Use the globally configured model # Already assigned in a previous cell\n",
        "\n",
        "    def get_dynamic_risk_free_rate(self):\n",
        "        \"\"\"Fetch current 10-year G-Sec yield\"\"\"\n",
        "        try:\n",
        "            # Try to get from a reliable source\n",
        "            # For now, using a realistic current rate\n",
        "            # In production, you'd scrape from RBI or use an API\n",
        "            return 0.072  # 7.2% as of recent data\n",
        "        except:\n",
        "            return 0.065  # Fallback to 6.5%\n",
        "\n",
        "    def get_circuit_limits(self, symbol):\n",
        "        \"\"\"\n",
        "        Get circuit breaker limits for the stock.\n",
        "        NOTE: This is a simplification. Actual NSE circuit limits vary based on\n",
        "        stock category (e.g., EQ, BE, T group), stage of price band reduction,\n",
        "        and are dynamic. Relying on fixed percentages based on index membership\n",
        "        is an approximation. For production, fetch from NSE or a reliable API.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "            prev_close = info.get('previousClose', None) # Use None as default\n",
        "\n",
        "            if prev_close is None or not isinstance(prev_close, (int, float)) or np.isnan(prev_close) or prev_close <= 0:\n",
        "                logger.warning(f\"Previous close not available or invalid for {symbol}. Cannot calculate circuit limits.\")\n",
        "                return None\n",
        "\n",
        "            # Enhanced NSE circuit limits (based on index membership approximation)\n",
        "            # This is still a simplification of complex exchange rules.\n",
        "            circuit_percent = 0.10 # Default to 10%\n",
        "\n",
        "            # Check if the stock is in a major index for higher limits\n",
        "            if symbol in self.get_index_membership(symbol): # Reuse existing index check\n",
        "                 if 'NIFTY50' in self.get_index_membership(symbol):\n",
        "                      circuit_percent = 0.20 # 20% for NIFTY50 stocks\n",
        "                 elif 'NIFTY_NEXT50' in self.get_index_membership(symbol):\n",
        "                      circuit_percent = 0.15 # Example: 15% for NIFTY Next 50 (approximation)\n",
        "\n",
        "\n",
        "            return {\n",
        "                'upper_circuit': prev_close * (1 + circuit_percent),\n",
        "                'lower_circuit': prev_close * (1 - circuit_percent),\n",
        "                'circuit_percent': circuit_percent\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting circuit limits for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def assess_circuit_risk(self, current_price, circuit_limits):\n",
        "        \"\"\"Assess proximity to circuit limits\"\"\"\n",
        "        if not circuit_limits or current_price is None or np.isnan(current_price) or current_price <= 0:\n",
        "            return 0\n",
        "\n",
        "        upper_circuit = circuit_limits.get('upper_circuit')\n",
        "        lower_circuit = circuit_limits.get('lower_circuit')\n",
        "\n",
        "        if upper_circuit is None or lower_circuit is None or np.isnan(upper_circuit) or np.isnan(lower_circuit):\n",
        "             logger.warning(\"Circuit limits are invalid, cannot assess circuit risk.\")\n",
        "             return 0\n",
        "\n",
        "        upper_distance = (upper_circuit - current_price) / current_price if current_price > 0 else float('inf')\n",
        "        lower_distance = (current_price - lower_circuit) / current_price if current_price > 0 else float('inf')\n",
        "\n",
        "\n",
        "        # Risk scoring based on proximity\n",
        "        if upper_distance < 0.02:  # Within 2% of upper circuit\n",
        "            return -20  # High risk\n",
        "        elif upper_distance < 0.05:  # Within 5%\n",
        "            return -10\n",
        "        elif lower_distance < 0.02:  # Within 2% of lower circuit\n",
        "            return -25  # Very high risk\n",
        "        elif lower_distance < 0.05:\n",
        "            return -15\n",
        "\n",
        "        return 0\n",
        "\n",
        "    def get_liquidity_score(self, price_data: pd.DataFrame) -> float:\n",
        "        \"\"\"Enhanced liquidity analysis\"\"\"\n",
        "        try:\n",
        "            # Explicitly check for sufficient data and 'Volume' column\n",
        "            if price_data.empty or 'Volume' not in price_data.columns or len(price_data) < 20:\n",
        "                 logger.warning(\"Insufficient price data or missing Volume column for liquidity calculation.\")\n",
        "                 return 5 # Assign a very low liquidity score\n",
        "\n",
        "            # Calculate various liquidity metrics\n",
        "            avg_volume_20d = price_data['Volume'].rolling(20).mean().iloc[-1]\n",
        "            avg_volume_5d = price_data['Volume'].rolling(5).mean().iloc[-1]\n",
        "            current_close = price_data['Close'].iloc[-1] if not price_data['Close'].empty else np.nan\n",
        "\n",
        "            if current_close is None or np.isnan(current_close) or current_close <= 0:\n",
        "                 logger.warning(\"Current close price is invalid for liquidity calculation.\")\n",
        "                 return 5\n",
        "\n",
        "            # Average daily turnover\n",
        "            avg_turnover_20d = avg_volume_20d * current_close if avg_volume_20d is not None and not np.isnan(avg_volume_20d) else np.nan\n",
        "\n",
        "            # Volume spike detection - handle division by zero explicitly\n",
        "            volume_spike = np.nan\n",
        "            if avg_volume_20d is not None and not np.isnan(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                volume_spike = avg_volume_5d / avg_volume_20d if avg_volume_5d is not None and not np.isnan(avg_volume_5d) else np.nan\n",
        "            elif avg_volume_5d is not None and not np.isnan(avg_volume_5d) and avg_volume_5d > 0: # Case where 20d avg is 0 but 5d is not\n",
        "                 volume_spike = 1 # Treat as normal if 20d is 0 but 5d has volume\n",
        "            else:\n",
        "                 logger.warning(\"Average volume is zero or NaN, cannot calculate volume spike.\")\n",
        "\n",
        "\n",
        "            # Volume consistency - handle division by zero explicitly\n",
        "            volume_std = price_data['Volume'].rolling(20).std().iloc[-1] if len(price_data) >= 20 else np.nan\n",
        "            volume_cv = np.nan\n",
        "            if avg_volume_20d is not None and not np.isnan(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                volume_cv = volume_std / avg_volume_20d if volume_std is not None and not np.isnan(volume_std) else np.nan\n",
        "            elif volume_std is not None and not np.isnan(volume_std) and volume_std > 0: # Case where 20d avg is 0 but std is not (unlikely but safeguard)\n",
        "                 volume_cv = 1 # Treat as high variability if avg is 0 but std is not\n",
        "            else:\n",
        "                 logger.warning(\"Average volume or volume standard deviation is zero or NaN, cannot calculate volume CV.\")\n",
        "\n",
        "\n",
        "            # Liquidity scoring\n",
        "            liquidity_score = 0\n",
        "\n",
        "            # Turnover-based scoring - handle NaN\n",
        "            if avg_turnover_20d is not None and not np.isnan(avg_turnover_20d):\n",
        "                if avg_turnover_20d > 500_00_00_000:  # > 500 Cr\n",
        "                    liquidity_score += 40\n",
        "                elif avg_turnover_20d > 100_00_00_000:  # > 100 Cr\n",
        "                    liquidity_score += 30\n",
        "                elif avg_turnover_20d > 10_00_00_000:  # > 10 Cr\n",
        "                    liquidity_score += 20\n",
        "                elif avg_turnover_20d > 1_00_00_000:  # > 1 Cr\n",
        "                    liquidity_score += 10\n",
        "                else:\n",
        "                    liquidity_score += 5\n",
        "            else:\n",
        "                 logger.warning(\"Average turnover is NaN, skipping turnover score.\")\n",
        "\n",
        "\n",
        "            # Volume consistency score - handle NaN\n",
        "            if volume_cv is not None and not np.isnan(volume_cv):\n",
        "                 if volume_cv < 0.5:  # Low volatility in volume\n",
        "                     liquidity_score += 20\n",
        "                 elif volume_cv < 1.0:\n",
        "                     liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume CV is NaN, skipping volume consistency score.\")\n",
        "\n",
        "            # Recent volume trend score - handle NaN\n",
        "            if volume_spike is not None and not np.isnan(volume_spike):\n",
        "                 if volume_spike > 1.2:  # 20% higher recent volume\n",
        "                     liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume spike is NaN, skipping recent volume trend score.\")\n",
        "\n",
        "\n",
        "            return max(5, min(liquidity_score, 70))  # Cap at 70, minimum score 5 for insufficient data\n",
        "\n",
        "        except Exception as e: # Catch specific exceptions for better debugging\n",
        "            logger.error(f\"Error calculating liquidity score: {str(e)}\")\n",
        "            return 5  # Default very low liquidity on error\n",
        "\n",
        "\n",
        "    def get_peer_companies(self, symbol, stock_info):\n",
        "        \"\"\"Identify peer companies for comparison\"\"\"\n",
        "        try:\n",
        "            sector = stock_info.get('sector', '')\n",
        "            market_cap = stock_info.get('marketCap', 0)\n",
        "\n",
        "            # Define market cap categories\n",
        "            if market_cap > 10_00_000_00_00_000:  # > 10 Lakh Cr\n",
        "                cap_category = 'Large Cap'\n",
        "            elif market_cap > 50_000_00_00_000:   # > 50K Cr\n",
        "                cap_category = 'Mid Cap'\n",
        "            else:\n",
        "                cap_category = 'Small Cap'\n",
        "\n",
        "            # Peer mapping (simplified - in production, use a comprehensive database)\n",
        "            peer_map = {\n",
        "                'Technology': {\n",
        "                    'Large Cap': ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS'],\n",
        "                    'Mid Cap': ['TECHM.NS', 'LTTS.NS', 'PERSISTENT.NS', 'COFORGE.NS'],\n",
        "                    'Small Cap': ['ZENSAR.NS', 'ECLERX.NS', 'MASTEK.NS']\n",
        "                },\n",
        "                'Financial Services': {\n",
        "                    'Large Cap': ['HDFCBANK.NS', 'ICICIBANK.NS', 'KOTAKBANK.NS', 'AXISBANK.NS'],\n",
        "                    'Mid Cap': ['IDFCFIRSTB.NS', 'FEDERALBNK.NS', 'INDUSINDBK.NS'],\n",
        "                    'Small Cap': ['SOUTHBANK.NS', 'UJJIVAN.NS', 'EQUITASBNK.NS']\n",
        "                },\n",
        "                'Healthcare': {\n",
        "                    'Large Cap': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS'],\n",
        "                    'Mid Cap': ['TORNTPHARM.NS', 'ALKEM.NS', 'LUPIN.NS'],\n",
        "                    'Small Cap': ['CAPLIPOINT.NS', 'BLISS.NS', 'INDOCO.NS']\n",
        "                }\n",
        "                # Add more sectors as needed\n",
        "            }\n",
        "\n",
        "            # Get peers, excluding the current symbol\n",
        "            peers = peer_map.get(sector, {}).get(cap_category, [])\n",
        "            peers = [p for p in peers if p != symbol]\n",
        "\n",
        "            return peers[:5]  # Return top 5 peers\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting peer companies: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def calculate_peer_relative_performance(self, symbol, peers, days=30):\n",
        "        \"\"\"Compare stock performance with peers\"\"\"\n",
        "        try:\n",
        "            results = {}\n",
        "\n",
        "            # Get performance for main stock\n",
        "            main_ticker = yf.Ticker(symbol)\n",
        "            main_hist = main_ticker.history(period=f\"{days}d\")\n",
        "            if len(main_hist) > 0 and 'Close' in main_hist.columns and not main_hist['Close'].empty:\n",
        "                main_return = ((main_hist['Close'].iloc[-1] / main_hist['Close'].iloc[0]) - 1) * 100 if main_hist['Close'].iloc[0] > 0 else np.nan\n",
        "            else:\n",
        "                main_return = np.nan\n",
        "                logger.warning(f\"Insufficient historical data for {symbol} to calculate peer relative performance.\")\n",
        "\n",
        "\n",
        "            # Get peer performances\n",
        "            peer_returns = []\n",
        "            for peer in peers:\n",
        "                try:\n",
        "                    peer_ticker = yf.Ticker(peer)\n",
        "                    peer_hist = peer_ticker.history(period=f\"{days}d\")\n",
        "                    if len(peer_hist) > 0 and 'Close' in peer_hist.columns and not peer_hist['Close'].empty and peer_hist['Close'].iloc[0] > 0:\n",
        "                        peer_return = ((peer_hist['Close'].iloc[-1] / peer_hist['Close'].iloc[0]) - 1) * 100\n",
        "                        peer_returns.append(peer_return)\n",
        "                    else:\n",
        "                         logger.warning(f\"Insufficient historical data for peer {peer}.\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Could not get peer history for {peer}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            if peer_returns and main_return is not None and not np.isnan(main_return):\n",
        "                avg_peer_return = np.mean(peer_returns)\n",
        "                relative_performance = main_return - avg_peer_return\n",
        "\n",
        "                results = {\n",
        "                    'stock_return': main_return,\n",
        "                    'avg_peer_return': avg_peer_return,\n",
        "                    'relative_performance': relative_performance,\n",
        "                    'outperformance': relative_performance > 0\n",
        "                }\n",
        "            else:\n",
        "                 logger.warning(\"Peer returns not available or main stock return is NaN, cannot calculate relative performance.\")\n",
        "\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating peer relative performance: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def get_index_membership(self, symbol):\n",
        "        \"\"\"Check index membership for the stock\"\"\"\n",
        "        # Simplified index constituents (in production, fetch from NSE)\n",
        "        index_constituents = {\n",
        "            'NIFTY50': ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS'],\n",
        "            'NIFTY_NEXT50': ['VEDL.NS', 'PNB.NS', 'INDIGO.NS', 'BANDHANBNK.NS'],\n",
        "            'NIFTY_MIDCAP150': ['PERSISTENT.NS', 'COFORGE.NS', 'LTTS.NS']\n",
        "        }\n",
        "\n",
        "        membership = []\n",
        "        for index, constituents in index_constituents.items():\n",
        "            if symbol in constituents:\n",
        "                membership.append(index)\n",
        "\n",
        "        return membership\n",
        "\n",
        "    def calculate_enhanced_technical_score(self, indicators: Dict, circuit_risk: float) -> float:\n",
        "        \"\"\"Calculate enhanced technical analysis score\"\"\"\n",
        "        base_score = 0\n",
        "        indicator_scores = {} # To store scores for each indicator\n",
        "\n",
        "        try:\n",
        "            # RSI Score (points based on significance, e.g., max 10 for oversold)\n",
        "            rsi = indicators.get('RSI', None)\n",
        "            if rsi is not None and not np.isnan(rsi):\n",
        "                 if rsi < 30: indicator_scores['RSI'] = 10 # Oversold\n",
        "                 elif 30 <= rsi < 40: indicator_scores['RSI'] = 8 # Approaching oversold\n",
        "                 elif 40 <= rsi <= 60: indicator_scores['RSI'] = 5 # Neutral zone\n",
        "                 elif 60 < rsi <= 70: indicator_scores['RSI'] = 3 # Approaching overbought\n",
        "                 else: indicator_scores['RSI'] = 1 # Overbought\n",
        "            else:\n",
        "                 indicator_scores['RSI'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"RSI not calculated or is NaN/None. Assigning 0 score for RSI.\")\n",
        "\n",
        "            # MACD scoring (points based on crossover and position relative to zero)\n",
        "            macd = indicators.get('MACD', None)\n",
        "            macd_signal = indicators.get('MACD_signal', None)\n",
        "\n",
        "            if macd is not None and macd_signal is not None and not np.isnan(macd) and not np.isnan(macd_signal):\n",
        "                 if macd > macd_signal:\n",
        "                     if macd > 0: indicator_scores['MACD'] = 10 # Bullish crossover above zero\n",
        "                     else: indicator_scores['MACD'] = 7 # Bullish crossover below zero\n",
        "                 else:\n",
        "                     if macd < 0: indicator_scores['MACD'] = 1 # Bearish crossover below zero\n",
        "                     else: indicator_scores['MACD'] = 3 # Bearish crossover above zero\n",
        "            else:\n",
        "                 indicator_scores['MACD'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"MACD or MACD signal not calculated or is NaN/None. Assigning 0 score for MACD.\")\n",
        "\n",
        "            # Moving Average Score (points based on MA crossovers and price position)\n",
        "            current_price = indicators.get('current_price', None)\n",
        "            sma_20 = indicators.get('SMA_20', None)\n",
        "            sma_50 = indicators.get('SMA_50', None)\n",
        "            sma_200 = indicators.get('SMA_200', None)\n",
        "\n",
        "            ma_score = 0\n",
        "            valid_mas = 0\n",
        "\n",
        "            if sma_20 is not None and not np.isnan(sma_20) and current_price is not None and not np.isnan(current_price):\n",
        "                 valid_mas += 1\n",
        "                 if current_price > sma_20: ma_score += 5\n",
        "                 else: ma_score += 1\n",
        "\n",
        "            if sma_50 is not None and not np.isnan(sma_50) and current_price is not None and not np.isnan(current_price):\n",
        "                 valid_mas += 1\n",
        "                 if current_price > sma_50: ma_score += 5\n",
        "                 else: ma_score += 1\n",
        "\n",
        "            if sma_200 is not None and not np.isnan(sma_200) and current_price is not None and not np.isnan(current_price):\n",
        "                 valid_mas += 1\n",
        "                 if current_price > sma_200: ma_score += 5\n",
        "                 else: ma_score += 1\n",
        "\n",
        "            # Add points for bullish crossovers\n",
        "            if sma_20 is not None and sma_50 is not None and not np.isnan(sma_20) and not np.isnan(sma_50):\n",
        "                 if sma_20 > sma_50: ma_score += 5\n",
        "\n",
        "            if sma_50 is not None and sma_200 is not None and not np.isnan(sma_50) and not np.isnan(sma_200):\n",
        "                 if sma_50 > sma_200: ma_score += 5\n",
        "\n",
        "            indicator_scores['Moving_Averages'] = ma_score # Max possible MA score is 25 (5+5+5 for price > MA + 5+5 for crossovers)\n",
        "\n",
        "            if valid_mas == 0:\n",
        "                 logger.warning(\"No valid Moving Averages calculated. Assigning 0 score for Moving Averages.\")\n",
        "                 indicator_scores['Moving_Averages'] = 0\n",
        "\n",
        "\n",
        "            # Bollinger Bands Score (points based on price position relative to bands)\n",
        "            bb_upper = indicators.get('BB_upper', None)\n",
        "            bb_lower = indicators.get('BB_lower', None)\n",
        "            bb_middle = indicators.get('BB_middle', None)\n",
        "\n",
        "            if current_price is not None and bb_upper is not None and bb_lower is not None and bb_middle is not None and \\\n",
        "               not np.isnan(current_price) and not np.isnan(bb_upper) and not np.isnan(bb_lower) and not np.isnan(bb_middle):\n",
        "                if current_price < bb_lower: indicator_scores['Bollinger_Bands'] = 10 # Price below lower band (potential buy signal)\n",
        "                elif bb_lower <= current_price < bb_middle: indicator_scores['Bollinger_Bands'] = 7 # Between lower and middle band\n",
        "                elif bb_middle <= current_price < bb_upper: indicator_scores['Bollinger_Bands'] = 3 # Between middle and upper band\n",
        "                else: indicator_scores['Bollinger_Bands'] = 1 # Price above upper band (potential sell signal)\n",
        "            else:\n",
        "                 indicator_scores['Bollinger_Bands'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Bollinger Bands or current price not available or is NaN/None. Assigning 0 score for Bollinger Bands.\")\n",
        "\n",
        "\n",
        "            # Volume Score (points based on volume relative to average)\n",
        "            volume_ratio = indicators.get('Volume_ratio', None)\n",
        "            if volume_ratio is not None and not np.isnan(volume_ratio):\n",
        "                 if volume_ratio > 1.5: indicator_scores['Volume'] = 10 # High volume\n",
        "                 elif 0.8 <= volume_ratio <= 1.5: indicator_scores['Volume'] = 7 # Normal volume\n",
        "                 else: indicator_scores['Volume'] = 3 # Low volume\n",
        "            else:\n",
        "                 indicator_scores['Volume'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Volume ratio not calculated or is NaN/None. Assigning 0 score for Volume.\")\n",
        "\n",
        "            # Sum the scores from individual indicators\n",
        "            base_score = sum(indicator_scores.values())\n",
        "\n",
        "            # Add circuit risk adjustment (already handled as negative points)\n",
        "            final_score = base_score + circuit_risk\n",
        "\n",
        "            # Ensure score is within 0-50 range (assuming max base_score is around 50 based on point allocation)\n",
        "            # Max possible indicator score (10+10+25+10+10) = 65. Let's normalize this to 50.\n",
        "            normalized_base_score = (base_score / 65.0) * 50.0 if base_score > 0 else 0\n",
        "            final_score = normalized_base_score + circuit_risk\n",
        "\n",
        "\n",
        "            return max(0, min(final_score, 50))\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating enhanced technical score: {str(e)}\")\n",
        "            return 0\n",
        "\n",
        "\n",
        "    def fetch_news(self, symbol: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Fetches recent news headlines for the given stock symbol.\n",
        "        NOTE: This is a placeholder. In a real application, you would integrate\n",
        "        with a News API (like News API, Alpha Vantage, etc.) here.\n",
        "        \"\"\"\n",
        "        print(f\"Fetching news for {symbol} (placeholder)...\")\n",
        "        # Placeholder news headlines - replace with actual API call\n",
        "        return [\n",
        "            f\"{symbol} stock price rises on positive market sentiment\",\n",
        "            f\"{symbol} announces strong quarterly results, beating estimates\",\n",
        "            f\"Experts bullish on {symbol}'s future outlook\",\n",
        "            f\"{symbol} faces regulatory challenges in key market\",\n",
        "            f\"Competitor's new product launch impacts {symbol}'s market share\",\n",
        "            f\"Global market trends positively impacting {symbol}\",\n",
        "            f\"{symbol} management provides optimistic guidance\",\n",
        "            f\"Increased foreign investment flows into {symbol}\",\n",
        "            f\"Regulatory approval received for {symbol}'s new product\",\n",
        "            f\"Production issues reported for {symbol}\",\n",
        "            f\"Increased competition puts pressure on {symbol}'s margins\",\n",
        "            f\"Analyst downgrades rating for {symbol}\",\n",
        "            f\"Supply chain disruptions affect {symbol}'s operations\",\n",
        "            f\"Geopolitical tensions create uncertainty for {symbol}\",\n",
        "            f\"{symbol} announces stock split\",\n",
        "            f\"Dividend declared by {symbol}\"\n",
        "        ]\n",
        "\n",
        "\n",
        "    def analyze_sentiment(self, news_headlines: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of news headlines using the Gemini API.\n",
        "        Returns a dictionary with sentiment counts (positive, neutral, negative)\n",
        "        and a sentiment score.\n",
        "        \"\"\"\n",
        "        # Use the globally defined gemini_model\n",
        "        if not 'gemini_model' in globals() or not gemini_model or not news_headlines:\n",
        "            print(\"Gemini API not configured or no news to analyze. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis skipped.'}\n",
        "\n",
        "        logger.info(\"Analyzing sentiment using Gemini API...\")\n",
        "        prompt = \"Analyze the sentiment of the following news headlines for a stock and categorize each as Positive, Neutral, or Negative. Provide a concise summary of the overall sentiment.\\n\\n\"\n",
        "        for headline in news_headlines:\n",
        "            prompt += f\"- {headline}\\n\"\n",
        "        prompt += \"\\nSentiment Analysis Results (Categorization and Summary):\\n\"\n",
        "\n",
        "        try:\n",
        "            response = gemini_model.generate_content(prompt)\n",
        "            sentiment_text = response.text.strip()\n",
        "            logger.info(f\"Gemini API Response: {sentiment_text[:200]}...\") # Log first 200 chars\n",
        "\n",
        "            # Parse the response to count sentiments and extract summary\n",
        "            positive_count = sentiment_text.lower().count('positive')\n",
        "            neutral_count = sentiment_text.lower().count('neutral')\n",
        "            negative_count = sentiment_text.lower().count('negative')\n",
        "\n",
        "            # Attempt to extract a summary line - this is a heuristic\n",
        "            summary_line = \"No summary extracted.\"\n",
        "            lines = sentiment_text.split('\\n')\n",
        "            for line in lines:\n",
        "                 lower_line = line.lower()\n",
        "                 if 'summary' in lower_line or 'overall sentiment' in lower_line:\n",
        "                     summary_line = line.strip()\n",
        "                     break\n",
        "            if summary_line == \"No summary extracted.\" and lines:\n",
        "                 # If no explicit summary found, take the last non-empty line as a potential summary\n",
        "                 for line in reversed(lines):\n",
        "                     if line.strip():\n",
        "                         summary_line = line.strip()\n",
        "                         break\n",
        "\n",
        "\n",
        "            total_headlines = len(news_headlines)\n",
        "            if total_headlines > 0:\n",
        "                # Scoring based on the ratio of positive vs negative headlines, scaled to 25 points\n",
        "                # (Positive - Negative) / Total * 12.5 + 12.5 -> Range 0-25\n",
        "                sentiment_score = ((positive_count - negative_count) / total_headlines) * 12.5 + 12.5\n",
        "            else:\n",
        "                sentiment_score = 12.5 # Neutral score if no headlines\n",
        "\n",
        "            return {\n",
        "                'positive': positive_count,\n",
        "                'neutral': neutral_count,\n",
        "                'negative': negative_count,\n",
        "                'score': max(0, min(sentiment_score, 25)), # Cap score between 0 and 25\n",
        "                'summary': summary_line\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing sentiment with Gemini API: {e}. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis failed.'}\n",
        "\n",
        "\n",
        "    def generate_enhanced_recommendation(self, fundamental_score, technical_score,\n",
        "                                       liquidity_score, peer_performance, index_membership,\n",
        "                                       sentiment_analysis_results):\n",
        "        \"\"\"Generate comprehensive recommendation including sentiment\"\"\"\n",
        "        sentiment_score = sentiment_analysis_results.get('score', 0)\n",
        "        total_score = fundamental_score + technical_score + liquidity_score + sentiment_score # Add sentiment score\n",
        "\n",
        "        # Adjust for peer performance\n",
        "        if peer_performance.get('outperformance', False):\n",
        "            total_score += 5\n",
        "\n",
        "        # Bonus for index membership\n",
        "        if index_membership:\n",
        "            total_score += 5\n",
        "\n",
        "        # Max possible score is 50 (Fundamental) + 50 (Technical) + 70 (Liquidity) + 25 (Sentiment) + 5 (Peer) + 5 (Index) = 205\n",
        "        # Let's re-evaluate the recommendation thresholds based on this potential range\n",
        "\n",
        "        if total_score >= 160: # Example Thresholds (adjust as needed)\n",
        "            recommendation = \"STRONG BUY\"\n",
        "            confidence = \"High\"\n",
        "        elif total_score >= 130:\n",
        "            recommendation = \"BUY\"\n",
        "            confidence = \"Moderate to High\"\n",
        "        elif total_score >= 90:\n",
        "            recommendation = \"HOLD\"\n",
        "            confidence = \"Moderate\"\n",
        "        elif total_score >= 60:\n",
        "            return \"SELL\"\n",
        "        else:\n",
        "            return \"STRONG SELL\"\n",
        "\n",
        "        return {\n",
        "            'recommendation': recommendation,\n",
        "            'confidence': confidence,\n",
        "            'total_score': total_score,\n",
        "            'breakdown': {\n",
        "                'fundamental': fundamental_score,\n",
        "                'technical': technical_score,\n",
        "                'liquidity': liquidity_score,\n",
        "                'sentiment': sentiment_score\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "\n",
        "    # Get basic analysis from Part 1\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        return None\n",
        "\n",
        "    # Get current price\n",
        "    current_price = stock_data.current_price\n",
        "\n",
        "    # Enhanced analysis\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "\n",
        "    # 3. Peer analysis\n",
        "    peers = enhanced_analyzer.get_peer_companies(symbol, stock_data.info)\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peers)\n",
        "\n",
        "    # 4. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "\n",
        "    # 5. Recalculate technical score with circuit risk\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "\n",
        "    # 6. Fetch and analyze news sentiment\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "\n",
        "\n",
        "    # 7. Generate enhanced recommendation\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance,\n",
        "        index_membership,\n",
        "        sentiment_analysis_results # Pass sentiment analysis results\n",
        "    )\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score,\n",
        "            'peers': peers,\n",
        "            'peer_performance': peer_performance,\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage (removed from here as it's part of the next display step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa12ae06"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the combined analysis report to show the effect of the enhanced circuit limit calculation and other features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "d8033ea2"
      },
      "source": [
        "#@title Analyze a stock and display the combined results\n",
        "symbol_to_analyze = \"RELIANCE.NS\" # You can change this symbol\n",
        "\n",
        "# Ensure both analyzers are instantiated (they should be if the cells above were run)\n",
        "# If not, you might need to re-run the cells defining IndianStockAnalyzer and EnhancedStockAnalyzer\n",
        "try:\n",
        "    stock_analyzer = IndianStockAnalyzer()\n",
        "    enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "except NameError:\n",
        "    print(\"Please run the cells defining IndianStockAnalyzer and EnhancedStockAnalyzer first.\")\n",
        "    # Exit or handle the error appropriately if classes are not defined\n",
        "    stock_analyzer = None\n",
        "    enhanced_analyzer = None\n",
        "\n",
        "\n",
        "if stock_analyzer and enhanced_analyzer:\n",
        "    combined_analysis_report = analyze_stock_enhanced(symbol_to_analyze, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if combined_analysis_report:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Combined Stock Analysis Report for {symbol_to_analyze}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Display basic analysis results\n",
        "        basic = combined_analysis_report['basic_analysis']\n",
        "        print(f\"\\n--- Basic Analysis (from Part 1) ---\")\n",
        "        print(f\"Company Name: {basic.company_name}\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if basic.current_price is not None else \"Current Price: N/A\")\n",
        "        print(f\"Market Cap: ₹{basic.market_cap/10000000:,.2f} Cr\" if basic.market_cap is not None else \"Market Cap: N/A\") # Use stored market_cap\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "        print(f\"Fundamental Score: {basic.fundamental_score}/50\")\n",
        "        print(f\"Technical Score: {basic.technical_score}/50\")\n",
        "        print(f\"Basic Recommendation: {basic.recommendation}\")\n",
        "        print(\"\\nFundamental Metrics:\")\n",
        "        for metric, value in basic.metrics.items():\n",
        "             if metric != 'Fundamental_Score':\n",
        "                if value is not None and not np.isnan(value):\n",
        "                     if isinstance(value, float):\n",
        "                         if metric in ['ROE', 'Revenue_Growth', 'Net_Profit_Margin', 'Debt_to_Equity']:\n",
        "                             print(f\"{metric}: {value*100:.2f}%\") # Display as percentage for D/E, ROE, Growth, Margin\n",
        "                         else:\n",
        "                             print(f\"{metric}: {value:.2f}\")\n",
        "                     else:\n",
        "                         print(f\"{metric}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{metric}: N/A (Missing Data)\")\n",
        "\n",
        "\n",
        "        print(\"\\nTechnical Indicators:\")\n",
        "        for indicator, value in basic.indicators.items():\n",
        "             if indicator != 'current_price':\n",
        "                if value is not None and not np.isnan(value):\n",
        "                    if isinstance(value, float):\n",
        "                        print(f\"{indicator}: {value:,.2f}\")\n",
        "                    else:\n",
        "                        print(f\"{indicator}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{indicator}: N/A (Insufficient Data)\")\n",
        "\n",
        "\n",
        "        # Display enhanced features and final recommendation\n",
        "        enhanced = combined_analysis_report['enhanced_features']\n",
        "        final = combined_analysis_report['final_recommendation']\n",
        "\n",
        "        print(f\"\\n--- Enhanced Analysis (from Part 2) ---\")\n",
        "        print(f\"Circuit Limits: {enhanced.get('circuit_limits', {}).get('lower_circuit', 'N/A'):.2f} - {enhanced.get('circuit_limits', {}).get('upper_circuit', 'N/A'):.2f}\" if enhanced.get('circuit_limits') else \"Circuit Limits: N/A\")\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        print(f\"Liquidity Score: {enhanced.get('liquidity_score', 'N/A')}/70\")\n",
        "\n",
        "        if enhanced.get('peers'):\n",
        "            print(f\"Peer Companies: {', '.join(enhanced['peers'])}\")\n",
        "            if enhanced.get('peer_performance'):\n",
        "                print(f\"30-day Return: {enhanced['peer_performance'].get('stock_return', 'N/A'):.2f}%\" if enhanced['peer_performance'].get('stock_return') is not None else \"30-day Return: N/A\")\n",
        "                print(f\"Peer Avg Return: {enhanced['peer_performance'].get('avg_peer_return', 'N/A'):.2f}%\" if enhanced['peer_performance'].get('avg_peer_return') is not None else \"Peer Avg Return: N/A\")\n",
        "                print(f\"Relative Performance: {enhanced['peer_performance'].get('relative_performance', 'N/A'):.2f}%\" if enhanced['peer_performance'].get('relative_performance') is not None else \"Relative Performance: N/A\")\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             for headline in enhanced['news_headlines']:\n",
        "                 print(f\"- {headline}\")\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             print(f\"Sentiment Score: {sentiment_results.get('score', 0):.2f}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Final Recommendation ---\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} ({final.get('confidence', 'N/A')})\")\n",
        "        print(f\"Total Score: {final.get('total_score', 0):.2f}/205\")\n",
        "        print(\"Score Breakdown:\")\n",
        "        print(f\"  - Fundamental: {final.get('breakdown', {}).get('fundamental', 'N/A'):.2f}\")\n",
        "        print(f\"  - Technical (Enhanced): {final.get('breakdown', {}).get('technical', 'N/A')}\") # Technical score might not be float always\n",
        "        print(f\"  - Liquidity: {final.get('breakdown', {}).get('liquidity', 'N/A'):.2f}\")\n",
        "        print(f\"  - Sentiment: {final.get('breakdown', {}).get('sentiment', 'N/A'):.2f}\")\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Could not generate combined analysis report for {symbol_to_analyze}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bb65d59"
      },
      "source": [
        "## Refine industry benchmarks\n",
        "\n",
        "### Subtask:\n",
        "Review and potentially expand the industry benchmarks for fundamental metrics to cover more sectors or allow for custom benchmarks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3894095b"
      },
      "source": [
        "**Reasoning**:\n",
        "Review the existing industry benchmarks, identify missing sectors, and consider adding more sectors to the benchmarks dictionary or outlining a plan for dynamic benchmarks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f170ffd"
      },
      "source": [
        "# Step 1: Examine existing industry_benchmarks\n",
        "print(\"--- Review of Existing Industry Benchmarks ---\")\n",
        "analyzer = IndianStockAnalyzer() # Instantiate to access benchmarks\n",
        "existing_benchmarks = analyzer.industry_benchmarks\n",
        "default_benchmarks = analyzer.default_benchmarks\n",
        "\n",
        "print(\"Existing Industry Benchmarks:\")\n",
        "for sector, metrics in existing_benchmarks.items():\n",
        "    print(f\"- {sector.capitalize()}: {list(metrics.keys())}\")\n",
        "\n",
        "print(\"\\nDefault Benchmarks:\")\n",
        "print(list(default_benchmarks.keys()))\n",
        "\n",
        "# Step 2: Identify missing major Indian market sectors\n",
        "# Common major sectors in India include:\n",
        "# - IT (covered)\n",
        "# - Banking (covered)\n",
        "# - Pharma (covered)\n",
        "# - FMCG (covered)\n",
        "# - Auto (covered)\n",
        "# - Infrastructure (covered)\n",
        "# - Energy (covered)\n",
        "# - Realty (covered)\n",
        "# - Telecom (covered)\n",
        "# - Metals & Mining\n",
        "# - Capital Goods\n",
        "# - Chemicals\n",
        "# - Textiles\n",
        "# - Media & Entertainment\n",
        "# - Consumer Durables\n",
        "# - Utilities\n",
        "# - Services\n",
        "# - Construction\n",
        "\n",
        "missing_sectors = [\n",
        "    'metals & mining',\n",
        "    'capital goods',\n",
        "    'chemicals',\n",
        "    'textiles',\n",
        "    'media & entertainment',\n",
        "    'consumer durables',\n",
        "    'utilities',\n",
        "    'services',\n",
        "    'construction'\n",
        "]\n",
        "\n",
        "print(\"\\nPotentially Missing Major Sectors:\")\n",
        "for sector in missing_sectors:\n",
        "    print(f\"- {sector.title()}\")\n",
        "\n",
        "# Step 3: Consider static vs dynamic/custom benchmarks\n",
        "print(\"\\n--- Consideration of Static vs Dynamic/Custom Benchmarks ---\")\n",
        "print(\n",
        "    \"The current implementation uses static benchmarks defined within the class. \"\n",
        "    \"This is a good starting point but may not always be representative of current \"\n",
        "    \"market conditions or specific sub-sectors.\"\n",
        ")\n",
        "print(\n",
        "    \"Dynamic benchmarks (e.g., calculating median/average metrics for peers or the sector \"\n",
        "    \"from recent data) or allowing custom benchmarks would enhance accuracy.\"\n",
        ")\n",
        "\n",
        "# Step 4: Suggest improvements - Add more sectors or outline a plan\n",
        "print(\"\\n--- Suggested Improvements for Benchmarks ---\")\n",
        "print(\"Option 1: Add more sectors to the `industry_benchmarks` dictionary.\")\n",
        "print(\"This requires research to define appropriate 'excellent', 'good', and 'fair' thresholds for each metric in these sectors.\")\n",
        "print(\"Example sectors to consider adding: Metals & Mining, Capital Goods, Chemicals, Utilities.\")\n",
        "\n",
        "print(\"\\nOption 2: Outline a plan for implementing dynamic or custom benchmarks.\")\n",
        "print(\"Plan:\")\n",
        "print(\"a. **Dynamic Benchmarks:** Modify `get_industry_benchmarks` to fetch recent data for a sector or peer group and calculate median/average fundamental metrics to use as benchmarks.\")\n",
        "print(\"   - Requires robust data fetching for multiple symbols.\")\n",
        "print(\"   - Needs logic to handle sectors with limited data or peers.\")\n",
        "print(\"b. **Custom Benchmarks:** Add parameters to the `analyze_stock` or `IndianStockAnalyzer` constructor to allow users to provide their own benchmark dictionary.\")\n",
        "print(\"   - Requires validation of the custom benchmark structure.\")\n",
        "print(\"c. **Hybrid Approach:** Maintain static benchmarks as a fallback but prioritize dynamic or custom benchmarks if available.\")\n",
        "\n",
        "print(\"\\nRationale for not making immediate changes to benchmarks:\")\n",
        "print(\"Adding comprehensive, accurate benchmarks for all major sectors requires significant financial domain expertise and research. Implementing dynamic benchmarks is a more complex feature requiring additional data fetching and calculation logic.\")\n",
        "\n",
        "# Step 5: Document changes or rationale (already included in print statements above)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d82e2c7"
      },
      "source": [
        "**Reasoning**:\n",
        "Based on the review, several major sectors are missing. I will add a few of the identified missing sectors with plausible benchmark values to the `industry_benchmarks` dictionary in the `IndianStockAnalyzer` class. This directly addresses the subtask of expanding the benchmarks. I will also reiterate the limitations of static benchmarks and the possibility of future dynamic/custom benchmark implementation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ddfb1c16"
      },
      "source": [
        "#@title Part 1 of Main script (Expanded Benchmarks)\n",
        "# Indian Stock Analyzer - Part 1 (Corrected and Enhanced further)\n",
        "# Complete implementation with improvements for missing data handling and Debt-to-Equity validation\n",
        "# and expanded industry benchmarks\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import logging\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__) # Define logger globally\n",
        "\n",
        "@dataclass\n",
        "class StockData:\n",
        "    \"\"\"Data class to store comprehensive stock information\"\"\"\n",
        "    symbol: str\n",
        "    company_name: str\n",
        "    current_price: float\n",
        "    market_cap: float\n",
        "    info: Dict\n",
        "    price_data: pd.DataFrame\n",
        "    indicators: Dict\n",
        "    fundamental_score: float\n",
        "    technical_score: float\n",
        "    recommendation: str\n",
        "    metrics: Dict\n",
        "\n",
        "class IndianStockAnalyzer:\n",
        "    \"\"\"Comprehensive stock analyzer for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the analyzer with Indian market specific parameters\"\"\"\n",
        "        self.nifty_symbol = \"^NSEI\"\n",
        "        self.risk_free_rate = 0.065  # Will be made dynamic in Part 2\n",
        "\n",
        "        # Industry-specific benchmark thresholds for Indian markets\n",
        "        # Expanded with additional sectors\n",
        "        self.industry_benchmarks = {\n",
        "            'technology': {\n",
        "                'pe_ratio': {'excellent': 25, 'good': 35, 'fair': 45},\n",
        "                'debt_to_equity': {'excellent': 0.3, 'good': 0.5, 'fair': 0.8},\n",
        "                'roe': {'excellent': 0.25, 'good': 0.18, 'fair': 0.12},\n",
        "                'revenue_growth': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10}\n",
        "            },\n",
        "            'banking': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 20, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 8, 'good': 10, 'fair': 12}, # Higher D/E is normal for banks\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.25, 'good': 0.20, 'fair': 0.15}\n",
        "            },\n",
        "            'pharmaceutical': {\n",
        "                'pe_ratio': {'excellent': 20, 'good': 30, 'fair': 40},\n",
        "                'debt_to_equity': {'excellent': 0.4, 'good': 0.6, 'fair': 0.8},\n",
        "                'roe': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.08}\n",
        "            },\n",
        "            'fmcg': {\n",
        "                'pe_ratio': {'excellent': 30, 'good': 40, 'fair': 50},\n",
        "                'debt_to_equity': {'excellent': 0.5, 'good': 0.8, 'fair': 1.0},\n",
        "                'roe': {'excellent': 0.30, 'good': 0.25, 'fair': 0.15},\n",
        "                'revenue_growth': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.08}\n",
        "            },\n",
        "            'automobile': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "                'debt_to_equity': {'excellent': 0.6, 'good': 0.8, 'fair': 1.2},\n",
        "                'roe': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "            },\n",
        "            'infrastructure': {\n",
        "                'pe_ratio': {'excellent': 12, 'good': 18, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05}\n",
        "            },\n",
        "            'energy': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 15, 'fair': 20},\n",
        "                'debt_to_equity': {'excellent': 0.8, 'good': 1.2, 'fair': 1.5},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "            },\n",
        "            'realty': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 15, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05},\n",
        "                'revenue_growth': {'excellent': 0.25, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05}\n",
        "            },\n",
        "            'telecom': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05},\n",
        "                'revenue_growth': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.08, 'good': 0.05, 'fair': 0.03}\n",
        "            },\n",
        "             # Added missing major sectors (with illustrative benchmarks - these should be validated)\n",
        "            'metals & mining': {\n",
        "                'pe_ratio': {'excellent': 8, 'good': 12, 'fair': 18}, # Lower P/E typical\n",
        "                'debt_to_equity': {'excellent': 0.8, 'good': 1.3, 'fair': 1.8}, # Can be leveraged\n",
        "                'roe': {'excellent': 0.18, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.04}\n",
        "            },\n",
        "             'capital goods': {\n",
        "                'pe_ratio': {'excellent': 20, 'good': 30, 'fair': 40},\n",
        "                'debt_to_equity': {'excellent': 0.5, 'good': 0.8, 'fair': 1.2},\n",
        "                'roe': {'excellent': 0.18, 'good': 0.14, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.18, 'good': 0.13, 'fair': 0.08},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.04}\n",
        "            },\n",
        "             'chemicals': {\n",
        "                'pe_ratio': {'excellent': 25, 'good': 35, 'fair': 45},\n",
        "                'debt_to_equity': {'excellent': 0.4, 'good': 0.6, 'fair': 0.9},\n",
        "                'roe': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.06},\n",
        "                'net_profit_margin': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05}\n",
        "            },\n",
        "             'utilities': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 15, 'fair': 20},\n",
        "                'debt_to_equity': {'excellent': 1.5, 'good': 2.0, 'fair': 3.0}, # Higher D/E is common\n",
        "                'roe': {'excellent': 0.12, 'good': 0.09, 'fair': 0.06},\n",
        "                'revenue_growth': {'excellent': 0.08, 'good': 0.05, 'fair': 0.03}, # Stable, lower growth\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.07} # Stable margins\n",
        "            },\n",
        "             'construction': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 16, 'fair': 22},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.10, 'fair': 0.07},\n",
        "                'revenue_growth': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.08, 'good': 0.05, 'fair': 0.03}\n",
        "            },\n",
        "              'consumer durables': {\n",
        "                'pe_ratio': {'excellent': 35, 'good': 45, 'fair': 60}, # Higher P/E common\n",
        "                'debt_to_equity': {'excellent': 0.4, 'good': 0.7, 'fair': 1.0},\n",
        "                'roe': {'excellent': 0.25, 'good': 0.18, 'fair': 0.12},\n",
        "                'revenue_growth': {'excellent': 0.18, 'good': 0.12, 'fair': 0.08},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.04}\n",
        "            },\n",
        "             'textiles': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 22, 'fair': 30},\n",
        "                'debt_to_equity': {'excellent': 0.7, 'good': 1.0, 'fair': 1.5},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.10, 'fair': 0.07},\n",
        "                'revenue_growth': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.08, 'good': 0.05, 'fair': 0.03}\n",
        "            }\n",
        "\n",
        "\n",
        "        }\n",
        "\n",
        "        # Default benchmarks for other sectors\n",
        "        self.default_benchmarks = {\n",
        "            'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "            'debt_to_equity': {'excellent': 0.5, 'good': 1.0, 'fair': 1.5},\n",
        "            'roe': {'excellent': 0.15, 'good': 0.10, 'fair': 0.07},\n",
        "            'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "            'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "        }\n",
        "\n",
        "    def get_stock_data(self, symbol: str) -> Optional[yf.Ticker]:\n",
        "        \"\"\"Fetch stock data from Yahoo Finance\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            # Verify the ticker is valid by checking if it has info\n",
        "            if ticker.info and 'symbol' in ticker.info:\n",
        "                return ticker\n",
        "            else:\n",
        "                logger.error(f\"Invalid symbol: {symbol}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error fetching data for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_industry_benchmarks(self, sector: str) -> Dict:\n",
        "        \"\"\"Get industry-specific benchmarks\"\"\"\n",
        "        sector_lower = sector.lower() if sector else ''\n",
        "\n",
        "        # Map common sector names to our benchmark categories\n",
        "        sector_mapping = {\n",
        "            'technology': 'technology',\n",
        "            'information technology': 'technology',\n",
        "            'financial services': 'banking',\n",
        "            'financials': 'banking',\n",
        "            'healthcare': 'pharmaceutical',\n",
        "            'consumer defensive': 'fmcg',\n",
        "            'consumer staples': 'fmcg', # Alias\n",
        "            'consumer cyclical': 'automobile',\n",
        "            'industrials': 'infrastructure', # Broad mapping\n",
        "            'energy': 'energy',\n",
        "            'real estate': 'realty',\n",
        "            'communication services': 'telecom',\n",
        "            'metals and mining': 'metals & mining', # Map to new category\n",
        "            'capital goods': 'capital goods',\n",
        "            'chemicals': 'chemicals',\n",
        "            'textiles': 'textiles',\n",
        "            'media': 'media & entertainment', # Broad mapping\n",
        "            'consumer durables': 'consumer durables',\n",
        "            'utilities': 'utilities',\n",
        "            'services': 'services', # Keep 'services' even if no specific benchmark yet\n",
        "            'construction': 'construction'\n",
        "        }\n",
        "\n",
        "        benchmark_key = sector_mapping.get(sector_lower, None)\n",
        "\n",
        "        if benchmark_key and benchmark_key in self.industry_benchmarks:\n",
        "            return self.industry_benchmarks[benchmark_key]\n",
        "        else:\n",
        "            logger.info(f\"Using default benchmarks for sector: {sector}\")\n",
        "            return self.default_benchmarks\n",
        "\n",
        "    def calculate_technical_indicators(self, price_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate comprehensive technical indicators\"\"\"\n",
        "        indicators = {}\n",
        "        data_len = len(price_data)\n",
        "\n",
        "        try:\n",
        "            # Simple Moving Averages\n",
        "            if data_len >= 20:\n",
        "                 indicators['SMA_20'] = price_data['Close'].rolling(window=20).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['SMA_20'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_20.\")\n",
        "\n",
        "            if data_len >= 50:\n",
        "                 indicators['SMA_50'] = price_data['Close'].rolling(window=50).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['SMA_50'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_50.\")\n",
        "\n",
        "            if data_len >= 200:\n",
        "                 indicators['SMA_200'] = price_data['Close'].rolling(window=200).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['SMA_200'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_200.\")\n",
        "\n",
        "            # Exponential Moving Averages\n",
        "            if data_len >= 12:\n",
        "                 indicators['EMA_12'] = price_data['Close'].ewm(span=12, adjust=False).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['EMA_12'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for EMA_12.\")\n",
        "\n",
        "            if data_len >= 26:\n",
        "                 indicators['EMA_26'] = price_data['Close'].ewm(span=26, adjust=False).mean().iloc[-1]\n",
        "            else:\n",
        "                 indicators['EMA_26'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for EMA_26.\")\n",
        "\n",
        "            # RSI\n",
        "            if data_len >= 14:\n",
        "                indicators['RSI'] = self.calculate_rsi(price_data['Close'])\n",
        "            else:\n",
        "                 indicators['RSI'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for RSI.\")\n",
        "\n",
        "            # MACD (requires EMA_12 and EMA_26)\n",
        "            macd_line = np.nan\n",
        "            signal_line = np.nan\n",
        "            macd_histogram = np.nan\n",
        "\n",
        "            if 'EMA_12' in indicators and 'EMA_26' in indicators and not np.isnan(indicators['EMA_12']) and not np.isnan(indicators['EMA_26']):\n",
        "                 # Use the entire macd_line series for rolling calculation if possible\n",
        "                 full_macd_line_series = price_data['Close'].ewm(span=12, adjust=False).mean() - price_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "                 if len(full_macd_line_series.dropna()) >= 9:\n",
        "                      macd_line = full_macd_line_series.iloc[-1]\n",
        "                      signal_line = full_macd_line_series.ewm(span=9, adjust=False).mean().iloc[-1]\n",
        "                      if not np.isnan(signal_line):\n",
        "                         macd_histogram = macd_line - signal_line\n",
        "                 else:\n",
        "                      logger.warning(\"Insufficient data for MACD signal line calculation.\")\n",
        "            else:\n",
        "                 logger.warning(\"MACD not calculated due to missing EMA_12 or EMA_26.\")\n",
        "\n",
        "\n",
        "            indicators['MACD'] = macd_line\n",
        "            indicators['MACD_signal'] = signal_line\n",
        "            indicators['MACD_histogram'] = macd_histogram\n",
        "\n",
        "            # Log MACD values after calculation\n",
        "            logger.info(f\"Calculated MACD: {indicators['MACD']}, Signal: {indicators['MACD_signal']}\")\n",
        "\n",
        "\n",
        "            # Bollinger Bands (requires SMA_20 and enough data for std dev)\n",
        "            bb_period = 20\n",
        "            bb_std = 2\n",
        "            if data_len >= bb_period:\n",
        "                sma_bb = price_data['Close'].rolling(window=bb_period).mean()\n",
        "                std_bb = price_data['Close'].rolling(window=bb_period).std()\n",
        "                # Ensure SMA and STD are not NaN before calculating bands\n",
        "                if not np.isnan(sma_bb.iloc[-1]) and not np.isnan(std_bb.iloc[-1]):\n",
        "                    indicators['BB_upper'] = sma_bb.iloc[-1] + (std_bb.iloc[-1] * bb_std)\n",
        "                    indicators['BB_lower'] = sma_bb.iloc[-1] - (std_bb.iloc[-1] * bb_std)\n",
        "                    indicators['BB_middle'] = sma_bb.iloc[-1]\n",
        "                else:\n",
        "                    indicators['BB_upper'] = np.nan\n",
        "                    indicators['BB_lower'] = np.nan\n",
        "                    indicators['BB_middle'] = np.nan\n",
        "                    logger.warning(\"Bollinger Bands not calculated due to NaN in SMA or STD.\")\n",
        "            else:\n",
        "                indicators['BB_upper'] = np.nan\n",
        "                indicators['BB_lower'] = np.nan\n",
        "                indicators['BB_middle'] = np.nan\n",
        "                logger.warning(\"Insufficient data for Bollinger Bands.\")\n",
        "\n",
        "\n",
        "            # Volume indicators\n",
        "            if data_len >= 20:\n",
        "                 indicators['Volume_SMA'] = price_data['Volume'].rolling(window=20).mean().iloc[-1]\n",
        "                 if indicators['Volume_SMA'] is not None and not np.isnan(indicators['Volume_SMA']) and indicators['Volume_SMA'] > 0:\n",
        "                      indicators['Volume_ratio'] = price_data['Volume'].iloc[-1] / indicators['Volume_SMA']\n",
        "                 else:\n",
        "                      indicators['Volume_ratio'] = np.nan\n",
        "                      logger.warning(\"Volume SMA is zero or NaN, Volume ratio not calculated.\")\n",
        "            else:\n",
        "                 indicators['Volume_SMA'] = np.nan\n",
        "                 indicators['Volume_ratio'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for Volume SMA and ratio.\")\n",
        "\n",
        "\n",
        "            # Price position (requires SMA_20 and SMA_50)\n",
        "            current_price = price_data['Close'].iloc[-1] if data_len > 0 and 'Close' in price_data and not price_data['Close'].empty else np.nan\n",
        "            indicators['current_price'] = current_price # Store current price\n",
        "\n",
        "            if current_price is not None and not np.isnan(current_price) and 'SMA_20' in indicators and indicators['SMA_20'] is not None and not np.isnan(indicators['SMA_20']) and indicators['SMA_20'] > 0:\n",
        "                indicators['Price_to_SMA20'] = ((current_price / indicators['SMA_20'] - 1) * 100)\n",
        "            else:\n",
        "                 indicators['Price_to_SMA20'] = np.nan\n",
        "                 logger.warning(\"Price to SMA20 not calculated due to missing current price or SMA20.\")\n",
        "\n",
        "            if current_price is not None and not np.isnan(current_price) and 'SMA_50' in indicators and indicators['SMA_50'] is not None and not np.isnan(indicators['SMA_50']) and indicators['SMA_50'] > 0:\n",
        "                 indicators['Price_to_SMA50'] = ((current_price / indicators['SMA_50'] - 1) * 100)\n",
        "            else:\n",
        "                 indicators['Price_to_SMA50'] = np.nan\n",
        "                 logger.warning(\"Price to SMA50 not calculated due to missing current price or SMA50.\")\n",
        "\n",
        "\n",
        "            # Support and Resistance (requires enough data for rolling max/min)\n",
        "            if data_len >= 20:\n",
        "                 indicators['Resistance'] = price_data['High'].rolling(window=20).max().iloc[-1]\n",
        "                 indicators['Support'] = price_data['Low'].rolling(window=20).min().iloc[-1]\n",
        "            else:\n",
        "                 indicators['Resistance'] = np.nan\n",
        "                 indicators['Support'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for Support and Resistance.\")\n",
        "\n",
        "\n",
        "            return indicators\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating technical indicators: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> Optional[float]:\n",
        "        \"\"\"Calculate Relative Strength Index\"\"\"\n",
        "        try:\n",
        "            if len(prices) < period:\n",
        "                return np.nan # Return NaN for insufficient data\n",
        "\n",
        "            delta = prices.diff()\n",
        "            gain = delta.where(delta > 0, 0)\n",
        "            loss = -delta.where(delta < 0, 0)\n",
        "\n",
        "            avg_gain = gain.rolling(window=period).mean()\n",
        "            avg_loss = loss.rolling(window=period).mean()\n",
        "\n",
        "            # Handle division by zero if avg_loss is zero or NaN\n",
        "            if avg_loss.iloc[-1] is None or np.isnan(avg_loss.iloc[-1]) or avg_loss.iloc[-1] == 0:\n",
        "                 return 100.0 if avg_gain.iloc[-1] is not None and not np.isnan(avg_gain.iloc[-1]) and avg_gain.iloc[-1] > 0 else 50.0 # If no loss, RSI is 100 (if gain) or 50 (if no change)\n",
        "            elif avg_loss.iloc[-1] > 0:\n",
        "                rs = avg_gain / avg_loss\n",
        "                rsi = 100 - (100 / (1 + rs))\n",
        "                return rsi.iloc[-1]\n",
        "            else:\n",
        "                 return np.nan # Should not happen with abs, but as a safeguard\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating RSI: {str(e)}\")\n",
        "            return np.nan # Return NaN on error\n",
        "\n",
        "    def calculate_fundamental_score(self, info: Dict, benchmarks: Dict) -> Tuple[float, Dict]:\n",
        "        \"\"\"Calculate fundamental analysis score based on Indian market standards\"\"\"\n",
        "        score = 0\n",
        "        max_score = 50\n",
        "        metrics = {}\n",
        "\n",
        "        try:\n",
        "            # P/E Ratio (10 points)\n",
        "            pe_ratio = info.get('trailingPE', info.get('forwardPE', None))\n",
        "            if pe_ratio is not None and isinstance(pe_ratio, (int, float)) and not np.isnan(pe_ratio):\n",
        "                metrics['PE_Ratio'] = pe_ratio\n",
        "                if pe_ratio > 0: # Ensure PE is positive for scoring\n",
        "                     if pe_ratio <= benchmarks['pe_ratio']['excellent']:\n",
        "                         score += 10\n",
        "                     elif pe_ratio <= benchmarks['pe_ratio']['good']:\n",
        "                         score += 7\n",
        "                     elif pe_ratio <= benchmarks['pe_ratio']['fair']:\n",
        "                         score += 4\n",
        "                     else:\n",
        "                         score += 2\n",
        "                else:\n",
        "                    score += 1 # Small score for non-positive PE\n",
        "            else:\n",
        "                 metrics['PE_Ratio'] = np.nan\n",
        "                 logger.warning(\"PE Ratio not available or is invalid.\")\n",
        "\n",
        "\n",
        "            # Debt to Equity (10 points)\n",
        "            debt_to_equity_raw = info.get('debtToEquity', None)\n",
        "            debt_to_equity = np.nan # Initialize to NaN\n",
        "\n",
        "            if debt_to_equity_raw is not None and isinstance(debt_to_equity_raw, (int, float)) and not np.isnan(debt_to_equity_raw):\n",
        "                 # Handle potential outliers (very high values might indicate data issues)\n",
        "                 if debt_to_equity_raw > 10000: # Arbitrary large threshold for outlier detection\n",
        "                      logger.warning(f\"Debt to Equity raw value is unusually high: {debt_to_equity_raw}. Treating as potential data issue.\")\n",
        "                      # Could assign a very low score or NaN, depending on policy\n",
        "                      debt_to_equity = np.nan # Treat as invalid data for now\n",
        "                 else:\n",
        "                      # Heuristic for percentage vs decimal\n",
        "                      if debt_to_equity_raw > 100: # Likely a percentage\n",
        "                           debt_to_equity = debt_to_equity_raw / 100.0\n",
        "                      else: # Assume it's already a decimal\n",
        "                           debt_to_equity = debt_to_equity_raw\n",
        "\n",
        "                      # Re-check if the converted value is still reasonable (e.g., not from a huge raw decimal)\n",
        "                      if debt_to_equity is not None and not np.isnan(debt_to_equity) and debt_to_equity > 100: # Another threshold after conversion\n",
        "                          logger.warning(f\"Debt to Equity value after conversion is still very high: {debt_to_equity:.2f}. May indicate data issue or highly leveraged company.\")\n",
        "                          # Could assign a low score or cap it, for now let the scoring handle it.\n",
        "\n",
        "\n",
        "            metrics['Debt_to_Equity'] = debt_to_equity\n",
        "\n",
        "            # Score based on the validated debt_to_equity\n",
        "            if debt_to_equity is not None and not np.isnan(debt_to_equity):\n",
        "                if debt_to_equity <= benchmarks['debt_to_equity']['excellent']:\n",
        "                    score += 10\n",
        "                elif debt_to_equity <= benchmarks['debt_to_equity']['good']:\n",
        "                    score += 7\n",
        "                elif debt_to_equity <= benchmarks['debt_to_equity']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2\n",
        "            else:\n",
        "                 logger.warning(\"Debt to Equity not available, invalid, or an outlier. Assigning low score.\")\n",
        "                 score += 1 # Assign minimal score if D/E is not valid\n",
        "\n",
        "\n",
        "            # ROE (10 points)\n",
        "            roe = info.get('returnOnEquity', None)\n",
        "            if roe is not None and isinstance(roe, (int, float)) and not np.isnan(roe):\n",
        "                metrics['ROE'] = roe\n",
        "                if roe >= benchmarks['roe']['excellent']:\n",
        "                    score += 10\n",
        "                elif roe >= benchmarks['roe']['good']:\n",
        "                    score += 7\n",
        "                elif roe >= benchmarks['roe']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2\n",
        "            else:\n",
        "                 metrics['ROE'] = np.nan\n",
        "                 logger.warning(\"ROE not available or is invalid.\")\n",
        "\n",
        "            # Revenue Growth (10 points)\n",
        "            revenue_growth = info.get('revenueGrowth', None)\n",
        "            if revenue_growth is not None and isinstance(revenue_growth, (int, float)) and not np.isnan(revenue_growth):\n",
        "                metrics['Revenue_Growth'] = revenue_growth\n",
        "                if revenue_growth >= benchmarks['revenue_growth']['excellent']:\n",
        "                    score += 10\n",
        "                elif revenue_growth >= benchmarks['revenue_growth']['good']:\n",
        "                    score += 7\n",
        "                elif revenue_growth >= benchmarks['revenue_growth']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2\n",
        "            else:\n",
        "                 metrics['Revenue_Growth'] = np.nan\n",
        "                 logger.warning(\"Revenue Growth not available or is invalid.\")\n",
        "\n",
        "            # Net Profit Margin (10 points)\n",
        "            profit_margin = info.get('profitMargins', None)\n",
        "            if profit_margin is not None and isinstance(profit_margin, (int, float)) and not np.isnan(profit_margin):\n",
        "                metrics['Net_Profit_Margin'] = profit_margin\n",
        "                if profit_margin >= benchmarks['net_profit_margin']['excellent']:\n",
        "                    score += 10\n",
        "                elif profit_margin >= benchmarks['net_profit_margin']['good']:\n",
        "                    score += 7\n",
        "                elif profit_margin >= benchmarks['net_profit_margin']['fair']:\n",
        "                    score += 4\n",
        "                else:\n",
        "                    score += 2\n",
        "            else:\n",
        "                 metrics['Net_Profit_Margin'] = np.nan\n",
        "                 logger.warning(\"Net Profit Margin not available or is invalid.\")\n",
        "\n",
        "\n",
        "            # Normalize score to max_score (already capped by scoring logic)\n",
        "            metrics['Fundamental_Score'] = score\n",
        "\n",
        "            return score, metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating fundamental score: {str(e)}\")\n",
        "            return 0, {}\n",
        "\n",
        "    def calculate_technical_score(self, indicators: Dict) -> float:\n",
        "        \"\"\"Calculate technical analysis score\"\"\"\n",
        "        score = 0\n",
        "        max_score = 50\n",
        "        indicator_scores = {} # To store scores for each indicator\n",
        "\n",
        "        try:\n",
        "            # RSI Score (10 points)\n",
        "            rsi = indicators.get('RSI', None)\n",
        "            if rsi is not None and not np.isnan(rsi):\n",
        "                 if 40 <= rsi <= 60:  # Neutral zone\n",
        "                     indicator_scores['RSI'] = 7\n",
        "                 elif rsi < 40:  # Oversold\n",
        "                     indicator_scores['RSI'] = 10\n",
        "                 elif 60 < rsi <= 70:  # Overbought but not extreme\n",
        "                     indicator_scores['RSI'] = 5\n",
        "                 else:  # Extreme levels\n",
        "                     indicator_scores['RSI'] = 2\n",
        "            else:\n",
        "                 indicator_scores['RSI'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"RSI not calculated or is NaN/None. Assigning 0 score for RSI.\")\n",
        "\n",
        "\n",
        "            # MACD Score (10 points)\n",
        "            macd = indicators.get('MACD', None)\n",
        "            macd_signal = indicators.get('MACD_signal', None)\n",
        "\n",
        "            # Explicitly check if both are numbers before comparing\n",
        "            if isinstance(macd, (int, float)) and isinstance(macd_signal, (int, float)) and not np.isnan(macd) and not np.isnan(macd_signal):\n",
        "                 if macd > macd_signal:\n",
        "                     indicator_scores['MACD'] = 10\n",
        "                 else:\n",
        "                     indicator_scores['MACD'] = 3\n",
        "            else:\n",
        "                 indicator_scores['MACD'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"MACD or MACD signal not calculated or is not a valid number. Assigning 0 score for MACD.\")\n",
        "\n",
        "\n",
        "            # Moving Average Score (10 points) - Using SMA_20 vs SMA_50\n",
        "            sma_20 = indicators.get('SMA_20', None)\n",
        "            sma_50 = indicators.get('SMA_50', None)\n",
        "            if sma_20 is not None and sma_50 is not None and not np.isnan(sma_20) and not np.isnan(sma_50):\n",
        "                if sma_20 > sma_50:\n",
        "                    indicator_scores['Moving_Averages'] = 10\n",
        "                else:\n",
        "                    indicator_scores['Moving_Averages'] = 3\n",
        "            else:\n",
        "                indicator_scores['Moving_Averages'] = 0 # Assign 0 if NaN/None\n",
        "                logger.warning(\"SMA_20 or SMA_50 not calculated or is NaN/None. Assigning 0 score for Moving Averages.\")\n",
        "\n",
        "            # Bollinger Bands Score (10 points)\n",
        "            current_price = indicators.get('current_price', None) # Assuming current_price is passed in indicators\n",
        "            bb_upper = indicators.get('BB_upper', None)\n",
        "            bb_lower = indicators.get('BB_lower', None)\n",
        "            bb_middle = indicators.get('BB_middle', None)\n",
        "\n",
        "            if current_price is not None and bb_upper is not None and bb_lower is not None and bb_middle is not None and \\\n",
        "               not np.isnan(current_price) and not np.isnan(bb_upper) and not np.isnan(bb_lower) and not np.isnan(bb_middle):\n",
        "                if bb_lower < current_price < bb_middle:\n",
        "                    indicator_scores['Bollinger_Bands'] = 10  # Good buying zone\n",
        "                elif bb_middle < current_price < bb_upper:\n",
        "                    indicator_scores['Bollinger_Bands'] = 7   # Neutral to positive\n",
        "                else:\n",
        "                    indicator_scores['Bollinger_Bands'] = 3   # Near extremes\n",
        "            else:\n",
        "                 indicator_scores['Bollinger_Bands'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Bollinger Bands or current price not available or is NaN/None. Assigning 0 score for Bollinger Bands.\")\n",
        "\n",
        "\n",
        "            # Volume Score (10 points)\n",
        "            volume_ratio = indicators.get('Volume_ratio', None)\n",
        "            if volume_ratio is not None and not np.isnan(volume_ratio):\n",
        "                 if 0.8 <= volume_ratio <= 1.5:\n",
        "                     indicator_scores['Volume'] = 7   # Normal volume\n",
        "                 elif volume_ratio > 1.5:\n",
        "                     indicator_scores['Volume'] = 10  # High volume (positive if with price up)\n",
        "                 else:\n",
        "                     indicator_scores['Volume'] = 3   # Low volume\n",
        "            else:\n",
        "                 indicator_scores['Volume'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Volume ratio not calculated or is NaN/None. Assigning 0 score for Volume.\")\n",
        "\n",
        "            # Sum the scores from individual indicators\n",
        "            score = sum(indicator_scores.values())\n",
        "\n",
        "            return min(score, max_score) # Cap at max_score\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating technical score: {str(e)}\")\n",
        "            return 0\n",
        "\n",
        "    def generate_recommendation(self, fundamental_score: float, technical_score: float) -> str:\n",
        "        \"\"\"Generate investment recommendation based on scores\"\"\"\n",
        "        total_score = fundamental_score + technical_score\n",
        "\n",
        "        if total_score >= 75:\n",
        "            return \"STRONG BUY\"\n",
        "        elif total_score >= 60:\n",
        "            return \"BUY\"\n",
        "        elif total_score >= 40:\n",
        "            return \"HOLD\"\n",
        "        elif total_score >= 25:\n",
        "            return \"SELL\"\n",
        "        else:\n",
        "            return \"STRONG SELL\"\n",
        "\n",
        "    def analyze_stock(self, symbol: str) -> Optional[StockData]:\n",
        "        \"\"\"Main method to analyze a stock\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Starting analysis for {symbol}\")\n",
        "\n",
        "            # Get stock data\n",
        "            ticker = self.get_stock_data(symbol)\n",
        "            if not ticker:\n",
        "                return None\n",
        "\n",
        "            # Get stock info\n",
        "            info = ticker.info\n",
        "            if not info:\n",
        "                logger.error(f\"No info available for {symbol}\")\n",
        "                return None\n",
        "\n",
        "            # Get historical price data\n",
        "            # Fetching enough data for 200-day SMA calculation\n",
        "            price_data = ticker.history(period=\"1y\") # Changed to 1 year to support 200-day SMA\n",
        "            if price_data.empty: # Check if price_data is empty\n",
        "                logger.error(f\"No price data available for {symbol}\")\n",
        "                return None\n",
        "            # Also check for essential columns\n",
        "            if not all(col in price_data.columns for col in ['Open', 'High', 'Low', 'Close', 'Volume']):\n",
        "                 logger.error(f\"Price data for {symbol} is missing essential columns.\")\n",
        "                 return None\n",
        "\n",
        "\n",
        "            # Get current price\n",
        "            current_price = price_data['Close'].iloc[-1] if data_len > 0 and 'Close' in price_data and not price_data['Close'].empty else np.nan\n",
        "\n",
        "            # Add current price to indicators for technical score calculation\n",
        "            indicators = self.calculate_technical_indicators(price_data)\n",
        "            indicators['current_price'] = current_price # Ensure current price is available for BB score\n",
        "\n",
        "            # Get industry benchmarks\n",
        "            sector = info.get('sector', 'Unknown')\n",
        "            benchmarks = self.get_industry_benchmarks(sector)\n",
        "\n",
        "            # Calculate scores\n",
        "            fundamental_score, metrics = self.calculate_fundamental_score(info, benchmarks)\n",
        "            technical_score = self.calculate_technical_score(indicators)\n",
        "\n",
        "            # Generate recommendation\n",
        "            recommendation = self.generate_recommendation(fundamental_score, technical_score)\n",
        "\n",
        "            # Create StockData object\n",
        "            stock_data = StockData(\n",
        "                symbol=symbol,\n",
        "                company_name=info.get('longName', symbol),\n",
        "                current_price=current_price if not np.isnan(current_price) else 0.0, # Store 0 if current price is NaN\n",
        "                market_cap=info.get('marketCap', 0) if info.get('marketCap') is not None else 0, # Ensure marketCap is not None\n",
        "                info=info,\n",
        "                price_data=price_data,\n",
        "                indicators=indicators,\n",
        "                fundamental_score=fundamental_score,\n",
        "                technical_score=technical_score,\n",
        "                recommendation=recommendation,\n",
        "                metrics=metrics\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Analysis completed for {symbol}\")\n",
        "            return stock_data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def display_analysis(self, stock_data: StockData) -> None:\n",
        "        \"\"\"Display analysis results in a formatted manner\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Stock Analysis Report: {stock_data.company_name} ({stock_data.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{stock_data.current_price:,.2f}\" if stock_data.current_price is not None else \"Current Price: N/A\")\n",
        "        print(f\"Market Cap: ₹{stock_data.market_cap/10000000:,.2f} Cr\" if stock_data.market_cap is not None else \"Market Cap: N/A\") # Use stored market_cap\n",
        "        print(f\"Sector: {stock_data.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n📈 Technical Indicators:\")\n",
        "        # Display indicators, handling None values\n",
        "        for indicator, value in stock_data.indicators.items():\n",
        "            if indicator != 'current_price': # Avoid displaying current_price here\n",
        "                if value is not None and not np.isnan(value):\n",
        "                    if isinstance(value, float):\n",
        "                        print(f\"{indicator}: {value:,.2f}\")\n",
        "                    else:\n",
        "                        print(f\"{indicator}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{indicator}: N/A (Insufficient Data)\")\n",
        "\n",
        "\n",
        "        print(f\"\\n💰 Fundamental Metrics:\")\n",
        "        for metric, value in stock_data.metrics.items():\n",
        "            if metric != 'Fundamental_Score':\n",
        "                if value is not None and not np.isnan(value):\n",
        "                     if isinstance(value, float):\n",
        "                         if metric in ['ROE', 'Revenue_Growth', 'Net_Profit_Margin', 'Debt_to_Equity']:\n",
        "                             print(f\"{metric}: {value*100:.2f}%\") # Display as percentage for D/E, ROE, Growth, Margin\n",
        "                         else:\n",
        "                             print(f\"{metric}: {value:.2f}\")\n",
        "                     else:\n",
        "                         print(f\"{metric}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{metric}: N/A (Missing Data)\")\n",
        "\n",
        "\n",
        "        print(f\"\\n📊 Analysis Scores:\")\n",
        "        print(f\"Fundamental Score: {stock_data.fundamental_score}/50\")\n",
        "        print(f\"Technical Score: {stock_data.technical_score}/50\")\n",
        "        print(f\"Total Score: {stock_data.fundamental_score + stock_data.technical_score}/100\")\n",
        "\n",
        "        print(f\"\\n🎯 Recommendation: {stock_data.recommendation}\")\n",
        "        print(f\"{'='*60}\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "816bd5ab"
      },
      "source": [
        "## Improve logging\n",
        "\n",
        "### Subtask:\n",
        "Improve logging throughout the script to provide more detailed information about data fetching, calculations, and potential issues.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0638e36"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement enhanced logging by adding info and debug messages to key functions to track execution flow and variable values, as well as warning and error messages for potential issues, converting existing print statements to logger calls.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "5a3537b2"
      },
      "source": [
        "#@title Part 1 of Main script (Enhanced Logging)\n",
        "# Indian Stock Analyzer - Part 1 (Corrected and Enhanced further)\n",
        "# Complete implementation with improvements for missing data handling and Debt-to-Equity validation\n",
        "# and expanded industry benchmarks, with enhanced logging\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import logging\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure logging (ensure this is only configured once if running multiple cells)\n",
        "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "# logger = logging.getLogger(__name__) # Define logger globally\n",
        "\n",
        "@dataclass\n",
        "class StockData:\n",
        "    \"\"\"Data class to store comprehensive stock information\"\"\"\n",
        "    symbol: str\n",
        "    company_name: str\n",
        "    current_price: float\n",
        "    market_cap: float\n",
        "    info: Dict\n",
        "    price_data: pd.DataFrame\n",
        "    indicators: Dict\n",
        "    fundamental_score: float\n",
        "    technical_score: float\n",
        "    recommendation: str\n",
        "    metrics: Dict\n",
        "\n",
        "class IndianStockAnalyzer:\n",
        "    \"\"\"Comprehensive stock analyzer for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the analyzer with Indian market specific parameters\"\"\"\n",
        "        logger.info(\"Initializing IndianStockAnalyzer.\")\n",
        "        self.nifty_symbol = \"^NSEI\"\n",
        "        self.risk_free_rate = 0.065  # Will be made dynamic in Part 2\n",
        "\n",
        "        # Industry-specific benchmark thresholds for Indian markets\n",
        "        # Expanded with additional sectors\n",
        "        self.industry_benchmarks = {\n",
        "            'technology': {\n",
        "                'pe_ratio': {'excellent': 25, 'good': 35, 'fair': 45},\n",
        "                'debt_to_equity': {'excellent': 0.3, 'good': 0.5, 'fair': 0.8},\n",
        "                'roe': {'excellent': 0.25, 'good': 0.18, 'fair': 0.12},\n",
        "                'revenue_growth': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10}\n",
        "            },\n",
        "            'banking': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 20, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 8, 'good': 10, 'fair': 12}, # Higher D/E is normal for banks\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.25, 'good': 0.20, 'fair': 0.15}\n",
        "            },\n",
        "            'pharmaceutical': {\n",
        "                'pe_ratio': {'excellent': 20, 'good': 30, 'fair': 40},\n",
        "                'debt_to_equity': {'excellent': 0.4, 'good': 0.6, 'fair': 0.8},\n",
        "                'roe': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.08}\n",
        "            },\n",
        "            'fmcg': {\n",
        "                'pe_ratio': {'excellent': 30, 'good': 40, 'fair': 50},\n",
        "                'debt_to_equity': {'excellent': 0.5, 'good': 0.8, 'fair': 1.0},\n",
        "                'roe': {'excellent': 0.30, 'good': 0.25, 'fair': 0.15},\n",
        "                'revenue_growth': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.08}\n",
        "            },\n",
        "            'automobile': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "                'debt_to_equity': {'excellent': 0.6, 'good': 0.8, 'fair': 1.2},\n",
        "                'roe': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "            },\n",
        "            'infrastructure': {\n",
        "                'pe_ratio': {'excellent': 12, 'good': 18, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05}\n",
        "            },\n",
        "            'energy': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 15, 'fair': 20},\n",
        "                'debt_to_equity': {'excellent': 0.8, 'good': 1.2, 'fair': 1.5},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "            },\n",
        "            'realty': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 15, 'fair': 25},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05},\n",
        "                'revenue_growth': {'excellent': 0.25, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05}\n",
        "            },\n",
        "            'telecom': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05},\n",
        "                'revenue_growth': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.08, 'good': 0.05, 'fair': 0.03}\n",
        "            },\n",
        "             # Added missing major sectors (with illustrative benchmarks - these should be validated)\n",
        "            'metals & mining': {\n",
        "                'pe_ratio': {'excellent': 8, 'good': 12, 'fair': 18}, # Lower P/E typical\n",
        "                'debt_to_equity': {'excellent': 0.8, 'good': 1.3, 'fair': 1.8}, # Can be leveraged\n",
        "                'roe': {'excellent': 0.18, 'good': 0.12, 'fair': 0.08},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.04}\n",
        "            },\n",
        "             'capital goods': {\n",
        "                'pe_ratio': {'excellent': 20, 'good': 30, 'fair': 40},\n",
        "                'debt_to_equity': {'excellent': 0.5, 'good': 0.8, 'fair': 1.2},\n",
        "                'roe': {'excellent': 0.18, 'good': 0.14, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.18, 'good': 0.13, 'fair': 0.08},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.04}\n",
        "            },\n",
        "             'chemicals': {\n",
        "                'pe_ratio': {'excellent': 25, 'good': 35, 'fair': 45},\n",
        "                'debt_to_equity': {'excellent': 0.4, 'good': 0.6, 'fair': 0.9},\n",
        "                'roe': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.06},\n",
        "                'net_profit_margin': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05}\n",
        "            },\n",
        "             'utilities': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 15, 'fair': 20},\n",
        "                'debt_to_equity': {'excellent': 1.5, 'good': 2.0, 'fair': 3.0}, # Higher D/E is common\n",
        "                'roe': {'excellent': 0.12, 'good': 0.09, 'fair': 0.06},\n",
        "                'revenue_growth': {'excellent': 0.08, 'good': 0.05, 'fair': 0.03}, # Stable, lower growth\n",
        "                'net_profit_margin': {'excellent': 0.15, 'good': 0.10, 'fair': 0.07} # Stable margins\n",
        "            },\n",
        "             'construction': {\n",
        "                'pe_ratio': {'excellent': 10, 'good': 16, 'fair': 22},\n",
        "                'debt_to_equity': {'excellent': 1.0, 'good': 1.5, 'fair': 2.0},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.10, 'fair': 0.07},\n",
        "                'revenue_growth': {'excellent': 0.20, 'good': 0.15, 'fair': 0.10},\n",
        "                'net_profit_margin': {'excellent': 0.08, 'good': 0.05, 'fair': 0.03}\n",
        "            },\n",
        "              'consumer durables': {\n",
        "                'pe_ratio': {'excellent': 35, 'good': 45, 'fair': 60}, # Higher P/E common\n",
        "                'debt_to_equity': {'excellent': 0.4, 'good': 0.7, 'fair': 1.0},\n",
        "                'roe': {'excellent': 0.25, 'good': 0.18, 'fair': 0.12},\n",
        "                'revenue_growth': {'excellent': 0.18, 'good': 0.12, 'fair': 0.08},\n",
        "                'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.04}\n",
        "            },\n",
        "             'textiles': {\n",
        "                'pe_ratio': {'excellent': 15, 'good': 22, 'fair': 30},\n",
        "                'debt_to_equity': {'excellent': 0.7, 'good': 1.0, 'fair': 1.5},\n",
        "                'roe': {'excellent': 0.15, 'good': 0.10, 'fair': 0.07},\n",
        "                'revenue_growth': {'excellent': 0.12, 'good': 0.08, 'fair': 0.05},\n",
        "                'net_profit_margin': {'excellent': 0.08, 'good': 0.05, 'fair': 0.03}\n",
        "            }\n",
        "\n",
        "\n",
        "        }\n",
        "\n",
        "        # Default benchmarks for other sectors\n",
        "        self.default_benchmarks = {\n",
        "            'pe_ratio': {'excellent': 15, 'good': 25, 'fair': 35},\n",
        "            'debt_to_equity': {'excellent': 0.5, 'good': 1.0, 'fair': 1.5},\n",
        "            'roe': {'excellent': 0.15, 'good': 0.10, 'fair': 0.07},\n",
        "            'revenue_growth': {'excellent': 0.15, 'good': 0.10, 'fair': 0.05},\n",
        "            'net_profit_margin': {'excellent': 0.10, 'good': 0.07, 'fair': 0.05}\n",
        "        }\n",
        "        logger.info(\"IndianStockAnalyzer initialized.\")\n",
        "\n",
        "    def get_stock_data(self, symbol: str) -> Optional[yf.Ticker]:\n",
        "        \"\"\"Fetch stock data from Yahoo Finance\"\"\"\n",
        "        logger.info(f\"Attempting to fetch stock data for {symbol}.\")\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            # Verify the ticker is valid by checking if it has info\n",
        "            if ticker.info and 'symbol' in ticker.info:\n",
        "                logger.info(f\"Successfully fetched ticker data for {symbol}.\")\n",
        "                return ticker\n",
        "            else:\n",
        "                logger.error(f\"Invalid symbol or no info available for {symbol}.\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error fetching data for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_industry_benchmarks(self, sector: str) -> Dict:\n",
        "        \"\"\"Get industry-specific benchmarks\"\"\"\n",
        "        logger.debug(f\"Getting industry benchmarks for sector: {sector}\")\n",
        "        sector_lower = sector.lower() if sector else ''\n",
        "\n",
        "        # Map common sector names to our benchmark categories\n",
        "        sector_mapping = {\n",
        "            'technology': 'technology',\n",
        "            'information technology': 'technology',\n",
        "            'financial services': 'banking',\n",
        "            'financials': 'banking',\n",
        "            'healthcare': 'pharmaceutical',\n",
        "            'consumer defensive': 'fmcg',\n",
        "            'consumer staples': 'fmcg', # Alias\n",
        "            'consumer cyclical': 'automobile',\n",
        "            'industrials': 'infrastructure', # Broad mapping\n",
        "            'energy': 'energy',\n",
        "            'real estate': 'realty',\n",
        "            'communication services': 'telecom',\n",
        "            'metals and mining': 'metals & mining', # Map to new category\n",
        "            'capital goods': 'capital goods',\n",
        "            'chemicals': 'chemicals',\n",
        "            'textiles': 'textiles',\n",
        "            'media': 'media & entertainment', # Broad mapping\n",
        "            'consumer durables': 'consumer durables',\n",
        "            'utilities': 'utilities',\n",
        "            'services': 'services', # Keep 'services' even if no specific benchmark yet\n",
        "            'construction': 'construction'\n",
        "        }\n",
        "\n",
        "        benchmark_key = sector_mapping.get(sector_lower, None)\n",
        "\n",
        "        if benchmark_key and benchmark_key in self.industry_benchmarks:\n",
        "            logger.info(f\"Using specific industry benchmarks for sector: {sector}\")\n",
        "            return self.industry_benchmarks[benchmark_key]\n",
        "        else:\n",
        "            logger.info(f\"Using default benchmarks for sector: {sector}\")\n",
        "            return self.default_benchmarks\n",
        "\n",
        "    def calculate_technical_indicators(self, price_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate comprehensive technical indicators\"\"\"\n",
        "        logger.info(\"Calculating technical indicators.\")\n",
        "        indicators = {}\n",
        "        data_len = len(price_data)\n",
        "        logger.debug(f\"Price data length: {data_len}\")\n",
        "\n",
        "        try:\n",
        "            # Simple Moving Averages\n",
        "            if data_len >= 20:\n",
        "                 indicators['SMA_20'] = price_data['Close'].rolling(window=20).mean().iloc[-1]\n",
        "                 logger.debug(f\"Calculated SMA_20: {indicators['SMA_20']:.2f}\")\n",
        "            else:\n",
        "                 indicators['SMA_20'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_20.\")\n",
        "\n",
        "            if data_len >= 50:\n",
        "                 indicators['SMA_50'] = price_data['Close'].rolling(window=50).mean().iloc[-1]\n",
        "                 logger.debug(f\"Calculated SMA_50: {indicators['SMA_50']:.2f}\")\n",
        "            else:\n",
        "                 indicators['SMA_50'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_50.\")\n",
        "\n",
        "            if data_len >= 200:\n",
        "                 indicators['SMA_200'] = price_data['Close'].rolling(window=200).mean().iloc[-1]\n",
        "                 logger.debug(f\"Calculated SMA_200: {indicators['SMA_200']:.2f}\")\n",
        "            else:\n",
        "                 indicators['SMA_200'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_200.\")\n",
        "\n",
        "            # Exponential Moving Averages\n",
        "            if data_len >= 12:\n",
        "                 indicators['EMA_12'] = price_data['Close'].ewm(span=12, adjust=False).mean().iloc[-1]\n",
        "                 logger.debug(f\"Calculated EMA_12: {indicators['EMA_12']:.2f}\")\n",
        "            else:\n",
        "                 indicators['EMA_12'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for EMA_12.\")\n",
        "\n",
        "            if data_len >= 26:\n",
        "                 indicators['EMA_26'] = price_data['Close'].ewm(span=26, adjust=False).mean().iloc[-1]\n",
        "                 logger.debug(f\"Calculated EMA_26: {indicators['EMA_26']:.2f}\")\n",
        "            else:\n",
        "                 indicators['EMA_26'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for EMA_26.\")\n",
        "\n",
        "            # RSI\n",
        "            if data_len >= 14:\n",
        "                indicators['RSI'] = self.calculate_rsi(price_data['Close'])\n",
        "                logger.debug(f\"Calculated RSI: {indicators['RSI']:.2f}\")\n",
        "            else:\n",
        "                 indicators['RSI'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for RSI.\")\n",
        "\n",
        "            # MACD (requires EMA_12 and EMA_26)\n",
        "            macd_line = np.nan\n",
        "            signal_line = np.nan\n",
        "            macd_histogram = np.nan\n",
        "            logger.debug(\"Attempting to calculate MACD.\")\n",
        "\n",
        "            if 'EMA_12' in indicators and 'EMA_26' in indicators and not np.isnan(indicators['EMA_12']) and not np.isnan(indicators['EMA_26']):\n",
        "                 # Use the entire macd_line series for rolling calculation if possible\n",
        "                 full_macd_line_series = price_data['Close'].ewm(span=12, adjust=False).mean() - price_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "                 if len(full_macd_line_series.dropna()) >= 9:\n",
        "                      macd_line = full_macd_line_series.iloc[-1]\n",
        "                      signal_line = full_macd_line_series.ewm(span=9, adjust=False).mean().iloc[-1]\n",
        "                      if not np.isnan(signal_line):\n",
        "                         macd_histogram = macd_line - signal_line\n",
        "                 else:\n",
        "                      logger.warning(\"Insufficient data for MACD signal line calculation.\")\n",
        "            else:\n",
        "                 logger.warning(\"MACD not calculated due to missing EMA_12 or EMA_26.\")\n",
        "\n",
        "\n",
        "            indicators['MACD'] = macd_line\n",
        "            indicators['MACD_signal'] = signal_line\n",
        "            indicators['MACD_histogram'] = macd_histogram\n",
        "\n",
        "            # Log MACD values after calculation\n",
        "            logger.debug(f\"Final MACD: {indicators['MACD']}, Signal: {indicators['MACD_signal']}, Histogram: {indicators['MACD_histogram']}\")\n",
        "\n",
        "\n",
        "            # Bollinger Bands (requires SMA_20 and enough data for std dev)\n",
        "            bb_period = 20\n",
        "            bb_std = 2\n",
        "            logger.debug(f\"Attempting to calculate Bollinger Bands (Period: {bb_period}, Std Dev: {bb_std}).\")\n",
        "            if data_len >= bb_period:\n",
        "                sma_bb = price_data['Close'].rolling(window=bb_period).mean()\n",
        "                std_bb = price_data['Close'].rolling(window=bb_period).std()\n",
        "                # Ensure SMA and STD are not NaN before calculating bands\n",
        "                if not np.isnan(sma_bb.iloc[-1]) and not np.isnan(std_bb.iloc[-1]):\n",
        "                    indicators['BB_upper'] = sma_bb.iloc[-1] + (std_bb.iloc[-1] * bb_std)\n",
        "                    indicators['BB_lower'] = sma_bb.iloc[-1] - (std_bb.iloc[-1] * bb_std)\n",
        "                    indicators['BB_middle'] = sma_bb.iloc[-1]\n",
        "                    logger.debug(f\"Calculated BB_upper: {indicators['BB_upper']:.2f}, BB_lower: {indicators['BB_lower']:.2f}, BB_middle: {indicators['BB_middle']:.2f}\")\n",
        "                else:\n",
        "                    indicators['BB_upper'] = np.nan\n",
        "                    indicators['BB_lower'] = np.nan\n",
        "                    indicators['BB_middle'] = np.nan\n",
        "                    logger.warning(\"Bollinger Bands not calculated due to NaN in SMA or STD.\")\n",
        "            else:\n",
        "                indicators['BB_upper'] = np.nan\n",
        "                indicators['BB_lower'] = np.nan\n",
        "                indicators['BB_middle'] = np.nan\n",
        "                logger.warning(\"Insufficient data for Bollinger Bands.\")\n",
        "\n",
        "\n",
        "            # Volume indicators\n",
        "            logger.debug(\"Calculating Volume indicators.\")\n",
        "            if data_len >= 20:\n",
        "                 indicators['Volume_SMA'] = price_data['Volume'].rolling(window=20).mean().iloc[-1]\n",
        "                 logger.debug(f\"Calculated Volume_SMA: {indicators['Volume_SMA']:.2f}\")\n",
        "                 if indicators['Volume_SMA'] is not None and not np.isnan(indicators['Volume_SMA']) and indicators['Volume_SMA'] > 0:\n",
        "                      indicators['Volume_ratio'] = price_data['Volume'].iloc[-1] / indicators['Volume_SMA']\n",
        "                      logger.debug(f\"Calculated Volume_ratio: {indicators['Volume_ratio']:.2f}\")\n",
        "                 else:\n",
        "                      indicators['Volume_ratio'] = np.nan\n",
        "                      logger.warning(\"Volume SMA is zero or NaN, Volume ratio not calculated.\")\n",
        "            else:\n",
        "                 indicators['Volume_SMA'] = np.nan\n",
        "                 indicators['Volume_ratio'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for Volume SMA and ratio.\")\n",
        "\n",
        "\n",
        "            # Price position (requires SMA_20 and SMA_50)\n",
        "            current_price = price_data['Close'].iloc[-1] if data_len > 0 and 'Close' in price_data and not price_data['Close'].empty else np.nan\n",
        "            indicators['current_price'] = current_price # Store current price\n",
        "            logger.debug(f\"Current price: {current_price:.2f}\")\n",
        "\n",
        "            if current_price is not None and not np.isnan(current_price) and 'SMA_20' in indicators and indicators['SMA_20'] is not None and not np.isnan(indicators['SMA_20']) and indicators['SMA_20'] > 0:\n",
        "                indicators['Price_to_SMA20'] = ((current_price / indicators['SMA_20'] - 1) * 100)\n",
        "                logger.debug(f\"Calculated Price_to_SMA20: {indicators['Price_to_SMA20']:.2f}%\")\n",
        "            else:\n",
        "                 indicators['Price_to_SMA20'] = np.nan\n",
        "                 logger.warning(\"Price to SMA20 not calculated due to missing current price or SMA20.\")\n",
        "\n",
        "            if current_price is not None and not np.isnan(current_price) and 'SMA_50' in indicators and indicators['SMA_50'] is not None and not np.isnan(indicators['SMA_50']) and indicators['SMA_50'] > 0:\n",
        "                 indicators['Price_to_SMA50'] = ((current_price / indicators['SMA_50'] - 1) * 100)\n",
        "                 logger.debug(f\"Calculated Price_to_SMA50: {indicators['Price_to_SMA50']:.2f}%\")\n",
        "            else:\n",
        "                 indicators['Price_to_SMA50'] = np.nan\n",
        "                 logger.warning(\"Price to SMA50 not calculated due to missing current price or SMA50.\")\n",
        "\n",
        "\n",
        "            # Support and Resistance (requires enough data for rolling max/min)\n",
        "            logger.debug(\"Calculating Support and Resistance.\")\n",
        "            if data_len >= 20:\n",
        "                 indicators['Resistance'] = price_data['High'].rolling(window=20).max().iloc[-1]\n",
        "                 indicators['Support'] = price_data['Low'].rolling(window=20).min().iloc[-1]\n",
        "                 logger.debug(f\"Calculated Resistance: {indicators['Resistance']:.2f}, Support: {indicators['Support']:.2f}\")\n",
        "            else:\n",
        "                 indicators['Resistance'] = np.nan\n",
        "                 indicators['Support'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for Support and Resistance.\")\n",
        "\n",
        "            logger.info(\"Technical indicators calculation completed.\")\n",
        "            return indicators\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating technical indicators: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> Optional[float]:\n",
        "        \"\"\"Calculate Relative Strength Index\"\"\"\n",
        "        logger.debug(f\"Calculating RSI with period: {period}.\")\n",
        "        try:\n",
        "            if len(prices) < period:\n",
        "                logger.warning(f\"Insufficient data ({len(prices)} data points) for RSI calculation (requires {period}).\")\n",
        "                return np.nan # Return NaN for insufficient data\n",
        "\n",
        "            delta = prices.diff()\n",
        "            gain = delta.where(delta > 0, 0)\n",
        "            loss = -delta.where(delta < 0, 0)\n",
        "\n",
        "            avg_gain = gain.rolling(window=period).mean()\n",
        "            avg_loss = loss.rolling(window=period).mean()\n",
        "\n",
        "            # Handle division by zero if avg_loss is zero or NaN\n",
        "            if avg_loss.iloc[-1] is None or np.isnan(avg_loss.iloc[-1]) or avg_loss.iloc[-1] == 0:\n",
        "                 rsi_value = 100.0 if avg_gain.iloc[-1] is not None and not np.isnan(avg_gain.iloc[-1]) and avg_gain.iloc[-1] > 0 else 50.0 # If no loss, RSI is 100 (if gain) or 50 (if no change)\n",
        "                 logger.debug(f\"Calculated RSI (zero avg_loss): {rsi_value:.2f}\")\n",
        "                 return rsi_value\n",
        "            elif avg_loss.iloc[-1] > 0:\n",
        "                rs = avg_gain / avg_loss\n",
        "                rsi = 100 - (100 / (1 + rs))\n",
        "                rsi_value = rsi.iloc[-1]\n",
        "                logger.debug(f\"Calculated RSI: {rsi_value:.2f}\")\n",
        "                return rsi_value\n",
        "            else:\n",
        "                 logger.warning(\"Unexpected condition in RSI calculation (avg_loss not > 0 and not zero/NaN).\")\n",
        "                 return np.nan # Should not happen with abs, but as a safeguard\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating RSI: {str(e)}\")\n",
        "            return np.nan # Return NaN on error\n",
        "\n",
        "    def calculate_fundamental_score(self, info: Dict, benchmarks: Dict) -> Tuple[float, Dict]:\n",
        "        \"\"\"Calculate fundamental analysis score based on Indian market standards\"\"\"\n",
        "        logger.info(\"Calculating fundamental score.\")\n",
        "        score = 0\n",
        "        max_score = 50\n",
        "        metrics = {}\n",
        "        logger.debug(f\"Using benchmarks: {benchmarks}\")\n",
        "\n",
        "        try:\n",
        "            # P/E Ratio (10 points)\n",
        "            pe_ratio = info.get('trailingPE', info.get('forwardPE', None))\n",
        "            logger.debug(f\"Raw PE Ratio: {pe_ratio}\")\n",
        "            if pe_ratio is not None and isinstance(pe_ratio, (int, float)) and not np.isnan(pe_ratio):\n",
        "                metrics['PE_Ratio'] = pe_ratio\n",
        "                if pe_ratio > 0: # Ensure PE is positive for scoring\n",
        "                     if pe_ratio <= benchmarks['pe_ratio']['excellent']:\n",
        "                         score += 10\n",
        "                         logger.debug(f\"PE Ratio ({pe_ratio:.2f}) is Excellent. +10 pts.\")\n",
        "                     elif pe_ratio <= benchmarks['pe_ratio']['good']:\n",
        "                         score += 7\n",
        "                         logger.debug(f\"PE Ratio ({pe_ratio:.2f}) is Good. +7 pts.\")\n",
        "                     elif pe_ratio <= benchmarks['pe_ratio']['fair']:\n",
        "                         score += 4\n",
        "                         logger.debug(f\"PE Ratio ({pe_ratio:.2f}) is Fair. +4 pts.\")\n",
        "                     else:\n",
        "                         score += 2\n",
        "                         logger.debug(f\"PE Ratio ({pe_ratio:.2f}) is Poor. +2 pts.\")\n",
        "                else:\n",
        "                    score += 1 # Small score for non-positive PE\n",
        "                    logger.warning(f\"PE Ratio ({pe_ratio}) is non-positive. Assigning minimal score (+1 pt).\")\n",
        "            else:\n",
        "                 metrics['PE_Ratio'] = np.nan\n",
        "                 logger.warning(\"PE Ratio not available or is invalid. Assigning no score for PE.\")\n",
        "\n",
        "\n",
        "            # Debt to Equity (10 points)\n",
        "            debt_to_equity_raw = info.get('debtToEquity', None)\n",
        "            debt_to_equity = np.nan # Initialize to NaN\n",
        "            logger.debug(f\"Raw Debt to Equity: {debt_to_equity_raw}\")\n",
        "\n",
        "            if debt_to_equity_raw is not None and isinstance(debt_to_equity_raw, (int, float)) and not np.isnan(debt_to_equity_raw):\n",
        "                 # Handle potential outliers (very high values might indicate data issues)\n",
        "                 if debt_to_equity_raw > 10000: # Arbitrary large threshold for outlier detection\n",
        "                      logger.warning(f\"Debt to Equity raw value is unusually high: {debt_to_equity_raw}. Treating as potential data issue.\")\n",
        "                      # Could assign a very low score or NaN, depending on policy\n",
        "                      debt_to_equity = np.nan # Treat as invalid data for now\n",
        "                 else:\n",
        "                      # Heuristic for percentage vs decimal\n",
        "                      if debt_to_equity_raw > 100: # Likely a percentage\n",
        "                           debt_to_equity = debt_to_equity_raw / 100.0\n",
        "                           logger.debug(f\"Converted Debt to Equity from percentage: {debt_to_equity:.2f}\")\n",
        "                      else: # Assume it's already a decimal\n",
        "                           debt_to_equity = debt_to_equity_raw\n",
        "                           logger.debug(f\"Using Debt to Equity as decimal: {debt_to_equity:.2f}\")\n",
        "\n",
        "\n",
        "                      # Re-check if the converted value is still reasonable (e.g., not from a huge raw decimal)\n",
        "                      if debt_to_equity is not None and not np.isnan(debt_to_equity) and debt_to_equity > 100: # Another threshold after conversion\n",
        "                          logger.warning(f\"Debt to Equity value after conversion is still very high: {debt_to_equity:.2f}. May indicate data issue or highly leveraged company.\")\n",
        "                          # Could assign a low score or cap it, for now let the scoring handle it.\n",
        "\n",
        "\n",
        "            metrics['Debt_to_Equity'] = debt_to_equity\n",
        "\n",
        "            # Score based on the validated debt_to_equity\n",
        "            if debt_to_equity is not None and not np.isnan(debt_to_equity):\n",
        "                if debt_to_equity <= benchmarks['debt_to_equity']['excellent']:\n",
        "                    score += 10\n",
        "                    logger.debug(f\"Debt to Equity ({debt_to_equity:.2f}) is Excellent. +10 pts.\")\n",
        "                elif debt_to_equity <= benchmarks['debt_to_equity']['good']:\n",
        "                    score += 7\n",
        "                    logger.debug(f\"Debt to Equity ({debt_to_equity:.2f}) is Good. +7 pts.\")\n",
        "                elif debt_to_equity <= benchmarks['debt_to_equity']['fair']:\n",
        "                    score += 4\n",
        "                    logger.debug(f\"Debt to Equity ({debt_to_equity:.2f}) is Fair. +4 pts.\")\n",
        "                else:\n",
        "                    score += 2\n",
        "                    logger.debug(f\"Debt to Equity ({debt_to_equity:.2f}) is Poor. +2 pts.\")\n",
        "            else:\n",
        "                 logger.warning(\"Debt to Equity not available, invalid, or an outlier. Assigning low score (+1 pt).\")\n",
        "                 score += 1 # Assign minimal score if D/E is not valid\n",
        "\n",
        "\n",
        "            # ROE (10 points)\n",
        "            roe = info.get('returnOnEquity', None)\n",
        "            logger.debug(f\"Raw ROE: {roe}\")\n",
        "            if roe is not None and isinstance(roe, (int, float)) and not np.isnan(roe):\n",
        "                metrics['ROE'] = roe\n",
        "                if roe >= benchmarks['roe']['excellent']:\n",
        "                    score += 10\n",
        "                    logger.debug(f\"ROE ({roe:.2f}) is Excellent. +10 pts.\")\n",
        "                elif roe >= benchmarks['roe']['good']:\n",
        "                    score += 7\n",
        "                    logger.debug(f\"ROE ({roe:.2f}) is Good. +7 pts.\")\n",
        "                elif roe >= benchmarks['roe']['fair']:\n",
        "                    score += 4\n",
        "                    logger.debug(f\"ROE ({roe:.2f}) is Fair. +4 pts.\")\n",
        "                else:\n",
        "                    score += 2\n",
        "                    logger.debug(f\"ROE ({roe:.2f}) is Poor. +2 pts.\")\n",
        "            else:\n",
        "                 metrics['ROE'] = np.nan\n",
        "                 logger.warning(\"ROE not available or is invalid. Assigning no score for ROE.\")\n",
        "\n",
        "            # Revenue Growth (10 points)\n",
        "            revenue_growth = info.get('revenueGrowth', None)\n",
        "            logger.debug(f\"Raw Revenue Growth: {revenue_growth}\")\n",
        "            if revenue_growth is not None and isinstance(revenue_growth, (int, float)) and not np.isnan(revenue_growth):\n",
        "                metrics['Revenue_Growth'] = revenue_growth\n",
        "                if revenue_growth >= benchmarks['revenue_growth']['excellent']:\n",
        "                    score += 10\n",
        "                    logger.debug(f\"Revenue Growth ({revenue_growth:.2f}) is Excellent. +10 pts.\")\n",
        "                elif revenue_growth >= benchmarks['revenue_growth']['good']:\n",
        "                    score += 7\n",
        "                    logger.debug(f\"Revenue Growth ({revenue_growth:.2f}) is Good. +7 pts.\")\n",
        "                elif revenue_growth >= benchmarks['revenue_growth']['fair']:\n",
        "                    score += 4\n",
        "                    logger.debug(f\"Revenue Growth ({revenue_growth:.2f}) is Fair. +4 pts.\")\n",
        "                else:\n",
        "                    score += 2\n",
        "                    logger.debug(f\"Revenue Growth ({revenue_growth:.2f}) is Poor. +2 pts.\")\n",
        "            else:\n",
        "                 metrics['Revenue_Growth'] = np.nan\n",
        "                 logger.warning(\"Revenue Growth not available or is invalid. Assigning no score for Revenue Growth.\")\n",
        "\n",
        "            # Net Profit Margin (10 points)\n",
        "            profit_margin = info.get('profitMargins', None)\n",
        "            logger.debug(f\"Raw Net Profit Margin: {profit_margin}\")\n",
        "            if profit_margin is not None and isinstance(profit_margin, (int, float)) and not np.isnan(profit_margin):\n",
        "                metrics['Net_Profit_Margin'] = profit_margin\n",
        "                if profit_margin >= benchmarks['net_profit_margin']['excellent']:\n",
        "                    score += 10\n",
        "                    logger.debug(f\"Net Profit Margin ({profit_margin:.2f}) is Excellent. +10 pts.\")\n",
        "                elif profit_margin >= benchmarks['net_profit_margin']['good']:\n",
        "                    score += 7\n",
        "                    logger.debug(f\"Net Profit Margin ({profit_margin:.2f}) is Good. +7 pts.\")\n",
        "                elif profit_margin >= benchmarks['net_profit_margin']['fair']:\n",
        "                    score += 4\n",
        "                    logger.debug(f\"Net Profit Margin ({profit_margin:.2f}) is Fair. +4 pts.\")\n",
        "                else:\n",
        "                    score += 2\n",
        "                    logger.debug(f\"Net Profit Margin ({profit_margin:.2f}) is Poor. +2 pts.\")\n",
        "            else:\n",
        "                 metrics['Net_Profit_Margin'] = np.nan\n",
        "                 logger.warning(\"Net Profit Margin not available or is invalid. Assigning no score for Net Profit Margin.\")\n",
        "\n",
        "\n",
        "            # Normalize score to max_score (already capped by scoring logic)\n",
        "            metrics['Fundamental_Score'] = score\n",
        "            logger.info(f\"Fundamental score calculated: {score}/50\")\n",
        "            logger.debug(f\"Fundamental metrics: {metrics}\")\n",
        "\n",
        "            return score, metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating fundamental score: {str(e)}\")\n",
        "            return 0, {}\n",
        "\n",
        "    def calculate_technical_score(self, indicators: Dict) -> float:\n",
        "        \"\"\"Calculate technical analysis score\"\"\"\n",
        "        logger.info(\"Calculating technical score.\")\n",
        "        score = 0\n",
        "        max_score = 50\n",
        "        indicator_scores = {} # To store scores for each indicator\n",
        "        logger.debug(f\"Technical indicators used for scoring: {indicators}\")\n",
        "\n",
        "        try:\n",
        "            # RSI Score (10 points)\n",
        "            rsi = indicators.get('RSI', None)\n",
        "            if rsi is not None and not np.isnan(rsi):\n",
        "                 if 40 <= rsi <= 60:  # Neutral zone\n",
        "                     indicator_scores['RSI'] = 7\n",
        "                     logger.debug(f\"RSI ({rsi:.2f}) is Neutral. +7 pts.\")\n",
        "                 elif rsi < 40:  # Oversold\n",
        "                     indicator_scores['RSI'] = 10\n",
        "                     logger.debug(f\"RSI ({rsi:.2f}) is Oversold. +10 pts.\")\n",
        "                 elif 60 < rsi <= 70:  # Overbought but not extreme\n",
        "                     indicator_scores['RSI'] = 5\n",
        "                     logger.debug(f\"RSI ({rsi:.2f}) is Approaching Overbought. +5 pts.\")\n",
        "                 else:  # Extreme levels\n",
        "                     indicator_scores['RSI'] = 2\n",
        "                     logger.debug(f\"RSI ({rsi:.2f}) is Extreme. +2 pts.\")\n",
        "            else:\n",
        "                 indicator_scores['RSI'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"RSI not calculated or is NaN/None. Assigning 0 score for RSI.\")\n",
        "\n",
        "\n",
        "            # MACD Score (10 points)\n",
        "            macd = indicators.get('MACD', None)\n",
        "            macd_signal = indicators.get('MACD_signal', None)\n",
        "            logger.debug(f\"MACD: {macd}, Signal: {macd_signal}\")\n",
        "\n",
        "            # Explicitly check if both are numbers before comparing\n",
        "            if isinstance(macd, (int, float)) and isinstance(macd_signal, (int, float)) and not np.isnan(macd) and not np.isnan(macd_signal):\n",
        "                 if macd > macd_signal:\n",
        "                     indicator_scores['MACD'] = 10\n",
        "                     logger.debug(\"MACD > Signal (Bullish crossover). +10 pts.\")\n",
        "                 else:\n",
        "                     indicator_scores['MACD'] = 3\n",
        "                     logger.debug(\"MACD <= Signal (Bearish crossover). +3 pts.\")\n",
        "            else:\n",
        "                 indicator_scores['MACD'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"MACD or MACD signal not calculated or is not a valid number. Assigning 0 score for MACD.\")\n",
        "\n",
        "\n",
        "            # Moving Average Score (10 points) - Using SMA_20 vs SMA_50\n",
        "            sma_20 = indicators.get('SMA_20', None)\n",
        "            sma_50 = indicators.get('SMA_50', None)\n",
        "            logger.debug(f\"SMA_20: {sma_20}, SMA_50: {sma_50}\")\n",
        "            if sma_20 is not None and sma_50 is not None and not np.isnan(sma_20) and not np.isnan(sma_50):\n",
        "                if sma_20 > sma_50:\n",
        "                    indicator_scores['Moving_Averages'] = 10\n",
        "                    logger.debug(\"SMA_20 > SMA_50 (Bullish trend). +10 pts.\")\n",
        "                else:\n",
        "                    indicator_scores['Moving_Averages'] = 3\n",
        "                    logger.debug(\"SMA_20 <= SMA_50 (Bearish trend). +3 pts.\")\n",
        "            else:\n",
        "                indicator_scores['Moving_Averages'] = 0 # Assign 0 if NaN/None\n",
        "                logger.warning(\"SMA_20 or SMA_50 not calculated or is NaN/None. Assigning 0 score for Moving Averages.\")\n",
        "\n",
        "            # Bollinger Bands Score (10 points)\n",
        "            current_price = indicators.get('current_price', None) # Assuming current_price is passed in indicators\n",
        "            bb_upper = indicators.get('BB_upper', None)\n",
        "            bb_lower = indicators.get('BB_lower', None)\n",
        "            bb_middle = indicators.get('BB_middle', None)\n",
        "            logger.debug(f\"Current Price: {current_price}, BB_upper: {bb_upper}, BB_lower: {bb_lower}, BB_middle: {bb_middle}\")\n",
        "\n",
        "            if current_price is not None and bb_upper is not None and bb_lower is not None and bb_middle is not None and \\\n",
        "               not np.isnan(current_price) and not np.isnan(bb_upper) and not np.isnan(bb_lower) and not np.isnan(bb_middle):\n",
        "                if bb_lower < current_price < bb_middle:\n",
        "                    indicator_scores['Bollinger_Bands'] = 10  # Good buying zone\n",
        "                    logger.debug(\"Price between Lower and Middle BB (potential buy). +10 pts.\")\n",
        "                elif bb_middle < current_price < bb_upper:\n",
        "                    indicator_scores['Bollinger_Bands'] = 7   # Neutral to positive\n",
        "                    logger.debug(\"Price between Middle and Upper BB (neutral/positive). +7 pts.\")\n",
        "                else:\n",
        "                    indicator_scores['Bollinger_Bands'] = 3   # Near extremes\n",
        "                    logger.debug(\"Price near BB extremes. +3 pts.\")\n",
        "            else:\n",
        "                 indicator_scores['Bollinger_Bands'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Bollinger Bands or current price not available or is NaN/None. Assigning 0 score for Bollinger Bands.\")\n",
        "\n",
        "\n",
        "            # Volume Score (10 points)\n",
        "            volume_ratio = indicators.get('Volume_ratio', None)\n",
        "            logger.debug(f\"Volume ratio: {volume_ratio}\")\n",
        "            if volume_ratio is not None and not np.isnan(volume_ratio):\n",
        "                 if 0.8 <= volume_ratio <= 1.5:\n",
        "                     indicator_scores['Volume'] = 7   # Normal volume\n",
        "                     logger.debug(f\"Volume ratio ({volume_ratio:.2f}) is Normal. +7 pts.\")\n",
        "                 elif volume_ratio > 1.5:\n",
        "                     indicator_scores['Volume'] = 10  # High volume (positive if with price up)\n",
        "                     logger.debug(f\"Volume ratio ({volume_ratio:.2f}) is High. +10 pts.\")\n",
        "                 else:\n",
        "                     indicator_scores['Volume'] = 3   # Low volume\n",
        "                     logger.debug(f\"Volume ratio ({volume_ratio:.2f}) is Low. +3 pts.\")\n",
        "            else:\n",
        "                 indicator_scores['Volume'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Volume ratio not calculated or is NaN/None. Assigning 0 score for Volume.\")\n",
        "\n",
        "            # Sum the scores from individual indicators\n",
        "            score = sum(indicator_scores.values())\n",
        "            logger.info(f\"Technical score calculated (before capping): {score}\")\n",
        "\n",
        "            return min(score, max_score) # Cap at max_score\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating technical score: {str(e)}\")\n",
        "            return 0\n",
        "\n",
        "    def generate_recommendation(self, fundamental_score: float, technical_score: float) -> str:\n",
        "        \"\"\"Generate investment recommendation based on scores\"\"\"\n",
        "        logger.info(f\"Generating recommendation based on Fundamental Score: {fundamental_score}, Technical Score: {technical_score}\")\n",
        "        total_score = fundamental_score + technical_score\n",
        "        logger.debug(f\"Total score for basic recommendation: {total_score}\")\n",
        "\n",
        "        if total_score >= 75:\n",
        "            return \"STRONG BUY\"\n",
        "        elif total_score >= 60:\n",
        "            return \"BUY\"\n",
        "        elif total_score >= 40:\n",
        "            return \"HOLD\"\n",
        "        elif total_score >= 25:\n",
        "            return \"SELL\"\n",
        "        else:\n",
        "            return \"STRONG SELL\"\n",
        "\n",
        "    def analyze_stock(self, symbol: str) -> Optional[StockData]:\n",
        "        \"\"\"Main method to analyze a stock\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Starting analysis for {symbol}\")\n",
        "\n",
        "            # Get stock data\n",
        "            ticker = self.get_stock_data(symbol)\n",
        "            if not ticker:\n",
        "                logger.error(f\"Failed to get stock data for {symbol}. Analysis aborted.\")\n",
        "                return None\n",
        "\n",
        "            # Get stock info\n",
        "            info = ticker.info\n",
        "            if not info:\n",
        "                logger.error(f\"No info available for {symbol}. Analysis aborted.\")\n",
        "                return None\n",
        "            logger.debug(f\"Fetched stock info for {symbol}: {list(info.keys())}\")\n",
        "\n",
        "\n",
        "            # Get historical price data\n",
        "            # Fetching enough data for 200-day SMA calculation\n",
        "            logger.info(f\"Fetching 1 year historical price data for {symbol}.\")\n",
        "            price_data = ticker.history(period=\"1y\") # Changed to 1 year to support 200-day SMA\n",
        "            if price_data.empty: # Check if price_data is empty\n",
        "                logger.error(f\"No price data available for {symbol}. Analysis aborted.\")\n",
        "                return None\n",
        "            # Also check for essential columns\n",
        "            if not all(col in price_data.columns for col in ['Open', 'High', 'Low', 'Close', 'Volume']):\n",
        "                 logger.error(f\"Price data for {symbol} is missing essential columns. Analysis aborted.\")\n",
        "                 return None\n",
        "            logger.info(f\"Successfully fetched {len(price_data)} data points.\")\n",
        "\n",
        "\n",
        "            # Get current price\n",
        "            current_price = price_data['Close'].iloc[-1] if len(price_data) > 0 and 'Close' in price_data and not price_data['Close'].empty else np.nan\n",
        "            if np.isnan(current_price):\n",
        "                 logger.warning(f\"Could not get current price for {symbol}.\")\n",
        "\n",
        "\n",
        "            # Add current price to indicators for technical score calculation\n",
        "            indicators = self.calculate_technical_indicators(price_data)\n",
        "            indicators['current_price'] = current_price # Ensure current price is available for BB score\n",
        "\n",
        "            # Get industry benchmarks\n",
        "            sector = info.get('sector', 'Unknown')\n",
        "            benchmarks = self.get_industry_benchmarks(sector)\n",
        "            logger.info(f\"Identified sector: {sector}. Using benchmarks for this sector.\")\n",
        "\n",
        "\n",
        "            # Calculate scores\n",
        "            fundamental_score, metrics = self.calculate_fundamental_score(info, benchmarks)\n",
        "            technical_score = self.calculate_technical_score(indicators)\n",
        "\n",
        "            # Generate recommendation\n",
        "            recommendation = self.generate_recommendation(fundamental_score, technical_score)\n",
        "\n",
        "            # Create StockData object\n",
        "            stock_data = StockData(\n",
        "                symbol=symbol,\n",
        "                company_name=info.get('longName', symbol),\n",
        "                current_price=current_price if not np.isnan(current_price) else 0.0, # Store 0 if current price is NaN\n",
        "                market_cap=info.get('marketCap', 0) if info.get('marketCap') is not None else 0, # Ensure marketCap is not None\n",
        "                info=info,\n",
        "                price_data=price_data,\n",
        "                indicators=indicators,\n",
        "                fundamental_score=fundamental_score,\n",
        "                technical_score=technical_score,\n",
        "                recommendation=recommendation,\n",
        "                metrics=metrics\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Analysis completed for {symbol}\")\n",
        "            return stock_data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def display_analysis(self, stock_data: StockData) -> None:\n",
        "        \"\"\"Display analysis results in a formatted manner\"\"\"\n",
        "        # Convert print statements to logger.info for consistency, or keep print for final output\n",
        "        # Keeping print for final formatted output as before\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Stock Analysis Report: {stock_data.company_name} ({stock_data.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{stock_data.current_price:,.2f}\" if stock_data.current_price is not None else \"Current Price: N/A\")\n",
        "        print(f\"Market Cap: ₹{stock_data.market_cap/10000000:,.2f} Cr\" if stock_data.market_cap is not None else \"Market Cap: N/A\") # Use stored market_cap\n",
        "        print(f\"Sector: {stock_data.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n📈 Technical Indicators:\")\n",
        "        # Display indicators, handling None values\n",
        "        for indicator, value in stock_data.indicators.items():\n",
        "            if indicator != 'current_price': # Avoid displaying current_price here\n",
        "                if value is not None and not np.isnan(value):\n",
        "                    if isinstance(value, float):\n",
        "                        print(f\"{indicator}: {value:,.2f}\")\n",
        "                    else:\n",
        "                        print(f\"{indicator}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{indicator}: N/A (Insufficient Data)\")\n",
        "\n",
        "\n",
        "        print(f\"\\n💰 Fundamental Metrics:\")\n",
        "        for metric, value in stock_data.metrics.items():\n",
        "            if metric != 'Fundamental_Score':\n",
        "                if value is not None and not np.isnan(value):\n",
        "                     if isinstance(value, float):\n",
        "                         if metric in ['ROE', 'Revenue_Growth', 'Net_Profit_Margin', 'Debt_to_Equity']:\n",
        "                             print(f\"{metric}: {value*100:.2f}%\") # Display as percentage for D/E, ROE, Growth, Margin\n",
        "                         else:\n",
        "                             print(f\"{metric}: {value:.2f}\")\n",
        "                     else:\n",
        "                         print(f\"{metric}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{metric}: N/A (Missing Data)\")\n",
        "\n",
        "\n",
        "        print(f\"\\n📊 Analysis Scores:\")\n",
        "        print(f\"Fundamental Score: {stock_data.fundamental_score}/50\")\n",
        "        print(f\"Technical Score: {stock_data.technical_score}/50\")\n",
        "        print(f\"Total Score: {stock_data.fundamental_score + stock_data.technical_score}/100\")\n",
        "\n",
        "        print(f\"\\n🎯 Recommendation: {stock_data.recommendation}\")\n",
        "        print(f\"{'='*60}\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cc1fbfe"
      },
      "source": [
        "**Reasoning**:\n",
        "Continue improving logging in the EnhancedStockAnalyzer class, adding info and debug messages to key functions and converting print statements to logger calls where appropriate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "04b64409"
      },
      "source": [
        "#@title Sentimental analysis with API (Enhanced Logging)\n",
        "# Indian Stock Analyzer - Part 2 (Improved Version with Enhanced Data Handling and Logging)\n",
        "# This continues from your Part 1 implementation\n",
        "\n",
        "# Import the Python SDK for Gemini API\n",
        "# from google.colab import userdata # Already imported in a previous cell\n",
        "# import google.generativeai as genai # Already imported in a previous cell\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import the Python SDK for Gemini API\n",
        "# Used to securely store your API key\n",
        "# from google.colab import userdata # Already imported\n",
        "# import google.generativeai as genai # Already imported\n",
        "\n",
        "# Configure Gemini API (ensure GOOGLE_API_KEY is set in Colab secrets)\n",
        "# GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') # Already done in a previous cell\n",
        "# genai.configure(api_key=GOOGLE_API_KEY) # Already done in a previous cell\n",
        "# gemini_model = genai.GenerativeModel('gemini-2.0-flash') # Using a more recent model # Already done in a previous cell\n",
        "\n",
        "\n",
        "class EnhancedStockAnalyzer:\n",
        "    \"\"\"Enhanced analyzer with additional features for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        logger.info(\"Initializing EnhancedStockAnalyzer.\")\n",
        "        self.risk_free_rate = self.get_dynamic_risk_free_rate()\n",
        "        # self.gemini_model = gemini_model # Use the globally configured model # Already assigned in a previous cell\n",
        "        logger.info(f\"EnhancedStockAnalyzer initialized with risk-free rate: {self.risk_free_rate}\")\n",
        "\n",
        "\n",
        "    def get_dynamic_risk_free_rate(self):\n",
        "        \"\"\"Fetch current 10-year G-Sec yield\"\"\"\n",
        "        logger.info(\"Fetching dynamic risk-free rate.\")\n",
        "        try:\n",
        "            # Try to get from a reliable source\n",
        "            # For now, using a realistic current rate\n",
        "            # In production, you'd scrape from RBI or use an API\n",
        "            rate = 0.072  # 7.2% as of recent data\n",
        "            logger.info(f\"Fetched dynamic risk-free rate: {rate}\")\n",
        "            return rate\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not fetch dynamic risk-free rate: {str(e)}. Falling back to default.\")\n",
        "            return 0.065  # Fallback to 6.5%\n",
        "\n",
        "    def get_circuit_limits(self, symbol):\n",
        "        \"\"\"\n",
        "        Get circuit breaker limits for the stock.\n",
        "        NOTE: This is a simplification. Actual NSE circuit limits vary based on\n",
        "        stock category (e.g., EQ, BE, T group), stage of price band reduction,\n",
        "        and are dynamic. Relying on fixed percentages based on index membership\n",
        "        is an approximation. For production, fetch from NSE or a reliable API.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Attempting to get circuit limits for {symbol}.\")\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "            prev_close = info.get('previousClose', None) # Use None as default\n",
        "            logger.debug(f\"Previous close for circuit limit calculation: {prev_close}\")\n",
        "\n",
        "            if prev_close is None or not isinstance(prev_close, (int, float)) or np.isnan(prev_close) or prev_close <= 0:\n",
        "                logger.warning(f\"Previous close not available or invalid for {symbol}. Cannot calculate circuit limits.\")\n",
        "                return None\n",
        "\n",
        "            # Enhanced NSE circuit limits (based on index membership approximation)\n",
        "            # This is still a simplification of complex exchange rules.\n",
        "            circuit_percent = 0.10 # Default to 10%\n",
        "\n",
        "            # Check if the stock is in a major index for higher limits\n",
        "            # Need a way to access get_index_membership or pass index membership\n",
        "            # For now, reuse the simplified logic directly here for logging context\n",
        "            index_memberships = self.get_index_membership(symbol) # Call locally for log context\n",
        "            logger.debug(f\"Index memberships for {symbol}: {index_memberships}\")\n",
        "\n",
        "            if index_memberships: # Check if list is not empty\n",
        "                 if 'NIFTY50' in index_memberships:\n",
        "                      circuit_percent = 0.20 # 20% for NIFTY50 stocks\n",
        "                      logger.debug(f\"Using 20% circuit limit for NIFTY50 stock {symbol}.\")\n",
        "                 elif 'NIFTY_NEXT50' in index_memberships:\n",
        "                      circuit_percent = 0.15 # Example: 15% for NIFTY Next 50 (approximation)\n",
        "                      logger.debug(f\"Using 15% circuit limit for NIFTY Next 50 stock {symbol}.\")\n",
        "\n",
        "\n",
        "            upper_circuit = prev_close * (1 + circuit_percent)\n",
        "            lower_circuit = prev_close * (1 - circuit_percent)\n",
        "\n",
        "            circuit_limits = {\n",
        "                'upper_circuit': upper_circuit,\n",
        "                'lower_circuit': lower_circuit,\n",
        "                'circuit_percent': circuit_percent\n",
        "            }\n",
        "            logger.info(f\"Calculated circuit limits for {symbol}: Upper={upper_circuit:.2f}, Lower={lower_circuit:.2f}, Percent={circuit_percent*100:.1f}%\")\n",
        "            return circuit_limits\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting circuit limits for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def assess_circuit_risk(self, current_price, circuit_limits):\n",
        "        \"\"\"Assess proximity to circuit limits\"\"\"\n",
        "        logger.info(\"Assessing circuit risk.\")\n",
        "        if not circuit_limits or current_price is None or np.isnan(current_price) or current_price <= 0:\n",
        "            logger.warning(\"Cannot assess circuit risk due to missing circuit limits or invalid current price.\")\n",
        "            return 0\n",
        "\n",
        "        upper_circuit = circuit_limits.get('upper_circuit')\n",
        "        lower_circuit = circuit_limits.get('lower_circuit')\n",
        "        logger.debug(f\"Current price: {current_price}, Upper circuit: {upper_circuit}, Lower circuit: {lower_circuit}\")\n",
        "\n",
        "\n",
        "        if upper_circuit is None or lower_circuit is None or np.isnan(upper_circuit) or np.isnan(lower_circuit):\n",
        "             logger.warning(\"Circuit limits are invalid, cannot assess circuit risk.\")\n",
        "             return 0\n",
        "\n",
        "        upper_distance = (upper_circuit - current_price) / current_price if current_price > 0 else float('inf')\n",
        "        lower_distance = (current_price - lower_circuit) / current_price if current_price > 0 else float('inf')\n",
        "\n",
        "        circuit_risk_score = 0\n",
        "        # Risk scoring based on proximity\n",
        "        if upper_distance < 0.02:  # Within 2% of upper circuit\n",
        "            circuit_risk_score = -20  # High risk\n",
        "            logger.debug(f\"Within 2% of upper circuit (distance: {upper_distance:.2f}). Risk score: {circuit_risk_score}\")\n",
        "        elif upper_distance < 0.05:  # Within 5%\n",
        "            circuit_risk_score = -10\n",
        "            logger.debug(f\"Within 5% of upper circuit (distance: {upper_distance:.2f}). Risk score: {circuit_risk_score}\")\n",
        "        elif lower_distance < 0.02:  # Within 2% of lower circuit\n",
        "            circuit_risk_score = -25  # Very high risk\n",
        "            logger.debug(f\"Within 2% of lower circuit (distance: {lower_distance:.2f}). Risk score: {circuit_risk_score}\")\n",
        "        elif lower_distance < 0.05:\n",
        "            circuit_risk_score = -15\n",
        "            logger.debug(f\"Within 5% of lower circuit (distance: {lower_distance:.2f}). Risk score: {circuit_risk_score}\")\n",
        "        else:\n",
        "            logger.debug(\"Not close to circuit limits. Risk score: 0\")\n",
        "\n",
        "\n",
        "        logger.info(f\"Assessed circuit risk score: {circuit_risk_score}\")\n",
        "        return circuit_risk_score\n",
        "\n",
        "    def get_liquidity_score(self, price_data: pd.DataFrame) -> float:\n",
        "        \"\"\"Enhanced liquidity analysis\"\"\"\n",
        "        logger.info(\"Calculating liquidity score.\")\n",
        "        try:\n",
        "            # Explicitly check for sufficient data and 'Volume' column\n",
        "            if price_data.empty or 'Volume' not in price_data.columns or len(price_data) < 20:\n",
        "                 logger.warning(\"Insufficient price data or missing Volume column for liquidity calculation. Assigning low score.\")\n",
        "                 return 5 # Assign a very low liquidity score\n",
        "\n",
        "            # Calculate various liquidity metrics\n",
        "            avg_volume_20d = price_data['Volume'].rolling(20).mean().iloc[-1]\n",
        "            avg_volume_5d = price_data['Volume'].rolling(5).mean().iloc[-1]\n",
        "            current_close = price_data['Close'].iloc[-1] if not price_data['Close'].empty else np.nan\n",
        "\n",
        "            logger.debug(f\"Avg Volume (20d): {avg_volume_20d}, Avg Volume (5d): {avg_volume_5d}, Current Close: {current_close}\")\n",
        "\n",
        "\n",
        "            if current_close is None or np.isnan(current_close) or current_close <= 0:\n",
        "                 logger.warning(\"Current close price is invalid for liquidity calculation. Assigning low score.\")\n",
        "                 return 5\n",
        "\n",
        "            # Average daily turnover\n",
        "            avg_turnover_20d = avg_volume_20d * current_close if avg_volume_20d is not None and not np.isnan(avg_volume_20d) else np.nan\n",
        "            logger.debug(f\"Avg Turnover (20d): {avg_turnover_20d}\")\n",
        "\n",
        "            # Volume spike detection - handle division by zero explicitly\n",
        "            volume_spike = np.nan\n",
        "            if avg_volume_20d is not None and not np.isnan(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                volume_spike = avg_volume_5d / avg_volume_20d if avg_volume_5d is not None and not np.isnan(avg_volume_5d) else np.nan\n",
        "            elif avg_volume_5d is not None and not np.isnan(avg_volume_5d) and avg_volume_5d > 0: # Case where 20d avg is 0 but 5d is not\n",
        "                 volume_spike = 1 # Treat as normal if 20d is 0 but 5d has volume\n",
        "            else:\n",
        "                 logger.warning(\"Average volume is zero or NaN, cannot calculate volume spike.\")\n",
        "            logger.debug(f\"Volume Spike: {volume_spike}\")\n",
        "\n",
        "            # Volume consistency - handle division by zero explicitly\n",
        "            volume_std = price_data['Volume'].rolling(20).std().iloc[-1] if len(price_data) >= 20 else np.nan\n",
        "            volume_cv = np.nan\n",
        "            if avg_volume_20d is not None and not np.isnan(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                volume_cv = volume_std / avg_volume_20d if volume_std is not None and not np.isnan(volume_std) else np.nan\n",
        "            elif volume_std is not None and not np.isnan(volume_std) and volume_std > 0: # Case where 20d avg is 0 but std is not (unlikely but safeguard)\n",
        "                 volume_cv = 1 # Treat as high variability if avg is 0 but std is not\n",
        "            else:\n",
        "                 logger.warning(\"Average volume or volume standard deviation is zero or NaN, cannot calculate volume CV.\")\n",
        "            logger.debug(f\"Volume CV: {volume_cv}\")\n",
        "\n",
        "\n",
        "            # Liquidity scoring\n",
        "            liquidity_score = 0\n",
        "            logger.debug(\"Scoring liquidity metrics.\")\n",
        "\n",
        "            # Turnover-based scoring - handle NaN\n",
        "            if avg_turnover_20d is not None and not np.isnan(avg_turnover_20d):\n",
        "                if avg_turnover_20d > 500_00_00_000:  # > 500 Cr\n",
        "                    liquidity_score += 40\n",
        "                    logger.debug(\"+40 pts for Turnover > 500 Cr\")\n",
        "                elif avg_turnover_20d > 100_00_00_000:  # > 100 Cr\n",
        "                    liquidity_score += 30\n",
        "                    logger.debug(\"+30 pts for Turnover > 100 Cr\")\n",
        "                elif avg_turnover_20d > 10_00_00_000:  # > 10 Cr\n",
        "                    liquidity_score += 20\n",
        "                    logger.debug(\"+20 pts for Turnover > 10 Cr\")\n",
        "                elif avg_turnover_20d > 1_00_00_000:  # > 1 Cr\n",
        "                    liquidity_score += 10\n",
        "                    logger.debug(\"+10 pts for Turnover > 1 Cr\")\n",
        "                else:\n",
        "                    liquidity_score += 5\n",
        "                    logger.debug(\"+5 pts for Turnover <= 1 Cr\")\n",
        "            else:\n",
        "                 logger.warning(\"Average turnover is NaN, skipping turnover score.\")\n",
        "\n",
        "\n",
        "            # Volume consistency score - handle NaN\n",
        "            if volume_cv is not None and not np.isnan(volume_cv):\n",
        "                 if volume_cv < 0.5:  # Low volatility in volume\n",
        "                     liquidity_score += 20\n",
        "                     logger.debug(f\"+20 pts for Volume CV ({volume_cv:.2f}) < 0.5\")\n",
        "                 elif volume_cv < 1.0:\n",
        "                     liquidity_score += 10\n",
        "                     logger.debug(f\"+10 pts for Volume CV ({volume_cv:.2f}) < 1.0\")\n",
        "                 else:\n",
        "                     logger.debug(f\"+0 pts for Volume CV ({volume_cv:.2f}) >= 1.0\")\n",
        "            else:\n",
        "                 logger.warning(\"Volume CV is NaN, skipping volume consistency score.\")\n",
        "\n",
        "            # Recent volume trend score - handle NaN\n",
        "            if volume_spike is not None and not np.isnan(volume_spike):\n",
        "                 if volume_spike > 1.2:  # 20% higher recent volume\n",
        "                     liquidity_score += 10\n",
        "                     logger.debug(f\"+10 pts for Volume Spike ({volume_spike:.2f}) > 1.2\")\n",
        "                 else:\n",
        "                      logger.debug(f\"+0 pts for Volume Spike ({volume_spike:.2f}) <= 1.2\")\n",
        "            else:\n",
        "                 logger.warning(\"Volume spike is NaN, skipping recent volume trend score.\")\n",
        "\n",
        "\n",
        "            final_liquidity_score = max(5, min(liquidity_score, 70))  # Cap at 70, minimum score 5 for insufficient data\n",
        "            logger.info(f\"Calculated liquidity score: {final_liquidity_score}/70\")\n",
        "            return final_liquidity_score\n",
        "\n",
        "        except Exception as e: # Catch specific exceptions for better debugging\n",
        "            logger.error(f\"Error calculating liquidity score: {str(e)}\")\n",
        "            return 5  # Default very low liquidity on error\n",
        "\n",
        "\n",
        "    def get_peer_companies(self, symbol, stock_info):\n",
        "        \"\"\"Identify peer companies for comparison\"\"\"\n",
        "        logger.info(f\"Identifying peer companies for {symbol}.\")\n",
        "        try:\n",
        "            sector = stock_info.get('sector', '')\n",
        "            market_cap = stock_info.get('marketCap', 0)\n",
        "            logger.debug(f\"Stock sector: {sector}, Market Cap: {market_cap}\")\n",
        "\n",
        "            # Define market cap categories\n",
        "            if market_cap > 10_00_000_00_00_000:  # > 10 Lakh Cr\n",
        "                cap_category = 'Large Cap'\n",
        "            elif market_cap > 50_000_00_00_000:   # > 50K Cr\n",
        "                cap_category = 'Mid Cap'\n",
        "            else:\n",
        "                cap_category = 'Small Cap'\n",
        "            logger.debug(f\"Market Cap Category: {cap_category}\")\n",
        "\n",
        "            # Peer mapping (simplified - in production, use a comprehensive database)\n",
        "            peer_map = {\n",
        "                'Technology': {\n",
        "                    'Large Cap': ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS'],\n",
        "                    'Mid Cap': ['TECHM.NS', 'LTTS.NS', 'PERSISTENT.NS', 'COFORGE.NS'],\n",
        "                    'Small Cap': ['ZENSAR.NS', 'ECLERX.NS', 'MASTEK.NS']\n",
        "                },\n",
        "                'Financial Services': {\n",
        "                    'Large Cap': ['HDFCBANK.NS', 'ICICIBANK.NS', 'KOTAKBANK.NS', 'AXISBANK.NS'],\n",
        "                    'Mid Cap': ['IDFCFIRSTB.NS', 'FEDERALBNK.NS', 'INDUSINDBK.NS'],\n",
        "                    'Small Cap': ['SOUTHBANK.NS', 'UJJIVAN.NS', 'EQUITASBNK.NS']\n",
        "                },\n",
        "                'Healthcare': {\n",
        "                    'Large Cap': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS'],\n",
        "                    'Mid Cap': ['TORNTPHARM.NS', 'ALKEM.NS', 'LUPIN.NS'],\n",
        "                    'Small Cap': ['CAPLIPOINT.NS', 'BLISS.NS', 'INDOCO.NS']\n",
        "                }\n",
        "                # Add more sectors as needed\n",
        "            }\n",
        "\n",
        "            # Get peers, excluding the current symbol\n",
        "            peers = peer_map.get(sector, {}).get(cap_category, [])\n",
        "            peers = [p for p in peers if p != symbol]\n",
        "            logger.info(f\"Identified {len(peers)} peer companies for {symbol}.\")\n",
        "            logger.debug(f\"Peer list: {peers}\")\n",
        "\n",
        "            return peers[:5]  # Return top 5 peers\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting peer companies: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def calculate_peer_relative_performance(self, symbol, peers, days=30):\n",
        "        \"\"\"Compare stock performance with peers\"\"\"\n",
        "        logger.info(f\"Calculating {days}-day peer relative performance for {symbol}.\")\n",
        "        try:\n",
        "            results = {}\n",
        "\n",
        "            # Get performance for main stock\n",
        "            logger.debug(f\"Fetching {days}-day history for main stock {symbol}.\")\n",
        "            main_ticker = yf.Ticker(symbol)\n",
        "            main_hist = main_ticker.history(period=f\"{days}d\")\n",
        "            main_return = np.nan # Initialize to NaN\n",
        "\n",
        "            if len(main_hist) > 0 and 'Close' in main_hist.columns and not main_hist['Close'].empty:\n",
        "                 if main_hist['Close'].iloc[0] > 0:\n",
        "                      main_return = ((main_hist['Close'].iloc[-1] / main_hist['Close'].iloc[0]) - 1) * 100\n",
        "                      logger.debug(f\"Main stock ({symbol}) {days}-day return: {main_return:.2f}%\")\n",
        "                 else:\n",
        "                      logger.warning(f\"Initial close price is zero or negative for {symbol}. Cannot calculate main stock return.\")\n",
        "            else:\n",
        "                logger.warning(f\"Insufficient historical data for {symbol} to calculate peer relative performance.\")\n",
        "\n",
        "\n",
        "            # Get peer performances\n",
        "            peer_returns = []\n",
        "            logger.debug(f\"Fetching {days}-day history for peers: {peers}\")\n",
        "            for peer in peers:\n",
        "                try:\n",
        "                    peer_ticker = yf.Ticker(peer)\n",
        "                    peer_hist = peer_ticker.history(period=f\"{days}d\")\n",
        "                    if len(peer_hist) > 0 and 'Close' in peer_hist.columns and not peer_hist['Close'].empty and peer_hist['Close'].iloc[0] > 0:\n",
        "                        peer_return = ((peer_hist['Close'].iloc[-1] / peer_hist['Close'].iloc[0]) - 1) * 100\n",
        "                        peer_returns.append(peer_return)\n",
        "                        logger.debug(f\"Peer {peer} {days}-day return: {peer_return:.2f}%\")\n",
        "                    else:\n",
        "                         logger.warning(f\"Insufficient historical data for peer {peer}.\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Could not get peer history for {peer}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            if peer_returns and main_return is not None and not np.isnan(main_return):\n",
        "                avg_peer_return = np.mean(peer_returns)\n",
        "                relative_performance = main_return - avg_peer_return\n",
        "\n",
        "                results = {\n",
        "                    'stock_return': main_return,\n",
        "                    'avg_peer_return': avg_peer_return,\n",
        "                    'relative_performance': relative_performance,\n",
        "                    'outperformance': relative_performance > 0\n",
        "                }\n",
        "                logger.info(f\"Calculated peer relative performance for {symbol}: Relative Performance={relative_performance:.2f}%\")\n",
        "            else:\n",
        "                 logger.warning(\"Peer returns not available or main stock return is NaN, cannot calculate relative performance.\")\n",
        "                 logger.info(\"Peer relative performance calculation skipped.\")\n",
        "\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating peer relative performance: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def get_index_membership(self, symbol):\n",
        "        \"\"\"Check index membership for the stock\"\"\"\n",
        "        logger.debug(f\"Checking index membership for {symbol}.\")\n",
        "        # Simplified index constituents (in production, fetch from NSE)\n",
        "        index_constituents = {\n",
        "            'NIFTY50': ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS'],\n",
        "            'NIFTY_NEXT50': ['VEDL.NS', 'PNB.NS', 'INDIGO.NS', 'BANDHANBNK.NS'],\n",
        "            'NIFTY_MIDCAP150': ['PERSISTENT.NS', 'COFORGE.NS', 'LTTS.NS']\n",
        "        }\n",
        "\n",
        "        membership = []\n",
        "        for index, constituents in index_constituents.items():\n",
        "            if symbol in constituents:\n",
        "                membership.append(index)\n",
        "        logger.debug(f\"Index membership results for {symbol}: {membership}\")\n",
        "\n",
        "        return membership\n",
        "\n",
        "    def calculate_enhanced_technical_score(self, indicators: Dict, circuit_risk: float) -> float:\n",
        "        \"\"\"Calculate enhanced technical analysis score\"\"\"\n",
        "        logger.info(\"Calculating enhanced technical score.\")\n",
        "        base_score = 0\n",
        "        indicator_scores = {} # To store scores for each indicator\n",
        "        logger.debug(f\"Indicators for enhanced technical scoring: {indicators}\")\n",
        "        logger.debug(f\"Circuit risk score: {circuit_risk}\")\n",
        "\n",
        "        try:\n",
        "            # RSI Score (points based on significance, e.g., max 10 for oversold)\n",
        "            rsi = indicators.get('RSI', None)\n",
        "            if rsi is not None and not np.isnan(rsi):\n",
        "                 if rsi < 30: indicator_scores['RSI'] = 10 # Oversold\n",
        "                 elif 30 <= rsi < 40: indicator_scores['RSI'] = 8 # Approaching oversold\n",
        "                 elif 40 <= rsi <= 60: indicator_scores['RSI'] = 5 # Neutral zone\n",
        "                 elif 60 < rsi <= 70: indicator_scores['RSI'] = 3 # Approaching overbought\n",
        "                 else: indicator_scores['RSI'] = 1 # Overbought\n",
        "                 logger.debug(f\"RSI score: {indicator_scores['RSI']}\")\n",
        "            else:\n",
        "                 indicator_scores['RSI'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"RSI not calculated or is NaN/None. Assigning 0 score for RSI.\")\n",
        "\n",
        "            # MACD scoring (points based on crossover and position relative to zero)\n",
        "            macd = indicators.get('MACD', None)\n",
        "            macd_signal = indicators.get('MACD_signal', None)\n",
        "            logger.debug(f\"MACD: {macd}, Signal: {macd_signal} for scoring.\")\n",
        "\n",
        "            if macd is not None and macd_signal is not None and isinstance(macd, (int, float)) and isinstance(macd_signal, (int, float)) and not np.isnan(macd) and not np.isnan(macd_signal):\n",
        "                 if macd > macd_signal:\n",
        "                     if macd > 0: indicator_scores['MACD'] = 10 # Bullish crossover above zero\n",
        "                     else: indicator_scores['MACD'] = 7 # Bullish crossover below zero\n",
        "                     logger.debug(f\"MACD bullish crossover score: {indicator_scores['MACD']}\")\n",
        "                 else:\n",
        "                     if macd < 0: indicator_scores['MACD'] = 1 # Bearish crossover below zero\n",
        "                     else: indicator_scores['MACD'] = 3 # Bearish crossover above zero\n",
        "                     logger.debug(f\"MACD bearish crossover score: {indicator_scores['MACD']}\")\n",
        "            else:\n",
        "                 indicator_scores['MACD'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"MACD or MACD signal not calculated or is NaN/None. Assigning 0 score for MACD.\")\n",
        "\n",
        "            # Moving Average Score (points based on MA crossovers and price position)\n",
        "            current_price = indicators.get('current_price', None)\n",
        "            sma_20 = indicators.get('SMA_20', None)\n",
        "            sma_50 = indicators.get('SMA_50', None)\n",
        "            sma_200 = indicators.get('SMA_200', None)\n",
        "            logger.debug(f\"MA values for scoring: Current={current_price}, SMA20={sma_20}, SMA50={sma_50}, SMA200={sma_200}\")\n",
        "\n",
        "\n",
        "            ma_score = 0\n",
        "            valid_mas = 0\n",
        "\n",
        "            if sma_20 is not None and not np.isnan(sma_20) and current_price is not None and not np.isnan(current_price):\n",
        "                 valid_mas += 1\n",
        "                 if current_price > sma_20: ma_score += 5\n",
        "                 else: ma_score += 1\n",
        "                 logger.debug(f\"Price vs SMA20 score component: {ma_score}\")\n",
        "\n",
        "\n",
        "            if sma_50 is not None and not np.isnan(sma_50) and current_price is not None and not np.isnan(current_price):\n",
        "                 valid_mas += 1\n",
        "                 if current_price > sma_50: ma_score += 5\n",
        "                 else: ma_score += 1\n",
        "                 logger.debug(f\"Price vs SMA50 score component: {ma_score}\")\n",
        "\n",
        "            if sma_200 is not None and not np.isnan(sma_200) and current_price is not None and not np.isnan(current_price):\n",
        "                 valid_mas += 1\n",
        "                 if current_price > sma_200: ma_score += 5\n",
        "                 else: ma_score += 1\n",
        "                 logger.debug(f\"Price vs SMA200 score component: {ma_score}\")\n",
        "\n",
        "            # Add points for bullish crossovers\n",
        "            if sma_20 is not None and sma_50 is not None and not np.isnan(sma_20) and not np.isnan(sma_50):\n",
        "                 if sma_20 > sma_50:\n",
        "                     ma_score += 5\n",
        "                     logger.debug(f\"SMA20 > SMA50 crossover score component: {ma_score}\")\n",
        "\n",
        "\n",
        "            if sma_50 is not None and sma_200 is not None and not np.isnan(sma_50) and not np.isnan(sma_200):\n",
        "                 if sma_50 > sma_200:\n",
        "                     ma_score += 5\n",
        "                     logger.debug(f\"SMA50 > SMA200 crossover score component: {ma_score}\")\n",
        "\n",
        "\n",
        "            indicator_scores['Moving_Averages'] = ma_score # Max possible MA score is 25 (5+5+5 for price > MA + 5+5 for crossovers)\n",
        "\n",
        "            if valid_mas == 0:\n",
        "                 logger.warning(\"No valid Moving Averages calculated. Assigning 0 score for Moving Averages.\")\n",
        "                 indicator_scores['Moving_Averages'] = 0\n",
        "\n",
        "\n",
        "            logger.debug(f\"Moving Averages total score component: {indicator_scores['Moving_Averages']}\")\n",
        "\n",
        "\n",
        "            # Bollinger Bands Score (points based on price position relative to bands)\n",
        "            bb_upper = indicators.get('BB_upper', None)\n",
        "            bb_lower = indicators.get('BB_lower', None)\n",
        "            bb_middle = indicators.get('BB_middle', None)\n",
        "            logger.debug(f\"BB values for scoring: Upper={bb_upper}, Lower={bb_lower}, Middle={bb_middle}\")\n",
        "\n",
        "\n",
        "            if current_price is not None and bb_upper is not None and bb_lower is not None and bb_middle is not None and \\\n",
        "               not np.isnan(current_price) and not np.isnan(bb_upper) and not np.isnan(bb_lower) and not np.isnan(bb_middle):\n",
        "                if current_price < bb_lower: indicator_scores['Bollinger_Bands'] = 10 # Price below lower band (potential buy signal)\n",
        "                elif bb_lower <= current_price < bb_middle: indicator_scores['Bollinger_Bands'] = 7 # Between lower and middle band\n",
        "                elif bb_middle <= current_price < bb_upper: indicator_scores['Bollinger_Bands'] = 3 # Between middle and upper band\n",
        "                else: indicator_scores['Bollinger_Bands'] = 1 # Price above upper band (potential sell signal)\n",
        "                logger.debug(f\"Bollinger Bands score: {indicator_scores['Bollinger_Bands']}\")\n",
        "            else:\n",
        "                 indicator_scores['Bollinger_Bands'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Bollinger Bands or current price not available or is NaN/None. Assigning 0 score for Bollinger Bands.\")\n",
        "\n",
        "\n",
        "            # Volume Score (points based on volume relative to average)\n",
        "            volume_ratio = indicators.get('Volume_ratio', None)\n",
        "            logger.debug(f\"Volume ratio for scoring: {volume_ratio}\")\n",
        "            if volume_ratio is not None and not np.isnan(volume_ratio):\n",
        "                 if volume_ratio > 1.5: indicator_scores['Volume'] = 10 # High volume\n",
        "                 elif 0.8 <= volume_ratio <= 1.5: indicator_scores['Volume'] = 7 # Normal volume\n",
        "                 else: indicator_scores['Volume'] = 3 # Low volume\n",
        "                 logger.debug(f\"Volume score: {indicator_scores['Volume']}\")\n",
        "            else:\n",
        "                 indicator_scores['Volume'] = 0 # Assign 0 if NaN/None\n",
        "                 logger.warning(\"Volume ratio not calculated or is NaN/None. Assigning 0 score for Volume.\")\n",
        "\n",
        "            # Sum the scores from individual indicators\n",
        "            base_score = sum(indicator_scores.values())\n",
        "            logger.debug(f\"Sum of individual indicator scores: {base_score}\")\n",
        "\n",
        "            # Add circuit risk adjustment (already handled as negative points)\n",
        "            final_score = base_score + circuit_risk\n",
        "            logger.debug(f\"Base score ({base_score}) + Circuit risk ({circuit_risk}) = Raw final score ({final_score})\")\n",
        "\n",
        "\n",
        "            # Ensure score is within 0-50 range (assuming max base_score is around 50 based on point allocation)\n",
        "            # Max possible indicator score (10+10+25+10+10) = 65. Let's normalize this to 50.\n",
        "            normalized_base_score = (base_score / 65.0) * 50.0 if base_score > 0 else 0\n",
        "            final_score = normalized_base_score + circuit_risk\n",
        "            logger.debug(f\"Normalized base score: {normalized_base_score:.2f}. Final score after normalization and risk: {final_score:.2f}\")\n",
        "\n",
        "\n",
        "            capped_score = max(0, min(final_score, 50))\n",
        "            logger.info(f\"Enhanced technical score calculated: {capped_score}/50\")\n",
        "            return capped_score\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating enhanced technical score: {str(e)}\")\n",
        "            return 0\n",
        "\n",
        "\n",
        "    def fetch_news(self, symbol: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Fetches recent news headlines for the given stock symbol.\n",
        "        NOTE: This is a placeholder. In a real application, you would integrate\n",
        "        with a News API (like News API, Alpha Vantage, etc.) here.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Fetching news for {symbol} (placeholder)...\")\n",
        "        # Placeholder news headlines - replace with actual API call\n",
        "        news_headlines = [\n",
        "            f\"{symbol} stock price rises on positive market sentiment\",\n",
        "            f\"{symbol} announces strong quarterly results, beating estimates\",\n",
        "            f\"Experts bullish on {symbol}'s future outlook\",\n",
        "            f\"{symbol} faces regulatory challenges in key market\",\n",
        "            f\"Competitor's new product launch impacts {symbol}'s market share\",\n",
        "            f\"Global market trends positively impacting {symbol}\",\n",
        "            f\"{symbol} management provides optimistic guidance\",\n",
        "            f\"Increased foreign investment flows into {symbol}\",\n",
        "            f\"Regulatory approval received for {symbol}'s new product\",\n",
        "            f\"Production issues reported for {symbol}\",\n",
        "            f\"Increased competition puts pressure on {symbol}'s margins\",\n",
        "            f\"Analyst downgrades rating for {symbol}\",\n",
        "            f\"Supply chain disruptions affect {symbol}'s operations\",\n",
        "            f\"Geopolitical tensions create uncertainty for {symbol}\",\n",
        "            f\"{symbol} announces stock split\",\n",
        "            f\"Dividend declared by {symbol}\"\n",
        "        ]\n",
        "        logger.info(f\"Fetched {len(news_headlines)} news headlines (placeholder).\")\n",
        "        return news_headlines\n",
        "\n",
        "\n",
        "    def analyze_sentiment(self, news_headlines: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of news headlines using the Gemini API.\n",
        "        Returns a dictionary with sentiment counts (positive, neutral, negative)\n",
        "        and a sentiment score.\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting sentiment analysis.\")\n",
        "        # Use the globally defined gemini_model\n",
        "        if not 'gemini_model' in globals() or not gemini_model:\n",
        "            logger.warning(\"Gemini API not configured. Skipping sentiment analysis.\")\n",
        "            # Replace print with logger.warning\n",
        "            # print(\"Gemini API not configured or no news to analyze. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis skipped.'}\n",
        "\n",
        "        if not news_headlines:\n",
        "             logger.warning(\"No news headlines to analyze. Skipping sentiment analysis.\")\n",
        "             return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'No news to analyze.'}\n",
        "\n",
        "\n",
        "        logger.info(f\"Analyzing sentiment for {len(news_headlines)} headlines using Gemini API...\")\n",
        "        prompt = \"Analyze the sentiment of the following news headlines for a stock and categorize each as Positive, Neutral, or Negative. Provide a concise summary of the overall sentiment.\\n\\n\"\n",
        "        for headline in news_headlines:\n",
        "            prompt += f\"- {headline}\\n\"\n",
        "        prompt += \"\\nSentiment Analysis Results (Categorization and Summary):\\n\"\n",
        "\n",
        "        try:\n",
        "            response = gemini_model.generate_content(prompt)\n",
        "            sentiment_text = response.text.strip()\n",
        "            logger.debug(f\"Gemini API Raw Response:\\n{sentiment_text}\")\n",
        "            logger.info(f\"Gemini API Response Received.\")\n",
        "\n",
        "\n",
        "            # Parse the response to count sentiments and extract summary\n",
        "            positive_count = sentiment_text.lower().count('positive')\n",
        "            neutral_count = sentiment_text.lower().count('neutral')\n",
        "            negative_count = sentiment_text.lower().count('negative')\n",
        "            logger.debug(f\"Sentiment counts: Positive={positive_count}, Neutral={neutral_count}, Negative={negative_count}\")\n",
        "\n",
        "            # Attempt to extract a summary line - this is a heuristic\n",
        "            summary_line = \"No summary extracted.\"\n",
        "            lines = sentiment_text.split('\\n')\n",
        "            for line in lines:\n",
        "                 lower_line = line.lower()\n",
        "                 if 'summary' in lower_line or 'overall sentiment' in lower_line:\n",
        "                     summary_line = line.strip()\n",
        "                     break\n",
        "            if summary_line == \"No summary extracted.\" and lines:\n",
        "                 # If no explicit summary found, take the last non-empty line as a potential summary\n",
        "                 for line in reversed(lines):\n",
        "                     if line.strip():\n",
        "                         summary_line = line.strip()\n",
        "                         break\n",
        "            logger.debug(f\"Extracted summary line: {summary_line}\")\n",
        "\n",
        "\n",
        "            total_headlines = len(news_headlines)\n",
        "            if total_headlines > 0:\n",
        "                # Scoring based on the ratio of positive vs negative headlines, scaled to 25 points\n",
        "                # (Positive - Negative) / Total * 12.5 + 12.5 -> Range 0-25\n",
        "                sentiment_score = ((positive_count - negative_count) / total_headlines) * 12.5 + 12.5\n",
        "            else:\n",
        "                sentiment_score = 12.5 # Neutral score if no headlines\n",
        "\n",
        "            sentiment_score = max(0, min(sentiment_score, 25)) # Cap score between 0 and 25\n",
        "            logger.info(f\"Sentiment score calculated: {sentiment_score:.2f}/25\")\n",
        "\n",
        "            results = {\n",
        "                'positive': positive_count,\n",
        "                'neutral': neutral_count,\n",
        "                'negative': negative_count,\n",
        "                'score': sentiment_score,\n",
        "                'summary': summary_line\n",
        "            }\n",
        "            logger.info(\"Sentiment analysis completed.\")\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing sentiment with Gemini API: {e}. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis failed.'}\n",
        "\n",
        "\n",
        "    def generate_enhanced_recommendation(self, fundamental_score, technical_score,\n",
        "                                       liquidity_score, peer_performance, index_membership,\n",
        "                                       sentiment_analysis_results):\n",
        "        \"\"\"Generate comprehensive recommendation including sentiment\"\"\"\n",
        "        logger.info(\"Generating enhanced recommendation.\")\n",
        "        sentiment_score = sentiment_analysis_results.get('score', 0)\n",
        "        total_score = fundamental_score + technical_score + liquidity_score + sentiment_score # Add sentiment score\n",
        "        logger.debug(f\"Scores: Fundamental={fundamental_score:.2f}, Technical={technical_score:.2f}, Liquidity={liquidity_score:.2f}, Sentiment={sentiment_score:.2f}\")\n",
        "\n",
        "\n",
        "        # Adjust for peer performance\n",
        "        if peer_performance.get('outperformance', False):\n",
        "            total_score += 5\n",
        "            logger.debug(\"+5 pts for peer outperformance.\")\n",
        "\n",
        "        # Bonus for index membership\n",
        "        if index_membership:\n",
        "            total_score += 5\n",
        "            logger.debug(f\"+5 pts for index membership ({', '.join(index_membership)}).\")\n",
        "\n",
        "\n",
        "        # Max possible score is 50 (Fundamental) + 50 (Technical) + 70 (Liquidity) + 25 (Sentiment) + 5 (Peer) + 5 (Index) = 205\n",
        "        # Let's re-evaluate the recommendation thresholds based on this potential range\n",
        "\n",
        "        recommendation = \"UNKNOWN\"\n",
        "        confidence = \"Low\"\n",
        "\n",
        "        if total_score >= 160: # Example Thresholds (adjust as needed)\n",
        "            recommendation = \"STRONG BUY\"\n",
        "            confidence = \"High\"\n",
        "        elif total_score >= 130:\n",
        "            recommendation = \"BUY\"\n",
        "            confidence = \"Moderate to High\"\n",
        "        elif total_score >= 90:\n",
        "            recommendation = \"HOLD\"\n",
        "            confidence = \"Moderate\"\n",
        "        elif total_score >= 60:\n",
        "            recommendation = \"SELL\"\n",
        "            confidence = \"Moderate\"\n",
        "        else:\n",
        "            recommendation = \"STRONG SELL\"\n",
        "            confidence = \"High\"\n",
        "\n",
        "        logger.info(f\"Final total score: {total_score:.2f}. Recommendation: {recommendation} ({confidence})\")\n",
        "\n",
        "        return {\n",
        "            'recommendation': recommendation,\n",
        "            'confidence': confidence,\n",
        "            'total_score': total_score,\n",
        "            'breakdown': {\n",
        "                'fundamental': fundamental_score,\n",
        "                'technical': technical_score,\n",
        "                'liquidity': liquidity_score,\n",
        "                'sentiment': sentiment_score\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "    logger.info(f\"Starting enhanced analysis integration for {symbol}.\")\n",
        "\n",
        "    # Get basic analysis from Part 1\n",
        "    logger.info(\"Running basic analysis (Part 1).\")\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        logger.error(f\"Basic analysis failed for {symbol}. Cannot proceed with enhanced analysis.\")\n",
        "        return None\n",
        "\n",
        "    logger.info(\"Basic analysis completed successfully.\")\n",
        "\n",
        "    # Get current price\n",
        "    current_price = stock_data.current_price\n",
        "    logger.debug(f\"Current price from basic analysis: {current_price}\")\n",
        "\n",
        "\n",
        "    # Enhanced analysis\n",
        "    logger.info(\"Starting enhanced analysis features (Part 2).\")\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "    logger.info(f\"Circuit analysis completed. Risk score: {circuit_risk}\")\n",
        "\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "    logger.info(f\"Liquidity analysis completed. Score: {liquidity_score}\")\n",
        "\n",
        "    # 3. Peer analysis\n",
        "    peers = enhanced_analyzer.get_peer_companies(symbol, stock_data.info)\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peers)\n",
        "    logger.info(f\"Peer analysis completed. Performance results: {peer_performance}\")\n",
        "\n",
        "    # 4. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "    logger.info(f\"Index membership check completed. Memberships: {index_membership}\")\n",
        "\n",
        "\n",
        "    # 5. Recalculate technical score with circuit risk\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "    logger.info(f\"Enhanced technical score calculated: {enhanced_technical_score}\")\n",
        "\n",
        "\n",
        "    # 6. Fetch and analyze news sentiment\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "    logger.info(f\"Sentiment analysis completed. Results: {sentiment_analysis_results}\")\n",
        "\n",
        "\n",
        "    # 7. Generate enhanced recommendation\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance,\n",
        "        index_membership,\n",
        "        sentiment_analysis_results # Pass sentiment analysis results\n",
        "    )\n",
        "    logger.info(\"Enhanced recommendation generated.\")\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score,\n",
        "            'peers': peers,\n",
        "            'peer_performance': peer_performance,\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "\n",
        "    logger.info(f\"Enhanced analysis integration completed for {symbol}.\")\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage (removed from here as it's part of the next display step)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ef14263"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the combined analysis report using the enhanced logging.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3fceedf3"
      },
      "source": [
        "#@title Analyze a stock and display the combined results\n",
        "symbol_to_analyze = \"RELIANCE.NS\" # You can change this symbol\n",
        "\n",
        "# Ensure both analyzers are instantiated (they should be if the cells above were run)\n",
        "# If not, you might need to re-run the cells defining IndianStockAnalyzer and EnhancedStockAnalyzer\n",
        "try:\n",
        "    stock_analyzer = IndianStockAnalyzer()\n",
        "    enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "except NameError:\n",
        "    logger.error(\"IndianStockAnalyzer or EnhancedStockAnalyzer class not defined. Please run the preceding cells.\")\n",
        "    # print(\"Please run the cells defining IndianStockAnalyzer and EnhancedStockAnalyzer first.\")\n",
        "    # Exit or handle the error appropriately if classes are not defined\n",
        "    stock_analyzer = None\n",
        "    enhanced_analyzer = None\n",
        "\n",
        "\n",
        "if stock_analyzer and enhanced_analyzer:\n",
        "    combined_analysis_report = analyze_stock_enhanced(symbol_to_analyze, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if combined_analysis_report:\n",
        "        # Keeping print for final formatted output as requested by the user\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Combined Stock Analysis Report for {symbol_to_analyze}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Display basic analysis results\n",
        "        basic = combined_analysis_report['basic_analysis']\n",
        "        print(f\"\\n--- Basic Analysis (from Part 1) ---\")\n",
        "        print(f\"Company Name: {basic.company_name}\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if basic.current_price is not None else \"Current Price: N/A\")\n",
        "        print(f\"Market Cap: ₹{basic.market_cap/10000000:,.2f} Cr\" if basic.market_cap is not None else \"Market Cap: N/A\") # Use stored market_cap\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "        print(f\"Fundamental Score: {basic.fundamental_score}/50\")\n",
        "        print(f\"Technical Score: {basic.technical_score}/50\")\n",
        "        print(f\"Basic Recommendation: {basic.recommendation}\")\n",
        "        print(\"\\nFundamental Metrics:\")\n",
        "        for metric, value in basic.metrics.items():\n",
        "             if metric != 'Fundamental_Score':\n",
        "                if value is not None and not np.isnan(value):\n",
        "                     if isinstance(value, float):\n",
        "                         if metric in ['ROE', 'Revenue_Growth', 'Net_Profit_Margin', 'Debt_to_Equity']:\n",
        "                             print(f\"{metric}: {value*100:.2f}%\") # Display as percentage for D/E, ROE, Growth, Margin\n",
        "                         else:\n",
        "                             print(f\"{metric}: {value:.2f}\")\n",
        "                     else:\n",
        "                         print(f\"{metric}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{metric}: N/A (Missing Data)\")\n",
        "\n",
        "\n",
        "        print(\"\\nTechnical Indicators:\")\n",
        "        for indicator, value in basic.indicators.items():\n",
        "             if indicator != 'current_price':\n",
        "                if value is not None and not np.isnan(value):\n",
        "                    if isinstance(value, float):\n",
        "                        print(f\"{indicator}: {value:,.2f}\")\n",
        "                    else:\n",
        "                        print(f\"{indicator}: {value}\")\n",
        "                else:\n",
        "                    print(f\"{indicator}: N/A (Insufficient Data)\")\n",
        "\n",
        "\n",
        "        # Display enhanced features and final recommendation\n",
        "        enhanced = combined_analysis_report['enhanced_features']\n",
        "        final = combined_analysis_report['final_recommendation']\n",
        "\n",
        "        print(f\"\\n--- Enhanced Analysis (from Part 2) ---\")\n",
        "        print(f\"Circuit Limits: {enhanced.get('circuit_limits', {}).get('lower_circuit', 'N/A'):.2f} - {enhanced.get('circuit_limits', {}).get('upper_circuit', 'N/A'):.2f}\" if enhanced.get('circuit_limits') else \"Circuit Limits: N/A\")\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        print(f\"Liquidity Score: {enhanced.get('liquidity_score', 'N/A')}/70\")\n",
        "\n",
        "        if enhanced.get('peers'):\n",
        "            print(f\"Peer Companies: {', '.join(enhanced['peers'])}\")\n",
        "            if enhanced.get('peer_performance'):\n",
        "                print(f\"30-day Return: {enhanced['peer_performance'].get('stock_return', 'N/A'):.2f}%\" if enhanced['peer_performance'].get('stock_return') is not None and not np.isnan(enhanced['peer_performance'].get('stock_return')) else \"30-day Return: N/A\")\n",
        "                print(f\"Peer Avg Return: {enhanced['peer_performance'].get('avg_peer_return', 'N/A'):.2f}%\" if enhanced['peer_performance'].get('avg_peer_return') is not None and not np.isnan(enhanced['peer_performance'].get('avg_peer_return')) else \"Peer Avg Return: N/A\")\n",
        "                print(f\"Relative Performance: {enhanced['peer_performance'].get('relative_performance', 'N/A'):.2f}%\" if enhanced['peer_performance'].get('relative_performance') is not None and not np.isnan(enhanced['peer_performance'].get('relative_performance')) else \"Relative Performance: N/A\")\n",
        "\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             for headline in enhanced['news_headlines']:\n",
        "                 print(f\"- {headline}\")\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             print(f\"Sentiment Score: {sentiment_results.get('score', 0):.2f}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Final Recommendation ---\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} ({final.get('confidence', 'N/A')})\")\n",
        "        print(f\"Total Score: {final.get('total_score', 0):.2f}/205\")\n",
        "        print(\"Score Breakdown:\")\n",
        "        print(f\"  - Fundamental: {final.get('breakdown', {}).get('fundamental', 'N/A'):.2f}\")\n",
        "        print(f\"  - Technical (Enhanced): {final.get('breakdown', {}).get('technical', 'N/A'):.2f}\") # Technical score should be float\n",
        "        print(f\"  - Liquidity: {final.get('breakdown', {}).get('liquidity', 'N/A'):.2f}\")\n",
        "        print(f\"  - Sentiment: {final.get('breakdown', {}).get('sentiment', 'N/A'):.2f}\")\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "\n",
        "    else:\n",
        "        logger.error(f\"Could not generate combined analysis report for {symbol_to_analyze}.\")\n",
        "        # print(f\"Could not generate combined analysis report for {symbol_to_analyze}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "13f32e60"
      },
      "source": [
        "#@title Corrected analyze_stock_enhanced function and example usage\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- IndianStockAnalyzer class definition (from Part 1) ---\n",
        "# This needs to be included in this cell so it's defined before use\n",
        "class IndianStockAnalyzer:\n",
        "    \"\"\"Basic analyzer for Indian stocks\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the basic analyzer.\"\"\"\n",
        "        # Basic setup if needed for Part 1 (e.g., API keys, configurations)\n",
        "        pass\n",
        "\n",
        "    def analyze_stock(self, symbol):\n",
        "        \"\"\"\n",
        "        Performs basic fundamental and technical analysis for a given stock.\n",
        "        Returns an object or dictionary containing the analysis results.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Starting basic analysis for {symbol}\")\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            if not info:\n",
        "                 logger.warning(f\"Could not fetch info for {symbol}.\")\n",
        "                 return None\n",
        "\n",
        "            # Get price data for technical analysis\n",
        "            price_data = ticker.history(period=\"1y\") # Get 1 year of historical data\n",
        "\n",
        "            if price_data.empty:\n",
        "                logger.warning(f\"Could not fetch price data for {symbol}.\")\n",
        "                # Return info even if price data is missing, as fundamental data might still be available\n",
        "                # We will handle missing price data in enhanced calculations\n",
        "                return self.AnalysisResult(symbol, info, price_data, np.nan, {})\n",
        "\n",
        "\n",
        "            # 1. Fundamental Analysis (Simplified)\n",
        "            # Extract key fundamental data points\n",
        "            try:\n",
        "                market_cap = info.get('marketCap', np.nan)\n",
        "                pe_ratio = info.get('trailingPE', np.nan)\n",
        "                pb_ratio = info.get('priceToBook', np.nan)\n",
        "                dividend_yield = info.get('dividendYield', np.nan) # This is often already a percentage as a float\n",
        "                sector = info.get('sector', 'N/A')\n",
        "                industry = info.get('industry', 'N/A')\n",
        "                current_price = info.get('currentPrice', np.nan)\n",
        "                company_name = info.get('longName', symbol)\n",
        "\n",
        "                # Ensure dividend_yield is not None before checking if it's NaN\n",
        "                if dividend_yield is not None and not pd.isna(dividend_yield) and dividend_yield > 0:\n",
        "                     # If dividend_yield is a float between 0 and 1, assume it's a ratio and convert to percentage\n",
        "                     if 0 < dividend_yield <= 1:\n",
        "                         dividend_yield *= 100\n",
        "                         logger.info(f\"Converted dividend yield for {symbol} from ratio to percentage: {dividend_yield:.2f}%\")\n",
        "                     else:\n",
        "                         logger.info(f\"Dividend yield for {symbol} is {dividend_yield:.2f}%. Assuming it's already in percentage or other form.\")\n",
        "                else:\n",
        "                     logger.info(f\"Dividend yield for {symbol} is unavailable or zero ({dividend_yield}).\")\n",
        "                     dividend_yield = np.nan # Ensure it's NaN if None or invalid\n",
        "\n",
        "            except Exception as fund_e:\n",
        "                 logger.error(f\"Error extracting fundamental data for {symbol}: {fund_e}. Setting fundamental metrics to NaN.\")\n",
        "                 market_cap, pe_ratio, pb_ratio, dividend_yield, sector, industry, current_price, company_name = np.nan, np.nan, np.nan, np.nan, 'N/A', 'N/A', np.nan, symbol\n",
        "\n",
        "\n",
        "            # Calculate a simple fundamental score (out of 50)\n",
        "            fundamental_score = self.calculate_fundamental_score(market_cap, pe_ratio, pb_ratio, dividend_yield)\n",
        "\n",
        "            # 2. Technical Analysis (Simplified)\n",
        "            indicators = self.calculate_technical_indicators(price_data, current_price)\n",
        "            technical_score = self.calculate_technical_score(indicators) # Basic technical score (out of 50)\n",
        "\n",
        "            # Bundle results\n",
        "            # Create an object or dictionary to hold all analysis results\n",
        "            analysis_results = self.AnalysisResult(\n",
        "                symbol=symbol,\n",
        "                info=info,\n",
        "                price_data=price_data,\n",
        "                current_price=current_price, # Include current price\n",
        "                company_name=company_name, # Include company name\n",
        "                market_cap=market_cap, # Include market cap\n",
        "                fundamental_score=fundamental_score,\n",
        "                technical_score=technical_score,\n",
        "                indicators=indicators # Include calculated indicators\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Basic analysis completed for {symbol}\")\n",
        "            return analysis_results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"An error occurred during basic analysis for {symbol}: {str(e)}\")\n",
        "            return None # Return None if basic analysis fails\n",
        "\n",
        "    def calculate_fundamental_score(self, market_cap, pe_ratio, pb_ratio, dividend_yield):\n",
        "        \"\"\"Calculate a simple fundamental score based on key metrics (out of 50)\"\"\"\n",
        "        score = 0\n",
        "        # Ensure metrics are valid numbers before scoring\n",
        "        market_cap_valid = isinstance(market_cap, (int, float)) and not pd.isna(market_cap) and market_cap > 0\n",
        "        pe_ratio_valid = isinstance(pe_ratio, (int, float)) and not pd.isna(pe_ratio) and pe_ratio > 0\n",
        "        pb_ratio_valid = isinstance(pb_ratio, (int, float)) and not pd.isna(pb_ratio) and pb_ratio > 0\n",
        "        dividend_yield_valid = isinstance(dividend_yield, (int, float)) and not pd.isna(dividend_yield) and dividend_yield >= 0\n",
        "\n",
        "\n",
        "        # Market Cap (Scale based on size, larger usually means more stable)\n",
        "        if market_cap_valid:\n",
        "            if market_cap > 10_00_000_00_00_000:  # > 10 Lakh Cr (Large Cap)\n",
        "                score += 15\n",
        "            elif market_cap > 50_000_00_00_000:   # > 50K Cr (Mid Cap)\n",
        "                score += 10\n",
        "            else: # Small Cap and below\n",
        "                score += 5\n",
        "        else:\n",
        "             logger.warning(\"Market cap is invalid for fundamental scoring.\")\n",
        "\n",
        "\n",
        "        # PE Ratio (Lower is generally better, but depends on industry growth)\n",
        "        if pe_ratio_valid:\n",
        "            if pe_ratio < 20:\n",
        "                score += 15\n",
        "            elif pe_ratio < 30:\n",
        "                score += 10\n",
        "            elif pe_ratio < 40:\n",
        "                score += 5\n",
        "            else: # High PE\n",
        "                score += 2\n",
        "        else:\n",
        "             logger.warning(\"PE ratio is invalid for fundamental scoring.\")\n",
        "\n",
        "\n",
        "        # PB Ratio (Lower is generally better, indicates undervaluation)\n",
        "        if pb_ratio_valid:\n",
        "            if pb_ratio < 3:\n",
        "                score += 10\n",
        "            elif pb_ratio < 5:\n",
        "                score += 7\n",
        "            else:\n",
        "                score += 3\n",
        "        else:\n",
        "             logger.warning(\"PB ratio is invalid for fundamental scoring.\")\n",
        "\n",
        "\n",
        "        # Dividend Yield (Higher is better for income-seeking investors, indicates profitability)\n",
        "        if dividend_yield_valid:\n",
        "            if dividend_yield > 3: # > 3%\n",
        "                score += 10\n",
        "            elif dividend_yield > 1: # > 1%\n",
        "                score += 7\n",
        "            else:\n",
        "                score += 3\n",
        "        else:\n",
        "             logger.warning(\"Dividend yield is invalid for fundamental scoring.\")\n",
        "\n",
        "        logger.info(f\"Fundamental score calculated: {score}\")\n",
        "        return min(score, 50) # Cap score at 50\n",
        "\n",
        "    def calculate_technical_indicators(self, price_data, current_price):\n",
        "        \"\"\"Calculate key technical indicators\"\"\"\n",
        "        # Ensure price_data is valid before calculating indicators\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty:\n",
        "            logger.warning(\"Insufficient price data for technical indicator calculation.\")\n",
        "            return {'RSI': np.nan, 'MACD': np.nan, 'MACD_signal': np.nan, 'SMA_20': np.nan, 'SMA_50': np.nan,\n",
        "                    'BB_upper': np.nan, 'BB_lower': np.nan, 'BB_middle': np.nan, 'Volume_ratio': np.nan,\n",
        "                    'current_price': current_price} # Return NaNs if data is missing\n",
        "\n",
        "\n",
        "        indicators = {}\n",
        "        try:\n",
        "            # RSI (Relative Strength Index)\n",
        "            delta = price_data['Close'].diff()\n",
        "            gain = delta.where(delta > 0, 0)\n",
        "            loss = -delta.where(delta < 0, 0)\n",
        "            avg_gain = gain.ewm(com=14-1, adjust=False).mean()\n",
        "            avg_loss = loss.ewm(com=14-1, adjust=False).mean()\n",
        "            rs = avg_gain / avg_loss\n",
        "            indicators['RSI'] = 100 - (100 / (1 + rs)).iloc[-1]\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate RSI: {e}. Setting to NaN.\")\n",
        "            indicators['RSI'] = np.nan\n",
        "\n",
        "        try:\n",
        "            # MACD (Moving Average Convergence Divergence)\n",
        "            ema_12 = price_data['Close'].ewm(span=12, adjust=False).mean()\n",
        "            ema_26 = price_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "            indicators['MACD'] = (ema_12 - ema_26).iloc[-1]\n",
        "            indicators['MACD_signal'] = indicators['MACD'].ewm(span=9, adjust=False).mean().iloc[-1] # Calculate signal from MACD series\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate MACD: {e}. Setting to NaN.\")\n",
        "            indicators['MACD'] = np.nan\n",
        "            indicators['MACD_signal'] = np.nan\n",
        "\n",
        "        try:\n",
        "            # Moving Averages\n",
        "            indicators['SMA_20'] = price_data['Close'].rolling(window=20).mean().iloc[-1]\n",
        "            indicators['SMA_50'] = price_data['Close'].rolling(window=50).mean().iloc[-1]\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate Moving Averages: {e}. Setting to NaN.\")\n",
        "            indicators['SMA_20'] = np.nan\n",
        "            indicators['SMA_50'] = np.nan\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Bollinger Bands\n",
        "            rolling_mean = price_data['Close'].rolling(window=20).mean()\n",
        "            rolling_std = price_data['Close'].rolling(window=20).std()\n",
        "            indicators['BB_middle'] = rolling_mean.iloc[-1]\n",
        "            indicators['BB_upper'] = (rolling_mean + (rolling_std * 2)).iloc[-1]\n",
        "            indicators['BB_lower'] = (rolling_mean - (rolling_std * 2)).iloc[-1]\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate Bollinger Bands: {e}. Setting to NaN.\")\n",
        "            indicators['BB_middle'] = np.nan\n",
        "            indicators['BB_upper'] = np.nan\n",
        "            indicators['BB_lower'] = np.nan\n",
        "\n",
        "        try:\n",
        "            # Volume Analysis (e.g., current volume vs average volume)\n",
        "            avg_volume_30d = price_data['Volume'].rolling(window=30).mean().iloc[-1]\n",
        "            current_volume = price_data['Volume'].iloc[-1]\n",
        "            # Check for zero division and NaN before calculating ratio\n",
        "            if not pd.isna(avg_volume_30d) and avg_volume_30d > 0 and not pd.isna(current_volume):\n",
        "                 indicators['Volume_ratio'] = current_volume / avg_volume_30d\n",
        "            elif not pd.isna(current_volume) and current_volume > 0:\n",
        "                 # If 30d avg is zero or NaN but current volume is positive, assume high relative volume\n",
        "                 indicators['Volume_ratio'] = 2.0 # Arbitrary high ratio to indicate spike\n",
        "                 logger.warning(\"30-day average volume is invalid for volume ratio, assuming spike due to positive current volume.\")\n",
        "            else:\n",
        "                 indicators['Volume_ratio'] = np.nan\n",
        "                 logger.warning(\"Insufficient or invalid volume data for volume ratio calculation.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate Volume Ratio: {e}. Setting to NaN.\")\n",
        "            indicators['Volume_ratio'] = np.nan\n",
        "\n",
        "        # Include current price in indicators for technical score calculation\n",
        "        indicators['current_price'] = current_price if not pd.isna(current_price) else np.nan\n",
        "\n",
        "        logger.info(f\"Technical indicators calculated: {indicators}\")\n",
        "        return indicators\n",
        "\n",
        "\n",
        "    def calculate_technical_score(self, indicators):\n",
        "        \"\"\"Calculate a simple technical score based on indicators (out of 50)\"\"\"\n",
        "        score = 0\n",
        "        # Ensure indicators dictionary is valid\n",
        "        if not isinstance(indicators, dict):\n",
        "             logger.warning(\"Invalid indicators dictionary for technical scoring.\")\n",
        "             return 0\n",
        "\n",
        "        # Scoring based on common indicator signals\n",
        "        # Ensure indicator values are valid numbers before scoring\n",
        "        rsi = indicators.get('RSI', np.nan)\n",
        "        macd = indicators.get('MACD', np.nan)\n",
        "        macd_signal = indicators.get('MACD_signal', np.nan)\n",
        "        sma_20 = indicators.get('SMA_20', np.nan)\n",
        "        sma_50 = indicators.get('SMA_50', np.nan)\n",
        "        current_price = indicators.get('current_price', np.nan)\n",
        "        bb_upper = indicators.get('BB_upper', np.nan)\n",
        "        bb_lower = indicators.get('BB_lower', np.nan)\n",
        "        volume_ratio = indicators.get('Volume_ratio', np.nan)\n",
        "\n",
        "\n",
        "        # RSI Score\n",
        "        if not pd.isna(rsi):\n",
        "            if rsi < 30: # Oversold\n",
        "                score += 10\n",
        "            elif rsi > 70: # Overbought\n",
        "                score -= 10\n",
        "        else:\n",
        "             logger.warning(\"RSI is NaN for technical scoring.\")\n",
        "\n",
        "        # MACD Score (Bullish crossover)\n",
        "        if not pd.isna(macd) and not pd.isna(macd_signal):\n",
        "            if macd > macd_signal:\n",
        "                score += 10\n",
        "        else:\n",
        "             logger.warning(\"MACD or MACD signal is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        # Moving Average Crossover (Bullish: 20-day > 50-day)\n",
        "        if not pd.isna(sma_20) and not pd.isna(sma_50):\n",
        "            if sma_20 > sma_50:\n",
        "                score += 10\n",
        "        else:\n",
        "             logger.warning(\"SMA_20 or SMA_50 is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        # Bollinger Bands (Price near lower band suggests potential buy)\n",
        "        if not pd.isna(current_price) and not pd.isna(bb_lower) and not pd.isna(bb_upper):\n",
        "            if current_price < bb_lower:\n",
        "                score += 10\n",
        "            elif current_price > bb_upper:\n",
        "                score -= 10\n",
        "        else:\n",
        "             logger.warning(\"Bollinger Bands or current price is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        # Volume Spike (Significant volume increase can confirm trends)\n",
        "        if not pd.isna(volume_ratio):\n",
        "            if volume_ratio > 1.5: # Volume is 50% higher than average\n",
        "                 score += 10\n",
        "        else:\n",
        "             logger.warning(\"Volume ratio is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        logger.info(f\"Basic technical score calculated: {score}\")\n",
        "        return max(0, min(score, 50)) # Cap score between 0 and 50\n",
        "\n",
        "    # Define a simple class to hold analysis results, similar to a struct\n",
        "    class AnalysisResult:\n",
        "        def __init__(self, symbol, info, price_data, current_price, company_name, market_cap, fundamental_score, technical_score, indicators):\n",
        "            self.symbol = symbol\n",
        "            self.info = info\n",
        "            self.price_data = price_data\n",
        "            self.current_price = current_price\n",
        "            self.company_name = company_name\n",
        "            self.market_cap = market_cap\n",
        "            self.fundamental_score = fundamental_score\n",
        "            self.technical_score = technical_score\n",
        "            self.indicators = indicators\n",
        "\n",
        "        def __repr__(self):\n",
        "            return (f\"AnalysisResult(symbol='{self.symbol}', company_name='{self.company_name}', \"\n",
        "                    f\"current_price={self.current_price}, market_cap={self.market_cap}, \"\n",
        "                    f\"fundamental_score={self.fundamental_score}, technical_score={self.technical_score})\")\n",
        "# --- End of IndianStockAnalyzer class definition ---\n",
        "\n",
        "\n",
        "# Re-define the EnhancedStockAnalyzer class here as well to ensure the latest version is used\n",
        "class EnhancedStockAnalyzer:\n",
        "    \"\"\"Enhanced analyzer with additional features for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the enhanced analyzer.\"\"\"\n",
        "        self.risk_free_rate = self.get_dynamic_risk_free_rate()\n",
        "        # Assuming gemini_model is defined globally from a previous cell\n",
        "        global gemini_model # Access the global gemini_model\n",
        "        self.gemini_model = gemini_model\n",
        "\n",
        "        # More detailed circuit limit percentages based on NSE categorization (simplified)\n",
        "        self.circuit_limits_percentage = {\n",
        "            'category_a': 0.20, # Typically high-liquidity index stocks\n",
        "            'category_b': 0.10, # Most other actively traded stocks\n",
        "            'category_t': 0.05  # Stocks in trade-for-trade segment\n",
        "        }\n",
        "\n",
        "        # Simple mapping of some known stocks to categories for demonstration\n",
        "        self.stock_category_map = {\n",
        "            'RELIANCE.NS': 'category_a',\n",
        "            'TCS.NS': 'category_a',\n",
        "            'HDFCBANK.NS': 'category_a',\n",
        "            'INFY.NS': 'category_a',\n",
        "            'ICICIBANK.NS': 'category_a',\n",
        "            'VEDL.NS': 'category_b',\n",
        "            'PNB.NS': 'category_b',\n",
        "            'INDIGO.NS': 'category_b',\n",
        "            'BANDHANBNK.NS': 'category_b',\n",
        "            'PERSISTENT.NS': 'category_b',\n",
        "            'COFORGE.NS': 'category_b',\n",
        "            'LTTS.NS': 'category_b',\n",
        "        }\n",
        "\n",
        "\n",
        "    def get_dynamic_risk_free_rate(self):\n",
        "        \"\"\"Fetch current 10-year G-Sec yield\"\"\"\n",
        "        try:\n",
        "            return 0.072  # 7.2% as of recent data\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not fetch dynamic risk-free rate: {e}. Using fallback rate.\")\n",
        "            return 0.065\n",
        "\n",
        "    def get_circuit_limits(self, symbol):\n",
        "        \"\"\"Get circuit breaker limits for the stock based on categorization\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            if not info or 'previousClose' not in info:\n",
        "                 logger.warning(f\"Could not get previous close for {symbol}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "            prev_close = info.get('previousClose')\n",
        "            if pd.isna(prev_close) or prev_close <= 0:\n",
        "                 logger.warning(f\"Invalid previous close price for {symbol}: {prev_close}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "\n",
        "            stock_category = self.stock_category_map.get(symbol.upper(), 'category_b')\n",
        "            circuit_percent = self.circuit_limits_percentage.get(stock_category, 0.10)\n",
        "\n",
        "            logger.info(f\"Determined circuit percentage for {symbol} (Category: {stock_category}): {circuit_percent*100}%\")\n",
        "\n",
        "            upper_circuit = prev_close * (1 + circuit_percent)\n",
        "            lower_circuit = prev_close * (1 - circuit_percent)\n",
        "\n",
        "            return {\n",
        "                'upper_circuit': upper_circuit,\n",
        "                'lower_circuit': lower_circuit,\n",
        "                'circuit_percent': circuit_percent\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting circuit breaker limits for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def assess_circuit_risk(self, current_price, circuit_limits):\n",
        "        \"\"\"Assess proximity to circuit limits\"\"\"\n",
        "        if pd.isna(current_price) or current_price <= 0:\n",
        "             logger.warning(\"Invalid current price for circuit risk assessment.\")\n",
        "             return 0\n",
        "\n",
        "        if not circuit_limits or 'upper_circuit' not in circuit_limits or 'lower_circuit' not in circuit_limits:\n",
        "            logger.warning(\"Invalid or incomplete circuit limits provided.\")\n",
        "            return 0\n",
        "\n",
        "        upper_circuit = circuit_limits['upper_circuit']\n",
        "        lower_circuit = circuit_limits['lower_circuit']\n",
        "\n",
        "        if pd.isna(upper_circuit) or pd.isna(lower_circuit) or upper_circuit <= 0 or lower_circuit <= 0:\n",
        "             logger.warning(\"Circuit limits are invalid numbers. Cannot assess circuit risk.\")\n",
        "             return 0\n",
        "\n",
        "        risk_score = 0\n",
        "\n",
        "        if current_price >= upper_circuit:\n",
        "             risk_score -= 30\n",
        "        elif (upper_circuit - current_price) / current_price < 0.01:\n",
        "            risk_score -= 20\n",
        "        elif (upper_circuit - current_price) / current_price < 0.03:\n",
        "            risk_score -= 10\n",
        "        elif (upper_circuit - current_price) / current_price < 0.05:\n",
        "            risk_score -= 5\n",
        "\n",
        "        if current_price <= lower_circuit:\n",
        "            risk_score -= 40\n",
        "        elif (current_price - lower_circuit) / current_price < 0.01:\n",
        "            risk_score -= 30\n",
        "        elif (current_price - lower_circuit) / current_price < 0.03:\n",
        "            risk_score -= 15\n",
        "        elif (current_price - lower_circuit) / current_price < 0.05:\n",
        "            risk_score -= 8\n",
        "\n",
        "        logger.info(f\"Circuit risk score calculated: {risk_score}\")\n",
        "        return risk_score\n",
        "\n",
        "    def get_liquidity_score(self, price_data):\n",
        "        \"\"\"Enhanced liquidity analysis with NaN handling and better checks\"\"\"\n",
        "        liquidity_score = 0\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or len(price_data) < 20:\n",
        "            logger.warning(\"Insufficient price data for liquidity analysis. Assigning default score.\")\n",
        "            return 30\n",
        "\n",
        "        try:\n",
        "            avg_volume_20d = price_data['Volume'].rolling(20).mean().iloc[-1]\n",
        "            avg_volume_5d = price_data['Volume'].rolling(5).mean().iloc[-1]\n",
        "            current_close = price_data['Close'].iloc[-1]\n",
        "\n",
        "            if pd.isna(avg_volume_20d) or pd.isna(avg_volume_5d) or pd.isna(current_close) or current_close <= 0:\n",
        "                 logger.warning(\"Liquidity metrics are NaN or invalid. Cannot calculate liquidity score accurately. Assigning default.\")\n",
        "                 return 30\n",
        "\n",
        "            avg_turnover_20d = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d >= 0 and current_close > 0:\n",
        "                 avg_turnover_20d = avg_volume_20d * current_close\n",
        "\n",
        "            volume_spike = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                 if avg_volume_5d is not None and not pd.isna(avg_volume_5d):\n",
        "                     volume_spike = avg_volume_5d / avg_volume_20d\n",
        "                 else:\n",
        "                      logger.warning(\"5-day average volume is invalid for volume spike calculation.\")\n",
        "            elif avg_volume_5d is not None and not pd.isna(avg_volume_5d) and avg_volume_5d > 0:\n",
        "                 volume_spike = 1.0\n",
        "                 logger.warning(\"20-day average volume is invalid for volume spike, using 1.0 as relative indicator.\")\n",
        "            else:\n",
        "                 logger.warning(\"Insufficient or invalid volume data for volume spike calculation.\")\n",
        "\n",
        "            if not pd.isna(avg_turnover_20d):\n",
        "                if avg_turnover_20d > 500_00_00_000:\n",
        "                    liquidity_score += 40\n",
        "                elif avg_turnover_20d > 100_00_00_000:\n",
        "                    liquidity_score += 30\n",
        "                elif avg_turnover_20d > 10_00_00_000:\n",
        "                    liquidity_score += 20\n",
        "                elif avg_turnover_20d > 1_00_00_000:\n",
        "                    liquidity_score += 10\n",
        "                else:\n",
        "                    liquidity_score += 5\n",
        "            else:\n",
        "                 logger.warning(\"Average turnover is NaN. Skipping turnover scoring.\")\n",
        "                 liquidity_score += 10\n",
        "\n",
        "            volume_std = price_data['Volume'].rolling(20).std().iloc[-1] if len(price_data) >= 20 else np.nan\n",
        "            volume_cv = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0 and \\\n",
        "               volume_std is not None and not pd.isna(volume_std):\n",
        "                volume_cv = volume_std / avg_volume_20d\n",
        "\n",
        "            if not pd.isna(volume_cv):\n",
        "                if volume_cv < 0.5:\n",
        "                    liquidity_score += 20\n",
        "                elif volume_cv < 1.0:\n",
        "                    liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume coefficient of variation is NaN. Skipping consistency scoring.\")\n",
        "\n",
        "            if not pd.isna(volume_spike) and volume_spike > 1.2:\n",
        "                liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume spike ratio is NaN. Skipping trend scoring.\")\n",
        "\n",
        "            return min(liquidity_score, 70)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating liquidity score: {str(e)}\")\n",
        "            return 30\n",
        "\n",
        "    def get_peer_companies(self, symbol, stock_info):\n",
        "        \"\"\"Identify peer companies for comparison\"\"\"\n",
        "        try:\n",
        "            if not isinstance(stock_info, dict):\n",
        "                 logger.warning(\"Invalid stock info for peer identification.\")\n",
        "                 return []\n",
        "\n",
        "            sector = stock_info.get('sector', '')\n",
        "            market_cap = stock_info.get('marketCap', 0)\n",
        "\n",
        "            if not isinstance(sector, str):\n",
        "                 sector = ''\n",
        "            if not isinstance(market_cap, (int, float)) or pd.isna(market_cap) or market_cap <= 0:\n",
        "                 logger.warning(\"Invalid market cap for peer identification.\")\n",
        "                 market_cap = 0\n",
        "\n",
        "            if market_cap > 10_00_000_00_00_000:\n",
        "                cap_category = 'Large Cap'\n",
        "            elif market_cap > 50_000_00_00_000:\n",
        "                cap_category = 'Mid Cap'\n",
        "            else:\n",
        "                cap_category = 'Small Cap'\n",
        "\n",
        "            peer_map = {\n",
        "                'Technology': {\n",
        "                    'Large Cap': ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS'],\n",
        "                    'Mid Cap': ['TECHM.NS', 'LTTS.NS', 'PERSISTENT.NS', 'COFORGE.NS'],\n",
        "                    'Small Cap': ['ZENSAR.NS', 'ECLERX.NS', 'MASTEK.NS']\n",
        "                },\n",
        "                'Financial Services': {\n",
        "                    'Large Cap': ['HDFCBANK.NS', 'ICICIBANK.NS', 'KOTAKBANK.NS', 'AXISBANK.NS'],\n",
        "                    'Mid Cap': ['IDFCFIRSTB.NS', 'FEDERALBNK.NS', 'INDUSINDBK.NS'],\n",
        "                    'Small Cap': ['SOUTHBANK.NS', 'UJJIVAN.NS', 'EQUITASBNK.NS']\n",
        "                },\n",
        "                'Healthcare': {\n",
        "                    'Large Cap': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS'],\n",
        "                    'Mid Cap': ['TORNTPHARM.NS', 'ALKEM.NS', 'LUPIN.NS'],\n",
        "                    'Small Cap': ['CAPLIPOINT.NS', 'BLISS.NS', 'INDOCO.NS']\n",
        "                }\n",
        "            }\n",
        "\n",
        "            peers = peer_map.get(sector, {}).get(cap_category, [])\n",
        "            peers = [p for p in peers if isinstance(p, str) and p.upper() != symbol.upper()]\n",
        "\n",
        "            logger.info(f\"Identified {len(peers)} peer companies for {symbol} in {sector} ({cap_category} Cap).\")\n",
        "            return peers[:5]\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting peer companies for {symbol}: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def calculate_peer_relative_performance(self, symbol, peers, days=30):\n",
        "        \"\"\"Compare stock performance with peers, handling data issues robustly\"\"\"\n",
        "        results = {\n",
        "            'stock_return': np.nan,\n",
        "            'avg_peer_return': np.nan,\n",
        "            'relative_performance': np.nan,\n",
        "            'outperformance': False,\n",
        "            'days': days\n",
        "        }\n",
        "\n",
        "        if not isinstance(peers, list) or not peers:\n",
        "             logger.warning(\"No valid peer list provided for performance comparison.\")\n",
        "             pass\n",
        "\n",
        "        try:\n",
        "            main_ticker = yf.Ticker(symbol)\n",
        "            main_hist = main_ticker.history(period=f\"{days}d\")\n",
        "            main_return = np.nan\n",
        "\n",
        "            if not main_hist.empty and len(main_hist) > 1:\n",
        "                try:\n",
        "                    start_price = main_hist['Close'].iloc[0]\n",
        "                    end_price = main_hist['Close'].iloc[-1]\n",
        "                    if not pd.isna(start_price) and not pd.isna(end_price) and start_price > 0:\n",
        "                         main_return = ((end_price / start_price) - 1) * 100\n",
        "                    else:\n",
        "                         logger.warning(f\"Invalid start ({start_price}) or end price ({end_price}) for main stock ({symbol}) return calculation.\")\n",
        "                except Exception as ret_e:\n",
        "                     logger.warning(f\"Could not calculate main stock ({symbol}) return: {ret_e}. Setting to NaN.\")\n",
        "                     main_return = np.nan\n",
        "            else:\n",
        "                logger.warning(f\"Insufficient historical data for main stock ({symbol}) for return calculation.\")\n",
        "\n",
        "            results['stock_return'] = main_return\n",
        "\n",
        "        except Exception as main_stock_e:\n",
        "            logger.error(f\"Error fetching data or calculating return for main stock ({symbol}): {main_stock_e}. Main stock return set to NaN.\")\n",
        "            results['stock_return'] = np.nan\n",
        "\n",
        "        logger.warning(\"Skipping peer analysis to prevent errors. Peer performance metrics will be unavailable.\")\n",
        "        return results\n",
        "\n",
        "\n",
        "    def get_index_membership(self, symbol):\n",
        "        \"\"\"Check index membership for the stock\"\"\"\n",
        "        symbol_upper = symbol.upper() if isinstance(symbol, str) else ''\n",
        "\n",
        "        index_constituents = {\n",
        "            'NIFTY50': ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS'],\n",
        "            'NIFTY_NEXT50': ['VEDL.NS', 'PNB.NS', 'INDIGO.NS', 'BANDHANBNK.NS'],\n",
        "            'NIFTY_MIDCAP150': ['PERSISTENT.NS', 'COFORGE.NS', 'LTTS.NS']\n",
        "        }\n",
        "\n",
        "        membership = []\n",
        "        for index, constituents in index_constituents.items():\n",
        "            if symbol_upper and any(isinstance(c, str) and c.upper() == symbol_upper for c in constituents):\n",
        "                membership.append(index)\n",
        "\n",
        "        if membership:\n",
        "             logger.info(f\"Stock {symbol} is a member of indices: {', '.join(membership)}\")\n",
        "        else:\n",
        "             logger.info(f\"Stock {symbol} is not found in the hardcoded index constituents.\")\n",
        "\n",
        "        return membership\n",
        "\n",
        "    def calculate_enhanced_technical_score(self, indicators, circuit_risk):\n",
        "        \"\"\"Calculate enhanced technical analysis score with NaN handling and circuit risk\"\"\"\n",
        "        base_score = 0\n",
        "        indicators_calculated = 0\n",
        "        possible_indicator_points = 50\n",
        "\n",
        "        num_key_indicators = 5\n",
        "        indicator_point_contribution = possible_indicator_points / num_key_indicators\n",
        "\n",
        "        rsi = indicators.get('RSI', np.nan)\n",
        "        if not pd.isna(rsi):\n",
        "             indicators_calculated += 1\n",
        "             if 40 <= rsi <= 60:\n",
        "                 base_score += indicator_point_contribution * 0.7\n",
        "             elif rsi < 40:\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             else:\n",
        "                 base_score += indicator_point_contribution * 0.5\n",
        "        else:\n",
        "             logger.warning(\"RSI not calculated or is NaN.\")\n",
        "\n",
        "        macd = indicators.get('MACD', np.nan)\n",
        "        macd_signal = indicators.get('MACD_signal', np.nan)\n",
        "\n",
        "        if not pd.isna(macd) and not pd.isna(macd_signal):\n",
        "             indicators_calculated += 1\n",
        "             if macd > macd_signal:\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             else:\n",
        "                 base_score += indicator_point_contribution * 0.5\n",
        "        else:\n",
        "             logger.warning(\"MACD or MACD signal not calculated or is NaN. MACD score not added.\")\n",
        "\n",
        "        sma_20 = indicators.get('SMA_20', np.nan)\n",
        "        sma_50 = indicators.get('SMA_50', np.nan)\n",
        "        if not pd.isna(sma_20) and not pd.isna(sma_50):\n",
        "            indicators_calculated += 1\n",
        "            if sma_20 > sma_50:\n",
        "                base_score += indicator_point_contribution * 1.0\n",
        "            else:\n",
        "                base_score += indicator_point_contribution * 0.5\n",
        "        else:\n",
        "            logger.warning(\"SMA_20 or SMA_50 is NaN for technical scoring.\")\n",
        "\n",
        "        current_price = indicators.get('current_price', np.nan)\n",
        "        bb_upper = indicators.get('BB_upper', np.nan)\n",
        "        bb_lower = indicators.get('BB_lower', np.nan)\n",
        "        bb_middle = indicators.get('BB_middle', np.nan)\n",
        "\n",
        "        if not pd.isna(current_price) and not pd.isna(bb_upper) and not pd.isna(bb_lower) and not pd.isna(bb_middle):\n",
        "            indicators_calculated += 1\n",
        "            if not pd.isna(bb_lower) and not pd.isna(bb_middle) and not pd.isna(current_price) and bb_lower < current_price < bb_middle:\n",
        "                base_score += indicator_point_contribution * 1.0\n",
        "            elif not pd.isna(bb_middle) and not pd.isna(bb_upper) and not pd.isna(current_price) and bb_middle < current_price < bb_upper:\n",
        "                base_score += indicator_point_contribution * 0.7\n",
        "            else:\n",
        "                base_score += indicator_point_contribution * 0.5\n",
        "        else:\n",
        "             logger.warning(\"Bollinger Bands or current price is NaN for technical scoring.\")\n",
        "\n",
        "        volume_ratio = indicators.get('Volume_ratio', np.nan)\n",
        "        if not pd.isna(volume_ratio):\n",
        "             indicators_calculated += 1\n",
        "             if 0.8 <= volume_ratio <= 1.5:\n",
        "                 base_score += indicator_point_contribution * 0.7\n",
        "             elif volume_ratio > 1.5:\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             else:\n",
        "                 base_score += indicator_point_contribution * 0.5\n",
        "        else:\n",
        "             logger.warning(\"Volume ratio is NaN for technical scoring.\")\n",
        "\n",
        "        achieved_score_from_indicators = base_score\n",
        "\n",
        "        if indicators_calculated > 0:\n",
        "            max_possible_contribution = num_key_indicators * indicator_point_contribution\n",
        "            achieved_percentage = achieved_score_from_indicators / max_possible_contribution if max_possible_contribution > 0 else 0\n",
        "            adjusted_base_score = achieved_percentage * possible_indicator_points\n",
        "            if indicators_calculated < num_key_indicators:\n",
        "                 logger.warning(f\"Only {indicators_calculated}/{num_key_indicators} key technical indicators calculated. Adjusting base score from {achieved_score_from_indicators:.2f} (raw) to {adjusted_base_score:.2f}.\")\n",
        "            base_score = adjusted_base_score\n",
        "        else:\n",
        "             logger.warning(\"No key technical indicators calculated. Base technical score is 0.\")\n",
        "             base_score = 0\n",
        "\n",
        "        circuit_risk_adj = circuit_risk if isinstance(circuit_risk, (int, float)) and not pd.isna(circuit_risk) else 0\n",
        "\n",
        "        final_score = base_score + circuit_risk_adj\n",
        "\n",
        "        return max(0, min(final_score, 50))\n",
        "\n",
        "    def fetch_news(self, symbol: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Fetches recent news headlines for the given stock symbol.\n",
        "        NOTE: This is a placeholder. In a real application, you would integrate\n",
        "        with a News API (like News API, Alpha Vantage, etc.) here.\n",
        "        \"\"\"\n",
        "        print(f\"Fetching news for {symbol} (placeholder)...\")\n",
        "        symbol_str = str(symbol) if symbol is not None else \"Unknown Stock\"\n",
        "        return [\n",
        "            f\"{symbol_str} stock price rises on positive market sentiment\",\n",
        "            f\"{symbol_str} announces strong quarterly results, beating estimates\",\n",
        "            f\"Experts bullish on {symbol_str}'s future outlook\",\n",
        "            f\"I am a non-numeric entry that might cause an error\",\n",
        "            f\"{symbol_str} faces regulatory challenges in key market\",\n",
        "            f\"Competitor's new product launch impacts {symbol_str}'s market share\",\n",
        "            f\"Global market trends positively impacting {symbol_str}\",\n",
        "            f\"{symbol_str} management provides optimistic guidance\",\n",
        "            f\"Increased foreign investment flows into {symbol_str}\",\n",
        "            f\"Regulatory approval received for {symbol_str}'s new product\",\n",
        "            f\"Production issues reported for {symbol_str}\",\n",
        "            f\"Increased competition puts pressure on {symbol_str}'s margins\",\n",
        "            f\"Analyst downgrades rating for {symbol_str}\",\n",
        "            f\"Supply chain disruptions affect {symbol_str}'s operations\",\n",
        "            f\"Geopolitical tensions create uncertainty for {symbol_str}\",\n",
        "            f\"{symbol_str} announces stock split\",\n",
        "            f\"Dividend declared by {symbol_str}\"\n",
        "        ]\n",
        "\n",
        "\n",
        "    def analyze_sentiment(self, news_headlines: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of news headlines using the Gemini API.\n",
        "        Returns a dictionary with sentiment counts (positive, neutral, negative)\n",
        "        and a sentiment score.\n",
        "        \"\"\"\n",
        "        if not self.gemini_model:\n",
        "            print(\"Gemini API not configured. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Gemini API not configured. Sentiment analysis skipped.'}\n",
        "\n",
        "        if not isinstance(news_headlines, list) or not news_headlines:\n",
        "            print(\"No news headlines to analyze. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 12.5, 'summary': 'No news headlines. Sentiment analysis skipped.'}\n",
        "\n",
        "        logger.info(\"Analyzing sentiment using Gemini API...\")\n",
        "        prompt = \"Analyze the sentiment of the following news headlines for a stock and categorize each as Positive, Neutral, or Negative. Provide a concise summary of the overall sentiment.\\n\\n\"\n",
        "        for headline in news_headlines:\n",
        "            if isinstance(headline, str):\n",
        "                 prompt += f\"- {headline}\\n\"\n",
        "            else:\n",
        "                 logger.warning(f\"Skipping non-string headline: {headline}\")\n",
        "                 continue\n",
        "\n",
        "        if len(prompt) > 30000:\n",
        "             logger.warning(\"News headlines too long for Gemini API prompt. Truncating.\")\n",
        "             prompt = prompt[:30000] + \"\\n... (headlines truncated)\"\n",
        "\n",
        "        try:\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "            sentiment_text = response.text.strip()\n",
        "            logger.info(f\"Gemini API Response: {sentiment_text[:200]}...\")\n",
        "\n",
        "            positive_count = sentiment_text.lower().count('positive')\n",
        "            neutral_count = sentiment_text.lower().count('neutral')\n",
        "            negative_count = sentiment_text.lower().count('negative')\n",
        "\n",
        "            summary_line = \"No summary extracted.\"\n",
        "            lines = sentiment_text.split('\\n')\n",
        "            for line in lines:\n",
        "                 lower_line = line.lower()\n",
        "                 if 'summary' in lower_line or 'overall sentiment' in lower_line:\n",
        "                     summary_line = line.strip()\n",
        "                     break\n",
        "            if summary_line == \"No summary extracted.\" and lines:\n",
        "                 for line in reversed(lines):\n",
        "                     if line.strip():\n",
        "                         summary_line = line.strip()\n",
        "                         break\n",
        "\n",
        "            total_headlines = len([h for h in news_headlines if isinstance(h, str)])\n",
        "            if total_headlines > 0:\n",
        "                sentiment_score = ((positive_count - negative_count) / total_headlines) * 12.5 + 12.5\n",
        "            else:\n",
        "                sentiment_score = 12.5\n",
        "\n",
        "            return {\n",
        "                'positive': positive_count,\n",
        "                'neutral': neutral_count,\n",
        "                'negative': negative_count,\n",
        "                'score': max(0, min(sentiment_score, 25)),\n",
        "                'summary': summary_line\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing sentiment with Gemini API: {e}. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis failed.'}\n",
        "\n",
        "\n",
        "    def generate_enhanced_recommendation(self, fundamental_score, technical_score,\n",
        "                                       liquidity_score, peer_performance, index_membership,\n",
        "                                       sentiment_analysis_results):\n",
        "        \"\"\"Generate comprehensive recommendation including sentiment\"\"\"\n",
        "        fund_score = fundamental_score if isinstance(fundamental_score, (int, float)) and not pd.isna(fundamental_score) else 0\n",
        "        tech_score = technical_score if isinstance(technical_score, (int, float)) and not pd.isna(technical_score) else 0\n",
        "        liq_score = liquidity_score if isinstance(liquidity_score, (int, float)) and not pd.isna(liquidity_score) else 0\n",
        "        sentiment_score = sentiment_analysis_results.get('score', 0) if isinstance(sentiment_analysis_results.get('score'), (int, float)) and not pd.isna(sentiment_analysis_results.get('score')) else 0\n",
        "\n",
        "        total_score = fund_score + tech_score + liq_score + sentiment_score\n",
        "\n",
        "        peer_analysis_available = isinstance(peer_performance, dict) and \\\n",
        "                                  not (pd.isna(peer_performance.get('stock_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('avg_peer_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('relative_performance')))\n",
        "\n",
        "        if peer_analysis_available and peer_performance.get('outperformance', False) is True:\n",
        "            total_score += 5\n",
        "            logger.info(\"Adding bonus for peer outperformance.\")\n",
        "        elif not peer_analysis_available:\n",
        "             total_score -= 5\n",
        "             logger.warning(\"Applying small penalty as peer performance data is incomplete/unavailable.\")\n",
        "\n",
        "        if isinstance(index_membership, list) and index_membership:\n",
        "            total_score += 5\n",
        "            logger.info(\"Adding bonus for index membership.\")\n",
        "\n",
        "        recommendation = \"NEUTRAL\"\n",
        "        confidence = \"Low\"\n",
        "\n",
        "        if total_score >= 170:\n",
        "            recommendation = \"STRONG BUY\"\n",
        "            confidence = \"High\"\n",
        "        elif total_score >= 140:\n",
        "            recommendation = \"BUY\"\n",
        "            confidence = \"Moderate to High\"\n",
        "        elif total_score >= 100:\n",
        "            recommendation = \"HOLD\"\n",
        "            confidence = \"Moderate\"\n",
        "        elif total_score >= 70:\n",
        "            recommendation = \"SELL\"\n",
        "            confidence = \"Moderate\"\n",
        "        else:\n",
        "            recommendation = \"STRONG SELL\"\n",
        "            confidence = \"High\"\n",
        "\n",
        "        logger.info(f\"Generated enhanced recommendation: {recommendation} (Total Score: {total_score:.2f})\")\n",
        "\n",
        "        return {\n",
        "            'recommendation': recommendation,\n",
        "            'confidence': confidence,\n",
        "            'total_score': total_score,\n",
        "            'breakdown': {\n",
        "                'fundamental': fund_score,\n",
        "                'technical': tech_score,\n",
        "                'liquidity': liq_score,\n",
        "                'sentiment': sentiment_score,\n",
        "                'peer_adjustment': 5 if peer_analysis_available and peer_performance.get('outperformance', False) is True else (-5 if not peer_analysis_available else 0),\n",
        "                'index_adjustment': 5 if isinstance(index_membership, list) and index_membership else 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "    if not isinstance(symbol, str) or not symbol:\n",
        "        logger.error(\"Invalid stock symbol provided for enhanced analysis.\")\n",
        "        return None\n",
        "    if not isinstance(stock_analyzer_part1, IndianStockAnalyzer):\n",
        "        logger.error(\"Invalid IndianStockAnalyzer (Part 1) instance provided.\")\n",
        "        return None\n",
        "    if not isinstance(enhanced_analyzer, EnhancedStockAnalyzer):\n",
        "        logger.error(\"Invalid EnhancedStockAnalyzer (Part 2) instance provided.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    logger.info(f\"Starting enhanced analysis for {symbol}\")\n",
        "    # Get basic analysis from Part 1\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        logger.error(f\"Basic analysis failed for {symbol}.\")\n",
        "        return None\n",
        "\n",
        "    # Get current price - already validated in Part 1 analyze_stock\n",
        "    current_price = stock_data.current_price\n",
        "    if pd.isna(current_price) or current_price <= 0:\n",
        "         logger.warning(f\"Current price invalid ({current_price}). Enhanced analysis might be limited.\")\n",
        "\n",
        "\n",
        "    # Enhanced analysis\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    # Pass current_price to assess_circuit_risk (already validated as best as possible in Part 1)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    # Pass price_data (already validated in Part 1 analyze_stock)\n",
        "    # CORRECTED: Call get_liquidity_score on enhanced_analyzer and pass price_data from stock_data\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "\n",
        "    # 3. Peer analysis (now temporarily skipped)\n",
        "    # Pass info (already validated in Part 1 analyze_stock)\n",
        "    peers = enhanced_analyzer.get_peer_companies(symbol, stock_data.info) # Still get peers for reporting, even if analysis is skipped\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peers) # This function now returns early with default NaNs\n",
        "\n",
        "\n",
        "    # 4. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "\n",
        "    # 5. Recalculate technical score with circuit risk\n",
        "    # Pass indicators (already validated in Part 1 calculate_technical_indicators)\n",
        "    # Pass circuit_risk (already validated in assess_circuit_risk)\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "\n",
        "    # 6. Fetch and analyze news sentiment\n",
        "    # Pass symbol (already validated)\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    # Pass news_headlines (already validated)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "\n",
        "\n",
        "    # 7. Generate enhanced recommendation\n",
        "    # Pass scores and results (already validated within their respective functions)\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance, # Pass potentially incomplete/NaN peer performance\n",
        "        index_membership,\n",
        "        sentiment_analysis_results # Pass sentiment analysis results\n",
        "    )\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score, # Ensure correct liquidity score is included\n",
        "            'peers': peers,\n",
        "            'peer_performance': peer_performance, # Include peer performance, even if NaN\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "    logger.info(f\"Enhanced analysis completed for {symbol}\")\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize analyzers\n",
        "    # If running in Jupyter/Colab, use the following approach:\n",
        "    # First, make sure you've run the Part 1 code in a previous cell\n",
        "    # Then the IndianStockAnalyzer class will be available in the namespace\n",
        "\n",
        "    # For standalone script usage:\n",
        "    # from indian_stock_analyzer_part1 import IndianStockAnalyzer\n",
        "\n",
        "    # For Jupyter/Colab where Part 1 was run in previous cell:\n",
        "    # IndianStockAnalyzer should already be available\n",
        "\n",
        "    try:\n",
        "        # Check if IndianStockAnalyzer is already defined (from previous cell)\n",
        "        # This check is less critical now that the class is defined in this cell,\n",
        "        # but can remain as a fallback or for clarity.\n",
        "        IndianStockAnalyzer\n",
        "    except NameError:\n",
        "        print(\"IndianStockAnalyzer class was not defined in a previous cell, but is defined in this cell.\")\n",
        "        # The class definition is now included above, so this error should not occur.\n",
        "        pass\n",
        "\n",
        "\n",
        "    stock_analyzer = IndianStockAnalyzer()\n",
        "    enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "\n",
        "    # Analyze a stock\n",
        "    symbol = \"RELIANCE.NS\" # Example symbol\n",
        "    result = analyze_stock_enhanced(symbol, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if result:\n",
        "        # Display the enhanced report\n",
        "        enhanced = result['enhanced_features']\n",
        "        final = result['final_recommendation']\n",
        "        basic = result['basic_analysis'] # Get basic data for display\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Enhanced Analysis Report: {basic.company_name} ({basic.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if not pd.isna(basic.current_price) else \"Current Price: N/A\")\n",
        "        market_cap_cr = basic.market_cap / 10000000 if not pd.isna(basic.market_cap) else np.nan\n",
        "        print(f\"Market Cap: ₹{market_cap_cr:,.2f} Cr\" if not pd.isna(market_cap_cr) else \"Market Cap: N/A\")\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n⚙️ Enhanced Technical Analysis & Risk:\")\n",
        "        # Display enhanced technical indicators and risk\n",
        "        # Assuming you want to display relevant indicators from basic.indicators and the circuit risk score\n",
        "        circuit_limits_display = enhanced.get('circuit_limits')\n",
        "        if circuit_limits_display and not pd.isna(circuit_limits_display.get('lower_circuit')) and not pd.isna(circuit_limits_display.get('upper_circuit')):\n",
        "             print(f\"Circuit Limits: {circuit_limits_display.get('lower_circuit', 'N/A'):.2f} - {circuit_limits_display.get('upper_circuit', 'N/A'):.2f}\")\n",
        "        else:\n",
        "             print(\"Circuit Limits: N/A\")\n",
        "\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        # Check if liquidity score is available before formatting\n",
        "        liquidity_score_display = f\"{enhanced.get('liquidity_score', 'N/A')}/70\" if isinstance(enhanced.get('liquidity_score'), (int, float)) and not pd.isna(enhanced.get('liquidity_score')) else \"Liquidity Score: N/A/70\"\n",
        "        print(liquidity_score_display)\n",
        "\n",
        "\n",
        "        # Display some key technical indicators from basic analysis\n",
        "        print(\"\\nKey Technical Indicators (from Basic Analysis):\")\n",
        "        key_tech_indicators = ['RSI', 'MACD', 'MACD_signal', 'SMA_20', 'SMA_50', 'BB_middle', 'Volume_ratio']\n",
        "        for indicator_name in key_tech_indicators:\n",
        "            value = basic.indicators.get(indicator_name, np.nan)\n",
        "            if not pd.isna(value):\n",
        "                if isinstance(value, float):\n",
        "                     print(f\"  - {indicator_name}: {value:,.2f}\")\n",
        "                else:\n",
        "                     print(f\"  - {indicator_name}: {value}\")\n",
        "            else:\n",
        "                print(f\"  - {indicator_name}: N/A\")\n",
        "\n",
        "\n",
        "        print(f\"\\n🤝 Peer Analysis:\")\n",
        "        # Check if peer analysis was skipped or failed by examining the presence of meaningful data\n",
        "        peer_perf = enhanced.get('peer_performance')\n",
        "        if enhanced.get('peers') and peer_perf and not (pd.isna(peer_perf.get('stock_return')) and pd.isna(peer_perf.get('avg_peer_return')) and pd.isna(peer_perf.get('relative_performance'))):\n",
        "             print(f\"Peer Companies: {', '.join(enhanced['peers'])}\")\n",
        "             # Add checks for NaN before formatting float\n",
        "             stock_return_display = f\"{peer_perf.get('stock_return', 'N/A'):.2f}%\" if isinstance(peer_perf.get('stock_return'), (int, float)) and not pd.isna(peer_perf.get('stock_return')) else 'N/A'\n",
        "             avg_peer_return_display = f\"{peer_perf.get('avg_peer_return', 'N/A'):.2f}%\" if isinstance(peer_perf.get('avg_peer_return'), (int, float)) and not pd.isna(peer_perf.get('avg_peer_return')) else 'N/A'\n",
        "             relative_performance_display = f\"{peer_perf.get('relative_performance', 'N/A'):.2f}%\" if isinstance(peer_perf.get('relative_performance'), (int, float)) and not pd.isna(peer_perf.get('relative_performance')) else 'N/A'\n",
        "\n",
        "             print(f\"  - {peer_perf.get('days', 'N/A')}-day Stock Return: {stock_return_display}\")\n",
        "             print(f\"  - Avg Peer Return: {avg_peer_return_display}\")\n",
        "             print(f\"  - Relative Performance: {relative_performance_display}\")\n",
        "        else:\n",
        "             # Display a message indicating peer analysis was skipped/failed\n",
        "             print(\"Peer analysis skipped or failed. Data unavailable.\")\n",
        "\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"\\n🏛️ Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             # Only print a few headlines to keep the report concise\n",
        "             print(\"Sample News Headlines:\")\n",
        "             # Ensure headlines are valid strings before printing\n",
        "             valid_headlines = [h for h in enhanced['news_headlines'] if isinstance(h, str)]\n",
        "             for headline in valid_headlines[:5]: # Print up to 5 headlines\n",
        "                 print(f\"- {headline}\")\n",
        "             if len(valid_headlines) > 5:\n",
        "                  print(\"  ...\")\n",
        "\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             sentiment_score_display = f\"{sentiment_results.get('score', 0):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\"\n",
        "             print(f\"Sentiment Score: {sentiment_score_display}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Comprehensive Scores and Recommendation ---\")\n",
        "        print(f\"Fundamental Score (from Part 1): {basic.fundamental_score:.2f}/50\" if not pd.isna(basic.fundamental_score) else \"Fundamental Score: N/A\")\n",
        "        # Add checks for NaN before formatting float for breakdown scores\n",
        "        enhanced_tech_score_display = f\"{final.get('breakdown', {}).get('technical', 'N/A'):.2f}\" if isinstance(final.get('breakdown', {}).get('technical'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('technical')) else \"N/A\"\n",
        "        liquidity_score_display_breakdown = f\"{final.get('breakdown', {}).get('liquidity', 'N/A'):.2f}\" if isinstance(final.get('breakdown', {}).get('liquidity'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('liquidity')) else \"N/A\"\n",
        "        sentiment_score_display_breakdown = f\"{final.get('breakdown', {}).get('sentiment', 'N/A'):.2f}\" if isinstance(final.get('breakdown', {}).get('sentiment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('sentiment')) else \"N/A\"\n",
        "\n",
        "        print(f\"Technical Score (Enhanced): {enhanced_tech_score_display}/50\")\n",
        "        print(f\"Liquidity Score: {liquidity_score_display_breakdown}/70\")\n",
        "        print(f\"Sentiment Score: {sentiment_score_display_breakdown}/25\")\n",
        "\n",
        "        # Display adjustment scores\n",
        "        peer_adj_display = f\"{final.get('breakdown', {}).get('peer_adjustment', 'N/A'):+.2f}\" if isinstance(final.get('breakdown', {}).get('peer_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('peer_adjustment')) else \"N/A\"\n",
        "        index_adj_display = f\"{final.get('breakdown', {}).get('index_adjustment', 'N/A'):+.2f}\" if isinstance(final.get('breakdown', {}).get('index_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('index_adjustment')) else \"N/A\"\n",
        "\n",
        "        print(f\"Peer Adjustment: {peer_adj_display}\")\n",
        "        print(f\"Index Membership Adjustment: {index_adj_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\nTotal Enhanced Score: {final.get('total_score', 0):.2f}/205\" if isinstance(final.get('total_score'), (int, float)) and not pd.isna(final.get('total_score')) else \"Total Enhanced Score: N/A\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} (Confidence: {final.get('confidence', 'N/A')})\")\n",
        "\n",
        "\n",
        "        print(f\"\\n{'='*60}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "dfbb86ed"
      },
      "source": [
        "# Part 1: IndianStockAnalyzer class definition\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import typing for type hints\n",
        "from typing import List, Dict\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- IndianStockAnalyzer class definition ---\n",
        "class IndianStockAnalyzer:\n",
        "    \"\"\"Basic analyzer for Indian stocks\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the basic analyzer.\"\"\"\n",
        "        # Basic setup if needed for Part 1 (e.g., API keys, configurations)\n",
        "        pass\n",
        "\n",
        "    def analyze_stock(self, symbol):\n",
        "        \"\"\"\n",
        "        Performs basic fundamental and technical analysis for a given stock.\n",
        "        Returns an object or dictionary containing the analysis results.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Starting basic analysis for {symbol}\")\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            if not info:\n",
        "                 logger.warning(f\"Could not fetch info for {symbol}.\")\n",
        "                 # Ensure all expected keys are present with None or np.nan if info is empty\n",
        "                 empty_info_result = self.AnalysisResult(\n",
        "                     symbol=symbol,\n",
        "                     info={}, # Provide an empty dict if info fetching failed\n",
        "                     price_data=pd.DataFrame(),\n",
        "                     current_price=np.nan,\n",
        "                     company_name=symbol,\n",
        "                     market_cap=np.nan,\n",
        "                     fundamental_score=np.nan,\n",
        "                     technical_score=np.nan,\n",
        "                     indicators={},\n",
        "                     pe_ratio=np.nan, # Added for Valuation\n",
        "                     pb_ratio=np.nan, # Added for Valuation\n",
        "                     ev_ebitda=np.nan # Added for Valuation\n",
        "                 )\n",
        "                 return empty_info_result\n",
        "\n",
        "\n",
        "            # Get price data for technical analysis\n",
        "            price_data = ticker.history(period=\"1y\") # Get 1 year of historical data\n",
        "\n",
        "            if price_data.empty:\n",
        "                logger.warning(f\"Could not fetch price data for {symbol}.\")\n",
        "                # Return info even if price data is missing, as fundamental data might still be available\n",
        "                # We will handle missing price data in enhanced calculations\n",
        "                return self.AnalysisResult(\n",
        "                     symbol=symbol,\n",
        "                     info=info, # Use fetched info\n",
        "                     price_data=price_data,\n",
        "                     current_price=info.get('currentPrice', np.nan), # Get current price from info if price_data is empty\n",
        "                     company_name=info.get('longName', symbol), # Get company name from info\n",
        "                     market_cap=info.get('marketCap', np.nan),  # Get market cap from info\n",
        "                     fundamental_score=np.nan, # Fundamental score needs fundamental data\n",
        "                     technical_score=np.nan, # Technical score needs price data\n",
        "                     indicators={}, # Indicators need price data\n",
        "                     pe_ratio=info.get('trailingPE', np.nan), # Added for Valuation\n",
        "                     pb_ratio=info.get('priceToBook', np.nan), # Added for Valuation\n",
        "                     ev_ebitda=info.get('enterpriseToEbitda', np.nan) # Added for Valuation\n",
        "                )\n",
        "\n",
        "\n",
        "            # 1. Fundamental Analysis (Simplified)\n",
        "            # Extract key fundamental data points\n",
        "            try:\n",
        "                market_cap = info.get('marketCap', np.nan)\n",
        "                pe_ratio = info.get('trailingPE', np.nan)\n",
        "                pb_ratio = info.get('priceToBook', np.nan)\n",
        "                dividend_yield = info.get('dividendYield', np.nan) # This is often already a percentage as a float\n",
        "                sector = info.get('sector', 'N/A')\n",
        "                industry = info.get('industry', 'N/A')\n",
        "                current_price = info.get('currentPrice', np.nan)\n",
        "                company_name = info.get('longName', symbol)\n",
        "                ev_ebitda = info.get('enterpriseToEbitda', np.nan) # Added for Valuation\n",
        "\n",
        "                # Ensure dividend_yield is not None before checking if it's NaN\n",
        "                if dividend_yield is not None and not pd.isna(dividend_yield) and dividend_yield > 0:\n",
        "                     # If dividend_yield is a float between 0 and 1, assume it's a ratio and convert to percentage\n",
        "                     if 0 < dividend_yield <= 1:\n",
        "                         dividend_yield *= 100\n",
        "                         logger.info(f\"Converted dividend yield for {symbol} from ratio to percentage: {dividend_yield:.2f}%\")\n",
        "                     else:\n",
        "                         logger.info(f\"Dividend yield for {symbol} is {dividend_yield:.2f}%. Assuming it's already in percentage or other form.\")\n",
        "                else:\n",
        "                     logger.info(f\"Dividend yield for {symbol} is unavailable or zero ({dividend_yield}).\")\n",
        "                     dividend_yield = np.nan # Ensure it's NaN if None or invalid\n",
        "\n",
        "            except Exception as fund_e:\n",
        "                 logger.error(f\"Error extracting fundamental data for {symbol}: {fund_e}. Setting fundamental metrics to NaN.\")\n",
        "                 market_cap, pe_ratio, pb_ratio, dividend_yield, sector, industry, current_price, company_name, ev_ebitda = np.nan, np.nan, np.nan, np.nan, 'N/A', 'N/A', np.nan, symbol, np.nan\n",
        "\n",
        "\n",
        "            # Calculate a simple fundamental score (out of 50)\n",
        "            fundamental_score = self.calculate_fundamental_score(market_cap, pe_ratio, pb_ratio, dividend_yield)\n",
        "\n",
        "            # 2. Technical Analysis (Simplified)\n",
        "            indicators = self.calculate_technical_indicators(price_data, current_price)\n",
        "            technical_score = self.calculate_technical_score(indicators) # Basic technical score (out of 50)\n",
        "\n",
        "            # Bundle results\n",
        "            # Create an object or dictionary to hold all analysis results\n",
        "            analysis_results = self.AnalysisResult(\n",
        "                symbol=symbol,\n",
        "                info=info,\n",
        "                price_data=price_data,\n",
        "                current_price=current_price, # Include current price\n",
        "                company_name=company_name, # Include company name\n",
        "                market_cap=market_cap, # Include market cap\n",
        "                fundamental_score=fundamental_score,\n",
        "                technical_score=technical_score,\n",
        "                indicators=indicators, # Include calculated indicators\n",
        "                pe_ratio=pe_ratio, # Added for Valuation\n",
        "                pb_ratio=pb_ratio, # Added for Valuation\n",
        "                ev_ebitda=ev_ebitda # Added for Valuation\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Basic analysis completed for {symbol}\")\n",
        "            return analysis_results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"An error occurred during basic analysis for {symbol}: {str(e)}\")\n",
        "            return None # Return None if basic analysis fails\n",
        "\n",
        "    def calculate_fundamental_score(self, market_cap, pe_ratio, pb_ratio, dividend_yield):\n",
        "        \"\"\"Calculate a simple fundamental score based on key metrics (out of 50)\"\"\"\n",
        "        score = 0\n",
        "        # Ensure metrics are valid numbers before scoring\n",
        "        market_cap_valid = isinstance(market_cap, (int, float)) and not pd.isna(market_cap) and market_cap > 0\n",
        "        pe_ratio_valid = isinstance(pe_ratio, (int, float)) and not pd.isna(pe_ratio) and pe_ratio > 0\n",
        "        pb_ratio_valid = isinstance(pb_ratio, (int, float)) and not pd.isna(pb_ratio) and pb_ratio > 0\n",
        "        dividend_yield_valid = isinstance(dividend_yield, (int, float)) and not pd.isna(dividend_yield) and dividend_yield >= 0\n",
        "\n",
        "\n",
        "        # Market Cap (Scale based on size, larger usually means more stable)\n",
        "        if market_cap_valid:\n",
        "            if market_cap > 10_00_000_00_00_000:  # > 10 Lakh Cr (Large Cap)\n",
        "                score += 15\n",
        "            elif market_cap > 50_000_00_00_000:   # > 50K Cr (Mid Cap)\n",
        "                score += 10\n",
        "            else: # Small Cap and below\n",
        "                score += 5\n",
        "        else:\n",
        "             logger.warning(\"Market cap is invalid for fundamental scoring.\")\n",
        "\n",
        "\n",
        "        # PE Ratio (Lower is generally better, but depends on industry growth)\n",
        "        if pe_ratio_valid:\n",
        "            if pe_ratio < 20:\n",
        "                score += 15\n",
        "            elif pe_ratio < 30:\n",
        "                score += 10\n",
        "            elif pe_ratio < 40:\n",
        "                score += 5\n",
        "            else: # High PE\n",
        "                score += 2\n",
        "        else:\n",
        "             logger.warning(\"PE ratio is invalid for fundamental scoring.\")\n",
        "\n",
        "\n",
        "        # PB Ratio (Lower is generally better, indicates undervaluation)\n",
        "        if pb_ratio_valid:\n",
        "            if pb_ratio < 3:\n",
        "                score += 10\n",
        "            elif pb_ratio < 5:\n",
        "                score += 7\n",
        "            else:\n",
        "                score += 3\n",
        "        else:\n",
        "             logger.warning(\"PB ratio is invalid for fundamental scoring.\")\n",
        "\n",
        "\n",
        "        # Dividend Yield (Higher is better for income-seeking investors, indicates profitability)\n",
        "        if dividend_yield_valid:\n",
        "            if dividend_yield > 3: # > 3%\n",
        "                score += 10\n",
        "            elif dividend_yield > 1: # > 1%\n",
        "                score += 7\n",
        "            else:\n",
        "                score += 3\n",
        "        else:\n",
        "             logger.warning(\"Dividend yield is invalid for fundamental scoring.\")\n",
        "\n",
        "        logger.info(f\"Fundamental score calculated: {score}\")\n",
        "        return min(score, 50) # Cap score at 50\n",
        "\n",
        "    def calculate_technical_indicators(self, price_data, current_price):\n",
        "        \"\"\"Calculate key technical indicators\"\"\"\n",
        "        # Ensure price_data is valid before calculating indicators\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty:\n",
        "            logger.warning(\"Insufficient price data for technical indicator calculation.\")\n",
        "            return {'RSI': np.nan, 'MACD': np.nan, 'MACD_signal': np.nan, 'SMA_20': np.nan, 'SMA_50': np.nan,\n",
        "                    'BB_upper': np.nan, 'BB_lower': np.nan, 'BB_middle': np.nan, 'Volume_ratio': np.nan,\n",
        "                    'current_price': current_price} # Return NaNs if data is missing\n",
        "\n",
        "\n",
        "        indicators = {}\n",
        "        try:\n",
        "            # RSI (Relative Strength Index)\n",
        "            delta = price_data['Close'].diff()\n",
        "            gain = delta.where(delta > 0, 0)\n",
        "            loss = -delta.where(delta < 0, 0)\n",
        "            avg_gain = gain.ewm(com=14-1, adjust=False).mean()\n",
        "            avg_loss = loss.ewm(com=14-1, adjust=False).mean()\n",
        "            rs = avg_gain / avg_loss\n",
        "            indicators['RSI'] = 100 - (100 / (1 + rs)).iloc[-1]\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate RSI: {e}. Setting to NaN.\")\n",
        "            indicators['RSI'] = np.nan\n",
        "\n",
        "        try:\n",
        "            # MACD (Moving Average Convergence Divergence)\n",
        "            ema_12 = price_data['Close'].ewm(span=12, adjust=False).mean()\n",
        "            ema_26 = price_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "            # Corrected MACD signal calculation to use the MACD Series\n",
        "            macd_series = ema_12 - ema_26\n",
        "            indicators['MACD'] = macd_series.iloc[-1]\n",
        "            indicators['MACD_signal'] = macd_series.ewm(span=9, adjust=False).mean().iloc[-1]\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate MACD: {e}. Setting to NaN.\")\n",
        "            indicators['MACD'] = np.nan\n",
        "            indicators['MACD_signal'] = np.nan\n",
        "\n",
        "        try:\n",
        "            # Moving Averages\n",
        "            indicators['SMA_20'] = price_data['Close'].rolling(window=20).mean().iloc[-1]\n",
        "            indicators['SMA_50'] = price_data['Close'].rolling(window=50).mean().iloc[-1]\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate Moving Averages: {e}. Setting to NaN.\")\n",
        "            indicators['SMA_20'] = np.nan\n",
        "            indicators['SMA_50'] = np.nan\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Bollinger Bands\n",
        "            rolling_mean = price_data['Close'].rolling(window=20).mean()\n",
        "            rolling_std = price_data['Close'].rolling(window=20).std()\n",
        "            indicators['BB_middle'] = rolling_mean.iloc[-1]\n",
        "            indicators['BB_upper'] = (rolling_mean + (rolling_std * 2)).iloc[-1]\n",
        "            indicators['BB_lower'] = (rolling_mean - (rolling_std * 2)).iloc[-1]\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate Bollinger Bands: {e}. Setting to NaN.\")\n",
        "            indicators['BB_middle'] = np.nan\n",
        "            indicators['BB_upper'] = np.nan\n",
        "            indicators['BB_lower'] = np.nan\n",
        "\n",
        "        try:\n",
        "            # Volume Analysis (e.g., current volume vs average volume)\n",
        "            avg_volume_30d = price_data['Volume'].rolling(window=30).mean().iloc[-1]\n",
        "            current_volume = price_data['Volume'].iloc[-1]\n",
        "            # Check for zero division and NaN before calculating ratio\n",
        "            if not pd.isna(avg_volume_30d) and avg_volume_30d > 0 and not pd.isna(current_volume):\n",
        "                 indicators['Volume_ratio'] = current_volume / avg_volume_30d\n",
        "            elif not pd.isna(current_volume) and current_volume > 0:\n",
        "                 # If 30d avg is zero or NaN but current volume is positive, assume high relative volume\n",
        "                 indicators['Volume_ratio'] = 2.0 # Arbitrary high ratio to indicate spike\n",
        "                 logger.warning(\"30-day average volume is invalid for volume ratio, assuming spike due to positive current volume.\")\n",
        "            else:\n",
        "                 indicators['Volume_ratio'] = np.nan\n",
        "                 logger.warning(\"Insufficient or invalid volume data for volume ratio calculation.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate Volume Ratio: {e}. Setting to NaN.\")\n",
        "            indicators['Volume_ratio'] = np.nan\n",
        "\n",
        "        # Include current price in indicators for technical score calculation\n",
        "        indicators['current_price'] = current_price if not pd.isna(current_price) else np.nan\n",
        "\n",
        "        logger.info(f\"Technical indicators calculated: {indicators}\")\n",
        "        return indicators\n",
        "\n",
        "\n",
        "    def calculate_technical_score(self, indicators):\n",
        "        \"\"\"Calculate a simple technical score based on indicators (out of 50)\"\"\"\n",
        "        score = 0\n",
        "        # Ensure indicators dictionary is valid\n",
        "        if not isinstance(indicators, dict):\n",
        "             logger.warning(\"Invalid indicators dictionary for technical scoring.\")\n",
        "             return 0\n",
        "\n",
        "        # Scoring based on common indicator signals\n",
        "        # Ensure indicator values are valid numbers before scoring\n",
        "        rsi = indicators.get('RSI', np.nan)\n",
        "        macd = indicators.get('MACD', np.nan)\n",
        "        macd_signal = indicators.get('MACD_signal', np.nan)\n",
        "        sma_20 = indicators.get('SMA_20', np.nan)\n",
        "        sma_50 = indicators.get('SMA_50', np.nan)\n",
        "        current_price = indicators.get('current_price', np.nan)\n",
        "        bb_upper = indicators.get('BB_upper', np.nan)\n",
        "        bb_lower = indicators.get('BB_lower', np.nan)\n",
        "        volume_ratio = indicators.get('Volume_ratio', np.nan)\n",
        "\n",
        "\n",
        "        # RSI Score\n",
        "        if not pd.isna(rsi):\n",
        "            if rsi < 30: # Oversold\n",
        "                score += 10\n",
        "            elif rsi > 70: # Overbought\n",
        "                score -= 10\n",
        "        else:\n",
        "             logger.warning(\"RSI is NaN for technical scoring.\")\n",
        "\n",
        "        # MACD Score (Bullish crossover)\n",
        "        if not pd.isna(macd) and not pd.isna(macd_signal):\n",
        "            if macd > macd_signal:\n",
        "                score += 10\n",
        "        else:\n",
        "             logger.warning(\"MACD or MACD signal is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        # Moving Average Crossover (Bullish: 20-day > 50-day)\n",
        "        if not pd.isna(sma_20) and not pd.isna(sma_50):\n",
        "            if sma_20 > sma_50:\n",
        "                score += 10\n",
        "            else:\n",
        "                score += 5 # Add a small score if 20-day is below but close to 50-day\n",
        "        else:\n",
        "             logger.warning(\"SMA_20 or SMA_50 is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        # Bollinger Bands (Price near lower band suggests potential buy)\n",
        "        if not pd.isna(current_price) and not pd.isna(bb_lower) and not pd.isna(bb_upper):\n",
        "            if current_price < bb_lower:\n",
        "                score += 10\n",
        "            elif current_price > bb_upper:\n",
        "                score -= 10\n",
        "            elif bb_lower < current_price < bb_upper: # Price is within the bands\n",
        "                 score += 5 # Add a small score for price being within bands, indicating less volatility\n",
        "        else:\n",
        "             logger.warning(\"Bollinger Bands or current price is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        # Volume Spike (Significant volume increase can confirm trends)\n",
        "        if not pd.isna(volume_ratio):\n",
        "            if volume_ratio > 1.5: # Volume is 50% higher than average\n",
        "                 score += 10\n",
        "            elif volume_ratio < 0.8: # Volume is significantly lower than average\n",
        "                 score += 2 # Small score for low volume\n",
        "            else:\n",
        "                 score += 5 # Average volume is neutral\n",
        "        else:\n",
        "             logger.warning(\"Volume ratio is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        logger.info(f\"Basic technical score calculated: {score}\")\n",
        "        return max(0, min(score, 50)) # Cap score between 0 and 50\n",
        "\n",
        "    # Define a simple class to hold analysis results, similar to a struct\n",
        "    class AnalysisResult:\n",
        "        def __init__(self, symbol, info, price_data, current_price, company_name, market_cap,\n",
        "                     fundamental_score, technical_score, indicators, pe_ratio=np.nan,\n",
        "                     pb_ratio=np.nan, ev_ebitda=np.nan): # Added for Valuation\n",
        "            self.symbol = symbol\n",
        "            self.info = info\n",
        "            self.price_data = price_data\n",
        "            self.current_price = current_price\n",
        "            self.company_name = company_name\n",
        "            self.market_cap = market_cap\n",
        "            self.fundamental_score = fundamental_score\n",
        "            self.technical_score = technical_score\n",
        "            self.indicators = indicators\n",
        "            self.pe_ratio = pe_ratio # Added for Valuation\n",
        "            self.pb_ratio = pb_ratio # Added for Valuation\n",
        "            self.ev_ebitda = ev_ebitda # Added for Valuation\n",
        "\n",
        "        def __repr__(self):\n",
        "            return (f\"AnalysisResult(symbol='{self.symbol}', company_name='{self.company_name}', \"\n",
        "                    f\"current_price={self.current_price}, market_cap={self.market_cap}, \"\n",
        "                    f\"fundamental_score={self.fundamental_score}, technical_score={self.technical_score}, \"\n",
        "                    f\"pe_ratio={self.pe_ratio}, pb_ratio={self.pb_ratio}, ev_ebitda={self.ev_ebitda})\") # Updated repr\n",
        "# --- End of IndianStockAnalyzer class definition ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "cellView": "form",
        "id": "786b5e93",
        "outputId": "82d59232-a7a1-49d7-9e48-b49e084cbdf7"
      },
      "source": [
        "# Part 2: EnhancedStockAnalyzer class definition (with Peer Map fix, Volume Spike logging, Peer Valuation Fetching, Sector Average Calculation, and Valuation Comparison - Type Hints Removed as Workaround)\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import typing for type hints - keep import but don't use in method signature\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# --- EnhancedStockAnalyzer class definition ---\n",
        "class EnhancedStockAnalyzer:\n",
        "    \"\"\"Enhanced analyzer with additional features for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the enhanced analyzer.\"\"\"\n",
        "        self.risk_free_rate = self.get_dynamic_risk_free_rate()\n",
        "        # Assuming gemini_model is defined globally from a previous cell\n",
        "        global gemini_model # Access the global gemini_model\n",
        "        self.gemini_model = gemini_model\n",
        "\n",
        "        # More detailed circuit limit percentages based on NSE categorization (simplified)\n",
        "        self.circuit_limits_percentage = {\n",
        "            'category_a': 0.20, # Typically high-liquidity index stocks\n",
        "            'category_b': 0.10, # Most other actively traded stocks\n",
        "            'category_t': 0.05  # Stocks in trade-for-trade segment\n",
        "        }\n",
        "\n",
        "        # Simple mapping of some known stocks to categories for demonstration\n",
        "        self.stock_category_map = {\n",
        "            'RELIANCE.NS': 'category_a',\n",
        "            'TCS.NS': 'category_a',\n",
        "            'HDFCBANK.NS': 'category_a',\n",
        "            'INFY.NS': 'category_a',\n",
        "            'ICICIBANK.NS': 'category_a',\n",
        "            'VEDL.NS': 'category_b',\n",
        "            'PNB.NS': 'category_b',\n",
        "            'INDIGO.NS': 'category_b',\n",
        "            'BANDHANBNK.NS': 'category_b',\n",
        "            'PERSISTENT.NS': 'category_b',\n",
        "            'COFORGE.NS': 'category_b',\n",
        "            'LTTS.NS': 'category_b',\n",
        "        }\n",
        "\n",
        "\n",
        "    def get_dynamic_risk_free_rate(self):\n",
        "        \"\"\"Fetch current 10-year G-Sec yield\"\"\"\n",
        "        try:\n",
        "            return 0.072  # 7.2% as of recent data\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not fetch dynamic risk-free rate: {e}. Using fallback rate.\")\n",
        "            return 0.065\n",
        "\n",
        "    def get_circuit_limits(self, symbol):\n",
        "        \"\"\"Get circuit breaker limits for the stock based on categorization\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            if not info or 'previousClose' not in info:\n",
        "                 logger.warning(f\"Could not get previous close for {symbol}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "            prev_close = info.get('previousClose')\n",
        "            if pd.isna(prev_close) or prev_close <= 0:\n",
        "                 logger.warning(f\"Invalid previous close price for {symbol}: {prev_close}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "\n",
        "            stock_category = self.stock_category_map.get(symbol.upper(), 'category_b')\n",
        "            circuit_percent = self.circuit_limits_percentage.get(stock_category, 0.10)\n",
        "\n",
        "            logger.info(f\"Determined circuit percentage for {symbol} (Category: {stock_category}): {circuit_percent*100}%\")\n",
        "\n",
        "            upper_circuit = prev_close * (1 + circuit_percent)\n",
        "            lower_circuit = prev_close * (1 - circuit_percent)\n",
        "\n",
        "            return {\n",
        "                'upper_circuit': upper_circuit,\n",
        "                'lower_circuit': lower_circuit,\n",
        "                'circuit_percent': circuit_percent\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting circuit breaker limits for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def assess_circuit_risk(self, current_price, circuit_limits):\n",
        "        \"\"\"Assess proximity to circuit limits\"\"\"\n",
        "        if pd.isna(current_price) or current_price <= 0:\n",
        "             logger.warning(\"Invalid current price for circuit risk assessment.\")\n",
        "             return 0\n",
        "\n",
        "        if not circuit_limits or 'upper_circuit' not in circuit_limits or 'lower_circuit' not in circuit_limits:\n",
        "            logger.warning(\"Invalid or incomplete circuit limits provided.\")\n",
        "            return 0\n",
        "\n",
        "        upper_circuit = circuit_limits['upper_circuit']\n",
        "        lower_circuit = circuit_limits['lower_circuit']\n",
        "\n",
        "        if pd.isna(upper_circuit) or pd.isna(lower_circuit) or upper_circuit <= 0 or lower_circuit <= 0:\n",
        "             logger.warning(\"Circuit limits are invalid numbers. Cannot assess circuit risk.\")\n",
        "             return 0\n",
        "\n",
        "        risk_score = 0\n",
        "\n",
        "        if current_price >= upper_circuit:\n",
        "             risk_score -= 30\n",
        "        elif (upper_circuit - current_price) / current_price < 0.01:\n",
        "            risk_score -= 20\n",
        "        elif (upper_circuit - current_price) / current_price < 0.03:\n",
        "            risk_score -= 10\n",
        "        elif (upper_circuit - current_price) / current_price < 0.05:\n",
        "            risk_score -= 5\n",
        "\n",
        "        if current_price <= lower_circuit:\n",
        "            risk_score -= 40\n",
        "        elif (current_price - lower_circuit) / current_price < 0.01:\n",
        "            risk_score -= 30\n",
        "        elif (current_price - lower_circuit) / current_price < 0.03:\n",
        "            risk_score -= 15\n",
        "        elif (current_price - lower_circuit) / current_price < 0.05:\n",
        "            risk_score -= 8\n",
        "\n",
        "        logger.info(f\"Circuit risk score calculated: {risk_score}\")\n",
        "        return risk_score\n",
        "\n",
        "    def get_liquidity_score(self, price_data):\n",
        "        \"\"\"Enhanced liquidity analysis with NaN handling and better checks\"\"\"\n",
        "        liquidity_score = 0\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or len(price_data) < 20:\n",
        "            logger.warning(\"Insufficient price data for liquidity analysis. Assigning default score.\")\n",
        "            return 30\n",
        "\n",
        "        try:\n",
        "            avg_volume_20d = price_data['Volume'].rolling(20).mean().iloc[-1]\n",
        "            avg_volume_5d = price_data['Volume'].rolling(5).mean().iloc[-1]\n",
        "            current_close = price_data['Close'].iloc[-1]\n",
        "\n",
        "            # Add logging for diagnosis - before calculation check\n",
        "            logger.info(f\"Volume data for liquidity: avg_volume_20d: {avg_volume_20d}, avg_volume_5d: {avg_volume_5d}, current_close: {current_close}\")\n",
        "\n",
        "\n",
        "            if pd.isna(avg_volume_20d) or pd.isna(avg_volume_5d) or pd.isna(current_close) or current_close <= 0:\n",
        "                 logger.warning(\"Liquidity metrics are NaN or invalid. Cannot calculate liquidity score accurately. Assigning default.\")\n",
        "                 return 30\n",
        "\n",
        "            avg_turnover_20d = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d >= 0 and current_close > 0:\n",
        "                 avg_turnover_20d = avg_volume_20d * current_close\n",
        "\n",
        "            volume_spike = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                 if avg_volume_5d is not None and not pd.isna(avg_volume_5d):\n",
        "                     volume_spike = avg_volume_5d / avg_volume_20d\n",
        "                 else:\n",
        "                      logger.warning(\"5-day average volume is invalid for volume spike calculation.\")\n",
        "            elif not pd.isna(avg_volume_5d) and avg_volume_5d > 0:\n",
        "                 volume_spike = 1.0\n",
        "                 logger.warning(\"20-day average volume is invalid for volume spike, using 1.0 as relative indicator.\")\n",
        "            else:\n",
        "                 volume_spike = np.nan # Ensure volume_spike is NaN if both volumes are invalid\n",
        "                 logger.warning(\"Insufficient or invalid volume data for volume ratio calculation.\")\n",
        "\n",
        "            # Add logging for volume spike - after calculation\n",
        "            logger.info(f\"Volume spike calculated: {volume_spike}\")\n",
        "\n",
        "            # Corrected logic for scoring based on volume_spike\n",
        "            if not pd.isna(volume_spike):\n",
        "                if volume_spike > 1.5: # Volume is 50% higher than average\n",
        "                    liquidity_score += 10\n",
        "                elif volume_spike < 0.8: # Volume is significantly lower than average\n",
        "                    liquidity_score += 2 # Small score for low volume\n",
        "                else: # volume_spike is between 0.8 and 1.5 (inclusive of 0.8, exclusive of 1.5)\n",
        "                    liquidity_score += 5 # Average volume is neutral\n",
        "            else:\n",
        "                 logger.warning(\"Volume spike ratio is NaN. Skipping trend scoring.\")\n",
        "\n",
        "\n",
        "            if not pd.isna(avg_turnover_20d):\n",
        "                if avg_turnover_20d > 500_00_00_000:\n",
        "                    liquidity_score += 40\n",
        "                elif avg_turnover_20d > 100_00_00_000:\n",
        "                    liquidity_score += 30\n",
        "                elif avg_turnover_20d > 10_00_00_000:\n",
        "                    liquidity_score += 20\n",
        "                elif avg_turnover_20d > 1_00_00_000:\n",
        "                    liquidity_score += 10\n",
        "                else:\n",
        "                    liquidity_score += 5\n",
        "            else:\n",
        "                 logger.warning(\"Average turnover is NaN. Skipping turnover scoring.\")\n",
        "                 liquidity_score += 10\n",
        "\n",
        "            volume_std = price_data['Volume'].rolling(20).std().iloc[-1] if len(price_data) >= 20 else np.nan\n",
        "            volume_cv = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0 and \\\n",
        "               volume_std is not None and not pd.isna(volume_std):\n",
        "                volume_cv = volume_std / avg_volume_20d\n",
        "\n",
        "            if not pd.isna(volume_cv):\n",
        "                if volume_cv < 0.5:\n",
        "                    liquidity_score += 20\n",
        "                elif volume_cv < 1.0:\n",
        "                    liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume coefficient of variation is NaN. Skipping consistency scoring.\")\n",
        "\n",
        "            # The volume spike scoring is now handled above within the main if not pd.isna(volume_spike): block\n",
        "\n",
        "\n",
        "            return min(liquidity_score, 70)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating liquidity score: {str(e)}\")\n",
        "            return 30\n",
        "\n",
        "    # Updated return type hint to reflect list of dicts - Type hints removed as workaround\n",
        "    def get_peer_companies(self, symbol, stock_info):\n",
        "        \"\"\"Identify peer companies for comparison and fetch their valuation data\"\"\"\n",
        "        try:\n",
        "            if not isinstance(stock_info, dict):\n",
        "                 logger.warning(\"Invalid stock info for peer identification.\")\n",
        "                 return []\n",
        "\n",
        "            sector = stock_info.get('sector', '')\n",
        "            market_cap = stock_info.get('marketCap', 0)\n",
        "\n",
        "            if not isinstance(sector, str):\n",
        "                 sector = ''\n",
        "            if not isinstance(market_cap, (int, float)) or pd.isna(market_cap) or market_cap <= 0:\n",
        "                 logger.warning(\"Invalid market cap for peer identification.\")\n",
        "                 market_cap = 0\n",
        "\n",
        "            if market_cap > 10_00_000_00_00_000:\n",
        "                cap_category = 'Large Cap'\n",
        "            elif market_cap > 50_000_00_00_000:\n",
        "                cap_category = 'Mid Cap'\n",
        "            else:\n",
        "                cap_category = 'Small Cap'\n",
        "\n",
        "            peer_map = {\n",
        "                'Technology': {\n",
        "                    'Large Cap': ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS'],\n",
        "                    'Mid Cap': ['TECHM.NS', 'LTTS.NS', 'PERSISTENT.NS', 'COFORGE.NS'],\n",
        "                    'Small Cap': ['ZENSAR.NS', 'ECLERX.NS', 'MASTEK.NS']\n",
        "                },\n",
        "                'Financial Services': {\n",
        "                    'Large Cap': ['HDFCBANK.NS', 'ICICIBANK.NS', 'KOTAKBANK.NS', 'AXISBANK.NS'],\n",
        "                    'Mid Cap': ['IDFCFIRSTB.NS', 'FEDERALBNK.NS', 'INDUSINDBK.NS'],\n",
        "                    'Small Cap': ['SOUTHBANK.NS', 'UJJIVAN.NS', 'EQUITASBNK.NS']\n",
        "                },\n",
        "                'Healthcare': {\n",
        "                    'Large Cap': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS'],\n",
        "                    'Mid Cap': ['TORNTPHARM.NS', 'ALKEM.NS', 'LUPIN.NS'],\n",
        "                    'Small Cap': ['CAPLIPOINT.NS', 'BLISS.NS', 'INDOCO.NS']\n",
        "                },\n",
        "                # Added Energy sector mapping\n",
        "                'Energy': {\n",
        "                    'Large Cap': ['ONGC.NS', 'NTPC.NS', 'POWERGRID.NS'], # Exclude RELIANCE.NS here, filter below\n",
        "                    'Mid Cap': ['GAIL.NS', 'IOC.NS', 'NHPC.NS'],\n",
        "                    'Small Cap': ['GUJGASLTD.NS', 'IGL.NS', 'MAHAPOWER.NS']\n",
        "                }\n",
        "            }\n",
        "\n",
        "            peer_symbols = peer_map.get(sector, {}).get(cap_category, [])\n",
        "            # Ensure the current symbol is excluded from the peer list\n",
        "            peer_symbols = [p for p in peer_symbols if isinstance(p, str) and p.upper() != symbol.upper()]\n",
        "\n",
        "            logger.info(f\"Identified {len(peer_symbols)} potential peer companies for {symbol} in {sector} ({cap_category} Cap).\")\n",
        "\n",
        "            # Fetch valuation data for peers\n",
        "            peers_with_data = []\n",
        "            for peer_symbol in peer_symbols:\n",
        "                try:\n",
        "                    peer_ticker = yf.Ticker(peer_symbol)\n",
        "                    # Add timeout to avoid infinite waiting if a ticker is unresponsive\n",
        "                    # Note: yfinance fetch can still hang sometimes despite timeout attempts\n",
        "                    peer_info = peer_ticker.info # yfinance info fetch can sometimes hang\n",
        "                    if peer_info:\n",
        "                        peers_with_data.append({\n",
        "                            'symbol': peer_symbol,\n",
        "                            'pe_ratio': peer_info.get('trailingPE', np.nan),\n",
        "                            'pb_ratio': peer_info.get('priceToBook', np.nan),\n",
        "                            'ev_ebitda': peer_info.get('enterpriseToEbitda', np.nan),\n",
        "                            'sector': peer_info.get('sector', 'N/A'), # Include sector for potential cross-check\n",
        "                            'marketCap': peer_info.get('marketCap', np.nan) # Include market cap\n",
        "                        })\n",
        "                        logger.info(f\"Fetched valuation data for peer {peer_symbol}\")\n",
        "                    else:\n",
        "                        logger.warning(f\"Could not fetch info for peer {peer_symbol}. Skipping.\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Error fetching data for peer {peer_symbol}: {e}. Skipping.\")\n",
        "\n",
        "            logger.info(f\"Fetched data for {len(peers_with_data)} valid peers.\")\n",
        "            return peers_with_data[:5] # Limit to top 5 peers with data\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting peer companies for {symbol}: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    # Type hints removed as workaround\n",
        "    def calculate_sector_valuation_averages(self, peers_with_data):\n",
        "        \"\"\"Calculates average valuation ratios for a list of peers.\"\"\"\n",
        "        if not peers_with_data:\n",
        "            logger.warning(\"No peer data provided for calculating sector averages.\")\n",
        "            return {'avg_pe': np.nan, 'avg_pb': np.nan, 'avg_ev_ebitda': np.nan}\n",
        "\n",
        "        pe_ratios = [p.get('pe_ratio') for p in peers_with_data if isinstance(p.get('pe_ratio'), (int, float)) and not pd.isna(p.get('pe_ratio')) and p.get('pe_ratio') > 0]\n",
        "        pb_ratios = [p.get('pb_ratio') for p in peers_with_data if isinstance(p.get('pb_ratio'), (int, float)) and not pd.isna(p.get('pb_ratio')) and p.get('pb_ratio') > 0]\n",
        "        ev_ebitda_ratios = [p.get('ev_ebitda') for p in peers_with_data if isinstance(p.get('ev_ebitda'), (int, float)) and not pd.isna(p.get('ev_ebitda')) and p.get('ev_ebitda') > 0]\n",
        "\n",
        "        avg_pe = np.mean(pe_ratios) if pe_ratios else np.nan\n",
        "        avg_pb = np.mean(pb_ratios) if pb_ratios else np.nan\n",
        "        avg_ev_ebitda = np.mean(ev_ebitda_ratios) if ev_ebitda_ratios else np.nan\n",
        "\n",
        "        logger.info(f\"Calculated sector valuation averages: PE={avg_pe:.2f}, PB={avg_pb:.2f}, EV/EBITDA={avg_ev_ebitda:.2f}\")\n",
        "\n",
        "        return {'avg_pe': avg_pe, 'avg_pb': avg_pb, 'avg_ev_ebitda': avg_ev_ebitda}\n",
        "\n",
        "    # Type hints removed as workaround\n",
        "    def compare_valuation_to_peers(self, stock_valuation, sector_averages):\n",
        "        \"\"\"Compares stock's valuation ratios to sector averages.\"\"\"\n",
        "        comparison_results = {\n",
        "            'pe_comparison': 'N/A',\n",
        "            'pb_comparison': 'N/A',\n",
        "            'ev_ebitda_comparison': 'N/A',\n",
        "            'overall_valuation': 'N/A'\n",
        "        }\n",
        "\n",
        "        pe = stock_valuation.get('pe_ratio', np.nan)\n",
        "        pb = stock_valuation.get('pb_ratio', np.nan)\n",
        "        ev_ebitda = stock_valuation.get('ev_ebitda', np.nan)\n",
        "\n",
        "        avg_pe = sector_averages.get('avg_pe', np.nan)\n",
        "        avg_pb = sector_averages.get('avg_pb', np.nan)\n",
        "        avg_ev_ebitda = sector_averages.get('avg_ev_ebitda', np.nan)\n",
        "\n",
        "        # Track how many ratios indicate premium/discount\n",
        "        premium_indicators = 0\n",
        "        discount_indicators = 0\n",
        "        valid_comparisons = 0\n",
        "\n",
        "        # Compare PE\n",
        "        if not pd.isna(pe) and not pd.isna(avg_pe) and avg_pe > 0:\n",
        "            valid_comparisons += 1\n",
        "            if pe > avg_pe * 1.2: # More than 20% higher\n",
        "                comparison_results['pe_comparison'] = 'Premium (>20% higher than avg)'\n",
        "                premium_indicators += 1\n",
        "            elif pe > avg_pe * 1.05: # More than 5% higher\n",
        "                 comparison_results['pe_comparison'] = 'Slight Premium (>5% higher than avg)'\n",
        "                 premium_indicators += 1\n",
        "            elif pe < avg_pe * 0.8: # More than 20% lower\n",
        "                comparison_results['pe_comparison'] = 'Discount (>20% lower than avg)'\n",
        "                discount_indicators += 1\n",
        "            elif pe < avg_pe * 0.95: # More than 5% lower\n",
        "                 comparison_results['pe_comparison'] = 'Slight Discount (>5% lower than avg)'\n",
        "                 discount_indicators += 1\n",
        "            else:\n",
        "                comparison_results['pe_comparison'] = 'In line with avg'\n",
        "        else:\n",
        "             logger.warning(\"PE comparison not possible due to missing data.\")\n",
        "\n",
        "        # Compare PB\n",
        "        if not pd.isna(pb) and not pd.isna(avg_pb) and avg_pb > 0:\n",
        "            valid_comparisons += 1\n",
        "            if pb > avg_pb * 1.2:\n",
        "                comparison_results['pb_comparison'] = 'Premium (>20% higher than avg)'\n",
        "                premium_indicators += 1\n",
        "            elif pb > avg_pb * 1.05:\n",
        "                 comparison_results['pb_comparison'] = 'Slight Premium (>5% higher than avg)'\n",
        "                 premium_indicators += 1\n",
        "            elif pb < avg_pb * 0.8:\n",
        "                comparison_results['pb_comparison'] = 'Discount (>20% lower than avg)'\n",
        "                discount_indicators += 1\n",
        "            elif pb < avg_pb * 0.95:\n",
        "                 comparison_results['pb_comparison'] = 'Slight Discount (>5% lower than avg)'\n",
        "                 discount_indicators += 1\n",
        "            else:\n",
        "                comparison_results['pb_comparison'] = 'In line with avg'\n",
        "        else:\n",
        "             logger.warning(\"PB comparison not possible due to missing data.\")\n",
        "\n",
        "        # Compare EV/EBITDA\n",
        "        if not pd.isna(ev_ebitda) and not pd.isna(avg_ev_ebitda) and avg_ev_ebitda > 0:\n",
        "            valid_comparisons += 1\n",
        "            if ev_ebitda > avg_ev_ebitda * 1.2:\n",
        "                comparison_results['ev_ebitda_comparison'] = 'Premium (>20% higher than avg)'\n",
        "                premium_indicators += 1\n",
        "            elif ev_ebitda > avg_ev_ebitda * 1.05:\n",
        "                 comparison_results['ev_ebitda_comparison'] = 'Slight Premium (>5% higher than avg)'\n",
        "                 premium_indicators += 1\n",
        "            elif ev_ebitda < avg_ev_ebitda * 0.8:\n",
        "                comparison_results['ev_ebitda_comparison'] = 'Discount (>20% lower than avg)'\n",
        "                discount_indicators += 1\n",
        "            elif ev_ebitda < avg_ev_ebitda * 0.95:\n",
        "                 comparison_results['ev_ebitda_comparison'] = 'Slight Discount (>5% lower than avg)'\n",
        "                 discount_indicators += 1\n",
        "            else:\n",
        "                comparison_results['ev_ebitda_comparison'] = 'In line with avg'\n",
        "        else:\n",
        "             logger.warning(\"EV/EBITDA comparison not possible due to missing data.\")\n",
        "\n",
        "\n",
        "        # Simple overall valuation assessment\n",
        "        if valid_comparisons == 0:\n",
        "            comparison_results['overall_valuation'] = 'Valuation comparison not possible (No valid data)'\n",
        "        elif premium_indicators > discount_indicators:\n",
        "            comparison_results['overall_valuation'] = 'Potentially Overvalued vs. Peers'\n",
        "        elif discount_indicators > premium_indicators:\n",
        "            comparison_results['overall_valuation'] = 'Potentially Undervalued vs. Peers'\n",
        "        else:\n",
        "            comparison_results['overall_valuation'] = 'Fairly valued vs. Peers'\n",
        "\n",
        "\n",
        "        logger.info(f\"Valuation comparison results: {comparison_results}\")\n",
        "        return comparison_results\n",
        "\n",
        "\n",
        "    def calculate_peer_relative_performance(self, symbol, peers_with_data: List[Dict[str, Any]], days=30):\n",
        "        \"\"\"Compare stock performance with peers, handling data issues robustly\"\"\"\n",
        "        results = {\n",
        "            'stock_return': np.nan,\n",
        "            'avg_peer_return': np.nan,\n",
        "            'relative_performance': np.nan,\n",
        "            'outperformance': False,\n",
        "            'days': days\n",
        "        }\n",
        "\n",
        "        # Use the symbols from the fetched peer data for performance comparison\n",
        "        peers_for_performance = [p['symbol'] for p in peers_with_data if 'symbol' in p and isinstance(p['symbol'], str)]\n",
        "\n",
        "        if not peers_for_performance:\n",
        "             logger.warning(\"No valid peer symbols with data provided for performance comparison.\")\n",
        "             # Return the default results with NaNs if no peers\n",
        "             return results\n",
        "\n",
        "        # --- Removed the temporary skip here ---\n",
        "\n",
        "        try:\n",
        "            main_ticker = yf.Ticker(symbol)\n",
        "            main_hist = main_ticker.history(period=f\"{days}d\")\n",
        "            main_return = np.nan\n",
        "\n",
        "            if not main_hist.empty and len(main_hist) > 1:\n",
        "                try:\n",
        "                    start_price = main_hist['Close'].iloc[0]\n",
        "                    end_price = main_hist['Close'].iloc[-1]\n",
        "                    if not pd.isna(start_price) and not pd.isna(end_price) and start_price > 0:\n",
        "                         main_return = ((end_price / start_price) - 1) * 100\n",
        "                    else:\n",
        "                         logger.warning(f\"Invalid start ({start_price}) or end price ({end_price}) for main stock ({symbol}) return calculation.\")\n",
        "                except Exception as ret_e:\n",
        "                     logger.warning(f\"Could not calculate main stock ({symbol}) return: {ret_e}. Setting to NaN.\")\n",
        "                     main_return = np.nan\n",
        "            else:\n",
        "                logger.warning(f\"Insufficient historical data for main stock ({symbol}) for return calculation.\")\n",
        "\n",
        "            results['stock_return'] = main_return\n",
        "\n",
        "        except Exception as main_stock_e:\n",
        "            logger.error(f\"Error fetching data or calculating return for main stock ({symbol}): {main_stock_e}. Main stock return set to NaN.\")\n",
        "            results['stock_return'] = np.nan\n",
        "\n",
        "        # Calculate peer returns\n",
        "        peer_returns = []\n",
        "        for peer_symbol in peers_for_performance: # Use the filtered list of symbols\n",
        "             try:\n",
        "                 peer_ticker = yf.Ticker(peer_symbol)\n",
        "                 peer_hist = peer_ticker.history(period=f\"{days}d\")\n",
        "                 if not peer_hist.empty and len(peer_hist) > 1:\n",
        "                     try:\n",
        "                          peer_start_price = peer_hist['Close'].iloc[0]\n",
        "                          peer_end_price = peer_hist['Close'].iloc[-1]\n",
        "                          if not pd.isna(peer_start_price) and not pd.isna(peer_end_price) and peer_start_price > 0:\n",
        "                             peer_return = ((peer_end_price / peer_start_price) - 1) * 100\n",
        "                             peer_returns.append(peer_return)\n",
        "                          else:\n",
        "                             logger.warning(f\"Invalid start or end price for peer ({peer_symbol}) return calculation.\")\n",
        "                     except Exception as peer_ret_e:\n",
        "                         logger.warning(f\"Could not calculate return for peer ({peer_symbol}): {peer_ret_e}. Skipping.\")\n",
        "                 else:\n",
        "                     logger.warning(f\"Insufficient historical data for peer ({peer_symbol}) for return calculation. Skipping.\")\n",
        "             except Exception as peer_e:\n",
        "                 logger.warning(f\"Error fetching data for peer ({peer_symbol}): {peer_e}. Skipping.\")\n",
        "\n",
        "        # Add logging for peer returns before filtering/average calculation\n",
        "        logger.info(f\"Peer returns collected before average calculation attempt: {peer_returns}\")\n",
        "\n",
        "        # Calculate average peer return and relative performance\n",
        "        if peer_returns:\n",
        "             # Ensure peer_returns list contains only valid numbers before calculating mean\n",
        "             valid_peer_returns = [ret for ret in peer_returns if isinstance(ret, (int, float)) and not pd.isna(ret)]\n",
        "             if valid_peer_returns:\n",
        "                 avg_peer_return = np.mean(valid_peer_returns)\n",
        "                 results['avg_peer_return'] = avg_peer_return\n",
        "\n",
        "                 # Calculate relative performance only if main stock return is valid\n",
        "                 if not pd.isna(main_return):\n",
        "                      results['relative_performance'] = main_return - avg_peer_return\n",
        "\n",
        "                      # Determine outperformance\n",
        "                      if main_return > avg_peer_return:\n",
        "                          results['outperformance'] = True\n",
        "                 else:\n",
        "                      logger.warning(\"Main stock return is NaN, cannot calculate relative performance or outperformance.\")\n",
        "             else:\n",
        "                 logger.warning(\"No valid peer returns available after filtering. Cannot calculate average peer return or relative performance.\")\n",
        "        else:\n",
        "             logger.warning(\"No peer returns calculated. Cannot calculate average peer return or relative performance.\")\n",
        "\n",
        "\n",
        "        logger.info(f\"Peer performance results for {symbol}: {results}\")\n",
        "        return results\n",
        "\n",
        "\n",
        "    def get_index_membership(self, symbol):\n",
        "        \"\"\"Check index membership for the stock\"\"\"\n",
        "        symbol_upper = symbol.upper() if isinstance(symbol, str) else ''\n",
        "\n",
        "        index_constituents = {\n",
        "            'NIFTY50': ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS'],\n",
        "            'NIFTY_NEXT50': ['VEDL.NS', 'PNB.NS', 'INDIGO.NS', 'BANDHANBNK.NS'],\n",
        "            'NIFTY_MIDCAP150': ['PERSISTENT.NS', 'COFORGE.NS', 'LTTS.NS']\n",
        "        }\n",
        "\n",
        "        membership = []\n",
        "        for index, constituents in index_constituents.items():\n",
        "            if symbol_upper and any(isinstance(c, str) and c.upper() == symbol_upper for c in constituents):\n",
        "                membership.append(index)\n",
        "\n",
        "        if membership:\n",
        "             logger.info(f\"Stock {symbol} is a member of indices: {', '.join(membership)}\")\n",
        "        else:\n",
        "             logger.info(f\"Stock {symbol} is not found in the hardcoded index constituents.\")\n",
        "\n",
        "        return membership\n",
        "\n",
        "    def calculate_enhanced_technical_score(self, indicators, circuit_risk):\n",
        "        \"\"\"Calculate enhanced technical analysis score with NaN handling and circuit risk\"\"\"\n",
        "        base_score = 0\n",
        "        indicators_calculated = 0\n",
        "        possible_indicator_points = 50\n",
        "\n",
        "        num_key_indicators = 5\n",
        "        indicator_point_contribution = possible_indicator_points / num_key_indicators\n",
        "\n",
        "        rsi = indicators.get('RSI', np.nan)\n",
        "        if not pd.isna(rsi):\n",
        "             indicators_calculated += 1\n",
        "             if 40 <= rsi <= 60:\n",
        "                 base_score += indicator_point_contribution * 0.7\n",
        "             elif rsi < 40:\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             else:\n",
        "                 base_score += indicator_point_contribution * 0.5\n",
        "        else:\n",
        "             logger.warning(\"RSI not calculated or is NaN.\")\n",
        "\n",
        "        macd = indicators.get('MACD', np.nan)\n",
        "        macd_signal = indicators.get('MACD_signal', np.nan)\n",
        "\n",
        "        if not pd.isna(macd) and not pd.isna(macd_signal):\n",
        "             indicators_calculated += 1\n",
        "             if macd > macd_signal:\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             else:\n",
        "                 base_score += indicator_point_contribution * 0.5\n",
        "        else:\n",
        "             logger.warning(\"MACD or MACD signal is NaN for technical scoring.\")\n",
        "\n",
        "        sma_20 = indicators.get('SMA_20', np.nan)\n",
        "        sma_50 = indicators.get('SMA_50', np.nan)\n",
        "        if not pd.isna(sma_20) and not pd.isna(sma_50):\n",
        "            indicators_calculated += 1\n",
        "            if sma_20 > sma_50:\n",
        "                base_score += indicator_point_contribution * 1.0\n",
        "            else:\n",
        "                base_score += indicator_point_contribution * 0.5\n",
        "        else:\n",
        "             logger.warning(\"SMA_20 or SMA_50 is NaN for technical scoring.\")\n",
        "\n",
        "        current_price = indicators.get('current_price', np.nan)\n",
        "        bb_upper = indicators.get('BB_upper', np.nan)\n",
        "        bb_lower = indicators.get('BB_lower', np.nan)\n",
        "        bb_middle = indicators.get('BB_middle', np.nan)\n",
        "\n",
        "        if not pd.isna(current_price) and not pd.isna(bb_upper) and not pd.isna(bb_lower) and not pd.isna(bb_middle):\n",
        "            indicators_calculated += 1\n",
        "            if not pd.isna(bb_lower) and not pd.isna(bb_middle) and not pd.isna(current_price) and bb_lower < current_price < bb_middle:\n",
        "                base_score += indicator_point_contribution * 1.0\n",
        "            elif not pd.isna(bb_middle) and not pd.isna(bb_upper) and not pd.isna(current_price) and bb_middle < current_price < bb_upper:\n",
        "                base_score += indicator_point_contribution * 0.7\n",
        "            else:\n",
        "                base_score += indicator_point_contribution * 0.5\n",
        "        else:\n",
        "             logger.warning(\"Bollinger Bands or current price is NaN for technical scoring.\")\n",
        "\n",
        "        volume_ratio = indicators.get('Volume_ratio', np.nan)\n",
        "        if not pd.isna(volume_ratio):\n",
        "             indicators_calculated += 1\n",
        "             if volume_ratio > 1.5: # Volume is 50% higher than average\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             elif volume_ratio < 0.8: # Volume is significantly lower than average\n",
        "                 base_score += indicator_point_contribution * 0.2 # Small score for low volume\n",
        "             else: # Average volume is neutral\n",
        "                 base_score += indicator_point_contribution * 0.5\n",
        "        else:\n",
        "             logger.warning(\"Volume ratio is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        achieved_score_from_indicators = base_score\n",
        "\n",
        "        if indicators_calculated > 0:\n",
        "            max_possible_contribution = num_key_indicators * indicator_point_contribution\n",
        "            achieved_percentage = achieved_score_from_indicators / max_possible_contribution if max_possible_contribution > 0 else 0\n",
        "            adjusted_base_score = achieved_percentage * possible_indicator_points\n",
        "            if indicators_calculated < num_key_indicators:\n",
        "                 logger.warning(f\"Only {indicators_calculated}/{num_key_indicators} key technical indicators calculated. Adjusting base score from {achieved_score_from_indicators:.2f} (raw) to {adjusted_base_score:.2f}.\")\n",
        "            base_score = adjusted_base_score\n",
        "        else:\n",
        "             logger.warning(\"No key technical indicators calculated. Base technical score is 0.\")\n",
        "             base_score = 0\n",
        "\n",
        "        circuit_risk_adj = circuit_risk if isinstance(circuit_risk, (int, float)) and not pd.isna(circuit_risk) else 0\n",
        "\n",
        "        final_score = base_score + circuit_risk_adj\n",
        "\n",
        "        return max(0, min(final_score, 50))\n",
        "\n",
        "\n",
        "    def fetch_news(self, symbol: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Fetches recent news headlines for the given stock symbol.\n",
        "        NOTE: This is a placeholder. In a real application, you would integrate\n",
        "        with a News API (like News API, Alpha Vantage, etc.) here.\n",
        "        \"\"\"\n",
        "        print(f\"Fetching news for {symbol} (placeholder)...\")\n",
        "        symbol_str = str(symbol) if symbol is not None else \"Unknown Stock\"\n",
        "        return [\n",
        "            f\"{symbol_str} stock price rises on positive market sentiment\",\n",
        "            f\"{symbol_str} announces strong quarterly results, beating estimates\",\n",
        "            f\"Experts bullish on {symbol_str}'s future outlook\",\n",
        "            f\"I am a non-numeric entry that might cause an error\",\n",
        "            f\"{symbol_str} faces regulatory challenges in key market\",\n",
        "            f\"Competitor's new product launch impacts {symbol_str}'s market share\",\n",
        "            f\"Global market trends positively impacting {symbol_str}\",\n",
        "            f\"{symbol_str} management provides optimistic guidance\",\n",
        "            f\"Increased foreign investment flows into {symbol_str}\",\n",
        "            f\"Regulatory approval received for {symbol_str}'s new product\",\n",
        "            f\"Production issues reported for {symbol_str}\",\n",
        "            f\"Increased competition puts pressure on {symbol_str}'s margins\",\n",
        "            f\"Analyst downgrades rating for {symbol_str}\",\n",
        "            f\"Supply chain disruptions affect {symbol_str}'s operations\",\n",
        "            f\"Geopolitical tensions create uncertainty for {symbol_str}\",\n",
        "            f\"{symbol_str} announces stock split\",\n",
        "            f\"Dividend declared by {symbol_str}\"\n",
        "        ]\n",
        "\n",
        "\n",
        "    def analyze_sentiment(self, news_headlines: List[str]) -> Dict):\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of news headlines using the Gemini API.\n",
        "        Returns a dictionary with sentiment counts (positive, neutral, negative)\n",
        "        and a sentiment score.\n",
        "        \"\"\"\n",
        "        if not self.gemini_model:\n",
        "            print(\"Gemini API not configured. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Gemini API not configured. Sentiment analysis skipped.'}\n",
        "\n",
        "        if not isinstance(news_headlines, list) or not news_headlines:\n",
        "            print(\"No news headlines to analyze. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 12.5, 'summary': 'No news headlines. Sentiment analysis skipped.'}\n",
        "\n",
        "        logger.info(\"Analyzing sentiment using Gemini API...\")\n",
        "        prompt = \"Analyze the sentiment of the following news headlines for a stock and categorize each as Positive, Neutral, or Negative. Provide a concise summary of the overall sentiment.\\n\\n\"\n",
        "        for headline in news_headlines:\n",
        "            if isinstance(headline, str):\n",
        "                 prompt += f\"- {headline}\\n\"\n",
        "            else:\n",
        "                 logger.warning(f\"Skipping non-string headline: {headline}\")\n",
        "                 continue\n",
        "\n",
        "        if len(prompt) > 30000:\n",
        "             logger.warning(\"News headlines too long for Gemini API prompt. Truncating.\")\n",
        "             prompt = prompt[:30000] + \"\\n... (headlines truncated)\"\n",
        "\n",
        "        try:\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "            sentiment_text = response.text.strip()\n",
        "            logger.info(f\"Gemini API Response: {sentiment_text[:200]}...\")\n",
        "\n",
        "            positive_count = sentiment_text.lower().count('positive')\n",
        "            neutral_count = sentiment_text.lower().count('neutral')\n",
        "            negative_count = sentiment_text.lower().count('negative')\n",
        "\n",
        "            summary_line = \"No summary extracted.\"\n",
        "            lines = sentiment_text.split('\\n')\n",
        "            for line in lines:\n",
        "                 lower_line = line.lower()\n",
        "                 if 'summary' in lower_line or 'overall sentiment' in lower_line:\n",
        "                     summary_line = line.strip()\n",
        "                     break\n",
        "            if summary_line == \"No summary extracted.\" and lines:\n",
        "                 for line in reversed(lines):\n",
        "                     if line.strip():\n",
        "                         summary_line = line.strip()\n",
        "                         break\n",
        "\n",
        "            total_headlines = len([h for h in news_headlines if isinstance(h, str)])\n",
        "            if total_headlines > 0:\n",
        "                sentiment_score = ((positive_count - negative_count) / total_headlines) * 12.5 + 12.5\n",
        "            else:\n",
        "                sentiment_score = 12.5\n",
        "\n",
        "            return {\n",
        "                'positive': positive_count,\n",
        "                'neutral': neutral_count,\n",
        "                'negative': negative_count,\n",
        "                'score': max(0, min(sentiment_score, 25)),\n",
        "                'summary': summary_line\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing sentiment with Gemini API: {e}. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis failed.'}\n",
        "\n",
        "\n",
        "    def generate_enhanced_recommendation(self, fundamental_score, technical_score,\n",
        "                                       liquidity_score, peer_performance, index_membership,\n",
        "                                       sentiment_analysis_results):\n",
        "        \"\"\"Generate comprehensive recommendation including sentiment\"\"\"\n",
        "        fund_score = fundamental_score if isinstance(fundamental_score, (int, float)) and not pd.isna(fundamental_score) else 0\n",
        "        tech_score = technical_score if isinstance(technical_score, (int, float)) and not pd.isna(technical_score) else 0\n",
        "        liq_score = liquidity_score if isinstance(liquidity_score, (int, float)) and not pd.isna(liquidity_score) else 0\n",
        "        sentiment_score = sentiment_analysis_results.get('score', 0) if isinstance(sentiment_analysis_results.get('score'), (int, float)) and not pd.isna(sentiment_analysis_results.get('score')) else 0\n",
        "\n",
        "        total_score = fund_score + tech_score + liq_score + sentiment_score\n",
        "\n",
        "        peer_analysis_available = isinstance(peer_performance, dict) and \\\n",
        "                                  not (pd.isna(peer_performance.get('stock_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('avg_peer_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('relative_performance')))\n",
        "\n",
        "        if peer_analysis_available and peer_performance.get('outperformance', False) is True:\n",
        "            total_score += 5\n",
        "            logger.info(\"Adding bonus for peer outperformance.\")\n",
        "        elif not peer_analysis_available:\n",
        "             total_score -= 5\n",
        "             logger.warning(\"Applying small penalty as peer performance data is incomplete/unavailable.\")\n",
        "\n",
        "        if isinstance(index_membership, list) and index_membership:\n",
        "            total_score += 5\n",
        "            logger.info(\"Adding bonus for index membership.\")\n",
        "\n",
        "        recommendation = \"NEUTRAL\"\n",
        "        confidence = \"Low\"\n",
        "\n",
        "        if total_score >= 170:\n",
        "            recommendation = \"STRONG BUY\"\n",
        "            confidence = \"High\"\n",
        "        elif total_score >= 140:\n",
        "            recommendation = \"BUY\"\n",
        "            confidence = \"Moderate to High\"\n",
        "        elif total_score >= 100:\n",
        "            recommendation = \"HOLD\"\n",
        "            confidence = \"Moderate\"\n",
        "        elif total_score >= 70:\n",
        "            recommendation = \"SELL\"\n",
        "            confidence = \"Moderate\"\n",
        "        else:\n",
        "            recommendation = \"STRONG SELL\"\n",
        "            confidence = \"High\"\n",
        "\n",
        "        logger.info(f\"Generated enhanced recommendation: {recommendation} (Total Score: {total_score:.2f})\")\n",
        "\n",
        "        return {\n",
        "            'recommendation': recommendation,\n",
        "            'confidence': confidence,\n",
        "            'total_score': total_score,\n",
        "            'breakdown': {\n",
        "                'fundamental': fund_score,\n",
        "                'technical': tech_score,\n",
        "                'liquidity': liq_score,\n",
        "                'sentiment': sentiment_score,\n",
        "                'peer_adjustment': 5 if peer_analysis_available and peer_performance.get('outperformance', False) is True else (-5 if not peer_analysis_available else 0),\n",
        "                'index_adjustment': 5 if isinstance(index_membership, list) and index_membership else 0\n",
        "            }\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 732)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m732\u001b[0m\n\u001b[0;31m    }\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "f5431860"
      },
      "source": [
        "#@title Part 3: Example Usage and Report Display\n",
        "\n",
        "# Assuming IndianStockAnalyzer and EnhancedStockAnalyzer classes are defined in previous cells\n",
        "\n",
        "try:\n",
        "    # Check if classes are defined (from previous cells)\n",
        "    IndianStockAnalyzer\n",
        "    EnhancedStockAnalyzer\n",
        "except NameError:\n",
        "    print(\"Make sure to run the previous cells defining IndianStockAnalyzer and EnhancedStockAnalyzer classes.\")\n",
        "    # You might want to exit or handle this case differently in a full script\n",
        "    exit() # Exit if classes are not defined\n",
        "\n",
        "\n",
        "stock_analyzer = IndianStockAnalyzer()\n",
        "enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "\n",
        "# Analyze a stock\n",
        "symbol = \"RELIANCE.NS\" # Example symbol\n",
        "result = analyze_stock_enhanced(symbol, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "if result:\n",
        "    # Display the enhanced report\n",
        "    enhanced = result['enhanced_features']\n",
        "    final = result['final_recommendation']\n",
        "    basic = result['basic_analysis'] # Get basic data for display\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Enhanced Analysis Report: {basic.company_name} ({basic.symbol})\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    print(f\"\\n📊 Current Market Data:\")\n",
        "    print(f\"Current Price: ₹{basic.current_price:,.2f}\" if not pd.isna(basic.current_price) else \"Current Price: N/A\")\n",
        "    market_cap_cr = basic.market_cap / 10000000 if not pd.isna(basic.market_cap) else np.nan\n",
        "    print(f\"Market Cap: ₹{market_cap_cr:,.2f} Cr\" if not pd.isna(market_cap_cr) else \"Market Cap: N/A\")\n",
        "    print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "\n",
        "    print(f\"\\n⚙️ Enhanced Technical Analysis & Risk:\")\n",
        "    # Display enhanced technical indicators and risk\n",
        "    # Assuming you want to display relevant indicators from basic.indicators and the circuit risk score\n",
        "    circuit_limits_display = enhanced.get('circuit_limits')\n",
        "    if circuit_limits_display and not pd.isna(circuit_limits_display.get('lower_circuit')) and not pd.isna(circuit_limits_display.get('upper_circuit')):\n",
        "             print(f\"Circuit Limits: {circuit_limits_display.get('lower_circuit', 'N/A'):.2f} - {circuit_limits_display.get('upper_circuit', 'N/A'):.2f}\")\n",
        "    else:\n",
        "             print(\"Circuit Limits: N/A\")\n",
        "\n",
        "    print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "    # Check if liquidity score is available before formatting\n",
        "    liquidity_score_display = f\"{enhanced.get('liquidity_score', 'N/A')}/70\" if isinstance(enhanced.get('liquidity_score'), (int, float)) and not pd.isna(enhanced.get('liquidity_score')) else \"Liquidity Score: N/A/70\"\n",
        "    print(liquidity_score_display)\n",
        "\n",
        "\n",
        "    # Display some key technical indicators from basic analysis\n",
        "    print(\"\\nKey Technical Indicators (from Basic Analysis):\")\n",
        "    key_tech_indicators = ['RSI', 'MACD', 'MACD_signal', 'SMA_20', 'SMA_50', 'BB_middle', 'Volume_ratio']\n",
        "    for indicator_name in key_tech_indicators:\n",
        "        value = basic.indicators.get(indicator_name, np.nan)\n",
        "        if not pd.isna(value):\n",
        "            if isinstance(value, float):\n",
        "                 print(f\"  - {indicator_name}: {value:,.2f}\")\n",
        "            else:\n",
        "                 print(f\"  - {indicator_name}: {value}\")\n",
        "            # Add logging for these key technical indicators if they are calculated\n",
        "            logger.info(f\"Indicator {indicator_name}: {value}\")\n",
        "        else:\n",
        "            print(f\"  - {indicator_name}: N/A\")\n",
        "            logger.info(f\"Indicator {indicator_name}: N/A\")\n",
        "\n",
        "\n",
        "    print(f\"\\n🤝 Peer Analysis:\")\n",
        "    # Check if peer analysis was skipped or failed by examining the presence of meaningful data\n",
        "    peer_perf = enhanced.get('peer_performance')\n",
        "    # Updated check to see if peer_perf is a dictionary and has the expected keys with non-NaN values\n",
        "    if isinstance(peer_perf, dict) and \\\n",
        "       not pd.isna(peer_perf.get('stock_return')) and \\\n",
        "       not pd.isna(peer_perf.get('avg_peer_return')) and \\\n",
        "       not pd.isna(peer_perf.get('relative_performance')):\n",
        "\n",
        "         print(f\"Peer Companies: {', '.join(enhanced['peers'])}\")\n",
        "         # Add checks for NaN before formatting float\n",
        "         stock_return_display = f\"{peer_perf.get('stock_return', 'N/A'):.2f}%\" if isinstance(peer_perf.get('stock_return'), (int, float)) and not pd.isna(peer_perf.get('stock_return')) else 'N/A'\n",
        "         avg_peer_return_display = f\"{peer_perf.get('avg_peer_return', 'N/A'):.2f}%\" if isinstance(peer_perf.get('avg_peer_return'), (int, float)) and not pd.isna(peer_perf.get('avg_peer_return')) else 'N/A'\n",
        "         relative_performance_display = f\"{peer_perf.get('relative_performance', 'N/A'):.2f}%\" if isinstance(peer_perf.get('relative_performance'), (int, float)) and not pd.isna(peer_perf.get('relative_performance')) else 'N/A'\n",
        "\n",
        "         print(f\"  - {peer_perf.get('days', 'N/A')}-day Stock Return: {stock_return_display}\")\n",
        "         print(f\"  - Avg Peer Return: {avg_peer_return_display}\")\n",
        "         print(f\"  - Relative Performance: {relative_performance_display}\")\n",
        "    else:\n",
        "         # Display a message indicating peer analysis was skipped/failed or data is incomplete\n",
        "         print(\"Peer analysis skipped or failed or data unavailable.\")\n",
        "\n",
        "\n",
        "    if enhanced.get('index_membership'):\n",
        "        print(f\"\\n🏛️ Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "    # Sentiment Analysis Results\n",
        "    sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "    print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "    if enhanced.get('news_headlines'):\n",
        "         # Only print a few headlines to keep the report concise\n",
        "         print(\"Sample News Headlines:\")\n",
        "         # Ensure headlines are valid strings before printing\n",
        "         valid_headlines = [h for h in enhanced['news_headlines'] if isinstance(h, str)]\n",
        "         for headline in valid_headlines[:5]: # Print up to 5 headlines\n",
        "             print(f\"- {headline}\")\n",
        "         if len(valid_headlines) > 5:\n",
        "              print(\"  ...\")\n",
        "\n",
        "         print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "         sentiment_score_display = f\"{sentiment_results.get('score', 0):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\"\n",
        "         print(f\"Sentiment Score: {sentiment_score_display}/25\")\n",
        "         print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "    else:\n",
        "         print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "    print(f\"\\n--- Comprehensive Scores and Recommendation ---\")\n",
        "    print(f\"Fundamental Score (from Part 1): {basic.fundamental_score:.2f}/50\" if not pd.isna(basic.fundamental_score) else \"Fundamental Score: N/A\")\n",
        "    # Add checks for NaN before formatting float for breakdown scores\n",
        "    enhanced_tech_score_display = f\"{final.get('breakdown', {}).get('technical', 'N/A'):.2f}\" if isinstance(final.get('breakdown', {}).get('technical'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('technical')) else \"N/A\"\n",
        "    liquidity_score_display_breakdown = f\"{final.get('breakdown', {}).get('liquidity', 'N/A'):.2f}\" if isinstance(final.get('breakdown', {}).get('liquidity'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('liquidity')) else \"N/A\"\n",
        "    sentiment_score_display_breakdown = f\"{final.get('breakdown', {}).get('sentiment', 'N/A'):.2f}\" if isinstance(final.get('breakdown', {}).get('sentiment'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\" # Corrected sentiment score breakdown check\n",
        "\n",
        "    print(f\"Technical Score (Enhanced): {enhanced_tech_score_display}/50\")\n",
        "    print(f\"Liquidity Score: {liquidity_score_display_breakdown}/70\")\n",
        "    print(f\"Sentiment Score: {sentiment_score_display_breakdown}/25\")\n",
        "\n",
        "    # Display adjustment scores\n",
        "    peer_adj_display = f\"{final.get('breakdown', {}).get('peer_adjustment', 'N/A'):+.2f}\" if isinstance(final.get('breakdown', {}).get('peer_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('peer_adjustment')) else \"N/A\"\n",
        "    index_adj_display = f\"{final.get('breakdown', {}).get('index_adjustment', 'N/A'):+.2f}\" if isinstance(final.get('breakdown', {}).get('index_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('index_adjustment')) else \"N/A\"\n",
        "\n",
        "    print(f\"Peer Adjustment: {peer_adj_display}\")\n",
        "    print(f\"Index Membership Adjustment: {index_adj_display}\")\n",
        "\n",
        "\n",
        "    print(f\"\\nTotal Enhanced Score: {final.get('total_score', 0):.2f}/205\" if isinstance(final.get('total_score'), (int, float)) and not pd.isna(final.get('total_score')) else \"Total Enhanced Score: N/A\")\n",
        "    print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} (Confidence: {final.get('confidence', 'N/A')})\")\n",
        "\n",
        "\n",
        "    print(f\"\\n{'='*60}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43425719"
      },
      "source": [
        "# Task\n",
        "Enhance the stock analysis script by adding valuation analysis (P/E, P/B, EV/EBITDA vs. sector), downside risk assessment (stress testing/VaR), enhanced dividend yield calculation, and consideration of global macro impacts. Integrate these new analyses into the enhanced analysis report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "688e2fef"
      },
      "source": [
        "## Plan for valuation analysis\n",
        "\n",
        "### Subtask:\n",
        "Outline steps to calculate and compare P/E, P/B, and EV/EBITDA ratios against sector averages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5789b182"
      },
      "source": [
        "# Task\n",
        "Implement valuation analysis for the stock analyzer script, including fetching P/E, P/B, and EV/EBITDA ratios, comparing them to sector peer averages, and integrating the assessment into the final report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dd80b8a"
      },
      "source": [
        "## Fetch valuation data\n",
        "\n",
        "### Subtask:\n",
        "Modify the data fetching process to ensure P/E, P/B, and EV/EBITDA ratios are reliably retrieved using yfinance or other potential sources if needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b646a176"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the `IndianStockAnalyzer` class to reliably fetch P/E, P/B, and EV/EBITDA ratios from the fetched stock information and store them in the `metrics` dictionary, handling missing data and adding logging. This involves updating the `analyze_stock` method and the `AnalysisResult` dataclass definition within the `IndianStockAnalyzer` class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df500a82",
        "cellView": "form"
      },
      "source": [
        "#@title Part 1: IndianStockAnalyzer class definition (Enhanced Valuation Metrics)\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import typing for type hints\n",
        "from typing import List, Dict, Optional\n",
        "from dataclasses import dataclass # Import dataclass\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- IndianStockAnalyzer class definition ---\n",
        "@dataclass\n",
        "class AnalysisResult: # Define AnalysisResult dataclass here\n",
        "    \"\"\"Data class to store comprehensive stock information\"\"\"\n",
        "    symbol: str\n",
        "    company_name: str\n",
        "    current_price: float\n",
        "    market_cap: float\n",
        "    info: Dict\n",
        "    price_data: pd.DataFrame\n",
        "    indicators: Dict\n",
        "    fundamental_score: float\n",
        "    technical_score: float\n",
        "    recommendation: str # Added recommendation field\n",
        "    metrics: Dict # Ensure metrics dictionary is included\n",
        "\n",
        "class IndianStockAnalyzer:\n",
        "    \"\"\"Basic analyzer for Indian stocks\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the basic analyzer.\"\"\"\n",
        "        # Basic setup if needed for Part 1 (e.g., API keys, configurations)\n",
        "        pass\n",
        "\n",
        "    def analyze_stock(self, symbol: str) -> Optional[AnalysisResult]: # Added type hint for return\n",
        "        \"\"\"\n",
        "        Performs basic fundamental and technical analysis for a given stock.\n",
        "        Returns an AnalysisResult object containing the analysis results.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Starting basic analysis for {symbol}\")\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            if not info:\n",
        "                 logger.warning(f\"Could not fetch info for {symbol}. Analysis aborted.\")\n",
        "                 # Return a minimal AnalysisResult with N/A values\n",
        "                 return AnalysisResult(\n",
        "                     symbol=symbol,\n",
        "                     company_name=symbol,\n",
        "                     current_price=np.nan,\n",
        "                     market_cap=np.nan,\n",
        "                     info={},\n",
        "                     price_data=pd.DataFrame(),\n",
        "                     indicators={},\n",
        "                     fundamental_score=np.nan,\n",
        "                     technical_score=np.nan,\n",
        "                     recommendation=\"N/A\", # Added N/A recommendation\n",
        "                     metrics={}\n",
        "                 )\n",
        "\n",
        "\n",
        "            # Get price data for technical analysis\n",
        "            price_data = ticker.history(period=\"1y\") # Get 1 year of historical data\n",
        "\n",
        "            if price_data.empty:\n",
        "                logger.warning(f\"Could not fetch price data for {symbol}.\")\n",
        "                # Return info even if price data is missing, as fundamental data might still be available\n",
        "                # We will handle missing price data in enhanced calculations\n",
        "                # Ensure all fields are populated with N/A or empty structures\n",
        "                return AnalysisResult(\n",
        "                    symbol=symbol,\n",
        "                    company_name=info.get('longName', symbol),\n",
        "                    current_price=info.get('currentPrice', np.nan),\n",
        "                    market_cap=info.get('marketCap', np.nan),\n",
        "                    info=info,\n",
        "                    price_data=pd.DataFrame(), # Empty DataFrame\n",
        "                    indicators={},\n",
        "                    fundamental_score=np.nan,\n",
        "                    technical_score=np.nan,\n",
        "                    recommendation=\"N/A\", # Added N/A recommendation\n",
        "                    metrics={}\n",
        "                )\n",
        "\n",
        "\n",
        "            # 1. Fundamental Analysis (Simplified)\n",
        "            # Extract key fundamental data points\n",
        "            metrics = {} # Initialize metrics dictionary\n",
        "\n",
        "            try:\n",
        "                metrics['marketCap'] = info.get('marketCap', np.nan)\n",
        "                metrics['currentPrice'] = info.get('currentPrice', np.nan)\n",
        "                metrics['sector'] = info.get('sector', 'N/A')\n",
        "                metrics['industry'] = info.get('industry', 'N/A')\n",
        "                company_name = info.get('longName', symbol)\n",
        "\n",
        "                # Extract and store Valuation Ratios\n",
        "                metrics['trailingPE'] = info.get('trailingPE', np.nan)\n",
        "                logger.info(f\"Fetched trailingPE for {symbol}: {metrics['trailingPE']}\")\n",
        "\n",
        "                metrics['priceToBook'] = info.get('priceToBook', np.nan)\n",
        "                logger.info(f\"Fetched priceToBook for {symbol}: {metrics['priceToBook']}\")\n",
        "\n",
        "                enterprise_value = info.get('enterpriseValue', np.nan)\n",
        "                ebitda = info.get('ebitda', np.nan)\n",
        "                metrics['enterpriseValue'] = enterprise_value # Store raw value for reference\n",
        "                metrics['ebitda'] = ebitda # Store raw value for reference\n",
        "\n",
        "                # Calculate EV/EBITDA, handling potential division by zero or missing data\n",
        "                metrics['evToEbitda'] = np.nan # Default to NaN\n",
        "                if isinstance(enterprise_value, (int, float)) and not np.isnan(enterprise_value) and \\\n",
        "                   isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda != 0:\n",
        "                    metrics['evToEbitda'] = enterprise_value / ebitda\n",
        "                    logger.info(f\"Calculated evToEbitda for {symbol}: {metrics['evToEbitda']:.2f}\")\n",
        "                elif (isinstance(enterprise_value, (int, float)) and not np.isnan(enterprise_value)) and \\\n",
        "                     (isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda == 0):\n",
        "                     logger.warning(f\"EBITDA is zero for {symbol}. Cannot calculate EV/EBITDA.\")\n",
        "                else:\n",
        "                    logger.warning(f\"Missing Enterprise Value ({enterprise_value}) or EBITDA ({ebitda}) for {symbol}. Cannot calculate EV/EBITDA.\")\n",
        "\n",
        "\n",
        "                # Dividend Yield\n",
        "                dividend_yield = info.get('dividendYield', np.nan) # This is often already a percentage as a float\n",
        "                # Ensure dividend_yield is not None before checking if it's NaN\n",
        "                if dividend_yield is not None and isinstance(dividend_yield, (int, float)) and not pd.isna(dividend_yield) and dividend_yield >= 0:\n",
        "                     # If dividend_yield is a float between 0 and 1, assume it's a ratio and convert to percentage\n",
        "                     if 0 < dividend_yield <= 1:\n",
        "                         metrics['dividendYield'] = dividend_yield * 100\n",
        "                         logger.info(f\"Converted dividend yield for {symbol} from ratio to percentage: {metrics['dividendYield']:.2f}%\")\n",
        "                     else:\n",
        "                         metrics['dividendYield'] = dividend_yield # Assume it's already a percentage or other form\n",
        "                         logger.info(f\"Dividend yield for {symbol} is {metrics['dividendYield']:.2f}%. Assuming it's already in percentage or other form.\")\n",
        "                else:\n",
        "                     metrics['dividendYield'] = np.nan # Ensure it's NaN if None or invalid\n",
        "                     logger.warning(f\"Dividend yield for {symbol} is unavailable or zero ({dividend_yield}). Setting to NaN.\")\n",
        "\n",
        "\n",
        "                # Other fundamental metrics that might be useful later (Optional for this subtask but good practice)\n",
        "                metrics['returnOnEquity'] = info.get('returnOnEquity', np.nan)\n",
        "                metrics['revenueGrowth'] = info.get('revenueGrowth', np.nan)\n",
        "                metrics['profitMargins'] = info.get('profitMargins', np.nan)\n",
        "\n",
        "\n",
        "            except Exception as fund_e:\n",
        "                 logger.error(f\"Error extracting fundamental data for {symbol}: {fund_e}. Setting fundamental metrics to NaN.\")\n",
        "                 # Ensure metrics are still initialized to handle the rest of the process\n",
        "                 metrics.setdefault('marketCap', np.nan)\n",
        "                 metrics.setdefault('currentPrice', np.nan)\n",
        "                 metrics.setdefault('sector', 'N/A')\n",
        "                 metrics.setdefault('industry', 'N/A')\n",
        "                 metrics.setdefault('trailingPE', np.nan)\n",
        "                 metrics.setdefault('priceToBook', np.nan)\n",
        "                 metrics.setdefault('evToEbitda', np.nan) # Ensure this is set even on error\n",
        "                 metrics.setdefault('dividendYield', np.nan)\n",
        "                 metrics.setdefault('returnOnEquity', np.nan)\n",
        "                 metrics.setdefault('revenueGrowth', np.nan)\n",
        "                 metrics.setdefault('profitMargins', np.nan)\n",
        "                 company_name = info.get('longName', symbol) # Still try to get company name\n",
        "\n",
        "\n",
        "            # Calculate a simple fundamental score (out of 50) - This scoring logic remains the same\n",
        "            fundamental_score = self.calculate_fundamental_score(\n",
        "                 metrics.get('marketCap', np.nan),\n",
        "                 metrics.get('trailingPE', np.nan),\n",
        "                 metrics.get('priceToBook', np.nan),\n",
        "                 metrics.get('dividendYield', np.nan)\n",
        "            )\n",
        "\n",
        "\n",
        "            # 2. Technical Analysis (Simplified)\n",
        "            # Pass price_data and the fetched current_price to technical indicator calculation\n",
        "            indicators = self.calculate_technical_indicators(price_data, metrics.get('currentPrice', np.nan))\n",
        "            technical_score = self.calculate_technical_score(indicators) # Basic technical score (out of 50)\n",
        "\n",
        "            # Generate a basic recommendation (will be replaced by enhanced one later)\n",
        "            basic_recommendation = self.generate_recommendation(fundamental_score, technical_score)\n",
        "\n",
        "\n",
        "            # Bundle results\n",
        "            # Create an AnalysisResult object to hold all analysis results\n",
        "            analysis_results = AnalysisResult(\n",
        "                symbol=symbol,\n",
        "                company_name=company_name, # Use the fetched company name\n",
        "                current_price=metrics.get('currentPrice', np.nan), # Use the fetched current price\n",
        "                market_cap=metrics.get('marketCap', np.nan), # Use the fetched market cap\n",
        "                info=info, # Include the full info dictionary\n",
        "                price_data=price_data,\n",
        "                indicators=indicators,\n",
        "                fundamental_score=fundamental_score,\n",
        "                technical_score=technical_score,\n",
        "                recommendation=basic_recommendation, # Store the basic recommendation\n",
        "                metrics=metrics # Store the populated metrics dictionary\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Basic analysis completed for {symbol}\")\n",
        "            return analysis_results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"An unexpected error occurred during basic analysis for {symbol}: {str(e)}. Returning None.\")\n",
        "            return None # Return None if basic analysis fails due to unexpected error\n",
        "\n",
        "    def calculate_fundamental_score(self, market_cap: float, pe_ratio: float, pb_ratio: float, dividend_yield: float) -> float:\n",
        "        \"\"\"Calculate a simple fundamental score based on key metrics (out of 50)\"\"\"\n",
        "        score = 0\n",
        "        logger.info(\"Calculating basic fundamental score.\")\n",
        "        # Ensure metrics are valid numbers before scoring\n",
        "        market_cap_valid = isinstance(market_cap, (int, float)) and not pd.isna(market_cap) and market_cap > 0\n",
        "        pe_ratio_valid = isinstance(pe_ratio, (int, float)) and not pd.isna(pe_ratio) and pe_ratio > 0\n",
        "        pb_ratio_valid = isinstance(pb_ratio, (int, float)) and not pd.isna(pb_ratio) and pb_ratio > 0\n",
        "        dividend_yield_valid = isinstance(dividend_yield, (int, float)) and not pd.isna(dividend_yield) and dividend_yield >= 0\n",
        "\n",
        "        logger.debug(f\"Fundamental metrics validity: Market Cap={market_cap_valid}, PE={pe_ratio_valid}, PB={pb_ratio_valid}, Dividend Yield={dividend_yield_valid}\")\n",
        "\n",
        "        # Market Cap (Scale based on size, larger usually means more stable)\n",
        "        if market_cap_valid:\n",
        "            if market_cap > 10_00_000_00_00_000:  # > 10 Lakh Cr (Large Cap)\n",
        "                score += 15\n",
        "                logger.debug(f\"Market Cap ({market_cap:.2f}) is Large Cap. +15 pts.\")\n",
        "            elif market_cap > 50_000_00_00_000:   # > 50K Cr (Mid Cap)\n",
        "                score += 10\n",
        "                logger.debug(f\"Market Cap ({market_cap:.2f}) is Mid Cap. +10 pts.\")\n",
        "            else: # Small Cap and below\n",
        "                score += 5\n",
        "                logger.debug(f\"Market Cap ({market_cap:.2f}) is Small Cap or below. +5 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"Market cap is invalid for fundamental scoring.\")\n",
        "\n",
        "\n",
        "        # PE Ratio (Lower is generally better, but depends on industry growth)\n",
        "        if pe_ratio_valid:\n",
        "            if pe_ratio < 20:\n",
        "                score += 15\n",
        "                logger.debug(f\"PE Ratio ({pe_ratio:.2f}) < 20. +15 pts.\")\n",
        "            elif pe_ratio < 30:\n",
        "                score += 10\n",
        "                logger.debug(f\"PE Ratio ({pe_ratio:.2f}) < 30. +10 pts.\")\n",
        "            elif pe_ratio < 40:\n",
        "                score += 5\n",
        "                logger.debug(f\"PE Ratio ({pe_ratio:.2f}) < 40. +5 pts.\")\n",
        "            else: # High PE\n",
        "                score += 2\n",
        "                logger.debug(f\"PE Ratio ({pe_ratio:.2f}) >= 40. +2 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"PE ratio is invalid for fundamental scoring.\")\n",
        "\n",
        "\n",
        "        # PB Ratio (Lower is generally better, indicates undervaluation)\n",
        "        if pb_ratio_valid:\n",
        "            if pb_ratio < 3:\n",
        "                score += 10\n",
        "                logger.debug(f\"PB Ratio ({pb_ratio:.2f}) < 3. +10 pts.\")\n",
        "            elif pb_ratio < 5:\n",
        "                score += 7\n",
        "                logger.debug(f\"PB Ratio ({pb_ratio:.2f}) < 5. +7 pts.\")\n",
        "            else:\n",
        "                score += 3\n",
        "                logger.debug(f\"PB Ratio ({pb_ratio:.2f}) >= 5. +3 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"PB ratio is invalid for fundamental scoring.\")\n",
        "\n",
        "\n",
        "        # Dividend Yield (Higher is better for income-seeking investors, indicates profitability)\n",
        "        if dividend_yield_valid:\n",
        "            if dividend_yield > 3: # > 3%\n",
        "                score += 10\n",
        "                logger.debug(f\"Dividend Yield ({dividend_yield:.2f}%) > 3%. +10 pts.\")\n",
        "            elif dividend_yield > 1: # > 1%\n",
        "                score += 7\n",
        "                logger.debug(f\"Dividend Yield ({dividend_yield:.2f}%) > 1%. +7 pts.\")\n",
        "            else:\n",
        "                score += 3\n",
        "                logger.debug(f\"Dividend Yield ({dividend_yield:.2f}%) <= 1%. +3 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"Dividend yield is invalid for fundamental scoring.\")\n",
        "\n",
        "        logger.info(f\"Basic fundamental score calculated: {score}\")\n",
        "        return min(score, 50) # Cap score at 50\n",
        "\n",
        "    def calculate_technical_indicators(self, price_data: pd.DataFrame, current_price: float) -> Dict: # Added type hints\n",
        "        \"\"\"Calculate key technical indicators\"\"\"\n",
        "        logger.info(\"Calculating technical indicators.\")\n",
        "        # Ensure price_data is valid before calculating indicators\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty:\n",
        "            logger.warning(\"Insufficient price data for technical indicator calculation.\")\n",
        "            return {'RSI': np.nan, 'MACD': np.nan, 'MACD_signal': np.nan, 'SMA_20': np.nan, 'SMA_50': np.nan,\n",
        "                    'BB_upper': np.nan, 'BB_lower': np.nan, 'BB_middle': np.nan, 'Volume_ratio': np.nan,\n",
        "                    'current_price': current_price} # Return NaNs if data is missing\n",
        "\n",
        "\n",
        "        indicators = {}\n",
        "        data_len = len(price_data)\n",
        "\n",
        "        try:\n",
        "            # RSI (Relative Strength Index)\n",
        "            if data_len >= 14:\n",
        "                delta = price_data['Close'].diff()\n",
        "                gain = delta.where(delta > 0, 0)\n",
        "                loss = -delta.where(delta < 0, 0)\n",
        "                avg_gain = gain.ewm(com=14-1, adjust=False).mean()\n",
        "                avg_loss = loss.ewm(com=14-1, adjust=False).mean()\n",
        "                # Handle division by zero explicitly\n",
        "                if avg_loss.iloc[-1] is not None and not np.isnan(avg_loss.iloc[-1]) and avg_loss.iloc[-1] != 0:\n",
        "                    rs = avg_gain / avg_loss\n",
        "                    indicators['RSI'] = 100 - (100 / (1 + rs)).iloc[-1]\n",
        "                elif avg_gain.iloc[-1] is not None and not np.isnan(avg_gain.iloc[-1]) and avg_gain.iloc[-1] > 0:\n",
        "                     indicators['RSI'] = 100.0 # If no loss but gain, RSI is 100\n",
        "                else:\n",
        "                     indicators['RSI'] = 50.0 # If no gain and no loss, RSI is 50\n",
        "                logger.debug(f\"Calculated RSI: {indicators['RSI']:.2f}\")\n",
        "            else:\n",
        "                indicators['RSI'] = np.nan\n",
        "                logger.warning(\"Insufficient data for RSI.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate RSI: {e}. Setting to NaN.\")\n",
        "            indicators['RSI'] = np.nan\n",
        "\n",
        "        try:\n",
        "            # MACD (Moving Average Convergence Divergence)\n",
        "            if data_len >= 26: # Need at least 26 data points for 26-day EMA\n",
        "                ema_12 = price_data['Close'].ewm(span=12, adjust=False).mean()\n",
        "                ema_26 = price_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "                # Corrected MACD signal calculation to use the MACD Series\n",
        "                macd_series = ema_12 - ema_26\n",
        "                if data_len >= 26 + 9 - 1: # Need enough data points for 9-day EMA of MACD\n",
        "                     indicators['MACD'] = macd_series.iloc[-1]\n",
        "                     indicators['MACD_signal'] = macd_series.ewm(span=9, adjust=False).mean().iloc[-1]\n",
        "                     logger.debug(f\"Calculated MACD: {indicators['MACD']:.2f}, MACD Signal: {indicators['MACD_signal']:.2f}\")\n",
        "                else:\n",
        "                     indicators['MACD'] = np.nan\n",
        "                     indicators['MACD_signal'] = np.nan\n",
        "                     logger.warning(\"Insufficient data for MACD signal calculation.\")\n",
        "            else:\n",
        "                 indicators['MACD'] = np.nan\n",
        "                 indicators['MACD_signal'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for MACD calculation.\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate MACD: {e}. Setting to NaN.\")\n",
        "            indicators['MACD'] = np.nan\n",
        "            indicators['MACD_signal'] = np.nan\n",
        "\n",
        "        try:\n",
        "            # Moving Averages\n",
        "            if data_len >= 20:\n",
        "                 indicators['SMA_20'] = price_data['Close'].rolling(window=20).mean().iloc[-1]\n",
        "                 logger.debug(f\"Calculated SMA_20: {indicators['SMA_20']:.2f}\")\n",
        "            else:\n",
        "                 indicators['SMA_20'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_20.\")\n",
        "\n",
        "            if data_len >= 50:\n",
        "                 indicators['SMA_50'] = price_data['Close'].rolling(window=50).mean().iloc[-1]\n",
        "                 logger.debug(f\"Calculated SMA_50: {indicators['SMA_50']:.2f}\")\n",
        "            else:\n",
        "                 indicators['SMA_50'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_50.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate Moving Averages: {e}. Setting relevant MAs to NaN.\")\n",
        "            if 'SMA_20' not in indicators: indicators['SMA_20'] = np.nan\n",
        "            if 'SMA_50' not in indicators: indicators['SMA_50'] = np.nan\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Bollinger Bands\n",
        "            bb_period = 20\n",
        "            bb_std = 2\n",
        "            if data_len >= bb_period:\n",
        "                rolling_mean = price_data['Close'].rolling(window=bb_period).mean()\n",
        "                rolling_std = price_data['Close'].rolling(window=bb_period).std()\n",
        "                if not pd.isna(rolling_mean.iloc[-1]) and not pd.isna(rolling_std.iloc[-1]):\n",
        "                    indicators['BB_middle'] = rolling_mean.iloc[-1]\n",
        "                    indicators['BB_upper'] = (rolling_mean + (rolling_std * bb_std)).iloc[-1]\n",
        "                    indicators['BB_lower'] = (rolling_mean - (rolling_std * bb_std)).iloc[-1]\n",
        "                    logger.debug(f\"Calculated BB: Middle={indicators['BB_middle']:.2f}, Upper={indicators['BB_upper']:.2f}, Lower={indicators['BB_lower']:.2f}\")\n",
        "                else:\n",
        "                    indicators['BB_middle'] = np.nan\n",
        "                    indicators['BB_upper'] = np.nan\n",
        "                    indicators['BB_lower'] = np.nan\n",
        "                    logger.warning(\"Bollinger Bands calculation resulted in NaN.\")\n",
        "            else:\n",
        "                indicators['BB_middle'] = np.nan\n",
        "                indicators['BB_upper'] = np.nan\n",
        "                indicators['BB_lower'] = np.nan\n",
        "                logger.warning(\"Insufficient data for Bollinger Bands.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate Bollinger Bands: {e}. Setting to NaN.\")\n",
        "            indicators['BB_middle'] = np.nan\n",
        "            indicators['BB_upper'] = np.nan\n",
        "            indicators['BB_lower'] = np.nan\n",
        "\n",
        "        try:\n",
        "            # Volume Analysis (e.g., current volume vs average volume)\n",
        "            volume_period = 30\n",
        "            if data_len >= volume_period:\n",
        "                 avg_volume_30d = price_data['Volume'].rolling(window=volume_period).mean().iloc[-1]\n",
        "                 current_volume = price_data['Volume'].iloc[-1]\n",
        "                 # Check for zero division and NaN before calculating ratio\n",
        "                 if not pd.isna(avg_volume_30d) and avg_volume_30d > 0 and not pd.isna(current_volume):\n",
        "                      indicators['Volume_ratio'] = current_volume / avg_volume_30d\n",
        "                      logger.debug(f\"Calculated Volume Ratio: {indicators['Volume_ratio']:.2f}\")\n",
        "                 elif not pd.isna(current_volume) and current_volume > 0:\n",
        "                      # If 30d avg is zero or NaN but current volume is positive, assume high relative volume\n",
        "                      indicators['Volume_ratio'] = 2.0 # Arbitrary high ratio to indicate spike\n",
        "                      logger.warning(\"30-day average volume is invalid for volume ratio, assuming spike due to positive current volume.\")\n",
        "                 else:\n",
        "                      indicators['Volume_ratio'] = np.nan\n",
        "                      logger.warning(\"Insufficient or invalid volume data for volume ratio calculation.\")\n",
        "            else:\n",
        "                indicators['Volume_ratio'] = np.nan\n",
        "                logger.warning(\"Insufficient data for Volume Ratio.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate Volume Ratio: {e}. Setting to NaN.\")\n",
        "            indicators['Volume_ratio'] = np.nan\n",
        "\n",
        "        # Include current price in indicators for technical score calculation\n",
        "        indicators['current_price'] = current_price if not pd.isna(current_price) else np.nan\n",
        "\n",
        "        logger.info(f\"Technical indicators calculated: {indicators}\")\n",
        "        return indicators\n",
        "\n",
        "\n",
        "    def calculate_technical_score(self, indicators: Dict) -> float: # Added type hint\n",
        "        \"\"\"Calculate a simple technical score based on indicators (out of 50)\"\"\"\n",
        "        score = 0\n",
        "        logger.info(\"Calculating basic technical score.\")\n",
        "        # Ensure indicators dictionary is valid\n",
        "        if not isinstance(indicators, dict):\n",
        "             logger.warning(\"Invalid indicators dictionary for technical scoring.\")\n",
        "             return 0\n",
        "\n",
        "        # Scoring based on common indicator signals\n",
        "        # Ensure indicator values are valid numbers before scoring\n",
        "        rsi = indicators.get('RSI', np.nan)\n",
        "        macd = indicators.get('MACD', np.nan)\n",
        "        macd_signal = indicators.get('MACD_signal', np.nan)\n",
        "        sma_20 = indicators.get('SMA_20', np.nan)\n",
        "        sma_50 = indicators.get('SMA_50', np.nan)\n",
        "        current_price = indicators.get('current_price', np.nan)\n",
        "        bb_upper = indicators.get('BB_upper', np.nan)\n",
        "        bb_lower = indicators.get('BB_lower', np.nan)\n",
        "        volume_ratio = indicators.get('Volume_ratio', np.nan)\n",
        "\n",
        "        logger.debug(f\"Indicators for basic technical scoring: RSI={rsi}, MACD={macd}, Signal={macd_signal}, SMA20={sma_20}, SMA50={sma_50}, Price={current_price}, BB_Upper={bb_upper}, BB_Lower={bb_lower}, VolumeRatio={volume_ratio}\")\n",
        "\n",
        "\n",
        "        # RSI Score\n",
        "        if not pd.isna(rsi):\n",
        "            if rsi < 30: # Oversold\n",
        "                score += 10\n",
        "                logger.debug(\"RSI < 30. +10 pts.\")\n",
        "            elif rsi > 70: # Overbought\n",
        "                score -= 10\n",
        "                logger.debug(\"RSI > 70. -10 pts.\")\n",
        "            elif 40 <= rsi <= 60: # Neutral\n",
        "                 score += 5\n",
        "                 logger.debug(\"RSI 40-60. +5 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"RSI is NaN for technical scoring.\")\n",
        "\n",
        "        # MACD Score (Bullish crossover)\n",
        "        if not pd.isna(macd) and not pd.isna(macd_signal):\n",
        "            if macd > macd_signal:\n",
        "                score += 10\n",
        "                logger.debug(\"MACD > Signal. +10 pts.\")\n",
        "            else:\n",
        "                 score += 2 # Small score if bearish or neutral\n",
        "                 logger.debug(\"MACD <= Signal. +2 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"MACD or MACD signal is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        # Moving Average Crossover (Bullish: 20-day > 50-day)\n",
        "        if not pd.isna(sma_20) and not pd.isna(sma_50):\n",
        "            if sma_20 > sma_50:\n",
        "                score += 10\n",
        "                logger.debug(\"SMA20 > SMA50. +10 pts.\")\n",
        "            else:\n",
        "                score += 5 # Add a small score if 20-day is below but close to 50-day\n",
        "                logger.debug(\"SMA20 <= SMA50. +5 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"SMA_20 or SMA_50 is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        # Bollinger Bands (Price near lower band suggests potential buy)\n",
        "        if not pd.isna(current_price) and not pd.isna(bb_lower) and not pd.isna(bb_upper):\n",
        "            if not pd.isna(bb_lower) and current_price < bb_lower:\n",
        "                score += 10\n",
        "                logger.debug(\"Price < Lower BB. +10 pts.\")\n",
        "            elif not pd.isna(bb_upper) and current_price > bb_upper:\n",
        "                score -= 10\n",
        "                logger.debug(\"Price > Upper BB. -10 pts.\")\n",
        "            elif not pd.isna(bb_lower) and not pd.isna(bb_upper) and bb_lower <= current_price <= bb_upper: # Price is within the bands\n",
        "                 score += 5 # Add a small score for price being within bands, indicating less volatility\n",
        "                 logger.debug(\"Price within BB. +5 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"Bollinger Bands or current price is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        # Volume Spike (Significant volume increase can confirm trends)\n",
        "        if not pd.isna(volume_ratio):\n",
        "            if volume_ratio > 1.5: # Volume is 50% higher than average\n",
        "                 score += 10\n",
        "                 logger.debug(f\"Volume Ratio ({volume_ratio:.2f}) > 1.5. +10 pts.\")\n",
        "            elif volume_ratio < 0.8: # Volume is significantly lower than average\n",
        "                 score += 2 # Small score for low volume\n",
        "                 logger.debug(f\"Volume Ratio ({volume_ratio:.2f}) < 0.8. +2 pts.\")\n",
        "            else:\n",
        "                 score += 5 # Average volume is neutral\n",
        "                 logger.debug(f\"Volume Ratio ({volume_ratio:.2f}) 0.8-1.5. +5 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"Volume ratio is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        logger.info(f\"Basic technical score calculated: {score}\")\n",
        "        return max(0, min(score, 50)) # Cap score between 0 and 50\n",
        "\n",
        "    def generate_recommendation(self, fundamental_score: float, technical_score: float) -> str: # Added type hints\n",
        "        \"\"\"Generate investment recommendation based on scores\"\"\"\n",
        "        logger.info(f\"Generating basic recommendation based on Fundamental Score: {fundamental_score}, Technical Score: {technical_score}\")\n",
        "        # Ensure scores are valid numbers before summing\n",
        "        fund_score = fundamental_score if isinstance(fundamental_score, (int, float)) and not np.isnan(fundamental_score) else 0\n",
        "        tech_score = technical_score if isinstance(technical_score, (int, float)) and not np.isnan(technical_score) else 0\n",
        "\n",
        "        total_score = fund_score + tech_score\n",
        "        logger.debug(f\"Total score for basic recommendation: {total_score}\")\n",
        "\n",
        "        if total_score >= 75:\n",
        "            return \"STRONG BUY\"\n",
        "        elif total_score >= 60:\n",
        "            return \"BUY\"\n",
        "        elif total_score >= 40:\n",
        "            return \"HOLD\"\n",
        "        elif total_score >= 25:\n",
        "            return \"SELL\"\n",
        "        else:\n",
        "            return \"STRONG SELL\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a07f1d27"
      },
      "source": [
        "## Fetch sector peer data\n",
        "\n",
        "### Subtask:\n",
        "Enhance the peer data fetching or generation to include valuation ratios for peer companies within the same sector and market cap category.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57dc205f"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `get_peer_companies` function to fetch valuation ratios for peers and return this information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e975d6e",
        "cellView": "form"
      },
      "source": [
        "#@title Part 2: EnhancedStockAnalyzer class definition (with Peer Valuation Data Fetching)\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import typing for type hints\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- EnhancedStockAnalyzer class definition ---\n",
        "class EnhancedStockAnalyzer:\n",
        "    \"\"\"Enhanced analyzer with additional features for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the enhanced analyzer.\"\"\"\n",
        "        self.risk_free_rate = self.get_dynamic_risk_free_rate()\n",
        "        # Assuming gemini_model is defined globally from a previous cell\n",
        "        global gemini_model # Access the global gemini_model\n",
        "        self.gemini_model = gemini_model\n",
        "\n",
        "        # More detailed circuit limit percentages based on NSE categorization (simplified)\n",
        "        self.circuit_limits_percentage = {\n",
        "            'category_a': 0.20, # Typically high-liquidity index stocks\n",
        "            'category_b': 0.10, # Most other actively traded stocks\n",
        "            'category_t': 0.05  # Stocks in trade-for-trade segment\n",
        "        }\n",
        "\n",
        "        # Simple mapping of some known stocks to categories for demonstration\n",
        "        self.stock_category_map = {\n",
        "            'RELIANCE.NS': 'category_a',\n",
        "            'TCS.NS': 'category_a',\n",
        "            'HDFCBANK.NS': 'category_a',\n",
        "            'INFY.NS': 'category_a',\n",
        "            'ICICIBANK.NS': 'category_a',\n",
        "            'VEDL.NS': 'category_b',\n",
        "            'PNB.NS': 'category_b',\n",
        "            'INDIGO.NS': 'category_b',\n",
        "            'BANDHANBNK.NS': 'category_b',\n",
        "            'PERSISTENT.NS': 'category_b',\n",
        "            'COFORGE.NS': 'category_b',\n",
        "            'LTTS.NS': 'category_b',\n",
        "        }\n",
        "\n",
        "\n",
        "    def get_dynamic_risk_free_rate(self):\n",
        "        \"\"\"Fetch current 10-year G-Sec yield\"\"\"\n",
        "        try:\n",
        "            return 0.072  # 7.2% as of recent data\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not fetch dynamic risk-free rate: {e}. Using fallback rate.\")\n",
        "            return 0.065\n",
        "\n",
        "    def get_circuit_limits(self, symbol):\n",
        "        \"\"\"Get circuit breaker limits for the stock based on categorization\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            if not info or 'previousClose' not in info:\n",
        "                 logger.warning(f\"Could not get previous close for {symbol}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "            prev_close = info.get('previousClose')\n",
        "            if pd.isna(prev_close) or prev_close <= 0:\n",
        "                 logger.warning(f\"Invalid previous close price for {symbol}: {prev_close}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "\n",
        "            stock_category = self.stock_category_map.get(symbol.upper(), 'category_b')\n",
        "            circuit_percent = self.circuit_limits_percentage.get(stock_category, 0.10)\n",
        "\n",
        "            logger.info(f\"Determined circuit percentage for {symbol} (Category: {stock_category}): {circuit_percent*100}%\")\n",
        "\n",
        "            upper_circuit = prev_close * (1 + circuit_percent)\n",
        "            lower_circuit = prev_close * (1 - circuit_percent)\n",
        "\n",
        "            return {\n",
        "                'upper_circuit': upper_circuit,\n",
        "                'lower_circuit': lower_circuit,\n",
        "                'circuit_percent': circuit_percent\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting circuit breaker limits for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def assess_circuit_risk(self, current_price, circuit_limits):\n",
        "        \"\"\"Assess proximity to circuit limits\"\"\"\n",
        "        if pd.isna(current_price) or current_price <= 0:\n",
        "             logger.warning(\"Invalid current price for circuit risk assessment.\")\n",
        "             return 0\n",
        "\n",
        "        if not circuit_limits or 'upper_circuit' not in circuit_limits or 'lower_circuit' not in circuit_limits:\n",
        "            logger.warning(\"Invalid or incomplete circuit limits provided.\")\n",
        "            return 0\n",
        "\n",
        "        upper_circuit = circuit_limits['upper_circuit']\n",
        "        lower_circuit = circuit_limits['lower_circuit']\n",
        "\n",
        "        if pd.isna(upper_circuit) or pd.isna(lower_circuit) or upper_circuit <= 0 or lower_circuit <= 0:\n",
        "             logger.warning(\"Circuit limits are invalid numbers. Cannot assess circuit risk.\")\n",
        "             return 0\n",
        "\n",
        "        risk_score = 0\n",
        "\n",
        "        if current_price >= upper_circuit:\n",
        "             risk_score -= 30\n",
        "        elif (upper_circuit - current_price) / current_price < 0.01:\n",
        "            risk_score -= 20\n",
        "        elif (upper_circuit - current_price) / current_price < 0.03:\n",
        "            risk_score -= 10\n",
        "        elif (upper_circuit - current_price) / current_price < 0.05:\n",
        "            risk_score -= 5\n",
        "\n",
        "        if current_price <= lower_circuit:\n",
        "            risk_score -= 40\n",
        "        elif (current_price - lower_circuit) / current_price < 0.01:\n",
        "            risk_score -= 30\n",
        "        elif (current_price - lower_circuit) / current_price < 0.03:\n",
        "            risk_score -= 15\n",
        "        elif (current_price - lower_circuit) / current_price < 0.05:\n",
        "            risk_score -= 8\n",
        "\n",
        "        logger.info(f\"Circuit risk score calculated: {risk_score}\")\n",
        "        return risk_score\n",
        "\n",
        "    def get_liquidity_score(self, price_data):\n",
        "        \"\"\"Enhanced liquidity analysis with NaN handling and better checks\"\"\"\n",
        "        liquidity_score = 0\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or len(price_data) < 20:\n",
        "            logger.warning(\"Insufficient price data for liquidity analysis. Assigning default score.\")\n",
        "            return 30\n",
        "\n",
        "        try:\n",
        "            avg_volume_20d = price_data['Volume'].rolling(20).mean().iloc[-1]\n",
        "            avg_volume_5d = price_data['Volume'].rolling(5).mean().iloc[-1]\n",
        "            current_close = price_data['Close'].iloc[-1]\n",
        "\n",
        "            # Add logging for diagnosis - before calculation check\n",
        "            logger.info(f\"Volume data for liquidity: avg_volume_20d: {avg_volume_20d}, avg_volume_5d: {avg_volume_5d}, current_close: {current_close}\")\n",
        "\n",
        "\n",
        "            if pd.isna(avg_volume_20d) or pd.isna(avg_volume_5d) or pd.isna(current_close) or current_close <= 0:\n",
        "                 logger.warning(\"Liquidity metrics are NaN or invalid. Cannot calculate liquidity score accurately. Assigning default.\")\n",
        "                 return 30\n",
        "\n",
        "            avg_turnover_20d = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d >= 0 and current_close > 0:\n",
        "                 avg_turnover_20d = avg_volume_20d * current_close\n",
        "\n",
        "            volume_spike = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                 if avg_volume_5d is not None and not pd.isna(avg_volume_5d):\n",
        "                     volume_spike = avg_volume_5d / avg_volume_20d\n",
        "                 else:\n",
        "                      logger.warning(\"5-day average volume is invalid for volume spike calculation.\")\n",
        "            elif not pd.isna(avg_volume_5d) and avg_volume_5d > 0:\n",
        "                 volume_spike = 1.0\n",
        "                 logger.warning(\"20-day average volume is invalid for volume spike, using 1.0 as relative indicator.\")\n",
        "            else:\n",
        "                 volume_spike = np.nan # Ensure volume_spike is NaN if both volumes are invalid\n",
        "                 logger.warning(\"Insufficient or invalid volume data for volume ratio calculation.\")\n",
        "\n",
        "            # Add logging for volume spike - after calculation\n",
        "            logger.info(f\"Volume spike calculated: {volume_spike}\")\n",
        "\n",
        "            # Corrected logic for scoring based on volume_spike\n",
        "            if not pd.isna(volume_spike):\n",
        "                if volume_spike > 1.5: # Volume is 50% higher than average\n",
        "                    liquidity_score += 10\n",
        "                elif volume_spike < 0.8: # Volume is significantly lower than average\n",
        "                    liquidity_score += 2 # Small penalty for low volume\n",
        "                else: # volume_spike is between 0.8 and 1.5 (inclusive of 0.8, exclusive of 1.5)\n",
        "                    liquidity_score += 5 # Average volume is neutral\n",
        "            else:\n",
        "                 logger.warning(\"Volume spike ratio is NaN. Skipping trend scoring.\")\n",
        "\n",
        "\n",
        "            if not pd.isna(avg_turnover_20d):\n",
        "                if avg_turnover_20d > 500_00_00_000:\n",
        "                    liquidity_score += 40\n",
        "                elif avg_turnover_20d > 100_00_00_000:\n",
        "                    liquidity_score += 30\n",
        "                elif avg_turnover_20d > 10_00_00_000:\n",
        "                    liquidity_score += 20\n",
        "                elif avg_turnover_20d > 1_00_00_000:\n",
        "                    liquidity_score += 10\n",
        "                else:\n",
        "                    liquidity_score += 5\n",
        "            else:\n",
        "                 logger.warning(\"Average turnover is NaN. Skipping turnover scoring.\")\n",
        "                 liquidity_score += 10\n",
        "\n",
        "            volume_std = price_data['Volume'].rolling(20).std().iloc[-1] if len(price_data) >= 20 else np.nan\n",
        "            volume_cv = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0 and \\\n",
        "               volume_std is not None and not pd.isna(volume_std):\n",
        "                volume_cv = volume_std / avg_volume_20d\n",
        "\n",
        "            if not pd.isna(volume_cv):\n",
        "                if volume_cv < 0.5:\n",
        "                    liquidity_score += 20\n",
        "                elif volume_cv < 1.0:\n",
        "                    liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume coefficient of variation is NaN. Skipping consistency scoring.\")\n",
        "\n",
        "            # The volume spike scoring is now handled above within the main if not pd.isna(volume_spike): block\n",
        "\n",
        "\n",
        "            return min(liquidity_score, 70)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating liquidity score: {str(e)}\")\n",
        "            return 30\n",
        "\n",
        "    def get_peer_companies(self, symbol: str, stock_info: Dict) -> List[Dict]: # Modified return type hint\n",
        "        \"\"\"Identify peer companies and fetch their valuation ratios for comparison\"\"\"\n",
        "        logger.info(f\"Identifying peer companies and fetching valuation data for {symbol}.\")\n",
        "        peer_list_with_valuation = [] # List to store peer info including valuation\n",
        "\n",
        "        try:\n",
        "            if not isinstance(stock_info, dict):\n",
        "                 logger.warning(\"Invalid stock info for peer identification.\")\n",
        "                 return []\n",
        "\n",
        "            sector = stock_info.get('sector', '')\n",
        "            market_cap = stock_info.get('marketCap', 0)\n",
        "\n",
        "            if not isinstance(sector, str):\n",
        "                 sector = ''\n",
        "            if not isinstance(market_cap, (int, float)) or pd.isna(market_cap) or market_cap <= 0:\n",
        "                 logger.warning(\"Invalid market cap for peer identification.\")\n",
        "                 market_cap = 0\n",
        "\n",
        "            if market_cap > 10_00_000_00_00_000:\n",
        "                cap_category = 'Large Cap'\n",
        "            elif market_cap > 50_000_00_00_000:\n",
        "                cap_category = 'Mid Cap'\n",
        "            else:\n",
        "                cap_category = 'Small Cap'\n",
        "\n",
        "            # Peer mapping (simplified - in production, use a comprehensive database)\n",
        "            peer_map = {\n",
        "                'Technology': {\n",
        "                    'Large Cap': ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS'],\n",
        "                    'Mid Cap': ['TECHM.NS', 'LTTS.NS', 'PERSISTENT.NS', 'COFORGE.NS'],\n",
        "                    'Small Cap': ['ZENSAR.NS', 'ECLERX.NS', 'MASTEK.NS']\n",
        "                },\n",
        "                'Financial Services': {\n",
        "                    'Large Cap': ['HDFCBANK.NS', 'ICICIBANK.NS', 'KOTAKBANK.NS', 'AXISBANK.NS'],\n",
        "                    'Mid Cap': ['IDFCFIRSTB.NS', 'FEDERALBNK.NS', 'INDUSINDBK.NS'],\n",
        "                    'Small Cap': ['SOUTHBANK.NS', 'UJJIVAN.NS', 'EQUITASBNK.NS']\n",
        "                },\n",
        "                'Healthcare': {\n",
        "                    'Large Cap': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS'],\n",
        "                    'Mid Cap': ['TORNTPHARM.NS', 'ALKEM.NS', 'LUPIN.NS'],\n",
        "                    'Small Cap': ['CAPLIPOINT.NS', 'BLISS.NS', 'INDOCO.NS']\n",
        "                },\n",
        "                # Added Energy sector mapping\n",
        "                'Energy': {\n",
        "                    'Large Cap': ['ONGC.NS', 'NTPC.NS', 'POWERGRID.NS'], # Exclude RELIANCE.NS here, filter below\n",
        "                    'Mid Cap': ['GAIL.NS', 'IOC.NS', 'NHPC.NS'],\n",
        "                    'Small Cap': ['GUJGASLTD.NS', 'IGL.NS', 'MAHAPOWER.NS']\n",
        "                }\n",
        "            }\n",
        "\n",
        "            potential_peers = peer_map.get(sector, {}).get(cap_category, [])\n",
        "            # Ensure the current symbol is excluded from the peer list\n",
        "            filtered_peers = [p for p in potential_peers if isinstance(p, str) and p.upper() != symbol.upper()]\n",
        "\n",
        "            logger.info(f\"Identified {len(filtered_peers)} potential peer companies for {symbol} in {sector} ({cap_category} Cap). Fetching valuation data.\")\n",
        "\n",
        "            # Fetch valuation data for each filtered peer\n",
        "            for peer_symbol in filtered_peers:\n",
        "                 try:\n",
        "                      peer_ticker = yf.Ticker(peer_symbol)\n",
        "                      peer_info = peer_ticker.info\n",
        "\n",
        "                      if peer_info:\n",
        "                           peer_valuation = {\n",
        "                               'symbol': peer_symbol,\n",
        "                               'trailingPE': peer_info.get('trailingPE', np.nan),\n",
        "                               'priceToBook': peer_info.get('priceToBook', np.nan),\n",
        "                               'enterpriseValue': peer_info.get('enterpriseValue', np.nan), # Fetch for EV/EBITDA calculation\n",
        "                               'ebitda': peer_info.get('ebitda', np.nan) # Fetch for EV/EBITDA calculation\n",
        "                           }\n",
        "\n",
        "                           # Calculate EV/EBITDA for the peer\n",
        "                           ev = peer_valuation['enterpriseValue']\n",
        "                           ebitda = peer_valuation['ebitda']\n",
        "                           peer_valuation['evToEbitda'] = np.nan # Default to NaN\n",
        "                           if isinstance(ev, (int, float)) and not np.isnan(ev) and \\\n",
        "                              isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda != 0:\n",
        "                               peer_valuation['evToEbitda'] = ev / ebitda\n",
        "                           elif (isinstance(ev, (int, float)) and not np.isnan(ev)) and \\\n",
        "                                (isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda == 0):\n",
        "                                logger.warning(f\"EBITDA is zero for peer {peer_symbol}. Cannot calculate EV/EBITDA.\")\n",
        "                           else:\n",
        "                                logger.warning(f\"Missing Enterprise Value ({ev}) or EBITDA ({ebitda}) for peer {peer_symbol}. Cannot calculate EV/EBITDA.\")\n",
        "\n",
        "\n",
        "                           peer_list_with_valuation.append(peer_valuation)\n",
        "                           logger.debug(f\"Fetched valuation data for peer {peer_symbol}: PE={peer_valuation['trailingPE']}, PB={peer_valuation['priceToBook']}, EV/EBITDA={peer_valuation['evToEbitda']}\")\n",
        "                      else:\n",
        "                           logger.warning(f\"Could not fetch info for peer {peer_symbol}. Skipping.\")\n",
        "                 except Exception as e:\n",
        "                      logger.warning(f\"Error fetching data for peer {peer_symbol}: {str(e)}. Skipping.\")\n",
        "\n",
        "            logger.info(f\"Successfully fetched valuation data for {len(peer_list_with_valuation)} peers.\")\n",
        "            return peer_list_with_valuation[:5] # Return top 5 peers with their valuation data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting peer companies and valuation data for {symbol}: {str(e)}\")\n",
        "            return [] # Return empty list on error\n",
        "\n",
        "\n",
        "    def calculate_peer_relative_performance(self, symbol, peers, days=30):\n",
        "        \"\"\"Compare stock performance with peers, handling data issues robustly\"\"\"\n",
        "        results = {\n",
        "            'stock_return': np.nan,\n",
        "            'avg_peer_return': np.nan,\n",
        "            'relative_performance': np.nan,\n",
        "            'outperformance': False,\n",
        "            'days': days\n",
        "        }\n",
        "\n",
        "        if not isinstance(peers, list) or not peers:\n",
        "             logger.warning(\"No valid peer list provided for performance comparison.\")\n",
        "             # Return the default results with NaNs if no peers\n",
        "             return results\n",
        "\n",
        "        # --- Removed the temporary skip here ---\n",
        "\n",
        "        try:\n",
        "            main_ticker = yf.Ticker(symbol)\n",
        "            main_hist = main_ticker.history(period=f\"{days}d\")\n",
        "            main_return = np.nan\n",
        "\n",
        "            if not main_hist.empty and len(main_hist) > 1:\n",
        "                try:\n",
        "                    start_price = main_hist['Close'].iloc[0]\n",
        "                    end_price = main_hist['Close'].iloc[-1]\n",
        "                    if not pd.isna(start_price) and not pd.isna(end_price) and start_price > 0:\n",
        "                         main_return = ((end_price / start_price) - 1) * 100\n",
        "                    else:\n",
        "                         logger.warning(f\"Invalid start ({start_price}) or end price ({end_price}) for main stock ({symbol}) return calculation.\")\n",
        "                except Exception as ret_e:\n",
        "                     logger.warning(f\"Could not calculate main stock ({symbol}) return: {ret_e}. Setting to NaN.\")\n",
        "                     main_return = np.nan\n",
        "            else:\n",
        "                logger.warning(f\"Insufficient historical data for main stock ({symbol}) for return calculation.\")\n",
        "\n",
        "            results['stock_return'] = main_return\n",
        "\n",
        "        except Exception as main_stock_e:\n",
        "            logger.error(f\"Error fetching data or calculating return for main stock ({symbol}): {main_stock_e}. Main stock return set to NaN.\")\n",
        "            results['stock_return'] = np.nan\n",
        "\n",
        "        # Calculate peer returns\n",
        "        peer_returns = []\n",
        "        # The peers list now contains dictionaries with valuation data.\n",
        "        # We need to extract just the symbols for performance calculation.\n",
        "        peer_symbols_for_perf = [p['symbol'] for p in peers if isinstance(p, dict) and 'symbol' in p]\n",
        "\n",
        "        for peer_symbol in peer_symbols_for_perf:\n",
        "             try:\n",
        "                 peer_ticker = yf.Ticker(peer_symbol)\n",
        "                 peer_hist = peer_ticker.history(period=f\"{days}d\")\n",
        "                 if not peer_hist.empty and len(peer_hist) > 1:\n",
        "                     try:\n",
        "                          peer_start_price = peer_hist['Close'].iloc[0]\n",
        "                          peer_end_price = peer_hist['Close'].iloc[-1]\n",
        "                          if not pd.isna(peer_start_price) and not pd.isna(peer_end_price) and peer_start_price > 0:\n",
        "                             peer_return = ((peer_end_price / peer_start_price) - 1) * 100\n",
        "                             peer_returns.append(peer_return)\n",
        "                          else:\n",
        "                             logger.warning(f\"Invalid start or end price for peer ({peer_symbol}) return calculation.\")\n",
        "                     except Exception as peer_ret_e:\n",
        "                         logger.warning(f\"Could not calculate return for peer ({peer_symbol}): {peer_ret_e}. Skipping.\")\n",
        "                 else:\n",
        "                     logger.warning(f\"Insufficient historical data for peer ({peer_symbol}) for return calculation. Skipping.\")\n",
        "             except Exception as peer_e:\n",
        "                 logger.warning(f\"Error fetching data for peer ({peer_symbol}): {peer_e}. Skipping.\")\n",
        "\n",
        "        # Add logging for peer returns before filtering/average calculation\n",
        "        logger.info(f\"Peer returns collected before average calculation attempt: {peer_returns}\")\n",
        "\n",
        "        # Calculate average peer return and relative performance\n",
        "        if peer_returns:\n",
        "             # Ensure peer_returns list contains only valid numbers before calculating mean\n",
        "             valid_peer_returns = [ret for ret in peer_returns if isinstance(ret, (int, float)) and not pd.isna(ret)]\n",
        "             if valid_peer_returns:\n",
        "                 avg_peer_return = np.mean(valid_peer_returns)\n",
        "                 results['avg_peer_return'] = avg_peer_return\n",
        "\n",
        "                 # Calculate relative performance only if main stock return is valid\n",
        "                 if not pd.isna(main_return):\n",
        "                      results['relative_performance'] = main_return - avg_peer_return\n",
        "\n",
        "                      # Determine outperformance\n",
        "                      if main_return > avg_peer_return:\n",
        "                          results['outperformance'] = True\n",
        "                 else:\n",
        "                      logger.warning(\"Main stock return is NaN, cannot calculate relative performance or outperformance.\")\n",
        "             else:\n",
        "                 logger.warning(\"No valid peer returns available after filtering. Cannot calculate average peer return or relative performance.\")\n",
        "        else:\n",
        "             logger.warning(\"No peer returns calculated. Cannot calculate average peer return or relative performance.\")\n",
        "\n",
        "\n",
        "        logger.info(f\"Peer performance results for {symbol}: {results}\")\n",
        "        return results\n",
        "\n",
        "\n",
        "    def get_index_membership(self, symbol):\n",
        "        \"\"\"Check index membership for the stock\"\"\"\n",
        "        symbol_upper = symbol.upper() if isinstance(symbol, str) else ''\n",
        "\n",
        "        index_constituents = {\n",
        "            'NIFTY50': ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS'],\n",
        "            'NIFTY_NEXT50': ['VEDL.NS', 'PNB.NS', 'INDIGO.NS', 'BANDHANBNK.NS'],\n",
        "            'NIFTY_MIDCAP150': ['PERSISTENT.NS', 'COFORGE.NS', 'LTTS.NS']\n",
        "        }\n",
        "\n",
        "        membership = []\n",
        "        for index, constituents in index_constituents.items():\n",
        "            if symbol_upper and any(isinstance(c, str) and c.upper() == symbol_upper for c in constituents):\n",
        "                membership.append(index)\n",
        "\n",
        "        if membership:\n",
        "             logger.info(f\"Stock {symbol} is a member of indices: {', '.join(membership)}\")\n",
        "        else:\n",
        "             logger.info(f\"Stock {symbol} is not found in the hardcoded index constituents.\")\n",
        "\n",
        "        return membership\n",
        "\n",
        "    def calculate_enhanced_technical_score(self, indicators, circuit_risk):\n",
        "        \"\"\"Calculate enhanced technical analysis score with NaN handling and circuit risk\"\"\"\n",
        "        base_score = 0\n",
        "        indicators_calculated = 0\n",
        "        possible_indicator_points = 50\n",
        "\n",
        "        num_key_indicators = 5\n",
        "        indicator_point_contribution = possible_indicator_points / num_key_indicators\n",
        "\n",
        "        rsi = indicators.get('RSI', np.nan)\n",
        "        if not pd.isna(rsi):\n",
        "             indicators_calculated += 1\n",
        "             if 40 <= rsi <= 60:\n",
        "                 base_score += indicator_point_contribution * 0.7\n",
        "             elif rsi < 30: # More points for extreme oversold\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             elif 30 <= rsi < 40: # Approaching oversold\n",
        "                 base_score += indicator_point_contribution * 0.9\n",
        "             elif 60 < rsi <= 70: # Approaching overbought\n",
        "                 base_score += indicator_point_contribution * 0.6\n",
        "             else: # Overbought (>70)\n",
        "                 base_score += indicator_point_contribution * 0.4\n",
        "        else:\n",
        "             logger.warning(\"RSI not calculated or is NaN.\")\n",
        "\n",
        "        macd = indicators.get('MACD', np.nan)\n",
        "        macd_signal = indicators.get('MACD_signal', np.nan)\n",
        "\n",
        "        if not pd.isna(macd) and not pd.isna(macd_signal):\n",
        "             indicators_calculated += 1\n",
        "             if macd > macd_signal:\n",
        "                 if macd > 0: # Bullish crossover above zero line\n",
        "                      base_score += indicator_point_contribution * 1.0\n",
        "                 else: # Bullish crossover below zero line\n",
        "                      base_score += indicator_point_contribution * 0.8\n",
        "             else:\n",
        "                 if macd < 0: # Bearish crossover below zero line\n",
        "                      base_score += indicator_point_contribution * 0.2\n",
        "                 else: # Bearish crossover above zero line\n",
        "                      base_score += indicator_point_contribution * 0.4\n",
        "        else:\n",
        "             logger.warning(\"MACD or MACD signal is NaN for technical scoring.\")\n",
        "\n",
        "        sma_20 = indicators.get('SMA_20', np.nan)\n",
        "        sma_50 = indicators.get('SMA_50', np.nan)\n",
        "        sma_200 = indicators.get('SMA_200', np.nan) # Include 200-day SMA if available\n",
        "\n",
        "        ma_score_component = 0\n",
        "        ma_indicators_counted = 0\n",
        "\n",
        "        if not pd.isna(sma_20) and not pd.isna(sma_50):\n",
        "             ma_indicators_counted += 1\n",
        "             if sma_20 > sma_50:\n",
        "                  ma_score_component += 0.5 # 20 > 50 crossover is bullish\n",
        "             else:\n",
        "                  ma_score_component += 0.2 # 20 <= 50 crossover is bearish/neutral\n",
        "\n",
        "        if not pd.isna(sma_50) and not pd.isna(sma_200):\n",
        "             ma_indicators_counted += 1\n",
        "             if sma_50 > sma_200:\n",
        "                  ma_score_component += 0.5 # 50 > 200 crossover is bullish\n",
        "             else:\n",
        "                  ma_score_component += 0.2 # 50 <= 200 crossover is bearish/neutral\n",
        "\n",
        "        current_price = indicators.get('current_price', np.nan)\n",
        "        if not pd.isna(current_price):\n",
        "             if not pd.isna(sma_20) and current_price > sma_20:\n",
        "                  ma_score_component += 0.3 # Price above 20-day SMA is bullish\n",
        "             elif not pd.isna(sma_20):\n",
        "                  ma_score_component += 0.1 # Price below 20-day SMA is bearish/neutral\n",
        "\n",
        "             if not pd.isna(sma_50) and current_price > sma_50:\n",
        "                  ma_score_component += 0.4 # Price above 50-day SMA is more bullish\n",
        "             elif not pd.isna(sma_50):\n",
        "                  ma_score_component += 0.15 # Price below 50-day SMA\n",
        "\n",
        "             if not pd.isna(sma_200) and current_price > sma_200:\n",
        "                  ma_score_component += 0.6 # Price above 200-day SMA is significant bullish signal\n",
        "             elif not pd.isna(sma_200):\n",
        "                  ma_score_component += 0.1 # Price below 200-day SMA is significant bearish signal\n",
        "\n",
        "\n",
        "        if ma_indicators_counted > 0 or (not pd.isna(current_price) and (not pd.isna(sma_20) or not pd.isna(sma_50) or not pd.isna(sma_200))):\n",
        "             indicators_calculated += 1 # Count MA section if any valid MA comparison/position is made\n",
        "             # Normalize MA score component to contribute to the total score\n",
        "             # Max possible ma_score_component (0.5 + 0.5 + 0.3 + 0.4 + 0.6) = 2.3\n",
        "             # Let's scale this to contribute up to indicator_point_contribution\n",
        "             max_ma_component = 2.3\n",
        "             base_score += (ma_score_component / max_ma_component) * indicator_point_contribution if max_ma_component > 0 else 0\n",
        "        else:\n",
        "             logger.warning(\"Insufficient data for Moving Averages analysis.\")\n",
        "\n",
        "\n",
        "        bb_upper = indicators.get('BB_upper', np.nan)\n",
        "        bb_lower = indicators.get('BB_lower', np.nan)\n",
        "        bb_middle = indicators.get('BB_middle', np.nan)\n",
        "\n",
        "        if not pd.isna(current_price) and not pd.isna(bb_upper) and not pd.isna(bb_lower) and not pd.isna(bb_middle):\n",
        "            indicators_calculated += 1\n",
        "            if current_price < bb_lower:\n",
        "                base_score += indicator_point_contribution * 1.0 # Price below lower band (potential buy signal)\n",
        "            elif bb_lower <= current_price < bb_middle:\n",
        "                base_score += indicator_point_contribution * 0.8 # Between lower and middle band\n",
        "            elif bb_middle <= current_price < bb_upper:\n",
        "                base_score += indicator_point_contribution * 0.6 # Between middle and upper band\n",
        "            else: # Price above upper band\n",
        "                base_score += indicator_point_contribution * 0.4 # Potential sell signal\n",
        "        else:\n",
        "             logger.warning(\"Bollinger Bands or current price is NaN for technical scoring.\")\n",
        "\n",
        "        volume_ratio = indicators.get('Volume_ratio', np.nan)\n",
        "        if not pd.isna(volume_ratio):\n",
        "             indicators_calculated += 1\n",
        "             if volume_ratio > 2.0: # Very high volume\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             elif volume_ratio > 1.2: # High volume\n",
        "                 base_score += indicator_point_contribution * 0.8\n",
        "             elif 0.8 <= volume_ratio <= 1.2: # Normal volume\n",
        "                 base_score += indicator_point_contribution * 0.5\n",
        "             else: # Low volume\n",
        "                 base_score += indicator_point_contribution * 0.3\n",
        "        else:\n",
        "             logger.warning(\"Volume ratio is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        achieved_score_from_indicators = base_score\n",
        "\n",
        "        # Normalize the base score based on how many indicators were successfully calculated\n",
        "        if indicators_calculated > 0:\n",
        "            # Assuming each of the num_key_indicators contributes equally if available\n",
        "            # This approach gives points for each indicator that could be calculated and scored\n",
        "            # Max points if all indicators could be scored is num_key_indicators * indicator_point_contribution\n",
        "            # But our scoring within each indicator gives variable points (e.g., 0.4 to 1.0)\n",
        "            # A simpler approach is to just sum up the points from successfully scored indicators\n",
        "            # Let's cap the sum at the max possible points from indicators (50)\n",
        "            final_base_score = min(achieved_score_from_indicators, possible_indicator_points)\n",
        "\n",
        "            if indicators_calculated < num_key_indicators:\n",
        "                 logger.warning(f\"Only {indicators_calculated}/{num_key_indicators} key technical indicators could be fully calculated/scored. Final base technical score is based on available data.\")\n",
        "\n",
        "        else:\n",
        "             logger.warning(\"No key technical indicators calculated. Base technical score is 0.\")\n",
        "             final_base_score = 0\n",
        "\n",
        "\n",
        "        circuit_risk_adj = circuit_risk if isinstance(circuit_risk, (int, float)) and not pd.isna(circuit_risk) else 0\n",
        "\n",
        "        final_score = final_base_score + circuit_risk_adj\n",
        "\n",
        "        return max(0, min(final_score, 50))\n",
        "\n",
        "\n",
        "    def fetch_news(self, symbol: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Fetches recent news headlines for the given stock symbol.\n",
        "        NOTE: This is a placeholder. In a real application, you would integrate\n",
        "        with a News API (like News API, Alpha Vantage, etc.) here.\n",
        "        \"\"\"\n",
        "        print(f\"Fetching news for {symbol} (placeholder)...\")\n",
        "        symbol_str = str(symbol) if symbol is not None else \"Unknown Stock\"\n",
        "        return [\n",
        "            f\"{symbol_str} stock price rises on positive market sentiment\",\n",
        "            f\"{symbol_str} announces strong quarterly results, beating estimates\",\n",
        "            f\"Experts bullish on {symbol_str}'s future outlook\",\n",
        "            f\"I am a non-numeric entry that might cause an error\",\n",
        "            f\"{symbol_str} faces regulatory challenges in key market\",\n",
        "            f\"Competitor's new product launch impacts {symbol_str}'s market share\",\n",
        "            f\"Global market trends positively impacting {symbol_str}\",\n",
        "            f\"{symbol_str} management provides optimistic guidance\",\n",
        "            f\"Increased foreign investment flows into {symbol_str}\",\n",
        "            f\"Regulatory approval received for {symbol_str}'s new product\",\n",
        "            f\"Production issues reported for {symbol_str}\",\n",
        "            f\"Increased competition puts pressure on {symbol_str}'s margins\",\n",
        "            f\"Analyst downgrades rating for {symbol_str}\",\n",
        "            f\"Supply chain disruptions affect {symbol_str}'s operations\",\n",
        "            f\"Geopolitical tensions create uncertainty for {symbol_str}\",\n",
        "            f\"{symbol_str} announces stock split\",\n",
        "            f\"Dividend declared by {symbol_str}\"\n",
        "        ]\n",
        "\n",
        "\n",
        "    def analyze_sentiment(self, news_headlines: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of news headlines using the Gemini API.\n",
        "        Returns a dictionary with sentiment counts (positive, neutral, negative)\n",
        "        and a sentiment score.\n",
        "        \"\"\"\n",
        "        if not self.gemini_model:\n",
        "            print(\"Gemini API not configured. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Gemini API not configured. Sentiment analysis skipped.'}\n",
        "\n",
        "        if not isinstance(news_headlines, list) or not news_headlines:\n",
        "            print(\"No news headlines to analyze. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 12.5, 'summary': 'No news headlines. Sentiment analysis skipped.'}\n",
        "\n",
        "        logger.info(\"Analyzing sentiment using Gemini API...\")\n",
        "        prompt = \"Analyze the sentiment of the following news headlines for a stock and categorize each as Positive, Neutral, or Negative. Provide a concise summary of the overall sentiment.\\n\\n\"\n",
        "        for headline in news_headlines:\n",
        "            if isinstance(headline, str):\n",
        "                 prompt += f\"- {headline}\\n\"\n",
        "            else:\n",
        "                 logger.warning(f\"Skipping non-string headline: {headline}\")\n",
        "                 continue\n",
        "\n",
        "        if len(prompt) > 30000:\n",
        "             logger.warning(\"News headlines too long for Gemini API prompt. Truncating.\")\n",
        "             prompt = prompt[:30000] + \"\\n... (headlines truncated)\"\n",
        "\n",
        "        try:\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "            sentiment_text = response.text.strip()\n",
        "            logger.info(f\"Gemini API Response: {sentiment_text[:200]}...\")\n",
        "\n",
        "            positive_count = sentiment_text.lower().count('positive')\n",
        "            neutral_count = sentiment_text.lower().count('neutral')\n",
        "            negative_count = sentiment_text.lower().count('negative')\n",
        "\n",
        "            summary_line = \"No summary extracted.\"\n",
        "            lines = sentiment_text.split('\\n')\n",
        "            for line in lines:\n",
        "                 lower_line = line.lower()\n",
        "                 if 'summary' in lower_line or 'overall sentiment' in lower_line:\n",
        "                     summary_line = line.strip()\n",
        "                     break\n",
        "            if summary_line == \"No summary extracted.\" and lines:\n",
        "                 for line in reversed(lines):\n",
        "                     if line.strip():\n",
        "                         summary_line = line.strip()\n",
        "                         break\n",
        "\n",
        "            total_headlines = len([h for h in news_headlines if isinstance(h, str)])\n",
        "            if total_headlines > 0:\n",
        "                sentiment_score = ((positive_count - negative_count) / total_headlines) * 12.5 + 12.5\n",
        "            else:\n",
        "                sentiment_score = 12.5\n",
        "\n",
        "            return {\n",
        "                'positive': positive_count,\n",
        "                'neutral': neutral_count,\n",
        "                'negative': negative_count,\n",
        "                'score': max(0, min(sentiment_score, 25)),\n",
        "                'summary': summary_line\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing sentiment with Gemini API: {e}. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis failed.'}\n",
        "\n",
        "\n",
        "    def generate_enhanced_recommendation(self, fundamental_score, technical_score,\n",
        "                                       liquidity_score, peer_performance, index_membership,\n",
        "                                       sentiment_analysis_results):\n",
        "        \"\"\"Generate comprehensive recommendation including sentiment\"\"\"\n",
        "        fund_score = fundamental_score if isinstance(fundamental_score, (int, float)) and not pd.isna(fundamental_score) else 0\n",
        "        tech_score = technical_score if isinstance(technical_score, (int, float)) and not pd.isna(technical_score) else 0\n",
        "        liq_score = liquidity_score if isinstance(liquidity_score, (int, float)) and not pd.isna(liquidity_score) else 0\n",
        "        sentiment_score = sentiment_analysis_results.get('score', 0) if isinstance(sentiment_analysis_results.get('score'), (int, float)) and not pd.isna(sentiment_analysis_results.get('score')) else 0\n",
        "\n",
        "        total_score = fund_score + tech_score + liq_score + sentiment_score\n",
        "\n",
        "        peer_analysis_available = isinstance(peer_performance, dict) and \\\n",
        "                                  not (pd.isna(peer_performance.get('stock_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('avg_peer_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('relative_performance')))\n",
        "\n",
        "        if peer_analysis_available and peer_performance.get('outperformance', False) is True:\n",
        "            total_score += 5\n",
        "            logger.info(\"Adding bonus for peer outperformance.\")\n",
        "        elif not peer_analysis_available:\n",
        "             total_score -= 5\n",
        "             logger.warning(\"Applying small penalty as peer performance data is incomplete/unavailable.\")\n",
        "\n",
        "        if isinstance(index_membership, list) and index_membership:\n",
        "            total_score += 5\n",
        "            logger.info(\"Adding bonus for index membership.\")\n",
        "\n",
        "        recommendation = \"NEUTRAL\"\n",
        "        confidence = \"Low\"\n",
        "\n",
        "        if total_score >= 170:\n",
        "            recommendation = \"STRONG BUY\"\n",
        "            confidence = \"High\"\n",
        "        elif total_score >= 140:\n",
        "            recommendation = \"BUY\"\n",
        "            confidence = \"Moderate to High\"\n",
        "        elif total_score >= 100:\n",
        "            recommendation = \"HOLD\"\n",
        "            confidence = \"Moderate\"\n",
        "        elif total_score >= 70:\n",
        "            recommendation = \"SELL\"\n",
        "            confidence = \"Moderate\"\n",
        "        else:\n",
        "            recommendation = \"STRONG SELL\"\n",
        "            confidence = \"High\"\n",
        "\n",
        "        logger.info(f\"Generated enhanced recommendation: {recommendation} (Total Score: {total_score:.2f})\")\n",
        "\n",
        "        return {\n",
        "            'recommendation': recommendation,\n",
        "            'confidence': confidence,\n",
        "            'total_score': total_score,\n",
        "            'breakdown': {\n",
        "                'fundamental': fund_score,\n",
        "                'technical': tech_score,\n",
        "                'liquidity': liq_score,\n",
        "                'sentiment': sentiment_score,\n",
        "                'peer_adjustment': 5 if peer_analysis_available and peer_performance.get('outperformance', False) is True else (-5 if not peer_analysis_available else 0),\n",
        "                'index_adjustment': 5 if isinstance(index_membership, list) and index_membership else 0\n",
        "            }\n",
        "        }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52440820"
      },
      "source": [
        "**Reasoning**:\n",
        "The `get_peer_companies` function now returns a list of dictionaries including valuation data. Update the `analyze_stock_enhanced` function to store this enhanced peer data in the report.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c989e841",
        "cellView": "form"
      },
      "source": [
        "#@title Part 3: Enhanced Analysis Integration and Report Display (Updated Peer Data Handling)\n",
        "\n",
        "# Assuming IndianStockAnalyzer and EnhancedStockAnalyzer classes are defined in previous cells\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "    if not isinstance(symbol, str) or not symbol:\n",
        "        logger.error(\"Invalid stock symbol provided for enhanced analysis.\")\n",
        "        return None\n",
        "    if not isinstance(stock_analyzer_part1, IndianStockAnalyzer):\n",
        "        logger.error(\"Invalid IndianStockAnalyzer (Part 1) instance provided.\")\n",
        "        return None\n",
        "    if not isinstance(enhanced_analyzer, EnhancedStockAnalyzer):\n",
        "        logger.error(\"Invalid EnhancedStockAnalyzer (Part 2) instance provided.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    logger.info(f\"Starting enhanced analysis for {symbol}\")\n",
        "    # Get basic analysis from Part 1\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        logger.error(f\"Basic analysis failed for {symbol}.\")\n",
        "        return None\n",
        "\n",
        "    # Get current price - already validated in Part 1 analyze_stock\n",
        "    current_price = stock_data.current_price\n",
        "    if pd.isna(current_price) or current_price <= 0:\n",
        "         logger.warning(f\"Current price invalid ({current_price}). Enhanced analysis might be limited.\")\n",
        "\n",
        "\n",
        "    # Enhanced analysis\n",
        "    logger.info(\"Starting enhanced analysis features (Part 2).\")\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    # Pass current_price to assess_circuit_risk (already validated as best as possible in Part 1)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    # Pass price_data (already validated in Part 1 analyze_stock)\n",
        "    # CORRECTED: Call get_liquidity_score on enhanced_analyzer and pass price_data from stock_data\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "\n",
        "    # 3. Peer analysis (including valuation data)\n",
        "    # Pass info (already validated in Part 1 analyze_stock)\n",
        "    # The get_peer_companies method now returns a list of dictionaries with valuation data\n",
        "    peers_with_valuation = enhanced_analyzer.get_peer_companies(symbol, stock_data.info)\n",
        "    # Pass the list of peer symbols (extracted from the list of dictionaries) for performance comparison\n",
        "    peer_symbols_for_performance = [p['symbol'] for p in peers_with_valuation if isinstance(p, dict) and 'symbol' in p]\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peer_symbols_for_performance) # Pass just symbols\n",
        "\n",
        "\n",
        "    # 4. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "\n",
        "    # 5. Recalculate technical score with circuit risk\n",
        "    # Pass indicators (already validated in Part 1 calculate_technical_indicators)\n",
        "    # Pass circuit_risk (already validated in assess_circuit_risk)\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "\n",
        "    # 6. Fetch and analyze news sentiment\n",
        "    # Pass symbol (already validated)\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    # Pass news_headlines (already validated)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "\n",
        "\n",
        "    # 7. Generate enhanced recommendation\n",
        "    # Pass scores and results (already validated within their respective functions)\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance, # Pass potentially incomplete/NaN peer performance\n",
        "        index_membership,\n",
        "        sentiment_analysis_results # Pass sentiment analysis results\n",
        "    )\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score, # Ensure correct liquidity score is included\n",
        "            'peers': peers_with_valuation, # Store the list of peers with their valuation data\n",
        "            'peer_performance': peer_performance, # Include peer performance, even if NaN\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "    logger.info(f\"Enhanced analysis completed for {symbol}\")\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize analyzers\n",
        "    try:\n",
        "        stock_analyzer = IndianStockAnalyzer()\n",
        "        enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "    except NameError:\n",
        "        print(\"Make sure to run the previous cells defining IndianStockAnalyzer and EnhancedStockAnalyzer classes.\")\n",
        "        exit() # Exit if classes are not defined\n",
        "\n",
        "\n",
        "    # Analyze a stock\n",
        "    symbol = \"RELIANCE.NS\" # Example symbol\n",
        "    result = analyze_stock_enhanced(symbol, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if result:\n",
        "        # Display the enhanced report\n",
        "        enhanced = result['enhanced_features']\n",
        "        final = result['final_recommendation']\n",
        "        basic = result['basic_analysis'] # Get basic data for display\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Enhanced Analysis Report: {basic.company_name} ({basic.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if not pd.isna(basic.current_price) else \"Current Price: N/A\")\n",
        "        market_cap_cr = basic.market_cap / 10000000 if not pd.isna(basic.market_cap) else np.nan\n",
        "        print(f\"Market Cap: ₹{market_cap_cr:,.2f} Cr\" if not pd.isna(market_cap_cr) else \"Market Cap: N/A\")\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n⚙️ Enhanced Technical Analysis & Risk:\")\n",
        "        # Display enhanced technical indicators and risk\n",
        "        # Assuming you want to display relevant indicators from basic.indicators and the circuit risk score\n",
        "        circuit_limits_display = enhanced.get('circuit_limits')\n",
        "        if circuit_limits_display and not pd.isna(circuit_limits_display.get('lower_circuit')) and not pd.isna(circuit_limits_display.get('upper_circuit')):\n",
        "             print(f\"Circuit Limits: {circuit_limits_display.get('lower_circuit', 'N/A'):.2f} - {circuit_limits_display.get('upper_circuit', 'N/A'):.2f}\")\n",
        "        else:\n",
        "             print(\"Circuit Limits: N/A\")\n",
        "\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        # Check if liquidity score is available before formatting\n",
        "        liquidity_score_display = f\"{enhanced.get('liquidity_score', 'N/A')}/70\" if isinstance(enhanced.get('liquidity_score'), (int, float)) and not pd.isna(enhanced.get('liquidity_score')) else \"Liquidity Score: N/A/70\"\n",
        "        print(liquidity_score_display)\n",
        "\n",
        "\n",
        "        # Display some key technical indicators from basic analysis\n",
        "        print(\"\\nKey Technical Indicators (from Basic Analysis):\")\n",
        "        key_tech_indicators = ['RSI', 'MACD', 'MACD_signal', 'SMA_20', 'SMA_50', 'BB_middle', 'Volume_ratio']\n",
        "        for indicator_name in key_tech_indicators:\n",
        "            value = basic.indicators.get(indicator_name, np.nan)\n",
        "            if not pd.isna(value):\n",
        "                if isinstance(value, float):\n",
        "                     print(f\"  - {indicator_name}: {value:,.2f}\")\n",
        "                else:\n",
        "                     print(f\"  - {indicator_name}: {value}\")\n",
        "            # Add logging for these key technical indicators if they are calculated\n",
        "            logger.info(f\"Indicator {indicator_name}: {value}\")\n",
        "        else:\n",
        "            print(f\"  - {indicator_name}: N/A\")\n",
        "            logger.info(f\"Indicator {indicator_name}: N/A\")\n",
        "\n",
        "\n",
        "        print(f\"\\n🤝 Peer Analysis:\")\n",
        "        peers_with_valuation = enhanced.get('peers')\n",
        "        if isinstance(peers_with_valuation, list) and peers_with_valuation:\n",
        "             print(\"Peer Companies and Valuation Ratios:\")\n",
        "             for peer_data in peers_with_valuation:\n",
        "                  if isinstance(peer_data, dict) and 'symbol' in peer_data:\n",
        "                       peer_symbol = peer_data['symbol']\n",
        "                       peer_pe = peer_data.get('trailingPE', np.nan)\n",
        "                       peer_pb = peer_data.get('priceToBook', np.nan)\n",
        "                       peer_ev_ebitda = peer_data.get('evToEbitda', np.nan)\n",
        "\n",
        "                       pe_display = f\"{peer_pe:.2f}\" if not pd.isna(peer_pe) else \"N/A\"\n",
        "                       pb_display = f\"{peer_pb:.2f}\" if not pd.isna(peer_pb) else \"N/A\"\n",
        "                       ev_ebitda_display = f\"{peer_ev_ebitda:.2f}\" if not pd.isna(peer_ev_ebitda) else \"N/A\"\n",
        "\n",
        "                       print(f\"  - {peer_symbol}: PE={pe_display}, PB={pb_display}, EV/EBITDA={ev_ebitda_display}\")\n",
        "                  else:\n",
        "                       logger.warning(f\"Invalid peer data format in the list: {peer_data}\")\n",
        "                       print(f\"  - Invalid Peer Data: {peer_data}\")\n",
        "\n",
        "\n",
        "             # Display peer performance metrics separately\n",
        "             peer_perf = enhanced.get('peer_performance')\n",
        "             if isinstance(peer_perf, dict) and \\\n",
        "                not pd.isna(peer_perf.get('stock_return')) and \\\n",
        "                not pd.isna(peer_perf.get('avg_peer_return')) and \\\n",
        "                not pd.isna(peer_perf.get('relative_performance')):\n",
        "\n",
        "                  print(\"\\nPeer Performance:\")\n",
        "                  stock_return_display = f\"{peer_perf.get('stock_return', 'N/A'):.2f}%\" if isinstance(peer_perf.get('stock_return'), (int, float)) and not pd.isna(peer_perf.get('stock_return')) else 'N/A'\n",
        "                  avg_peer_return_display = f\"{peer_perf.get('avg_peer_return', 'N/A'):.2f}%\" if isinstance(peer_perf.get('avg_peer_return'), (int, float)) and not pd.isna(peer_perf.get('avg_peer_return')) else 'N/A'\n",
        "                  relative_performance_display = f\"{peer_perf.get('relative_performance', 'N/A'):.2f}%\" if isinstance(peer_perf.get('relative_performance'), (int, float)) and not pd.isna(peer_perf.get('relative_performance')) else 'N/A'\n",
        "\n",
        "                  print(f\"  - {peer_perf.get('days', 'N/A')}-day Stock Return: {stock_return_display}\")\n",
        "                  print(f\"  - Avg Peer Return: {avg_peer_return_display}\")\n",
        "                  print(f\"  - Relative Performance: {relative_performance_display}\")\n",
        "             else:\n",
        "                  print(\"Peer Performance Data Unavailable.\")\n",
        "\n",
        "        else:\n",
        "             print(\"No peer companies identified or data unavailable.\")\n",
        "\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"\\n🏛️ Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             # Only print a few headlines to keep the report concise\n",
        "             print(\"Sample News Headlines:\")\n",
        "             # Ensure headlines are valid strings before printing\n",
        "             valid_headlines = [h for h in enhanced['news_headlines'] if isinstance(h, str)]\n",
        "             for headline in valid_headlines[:5]: # Print up to 5 headlines\n",
        "                 print(f\"- {headline}\")\n",
        "             if len(valid_headlines) > 5:\n",
        "                  print(\"  ...\")\n",
        "\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             sentiment_score_display = f\"{sentiment_results.get('score', 0):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\"\n",
        "             print(f\"Sentiment Score: {sentiment_score_display}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Comprehensive Scores and Recommendation ---\")\n",
        "        print(f\"Fundamental Score (from Part 1): {basic.fundamental_score:.2f}/50\" if not pd.isna(basic.fundamental_score) else \"Fundamental Score: N/A\")\n",
        "        # Add checks for NaN before formatting float for breakdown scores\n",
        "        enhanced_tech_score_display = f\"{final.get('breakdown', {}).get('technical', 'N/A'):.2f}\" if isinstance(final.get('breakdown', {}).get('technical'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('technical')) else \"N/A\"\n",
        "        liquidity_score_display_breakdown = f\"{final.get('breakdown', {}).get('liquidity', 'N/A'):.2f}\" if isinstance(final.get('breakdown', {}).get('liquidity'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('liquidity')) else \"N/A\"\n",
        "        sentiment_score_display_breakdown = f\"{final.get('breakdown', {}).get('sentiment', 'N/A'):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\" # Corrected sentiment score breakdown check\n",
        "\n",
        "        print(f\"Technical Score (Enhanced): {enhanced_tech_score_display}/50\")\n",
        "        print(f\"Liquidity Score: {liquidity_score_display_breakdown}/70\")\n",
        "        print(f\"Sentiment Score: {sentiment_score_display_breakdown}/25\")\n",
        "\n",
        "        # Display adjustment scores\n",
        "        peer_adj_display = f\"{final.get('breakdown', {}).get('peer_adjustment', 'N/A'):+.2f}\" if isinstance(final.get('breakdown', {}).get('peer_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('peer_adjustment')) else \"N/A\"\n",
        "        index_adj_display = f\"{final.get('breakdown', {}).get('index_adjustment', 'N/A'):+.2f}\" if isinstance(final.get('breakdown', {}).get('index_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('index_adjustment')) else \"N/A\"\n",
        "\n",
        "        print(f\"Peer Adjustment: {peer_adj_display}\")\n",
        "        print(f\"Index Membership Adjustment: {index_adj_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\nTotal Enhanced Score: {final.get('total_score', 0):.2f}/205\" if isinstance(final.get('total_score'), (int, float)) and not pd.isna(final.get('total_score')) else \"Total Enhanced Score: N/A\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} (Confidence: {final.get('confidence', 'N/A')})\")\n",
        "\n",
        "\n",
        "        print(f\"\\n{'='*60}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ac0b6c7"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the calculation and comparison of the stock's valuation ratios (P/E, P/B, EV/EBITDA) against the average ratios of its identified peers. This involves iterating through the peer valuation data fetched in the previous step, calculating the average for each ratio, and then comparing the stock's ratios to these averages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1sB1cPk_x57",
        "cellView": "form"
      },
      "source": [
        "#@title Part 2: EnhancedStockAnalyzer class definition (with Valuation Comparison Logic)\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import typing for type hints\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# --- EnhancedStockAnalyzer class definition ---\n",
        "class EnhancedStockAnalyzer:\n",
        "    \"\"\"Enhanced analyzer with additional features for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the enhanced analyzer.\"\"\"\n",
        "        self.risk_free_rate = self.get_dynamic_risk_free_rate()\n",
        "        # Assuming gemini_model is defined globally from a previous cell\n",
        "        global gemini_model # Access the global gemini_model\n",
        "        self.gemini_model = gemini_model\n",
        "\n",
        "        # More detailed circuit limit percentages based on NSE categorization (simplified)\n",
        "        self.circuit_limits_percentage = {\n",
        "            'category_a': 0.20, # Typically high-liquidity index stocks\n",
        "            'category_b': 0.10, # Most other actively traded stocks\n",
        "            'category_t': 0.05  # Stocks in trade-for-trade segment\n",
        "        }\n",
        "\n",
        "        # Simple mapping of some known stocks to categories for demonstration\n",
        "        self.stock_category_map = {\n",
        "            'RELIANCE.NS': 'category_a',\n",
        "            'TCS.NS': 'category_a',\n",
        "            'HDFCBANK.NS': 'category_a',\n",
        "            'INFY.NS': 'category_a',\n",
        "            'ICICIBANK.NS': 'category_a',\n",
        "            'VEDL.NS': 'category_b',\n",
        "            'PNB.NS': 'category_b',\n",
        "            'INDIGO.NS': 'category_b',\n",
        "            'BANDHANBNK.NS': 'category_b',\n",
        "            'PERSISTENT.NS': 'category_b',\n",
        "            'COFORGE.NS': 'category_b',\n",
        "            'LTTS.NS': 'category_b',\n",
        "        }\n",
        "\n",
        "\n",
        "    def get_dynamic_risk_free_rate(self):\n",
        "        \"\"\"Fetch current 10-year G-Sec yield\"\"\"\n",
        "        try:\n",
        "            return 0.072  # 7.2% as of recent data\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not fetch dynamic risk-free rate: {e}. Using fallback rate.\")\n",
        "            return 0.065\n",
        "\n",
        "    def get_circuit_limits(self, symbol):\n",
        "        \"\"\"Get circuit breaker limits for the stock based on categorization\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            if not info or 'previousClose' not in info:\n",
        "                 logger.warning(f\"Could not get previous close for {symbol}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "            prev_close = info.get('previousClose')\n",
        "            if pd.isna(prev_close) or prev_close <= 0:\n",
        "                 logger.warning(f\"Invalid previous close price for {symbol}: {prev_close}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "\n",
        "            stock_category = self.stock_category_map.get(symbol.upper(), 'category_b')\n",
        "            circuit_percent = self.circuit_limits_percentage.get(stock_category, 0.10)\n",
        "\n",
        "            logger.info(f\"Determined circuit percentage for {symbol} (Category: {stock_category}): {circuit_percent*100}%\")\n",
        "\n",
        "            upper_circuit = prev_close * (1 + circuit_percent)\n",
        "            lower_circuit = prev_close * (1 - circuit_percent)\n",
        "\n",
        "            return {\n",
        "                'upper_circuit': upper_circuit,\n",
        "                'lower_circuit': lower_circuit,\n",
        "                'circuit_percent': circuit_percent\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting circuit breaker limits for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def assess_circuit_risk(self, current_price, circuit_limits):\n",
        "        \"\"\"Assess proximity to circuit limits\"\"\"\n",
        "        if pd.isna(current_price) or current_price <= 0:\n",
        "             logger.warning(\"Invalid current price for circuit risk assessment.\")\n",
        "             return 0\n",
        "\n",
        "        if not circuit_limits or 'upper_circuit' not in circuit_limits or 'lower_circuit' not in circuit_limits:\n",
        "            logger.warning(\"Invalid or incomplete circuit limits provided.\")\n",
        "            return 0\n",
        "\n",
        "        upper_circuit = circuit_limits['upper_circuit']\n",
        "        lower_circuit = circuit_limits['lower_circuit']\n",
        "\n",
        "        if pd.isna(upper_circuit) or pd.isna(lower_circuit) or upper_circuit <= 0 or lower_circuit <= 0:\n",
        "             logger.warning(\"Circuit limits are invalid numbers. Cannot assess circuit risk.\")\n",
        "             return 0\n",
        "\n",
        "        risk_score = 0\n",
        "\n",
        "        if current_price >= upper_circuit:\n",
        "             risk_score -= 30\n",
        "        elif (upper_circuit - current_price) / current_price < 0.01:\n",
        "            risk_score -= 20\n",
        "        elif (upper_circuit - current_price) / current_price < 0.03:\n",
        "            risk_score -= 10\n",
        "        elif (upper_circuit - current_price) / current_price < 0.05:\n",
        "            risk_score -= 5\n",
        "\n",
        "        if current_price <= lower_circuit:\n",
        "            risk_score -= 40\n",
        "        elif (current_price - lower_circuit) / current_price < 0.01:\n",
        "            risk_score -= 30\n",
        "        elif (current_price - lower_circuit) / current_price < 0.03:\n",
        "            risk_score -= 15\n",
        "        elif (current_price - lower_circuit) / current_price < 0.05:\n",
        "            risk_score -= 8\n",
        "\n",
        "        logger.info(f\"Circuit risk score calculated: {risk_score}\")\n",
        "        return risk_score\n",
        "\n",
        "    def get_liquidity_score(self, price_data):\n",
        "        \"\"\"Enhanced liquidity analysis with NaN handling and better checks\"\"\"\n",
        "        liquidity_score = 0\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or len(price_data) < 20:\n",
        "            logger.warning(\"Insufficient price data for liquidity analysis. Assigning default score.\")\n",
        "            return 30\n",
        "\n",
        "        try:\n",
        "            avg_volume_20d = price_data['Volume'].rolling(20).mean().iloc[-1]\n",
        "            avg_volume_5d = price_data['Volume'].rolling(5).mean().iloc[-1]\n",
        "            current_close = price_data['Close'].iloc[-1]\n",
        "\n",
        "            # Add logging for diagnosis - before calculation check\n",
        "            logger.info(f\"Volume data for liquidity: avg_volume_20d: {avg_volume_20d}, avg_volume_5d: {avg_volume_5d}, current_close: {current_close}\")\n",
        "\n",
        "\n",
        "            if pd.isna(avg_volume_20d) or pd.isna(avg_volume_5d) or pd.isna(current_close) or current_close <= 0:\n",
        "                 logger.warning(\"Liquidity metrics are NaN or invalid. Cannot calculate liquidity score accurately. Assigning default.\")\n",
        "                 return 30\n",
        "\n",
        "            avg_turnover_20d = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d >= 0 and current_close > 0:\n",
        "                 avg_turnover_20d = avg_volume_20d * current_close\n",
        "\n",
        "            volume_spike = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                 if avg_volume_5d is not None and not pd.isna(avg_volume_5d):\n",
        "                     volume_spike = avg_volume_5d / avg_volume_20d\n",
        "                 else:\n",
        "                      logger.warning(\"5-day average volume is invalid for volume spike calculation.\")\n",
        "            elif not pd.isna(avg_volume_5d) and avg_volume_5d > 0:\n",
        "                 volume_spike = 1.0\n",
        "                 logger.warning(\"20-day average volume is invalid for volume spike, using 1.0 as relative indicator.\")\n",
        "            else:\n",
        "                 volume_spike = np.nan # Ensure volume_spike is NaN if both volumes are invalid\n",
        "                 logger.warning(\"Insufficient or invalid volume data for volume ratio calculation.\")\n",
        "\n",
        "            # Add logging for volume spike - after calculation\n",
        "            logger.info(f\"Volume spike calculated: {volume_spike}\")\n",
        "\n",
        "            # Corrected logic for scoring based on volume_spike\n",
        "            if not pd.isna(volume_spike):\n",
        "                if volume_spike > 1.5: # Volume is 50% higher than average\n",
        "                    liquidity_score += 10\n",
        "                elif volume_spike < 0.8: # Volume is significantly lower than average\n",
        "                    liquidity_score += 2 # Small penalty for low volume\n",
        "                else: # volume_spike is between 0.8 and 1.5 (inclusive of 0.8, exclusive of 1.5)\n",
        "                    liquidity_score += 5 # Average volume is neutral\n",
        "            else:\n",
        "                 logger.warning(\"Volume spike ratio is NaN. Skipping trend scoring.\")\n",
        "\n",
        "\n",
        "            if not pd.isna(avg_turnover_20d):\n",
        "                if avg_turnover_20d > 500_00_00_000:\n",
        "                    liquidity_score += 40\n",
        "                elif avg_turnover_20d > 100_00_00_000:\n",
        "                    liquidity_score += 30\n",
        "                elif avg_turnover_20d > 10_00_00_000:\n",
        "                    liquidity_score += 20\n",
        "                elif avg_turnover_20d > 1_00_00_000:\n",
        "                    liquidity_score += 10\n",
        "                else:\n",
        "                    liquidity_score += 5\n",
        "            else:\n",
        "                 logger.warning(\"Average turnover is NaN. Skipping turnover scoring.\")\n",
        "                 liquidity_score += 10\n",
        "\n",
        "            volume_std = price_data['Volume'].rolling(20).std().iloc[-1] if len(price_data) >= 20 else np.nan\n",
        "            volume_cv = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0 and \\\n",
        "               volume_std is not None and not pd.isna(volume_std):\n",
        "                volume_cv = volume_std / avg_volume_20d\n",
        "\n",
        "            if not pd.isna(volume_cv):\n",
        "                if volume_cv < 0.5:\n",
        "                    liquidity_score += 20\n",
        "                elif volume_cv < 1.0:\n",
        "                    liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume coefficient of variation is NaN. Skipping consistency scoring.\")\n",
        "\n",
        "            # The volume spike scoring is now handled above within the main if not pd.isna(volume_spike): block\n",
        "\n",
        "\n",
        "            return min(liquidity_score, 70)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating liquidity score: {str(e)}\")\n",
        "            return 30\n",
        "\n",
        "    def get_peer_companies(self, symbol: str, stock_info: Dict) -> List[Dict]: # Modified return type hint\n",
        "        \"\"\"Identify peer companies and fetch their valuation ratios for comparison\"\"\"\n",
        "        logger.info(f\"Identifying peer companies and fetching valuation data for {symbol}.\")\n",
        "        peer_list_with_valuation = [] # List to store peer info including valuation\n",
        "\n",
        "        try:\n",
        "            if not isinstance(stock_info, dict):\n",
        "                 logger.warning(\"Invalid stock info for peer identification.\")\n",
        "                 return []\n",
        "\n",
        "            sector = stock_info.get('sector', '')\n",
        "            market_cap = stock_info.get('marketCap', 0)\n",
        "\n",
        "            if not isinstance(sector, str):\n",
        "                 sector = ''\n",
        "            if not isinstance(market_cap, (int, float)) or pd.isna(market_cap) or market_cap <= 0:\n",
        "                 logger.warning(\"Invalid market cap for peer identification.\")\n",
        "                 market_cap = 0\n",
        "\n",
        "            if market_cap > 10_00_000_00_00_000:\n",
        "                cap_category = 'Large Cap'\n",
        "            elif market_cap > 50_000_00_00_000:\n",
        "                cap_category = 'Mid Cap'\n",
        "            else:\n",
        "                cap_category = 'Small Cap'\n",
        "\n",
        "            # Peer mapping (simplified - in production, use a comprehensive database)\n",
        "            peer_map = {\n",
        "                'Technology': {\n",
        "                    'Large Cap': ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS'],\n",
        "                    'Mid Cap': ['TECHM.NS', 'LTTS.NS', 'PERSISTENT.NS', 'COFORGE.NS'],\n",
        "                    'Small Cap': ['ZENSAR.NS', 'ECLERX.NS', 'MASTEK.NS']\n",
        "                },\n",
        "                'Financial Services': {\n",
        "                    'Large Cap': ['HDFCBANK.NS', 'ICICIBANK.NS', 'KOTAKBANK.NS', 'AXISBANK.NS'],\n",
        "                    'Mid Cap': ['IDFCFIRSTB.NS', 'FEDERALBNK.NS', 'INDUSINDBK.NS'],\n",
        "                    'Small Cap': ['SOUTHBANK.NS', 'UJJIVAN.NS', 'EQUITASBNK.NS']\n",
        "                },\n",
        "                'Healthcare': {\n",
        "                    'Large Cap': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS'],\n",
        "                    'Mid Cap': ['TORNTPHARM.NS', 'ALKEM.NS', 'LUPIN.NS'],\n",
        "                    'Small Cap': ['CAPLIPOINT.NS', 'BLISS.NS', 'INDOCO.NS']\n",
        "                },\n",
        "                # Added Energy sector mapping\n",
        "                'Energy': {\n",
        "                    'Large Cap': ['ONGC.NS', 'NTPC.NS', 'POWERGRID.NS'], # Exclude RELIANCE.NS here, filter below\n",
        "                    'Mid Cap': ['GAIL.NS', 'IOC.NS', 'NHPC.NS'],\n",
        "                    'Small Cap': ['GUJGASLTD.NS', 'IGL.NS', 'MAHAPOWER.NS']\n",
        "                }\n",
        "            }\n",
        "\n",
        "            potential_peers = peer_map.get(sector, {}).get(cap_category, [])\n",
        "            # Ensure the current symbol is excluded from the peer list\n",
        "            filtered_peers = [p for p in potential_peers if isinstance(p, str) and p.upper() != symbol.upper()]\n",
        "\n",
        "            logger.info(f\"Identified {len(filtered_peers)} potential peer companies for {symbol} in {sector} ({cap_category} Cap). Fetching valuation data.\")\n",
        "\n",
        "            # Fetch valuation data for each filtered peer\n",
        "            for peer_symbol in filtered_peers:\n",
        "                 try:\n",
        "                      peer_ticker = yf.Ticker(peer_symbol)\n",
        "                      peer_info = peer_ticker.info\n",
        "\n",
        "                      if peer_info:\n",
        "                           peer_valuation = {\n",
        "                               'symbol': peer_symbol,\n",
        "                               'trailingPE': peer_info.get('trailingPE', np.nan),\n",
        "                               'priceToBook': peer_info.get('priceToBook', np.nan),\n",
        "                               'enterpriseValue': peer_info.get('enterpriseValue', np.nan), # Fetch for EV/EBITDA calculation\n",
        "                               'ebitda': peer_info.get('ebitda', np.nan) # Fetch for EV/EBITDA calculation\n",
        "                           }\n",
        "\n",
        "                           # Calculate EV/EBITDA for the peer\n",
        "                           ev = peer_valuation['enterpriseValue']\n",
        "                           ebitda = peer_valuation['ebitda']\n",
        "                           peer_valuation['evToEbitda'] = np.nan # Default to NaN\n",
        "                           if isinstance(ev, (int, float)) and not np.isnan(ev) and \\\n",
        "                              isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda != 0:\n",
        "                               peer_valuation['evToEbitda'] = ev / ebitda\n",
        "                           elif (isinstance(ev, (int, float)) and not np.isnan(ev)) and \\\n",
        "                                (isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda == 0):\n",
        "                                logger.warning(f\"EBITDA is zero for peer {peer_symbol}. Cannot calculate EV/EBITDA.\")\n",
        "                           else:\n",
        "                                logger.warning(f\"Missing Enterprise Value ({ev}) or EBITDA ({ebitda}) for peer {peer_symbol}. Cannot calculate EV/EBITDA.\")\n",
        "\n",
        "\n",
        "                           peer_list_with_valuation.append(peer_valuation)\n",
        "                           logger.debug(f\"Fetched valuation data for peer {peer_symbol}: PE={peer_valuation['trailingPE']}, PB={peer_valuation['priceToBook']}, EV/EBITDA={peer_valuation['evToEbitda']}\")\n",
        "                      else:\n",
        "                           logger.warning(f\"Could not fetch info for peer {peer_symbol}. Skipping.\")\n",
        "                 except Exception as e:\n",
        "                      logger.warning(f\"Error fetching data for peer {peer_symbol}: {str(e)}. Skipping.\")\n",
        "\n",
        "            logger.info(f\"Successfully fetched valuation data for {len(peer_list_with_valuation)} peers.\")\n",
        "            return peer_list_with_valuation[:5] # Return top 5 peers with their valuation data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting peer companies and valuation data for {symbol}: {str(e)}\")\n",
        "            return [] # Return empty list on error\n",
        "\n",
        "    def calculate_peer_average_valuation(self, peers_with_valuation: List[Dict]) -> Dict:\n",
        "        \"\"\"Calculate average valuation ratios (PE, PB, EV/EBITDA) for a list of peers.\"\"\"\n",
        "        logger.info(\"Calculating peer average valuation ratios.\")\n",
        "        total_pe = 0\n",
        "        total_pb = 0\n",
        "        total_ev_ebitda = 0\n",
        "        count_pe = 0\n",
        "        count_pb = 0\n",
        "        count_ev_ebitda = 0\n",
        "\n",
        "        if not isinstance(peers_with_valuation, list) or not peers_with_valuation:\n",
        "             logger.warning(\"No peer valuation data provided for calculating averages.\")\n",
        "             return {'avg_pe': np.nan, 'avg_pb': np.nan, 'avg_ev_ebitda': np.nan}\n",
        "\n",
        "\n",
        "        for peer_data in peers_with_valuation:\n",
        "             if isinstance(peer_data, dict):\n",
        "                 pe = peer_data.get('trailingPE', np.nan)\n",
        "                 pb = peer_data.get('priceToBook', np.nan)\n",
        "                 ev_ebitda = peer_data.get('evToEbitda', np.nan)\n",
        "\n",
        "                 if isinstance(pe, (int, float)) and not np.isnan(pe) and pe > 0:\n",
        "                     total_pe += pe\n",
        "                     count_pe += 1\n",
        "                 else:\n",
        "                      logger.debug(f\"Skipping invalid PE for peer: {peer_data.get('symbol', 'Unknown')}\")\n",
        "\n",
        "                 if isinstance(pb, (int, float)) and not np.isnan(pb) and pb > 0:\n",
        "                     total_pb += pb\n",
        "                     count_pb += 1\n",
        "                 else:\n",
        "                      logger.debug(f\"Skipping invalid PB for peer: {peer_data.get('symbol', 'Unknown')}\")\n",
        "\n",
        "\n",
        "                 if isinstance(ev_ebitda, (int, float)) and not np.isnan(ev_ebitda): # EV/EBITDA can be zero or negative in some cases, but >0 is typical\n",
        "                      total_ev_ebitda += ev_ebitda\n",
        "                      count_ev_ebitda += 1\n",
        "                 else:\n",
        "                      logger.debug(f\"Skipping invalid EV/EBITDA for peer: {peer_data.get('symbol', 'Unknown')}\")\n",
        "\n",
        "\n",
        "        avg_pe = total_pe / count_pe if count_pe > 0 else np.nan\n",
        "        avg_pb = total_pb / count_pb if count_pb > 0 else np.nan\n",
        "        avg_ev_ebitda = total_ev_ebitda / count_ev_ebitda if count_ev_ebitda > 0 else np.nan\n",
        "\n",
        "        logger.info(f\"Calculated peer averages: PE={avg_pe:.2f}, PB={avg_pb:.2f}, EV/EBITDA={avg_ev_ebitda:.2f}\")\n",
        "\n",
        "        return {\n",
        "            'avg_pe': avg_pe,\n",
        "            'avg_pb': avg_pb,\n",
        "            'avg_ev_ebitda': avg_ev_ebitda\n",
        "        }\n",
        "\n",
        "\n",
        "    def compare_valuation_to_peers(self, stock_valuation: Dict, peer_average_valuation: Dict) -> Dict:\n",
        "        \"\"\"Compare stock's valuation ratios to peer averages and provide assessment.\"\"\"\n",
        "        logger.info(\"Comparing stock valuation to peer averages.\")\n",
        "        comparison_results = {}\n",
        "        valuation_score_adjustment = 0 # Adjustment to the total score\n",
        "\n",
        "        stock_pe = stock_valuation.get('trailingPE', np.nan)\n",
        "        stock_pb = stock_valuation.get('priceToBook', np.nan)\n",
        "        stock_ev_ebitda = stock_valuation.get('evToEbitda', np.nan)\n",
        "\n",
        "        avg_pe = peer_average_valuation.get('avg_pe', np.nan)\n",
        "        avg_pb = peer_average_valuation.get('avg_pb', np.nan)\n",
        "        avg_ev_ebitda = peer_average_valuation.get('avg_ev_ebitda', np.nan)\n",
        "\n",
        "        logger.debug(f\"Stock Valuation: PE={stock_pe:.2f}, PB={stock_pb:.2f}, EV/EBITDA={stock_ev_ebitda:.2f}\")\n",
        "        logger.debug(f\"Peer Average Valuation: PE={avg_pe:.2f}, PB={avg_pb:.2f}, EV/EBITDA={avg_ev_ebitda:.2f}\")\n",
        "\n",
        "\n",
        "        # PE Ratio comparison (Lower is generally better relative to peers)\n",
        "        comparison_results['pe_comparison'] = 'N/A'\n",
        "        if not pd.isna(stock_pe) and not pd.isna(avg_pe) and avg_pe > 0:\n",
        "             if stock_pe < avg_pe * 0.8: # More than 20% below average\n",
        "                  comparison_results['pe_comparison'] = 'Significantly Undervalued (PE)'\n",
        "                  valuation_score_adjustment += 10\n",
        "             elif stock_pe < avg_pe * 0.95: # More than 5% below average\n",
        "                  comparison_results['pe_comparison'] = 'Undervalued (PE)'\n",
        "                  valuation_score_adjustment += 5\n",
        "             elif stock_pe > avg_pe * 1.2: # More than 20% above average\n",
        "                  comparison_results['pe_comparison'] = 'Significantly Overvalued (PE)'\n",
        "                  valuation_score_adjustment -= 10\n",
        "             elif stock_pe > avg_pe * 1.05: # More than 5% above average\n",
        "                  comparison_results['pe_comparison'] = 'Overvalued (PE)'\n",
        "                  valuation_score_adjustment -= 5\n",
        "             else:\n",
        "                  comparison_results['pe_comparison'] = 'Fairly Valued (PE)'\n",
        "        elif not pd.isna(stock_pe) and pd.isna(avg_pe):\n",
        "             comparison_results['pe_comparison'] = 'PE available, Peer Avg PE N/A'\n",
        "             logger.warning(\"Peer Average PE is NaN. Cannot compare stock PE to peers.\")\n",
        "        elif pd.isna(stock_pe) and not pd.isna(avg_pe):\n",
        "             comparison_results['pe_comparison'] = 'Stock PE N/A'\n",
        "             logger.warning(\"Stock PE is NaN. Cannot compare to peer Average PE.\")\n",
        "        else:\n",
        "             logger.warning(\"Stock PE and Peer Average PE are NaN. Cannot compare.\")\n",
        "\n",
        "\n",
        "        # PB Ratio comparison (Lower is generally better relative to peers)\n",
        "        comparison_results['pb_comparison'] = 'N/A'\n",
        "        if not pd.isna(stock_pb) and not pd.isna(avg_pb) and avg_pb > 0:\n",
        "             if stock_pb < avg_pb * 0.8: # More than 20% below average\n",
        "                  comparison_results['pb_comparison'] = 'Significantly Undervalued (PB)'\n",
        "                  valuation_score_adjustment += 8\n",
        "             elif stock_pb < avg_pb * 0.95: # More than 5% below average\n",
        "                  comparison_results['pb_comparison'] = 'Undervalued (PB)'\n",
        "                  valuation_score_adjustment += 4\n",
        "             elif stock_pb > avg_pb * 1.2: # More than 20% above average\n",
        "                  comparison_results['pb_comparison'] = 'Significantly Overvalued (PB)'\n",
        "                  valuation_score_adjustment -= 8\n",
        "             elif stock_pb > avg_pb * 1.05: # More than 5% above average\n",
        "                  comparison_results['pb_comparison'] = 'Overvalued (PB)'\n",
        "                  valuation_score_adjustment -= 4\n",
        "             else:\n",
        "                  comparison_results['pb_comparison'] = 'Fairly Valued (PB)'\n",
        "        elif not pd.isna(stock_pb) and pd.isna(avg_pb):\n",
        "             comparison_results['pb_comparison'] = 'PB available, Peer Avg PB N/A'\n",
        "             logger.warning(\"Peer Average PB is NaN. Cannot compare stock PB to peers.\")\n",
        "        elif pd.isna(stock_pb) and not pd.isna(avg_pb):\n",
        "             comparison_results['pb_comparison'] = 'Stock PB N/A'\n",
        "             logger.warning(\"Stock PB is NaN. Cannot compare to peer Average PB.\")\n",
        "        else:\n",
        "             logger.warning(\"Stock PB and Peer Average PB are NaN. Cannot compare.\")\n",
        "\n",
        "\n",
        "        # EV/EBITDA comparison (Lower is generally better relative to peers)\n",
        "        comparison_results['ev_ebitda_comparison'] = 'N/A'\n",
        "        if not pd.isna(stock_ev_ebitda) and not pd.isna(avg_ev_ebitda) and avg_ev_ebitda != 0:\n",
        "             if stock_ev_ebitda < avg_ev_ebitda * 0.8: # More than 20% below average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Significantly Undervalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment += 12\n",
        "             elif stock_ev_ebitda < avg_ev_ebitda * 0.95: # More than 5% below average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Undervalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment += 6\n",
        "             elif stock_ev_ebitda > avg_ev_ebitda * 1.2: # More than 20% above average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Significantly Overvalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment -= 12\n",
        "             elif stock_ev_ebitda > avg_ev_ebitda * 1.05: # More than 5% above average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Overvalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment -= 6\n",
        "             else:\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Fairly Valued (EV/EBITDA)'\n",
        "        elif not pd.isna(stock_ev_ebitda) and not pd.isna(avg_ev_ebitda) and avg_ev_ebitda == 0:\n",
        "             comparison_results['ev_ebitda_comparison'] = 'Peer Avg EV/EBITDA is 0'\n",
        "             logger.warning(\"Peer Average EV/EBITDA is zero. Cannot compare.\")\n",
        "        elif not pd.isna(stock_ev_ebitda) and pd.isna(avg_ev_ebitda):\n",
        "             comparison_results['ev_ebitda_comparison'] = 'EV/EBITDA available, Peer Avg EV/EBITDA N/A'\n",
        "             logger.warning(\"Peer Average EV/EBITDA is NaN. Cannot compare stock EV/EBITDA to peers.\")\n",
        "        elif pd.isna(stock_ev_ebitda) and not pd.isna(avg_ev_ebitda):\n",
        "             comparison_results['ev_ebitda_comparison'] = 'Stock EV/EBITDA N/A'\n",
        "             logger.warning(\"Stock EV/EBITDA is NaN. Cannot compare to peer Average EV/EBITDA.\")\n",
        "        else:\n",
        "             logger.warning(\"Stock EV/EBITDA and Peer Average EV/EBITDA are NaN. Cannot compare.\")\n",
        "\n",
        "\n",
        "        comparison_results['valuation_score_adjustment'] = valuation_score_adjustment\n",
        "\n",
        "        logger.info(f\"Valuation comparison results: {comparison_results}\")\n",
        "        return comparison_results\n",
        "\n",
        "\n",
        "    def calculate_peer_relative_performance(self, symbol, peers, days=30):\n",
        "        \"\"\"Compare stock performance with peers, handling data issues robustly\"\"\"\n",
        "        results = {\n",
        "            'stock_return': np.nan,\n",
        "            'avg_peer_return': np.nan,\n",
        "            'relative_performance': np.nan,\n",
        "            'outperformance': False,\n",
        "            'days': days\n",
        "        }\n",
        "\n",
        "        if not isinstance(peers, list) or not peers:\n",
        "             logger.warning(\"No valid peer list provided for performance comparison.\")\n",
        "             # Return the default results with NaNs if no peers\n",
        "             return results\n",
        "\n",
        "        # --- Removed the temporary skip here ---\n",
        "\n",
        "        try:\n",
        "            main_ticker = yf.Ticker(symbol)\n",
        "            main_hist = main_ticker.history(period=f\"{days}d\")\n",
        "            main_return = np.nan\n",
        "\n",
        "            if not main_hist.empty and len(main_hist) > 1:\n",
        "                try:\n",
        "                    start_price = main_hist['Close'].iloc[0]\n",
        "                    end_price = main_hist['Close'].iloc[-1]\n",
        "                    if not pd.isna(start_price) and not pd.isna(end_price) and start_price > 0:\n",
        "                         main_return = ((end_price / start_price) - 1) * 100\n",
        "                    else:\n",
        "                         logger.warning(f\"Invalid start ({start_price}) or end price ({end_price}) for main stock ({symbol}) return calculation.\")\n",
        "                except Exception as ret_e:\n",
        "                     logger.warning(f\"Could not calculate main stock ({symbol}) return: {ret_e}. Setting to NaN.\")\n",
        "                     main_return = np.nan\n",
        "            else:\n",
        "                logger.warning(f\"Insufficient historical data for main stock ({symbol}) for return calculation.\")\n",
        "\n",
        "            results['stock_return'] = main_return\n",
        "\n",
        "        except Exception as main_stock_e:\n",
        "            logger.error(f\"Error fetching data or calculating return for main stock ({symbol}): {main_stock_e}. Main stock return set to NaN.\")\n",
        "            results['stock_return'] = np.nan\n",
        "\n",
        "        # Calculate peer returns\n",
        "        peer_returns = []\n",
        "        # The peers list now contains dictionaries with valuation data.\n",
        "        # We need to extract just the symbols for performance calculation.\n",
        "        peer_symbols_for_perf = [p['symbol'] for p in peers if isinstance(p, dict) and 'symbol' in p]\n",
        "\n",
        "        for peer_symbol in peer_symbols_for_perf:\n",
        "             try:\n",
        "                 peer_ticker = yf.Ticker(peer_symbol)\n",
        "                 peer_hist = peer_ticker.history(period=f\"{days}d\")\n",
        "                 if not peer_hist.empty and len(peer_hist) > 1:\n",
        "                     try:\n",
        "                          peer_start_price = peer_hist['Close'].iloc[0]\n",
        "                          peer_end_price = peer_hist['Close'].iloc[-1]\n",
        "                          if not pd.isna(peer_start_price) and not pd.isna(peer_end_price) and peer_start_price > 0:\n",
        "                             peer_return = ((peer_end_price / peer_start_price) - 1) * 100\n",
        "                             peer_returns.append(peer_return)\n",
        "                          else:\n",
        "                             logger.warning(f\"Invalid start or end price for peer ({peer_symbol}) return calculation.\")\n",
        "                     except Exception as peer_ret_e:\n",
        "                         logger.warning(f\"Could not calculate return for peer ({peer_symbol}): {peer_ret_e}. Skipping.\")\n",
        "                 else:\n",
        "                     logger.warning(f\"Insufficient historical data for peer ({peer_symbol}) for return calculation. Skipping.\")\n",
        "             except Exception as peer_e:\n",
        "                 logger.warning(f\"Error fetching data for peer ({peer_symbol}): {peer_e}. Skipping.\")\n",
        "\n",
        "        # Add logging for peer returns before filtering/average calculation\n",
        "        logger.info(f\"Peer returns collected before average calculation attempt: {peer_returns}\")\n",
        "\n",
        "        # Calculate average peer return and relative performance\n",
        "        if peer_returns:\n",
        "             # Ensure peer_returns list contains only valid numbers before calculating mean\n",
        "             valid_peer_returns = [ret for ret in peer_returns if isinstance(ret, (int, float)) and not pd.isna(ret)]\n",
        "             if valid_peer_returns:\n",
        "                 avg_peer_return = np.mean(valid_peer_returns)\n",
        "                 results['avg_peer_return'] = avg_peer_return\n",
        "\n",
        "                 # Calculate relative performance only if main stock return is valid\n",
        "                 if not pd.isna(main_return):\n",
        "                      results['relative_performance'] = main_return - avg_peer_return\n",
        "\n",
        "                      # Determine outperformance\n",
        "                      if main_return > avg_peer_return:\n",
        "                          results['outperformance'] = True\n",
        "                 else:\n",
        "                      logger.warning(\"Main stock return is NaN, cannot calculate relative performance or outperformance.\")\n",
        "             else:\n",
        "                 logger.warning(\"No valid peer returns available after filtering. Cannot calculate average peer return or relative performance.\")\n",
        "        else:\n",
        "             logger.warning(\"No peer returns calculated. Cannot calculate average peer return or relative performance.\")\n",
        "\n",
        "\n",
        "        logger.info(f\"Peer performance results for {symbol}: {results}\")\n",
        "        return results\n",
        "\n",
        "\n",
        "    def get_index_membership(self, symbol):\n",
        "        \"\"\"Check index membership for the stock\"\"\"\n",
        "        symbol_upper = symbol.upper() if isinstance(symbol, str) else ''\n",
        "\n",
        "        index_constituents = {\n",
        "            'NIFTY50': ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS'],\n",
        "            'NIFTY_NEXT50': ['VEDL.NS', 'PNB.NS', 'INDIGO.NS', 'BANDHANBNK.NS'],\n",
        "            'NIFTY_MIDCAP150': ['PERSISTENT.NS', 'COFORGE.NS', 'LTTS.NS']\n",
        "        }\n",
        "\n",
        "        membership = []\n",
        "        for index, constituents in index_constituents.items():\n",
        "            if symbol_upper and any(isinstance(c, str) and c.upper() == symbol_upper for c in constituents):\n",
        "                membership.append(index)\n",
        "\n",
        "        if membership:\n",
        "             logger.info(f\"Stock {symbol} is a member of indices: {', '.join(membership)}\")\n",
        "        else:\n",
        "             logger.info(f\"Stock {symbol} is not found in the hardcoded index constituents.\")\n",
        "\n",
        "        return membership\n",
        "\n",
        "    def calculate_enhanced_technical_score(self, indicators, circuit_risk):\n",
        "        \"\"\"Calculate enhanced technical analysis score with NaN handling and circuit risk\"\"\"\n",
        "        base_score = 0\n",
        "        indicators_calculated = 0\n",
        "        possible_indicator_points = 50\n",
        "\n",
        "        num_key_indicators = 5\n",
        "        indicator_point_contribution = possible_indicator_points / num_key_indicators\n",
        "\n",
        "        rsi = indicators.get('RSI', np.nan)\n",
        "        if not pd.isna(rsi):\n",
        "             indicators_calculated += 1\n",
        "             if 40 <= rsi <= 60:\n",
        "                 base_score += indicator_point_contribution * 0.7\n",
        "             elif rsi < 30: # More points for extreme oversold\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             elif 30 <= rsi < 40: # Approaching oversold\n",
        "                 base_score += indicator_point_contribution * 0.9\n",
        "             elif 60 < rsi <= 70: # Approaching overbought\n",
        "                 base_score += indicator_point_contribution * 0.6\n",
        "             else: # Overbought (>70)\n",
        "                 base_score += indicator_point_contribution * 0.4\n",
        "        else:\n",
        "             logger.warning(\"RSI not calculated or is NaN.\")\n",
        "\n",
        "        macd = indicators.get('MACD', np.nan)\n",
        "        macd_signal = indicators.get('MACD_signal', np.nan)\n",
        "\n",
        "        if not pd.isna(macd) and not pd.isna(macd_signal):\n",
        "             indicators_calculated += 1\n",
        "             if macd > macd_signal:\n",
        "                 if macd > 0: # Bullish crossover above zero line\n",
        "                      base_score += indicator_point_contribution * 1.0\n",
        "                 else: # Bullish crossover below zero line\n",
        "                      base_score += indicator_point_contribution * 0.8\n",
        "             else:\n",
        "                 if macd < 0: # Bearish crossover below zero line\n",
        "                      base_score += indicator_point_contribution * 0.2\n",
        "                 else: # Bearish crossover above zero line\n",
        "                      base_score += indicator_point_contribution * 0.4\n",
        "        else:\n",
        "             logger.warning(\"MACD or MACD signal is NaN for technical scoring.\")\n",
        "\n",
        "        sma_20 = indicators.get('SMA_20', np.nan)\n",
        "        sma_50 = indicators.get('SMA_50', np.nan)\n",
        "        sma_200 = indicators.get('SMA_200', np.nan) # Include 200-day SMA if available\n",
        "\n",
        "        ma_score_component = 0\n",
        "        ma_indicators_counted = 0\n",
        "\n",
        "        if not pd.isna(sma_20) and not pd.isna(sma_50):\n",
        "             ma_indicators_counted += 1\n",
        "             if sma_20 > sma_50:\n",
        "                  ma_score_component += 0.5 # 20 > 50 crossover is bullish\n",
        "             else:\n",
        "                  ma_score_component += 0.2 # 20 <= 50 crossover is bearish/neutral\n",
        "\n",
        "        if not pd.isna(sma_50) and not pd.isna(sma_200):\n",
        "             ma_indicators_counted += 1\n",
        "             if sma_50 > sma_200:\n",
        "                  ma_score_component += 0.5 # 50 > 200 crossover is bullish\n",
        "             else:\n",
        "                  ma_score_component += 0.2 # 50 <= 200 crossover is bearish/neutral\n",
        "\n",
        "        current_price = indicators.get('current_price', np.nan)\n",
        "        if not pd.isna(current_price):\n",
        "             if not pd.isna(sma_20) and current_price > sma_20:\n",
        "                  ma_score_component += 0.3 # Price above 20-day SMA is bullish\n",
        "             elif not pd.isna(sma_20):\n",
        "                  ma_score_component += 0.1 # Price below 20-day SMA is bearish/neutral\n",
        "\n",
        "             if not pd.isna(sma_50) and current_price > sma_50:\n",
        "                  ma_score_component += 0.4 # Price above 50-day SMA is more bullish\n",
        "             elif not pd.isna(sma_50):\n",
        "                  ma_score_component += 0.15 # Price below 50-day SMA\n",
        "\n",
        "             if not pd.isna(sma_200) and current_price > sma_200:\n",
        "                  ma_score_component += 0.6 # Price above 200-day SMA is significant bullish signal\n",
        "             elif not pd.isna(sma_200):\n",
        "                  ma_score_component += 0.1 # Price below 200-day SMA is significant bearish signal\n",
        "\n",
        "\n",
        "        if ma_indicators_counted > 0 or (not pd.isna(current_price) and (not pd.isna(sma_20) or not pd.isna(sma_50) or not pd.isna(sma_200))):\n",
        "             indicators_calculated += 1 # Count MA section if any valid MA comparison/position is made\n",
        "             # Normalize MA score component to contribute to the total score\n",
        "             # Max possible ma_score_component (0.5 + 0.5 + 0.3 + 0.4 + 0.6) = 2.3\n",
        "             # Let's scale this to contribute up to indicator_point_contribution\n",
        "             max_ma_component = 2.3\n",
        "             base_score += (ma_score_component / max_ma_component) * indicator_point_contribution if max_ma_component > 0 else 0\n",
        "        else:\n",
        "             logger.warning(\"Insufficient data for Moving Averages analysis.\")\n",
        "\n",
        "\n",
        "        bb_upper = indicators.get('BB_upper', np.nan)\n",
        "        bb_lower = indicators.get('BB_lower', np.nan)\n",
        "        bb_middle = indicators.get('BB_middle', np.nan)\n",
        "\n",
        "        if not pd.isna(current_price) and not pd.isna(bb_upper) and not pd.isna(bb_lower) and not pd.isna(bb_middle):\n",
        "            indicators_calculated += 1\n",
        "            if current_price < bb_lower:\n",
        "                base_score += indicator_point_contribution * 1.0 # Price below lower band (potential buy signal)\n",
        "            elif bb_lower <= current_price < bb_middle:\n",
        "                base_score += indicator_point_contribution * 0.8 # Between lower and middle band\n",
        "            elif bb_middle <= current_price < bb_upper:\n",
        "                base_score += indicator_point_contribution * 0.6 # Between middle and upper band\n",
        "            else: # Price above upper band\n",
        "                base_score += indicator_point_contribution * 0.4 # Potential sell signal\n",
        "        else:\n",
        "             logger.warning(\"Bollinger Bands or current price is NaN for technical scoring.\")\n",
        "\n",
        "        volume_ratio = indicators.get('Volume_ratio', np.nan)\n",
        "        if not pd.isna(volume_ratio):\n",
        "             indicators_calculated += 1\n",
        "             if volume_ratio > 2.0: # Very high volume\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             elif volume_ratio > 1.2: # High volume\n",
        "                 base_score += indicator_point_contribution * 0.8\n",
        "             elif 0.8 <= volume_ratio <= 1.2: # Normal volume\n",
        "                 base_score += indicator_point_contribution * 0.5\n",
        "             else: # Low volume\n",
        "                 base_score += indicator_point_contribution * 0.3\n",
        "        else:\n",
        "             logger.warning(\"Volume ratio is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        achieved_score_from_indicators = base_score\n",
        "\n",
        "        # Normalize the base score based on how many indicators were successfully calculated\n",
        "        if indicators_calculated > 0:\n",
        "            # Assuming each of the num_key_indicators contributes equally if available\n",
        "            # This approach gives points for each indicator that could be calculated and scored\n",
        "            # Max points if all indicators could be scored is num_key_indicators * indicator_point_contribution\n",
        "            # But our scoring within each indicator gives variable points (e.g., 0.4 to 1.0)\n",
        "            # A simpler approach is to just sum up the points from successfully scored indicators\n",
        "            # Let's cap the sum at the max possible points from indicators (50)\n",
        "            final_base_score = min(achieved_score_from_indicators, possible_indicator_points)\n",
        "\n",
        "            if indicators_calculated < num_key_indicators:\n",
        "                 logger.warning(f\"Only {indicators_calculated}/{num_key_indicators} key technical indicators could be fully calculated/scored. Final base technical score is based on available data.\")\n",
        "\n",
        "        else:\n",
        "             logger.warning(\"No key technical indicators calculated. Base technical score is 0.\")\n",
        "             final_base_score = 0\n",
        "\n",
        "\n",
        "        circuit_risk_adj = circuit_risk if isinstance(circuit_risk, (int, float)) and not pd.isna(circuit_risk) else 0\n",
        "\n",
        "        final_score = final_base_score + circuit_risk_adj\n",
        "\n",
        "        return max(0, min(final_score, 50))\n",
        "\n",
        "\n",
        "    def fetch_news(self, symbol: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Fetches recent news headlines for the given stock symbol.\n",
        "        NOTE: This is a placeholder. In a real application, you would integrate\n",
        "        with a News API (like News API, Alpha Vantage, etc.) here.\n",
        "        \"\"\"\n",
        "        print(f\"Fetching news for {symbol} (placeholder)...\")\n",
        "        symbol_str = str(symbol) if symbol is not None else \"Unknown Stock\"\n",
        "        return [\n",
        "            f\"{symbol_str} stock price rises on positive market sentiment\",\n",
        "            f\"{symbol_str} announces strong quarterly results, beating estimates\",\n",
        "            f\"Experts bullish on {symbol_str}'s future outlook\",\n",
        "            f\"I am a non-numeric entry that might cause an error\",\n",
        "            f\"{symbol_str} faces regulatory challenges in key market\",\n",
        "            f\"Competitor's new product launch impacts {symbol_str}'s market share\",\n",
        "            f\"Global market trends positively impacting {symbol_str}\",\n",
        "            f\"{symbol_str} management provides optimistic guidance\",\n",
        "            f\"Increased foreign investment flows into {symbol_str}\",\n",
        "            f\"Regulatory approval received for {symbol_str}'s new product\",\n",
        "            f\"Production issues reported for {symbol_str}\",\n",
        "            f\"Increased competition puts pressure on {symbol_str}'s margins\",\n",
        "            f\"Analyst downgrades rating for {symbol_str}\",\n",
        "            f\"Supply chain disruptions affect {symbol_str}'s operations\",\n",
        "            f\"Geopolitical tensions create uncertainty for {symbol_str}\",\n",
        "            f\"{symbol_str} announces stock split\",\n",
        "            f\"Dividend declared by {symbol_str}\"\n",
        "        ]\n",
        "\n",
        "\n",
        "    def analyze_sentiment(self, news_headlines: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of news headlines using the Gemini API.\n",
        "        Returns a dictionary with sentiment counts (positive, neutral, negative)\n",
        "        and a sentiment score.\n",
        "        \"\"\"\n",
        "        if not self.gemini_model:\n",
        "            print(\"Gemini API not configured. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Gemini API not configured. Sentiment analysis skipped.'}\n",
        "\n",
        "        if not isinstance(news_headlines, list) or not news_headlines:\n",
        "            print(\"No news headlines to analyze. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 12.5, 'summary': 'No news headlines. Sentiment analysis skipped.'}\n",
        "\n",
        "        logger.info(\"Analyzing sentiment using Gemini API...\")\n",
        "        prompt = \"Analyze the sentiment of the following news headlines for a stock and categorize each as Positive, Neutral, or Negative. Provide a concise summary of the overall sentiment.\\n\\n\"\n",
        "        for headline in news_headlines:\n",
        "            if isinstance(headline, str):\n",
        "                 prompt += f\"- {headline}\\n\"\n",
        "            else:\n",
        "                 logger.warning(f\"Skipping non-string headline: {headline}\")\n",
        "                 continue\n",
        "\n",
        "        if len(prompt) > 30000:\n",
        "             logger.warning(\"News headlines too long for Gemini API prompt. Truncating.\")\n",
        "             prompt = prompt[:30000] + \"\\n... (headlines truncated)\"\n",
        "\n",
        "        try:\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "            sentiment_text = response.text.strip()\n",
        "            logger.info(f\"Gemini API Response: {sentiment_text[:200]}...\")\n",
        "\n",
        "            positive_count = sentiment_text.lower().count('positive')\n",
        "            neutral_count = sentiment_text.lower().count('neutral')\n",
        "            negative_count = sentiment_text.lower().count('negative')\n",
        "\n",
        "            summary_line = \"No summary extracted.\"\n",
        "            lines = sentiment_text.split('\\n')\n",
        "            for line in lines:\n",
        "                 lower_line = line.lower()\n",
        "                 if 'summary' in lower_line or 'overall sentiment' in lower_line:\n",
        "                     summary_line = line.strip()\n",
        "                     break\n",
        "            if summary_line == \"No summary extracted.\" and lines:\n",
        "                 for line in reversed(lines):\n",
        "                     if line.strip():\n",
        "                         summary_line = line.strip()\n",
        "                         break\n",
        "\n",
        "            total_headlines = len([h for h in news_headlines if isinstance(h, str)])\n",
        "            if total_headlines > 0:\n",
        "                sentiment_score = ((positive_count - negative_count) / total_headlines) * 12.5 + 12.5\n",
        "            else:\n",
        "                sentiment_score = 12.5\n",
        "\n",
        "            return {\n",
        "                'positive': positive_count,\n",
        "                'neutral': neutral_count,\n",
        "                'negative': negative_count,\n",
        "                'score': max(0, min(sentiment_score, 25)),\n",
        "                'summary': summary_line\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing sentiment with Gemini API: {e}. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis failed.'}\n",
        "\n",
        "\n",
        "    def generate_enhanced_recommendation(self, fundamental_score, technical_score,\n",
        "                                       liquidity_score, peer_performance, index_membership,\n",
        "                                       sentiment_analysis_results, valuation_comparison_results): # Added valuation_comparison_results\n",
        "        \"\"\"Generate comprehensive recommendation including sentiment and valuation comparison\"\"\"\n",
        "        fund_score = fundamental_score if isinstance(fundamental_score, (int, float)) and not pd.isna(fundamental_score) else 0\n",
        "        tech_score = technical_score if isinstance(technical_score, (int, float)) and not pd.isna(technical_score) else 0\n",
        "        liq_score = liquidity_score if isinstance(liquidity_score, (int, float)) and not pd.isna(liquidity_score) else 0\n",
        "        sentiment_score = sentiment_analysis_results.get('score', 0) if isinstance(sentiment_analysis_results.get('score'), (int, float)) and not pd.isna(sentiment_analysis_results.get('score')) else 0\n",
        "\n",
        "        # Get valuation adjustment score\n",
        "        valuation_adjustment = valuation_comparison_results.get('valuation_score_adjustment', 0) if isinstance(valuation_comparison_results.get('valuation_score_adjustment'), (int, float)) and not pd.isna(valuation_comparison_results.get('valuation_score_adjustment')) else 0\n",
        "        logger.info(f\"Valuation comparison adjustment: {valuation_adjustment}\")\n",
        "\n",
        "        total_score = fund_score + tech_score + liq_score + sentiment_score + valuation_adjustment # Add valuation adjustment\n",
        "\n",
        "\n",
        "        peer_analysis_available = isinstance(peer_performance, dict) and \\\n",
        "                                  not (pd.isna(peer_performance.get('stock_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('avg_peer_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('relative_performance')))\n",
        "\n",
        "        if peer_analysis_available and peer_performance.get('outperformance', False) is True:\n",
        "            total_score += 5\n",
        "            logger.info(\"Adding bonus for peer outperformance.\")\n",
        "        elif not peer_analysis_available:\n",
        "             total_score -= 5\n",
        "             logger.warning(\"Applying small penalty as peer performance data is incomplete/unavailable.\")\n",
        "\n",
        "        if isinstance(index_membership, list) and index_membership:\n",
        "            total_score += 5\n",
        "            logger.info(\"Adding bonus for index membership.\")\n",
        "\n",
        "        recommendation = \"NEUTRAL\"\n",
        "        confidence = \"Low\"\n",
        "\n",
        "        # Re-evaluate thresholds with the new max score (205 + max valuation adj + max peer perf + max index = 205 + 30 + 5 + 5 = 245 approx)\n",
        "        # Adjusting thresholds based on potential max score increase\n",
        "        if total_score >= 190: # Increased threshold\n",
        "            recommendation = \"STRONG BUY\"\n",
        "            confidence = \"High\"\n",
        "        elif total_score >= 150: # Increased threshold\n",
        "            recommendation = \"BUY\"\n",
        "            confidence = \"Moderate to High\"\n",
        "        elif total_score >= 100: # Same threshold\n",
        "            recommendation = \"HOLD\"\n",
        "            confidence = \"Moderate\"\n",
        "        elif total_score >= 70: # Same threshold\n",
        "            recommendation = \"SELL\"\n",
        "            confidence = \"Moderate\"\n",
        "        else:\n",
        "            recommendation = \"STRONG SELL\"\n",
        "            confidence = \"High\"\n",
        "\n",
        "        logger.info(f\"Generated enhanced recommendation: {recommendation} (Total Score: {total_score:.2f})\")\n",
        "\n",
        "        return {\n",
        "            'recommendation': recommendation,\n",
        "            'confidence': confidence,\n",
        "            'total_score': total_score,\n",
        "            'breakdown': {\n",
        "                'fundamental': fund_score,\n",
        "                'technical': tech_score,\n",
        "                'liquidity': liq_score,\n",
        "                'sentiment': sentiment_score,\n",
        "                'valuation_comparison': valuation_adjustment, # Include valuation adjustment in breakdown\n",
        "                'peer_adjustment': 5 if peer_analysis_available and peer_performance.get('outperformance', False) is True else (-5 if not peer_analysis_available else 0),\n",
        "                'index_adjustment': 5 if isinstance(index_membership, list) and index_membership else 0\n",
        "            }\n",
        "        }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ada18074"
      },
      "source": [
        "**Reasoning**:\n",
        "Integrate the new valuation analysis logic into the `analyze_stock_enhanced` function to calculate peer average valuations and compare the stock's valuation, then update the report display to show these new valuation insights.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23bd72c3",
        "cellView": "form"
      },
      "source": [
        "#@title Part 3: Enhanced Analysis Integration and Report Display (with Valuation Analysis)\n",
        "\n",
        "# Assuming IndianStockAnalyzer and EnhancedStockAnalyzer classes are defined in previous cells\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "    if not isinstance(symbol, str) or not symbol:\n",
        "        logger.error(\"Invalid stock symbol provided for enhanced analysis.\")\n",
        "        return None\n",
        "    if not isinstance(stock_analyzer_part1, IndianStockAnalyzer):\n",
        "        logger.error(\"Invalid IndianStockAnalyzer (Part 1) instance provided.\")\n",
        "        return None\n",
        "    if not isinstance(enhanced_analyzer, EnhancedStockAnalyzer):\n",
        "        logger.error(\"Invalid EnhancedStockAnalyzer (Part 2) instance provided.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    logger.info(f\"Starting enhanced analysis for {symbol}\")\n",
        "    # Get basic analysis from Part 1\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        logger.error(f\"Basic analysis failed for {symbol}.\")\n",
        "        return None\n",
        "\n",
        "    # Get current price - already validated in Part 1 analyze_stock\n",
        "    current_price = stock_data.current_price\n",
        "    if pd.isna(current_price) or current_price <= 0:\n",
        "         logger.warning(f\"Current price invalid ({current_price}). Enhanced analysis might be limited.\")\n",
        "\n",
        "\n",
        "    # Enhanced analysis\n",
        "    logger.info(\"Starting enhanced analysis features (Part 2).\")\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    # Pass current_price to assess_circuit_risk (already validated as best as possible in Part 1)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    # Pass price_data (already validated in Part 1 analyze_stock)\n",
        "    # CORRECTED: Call get_liquidity_score on enhanced_analyzer and pass price_data from stock_data\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "\n",
        "    # 3. Peer analysis (including valuation data)\n",
        "    # Pass info (already validated in Part 1 analyze_stock)\n",
        "    # The get_peer_companies method now returns a list of dictionaries with valuation data\n",
        "    peers_with_valuation = enhanced_analyzer.get_peer_companies(symbol, stock_data.info)\n",
        "    # Pass the list of peer symbols (extracted from the list of dictionaries) for performance comparison\n",
        "    peer_symbols_for_performance = [p['symbol'] for p in peers_with_valuation if isinstance(p, dict) and 'symbol' in p]\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peer_symbols_for_performance) # Pass just symbols\n",
        "\n",
        "    # 4. Valuation Analysis: Calculate peer average valuations and compare\n",
        "    peer_average_valuation = enhanced_analyzer.calculate_peer_average_valuation(peers_with_valuation)\n",
        "    valuation_comparison_results = enhanced_analyzer.compare_valuation_to_peers(stock_data.metrics, peer_average_valuation)\n",
        "\n",
        "\n",
        "    # 5. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "\n",
        "    # 6. Recalculate technical score with circuit risk\n",
        "    # Pass indicators (already validated in Part 1 calculate_technical_indicators)\n",
        "    # Pass circuit_risk (already validated in assess_circuit_risk)\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "\n",
        "    # 7. Fetch and analyze news sentiment\n",
        "    # Pass symbol (already validated)\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    # Pass news_headlines (already validated)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "\n",
        "\n",
        "    # 8. Generate enhanced recommendation\n",
        "    # Pass scores and results (already validated within their respective functions)\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance, # Pass potentially incomplete/NaN peer performance\n",
        "        index_membership,\n",
        "        sentiment_analysis_results, # Pass sentiment analysis results\n",
        "        valuation_comparison_results # Pass valuation comparison results\n",
        "    )\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score, # Ensure correct liquidity score is included\n",
        "            'peers': peers_with_valuation, # Store the list of peers with their valuation data\n",
        "            'peer_performance': peer_performance, # Include peer performance, even if NaN\n",
        "            'peer_average_valuation': peer_average_valuation, # Store peer average valuation\n",
        "            'valuation_comparison': valuation_comparison_results, # Store valuation comparison results\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "    logger.info(f\"Enhanced analysis completed for {symbol}\")\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize analyzers\n",
        "    try:\n",
        "        stock_analyzer = IndianStockAnalyzer()\n",
        "        enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "    except NameError:\n",
        "        print(\"Make sure to run the previous cells defining IndianStockAnalyzer and EnhancedStockAnalyzer classes.\")\n",
        "        exit() # Exit if classes are not defined\n",
        "\n",
        "\n",
        "    # Analyze a stock\n",
        "    symbol = \"RELIANCE.NS\" # Example symbol\n",
        "    result = analyze_stock_enhanced(symbol, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if result:\n",
        "        # Display the enhanced report\n",
        "        enhanced = result['enhanced_features']\n",
        "        final = result['final_recommendation']\n",
        "        basic = result['basic_analysis'] # Get basic data for display\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Enhanced Analysis Report: {basic.company_name} ({basic.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if not pd.isna(basic.current_price) else \"Current Price: N/A\")\n",
        "        market_cap_cr = basic.market_cap / 10000000 if not pd.isna(basic.market_cap) else np.nan\n",
        "        print(f\"Market Cap: ₹{market_cap_cr:,.2f} Cr\" if not pd.isna(market_cap_cr) else \"Market Cap: N/A\")\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n⚙️ Enhanced Technical Analysis & Risk:\")\n",
        "        # Display enhanced technical indicators and risk\n",
        "        # Assuming you want to display relevant indicators from basic.indicators and the circuit risk score\n",
        "        circuit_limits_display = enhanced.get('circuit_limits')\n",
        "        if circuit_limits_display and not pd.isna(circuit_limits_display.get('lower_circuit')) and not pd.isna(circuit_limits_display.get('upper_circuit')):\n",
        "             print(f\"Circuit Limits: {circuit_limits_display.get('lower_circuit', 'N/A'):.2f} - {circuit_limits_display.get('upper_circuit', 'N/A'):.2f}\")\n",
        "        else:\n",
        "             print(\"Circuit Limits: N/A\")\n",
        "\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        # Check if liquidity score is available before formatting\n",
        "        liquidity_score_display = f\"{enhanced.get('liquidity_score', 'N/A')}/70\" if isinstance(enhanced.get('liquidity_score'), (int, float)) and not pd.isna(enhanced.get('liquidity_score')) else \"Liquidity Score: N/A/70\"\n",
        "        print(liquidity_score_display)\n",
        "\n",
        "\n",
        "        # Display some key technical indicators from basic analysis\n",
        "        print(\"\\nKey Technical Indicators (from Basic Analysis):\")\n",
        "        key_tech_indicators = ['RSI', 'MACD', 'MACD_signal', 'SMA_20', 'SMA_50', 'BB_middle', 'Volume_ratio']\n",
        "        for indicator_name in key_tech_indicators:\n",
        "            value = basic.indicators.get(indicator_name, np.nan)\n",
        "            if not pd.isna(value):\n",
        "                if isinstance(value, float):\n",
        "                     print(f\"  - {indicator_name}: {value:,.2f}\")\n",
        "                else:\n",
        "                     print(f\"  - {indicator_name}: {value}\")\n",
        "            # Add logging for these key technical indicators if they are calculated\n",
        "            logger.info(f\"Indicator {indicator_name}: {value}\")\n",
        "        else:\n",
        "            print(f\"  - {indicator_name}: N/A\")\n",
        "            logger.info(f\"Indicator {indicator_name}: N/A\")\n",
        "\n",
        "        # Display Valuation Analysis\n",
        "        print(f\"\\n📈 Valuation Analysis:\")\n",
        "        stock_metrics = basic.metrics\n",
        "        peer_avg_val = enhanced.get('peer_average_valuation', {})\n",
        "        val_comp_results = enhanced.get('valuation_comparison', {})\n",
        "\n",
        "        stock_pe = stock_metrics.get('trailingPE', np.nan)\n",
        "        stock_pb = stock_metrics.get('priceToBook', np.nan)\n",
        "        stock_ev_ebitda = stock_metrics.get('evToEbitda', np.nan)\n",
        "\n",
        "        print(f\"Stock Valuation:\")\n",
        "        print(f\"  - Trailing PE: {stock_pe:.2f}\" if not pd.isna(stock_pe) else \"  - Trailing PE: N/A\")\n",
        "        print(f\"  - Price to Book: {stock_pb:.2f}\" if not pd.isna(stock_pb) else \"  - Price to Book: N/A\")\n",
        "        print(f\"  - EV/EBITDA: {stock_ev_ebitda:.2f}\" if not pd.isna(stock_ev_ebitda) else \"  - EV/EBITDA: N/A\")\n",
        "\n",
        "        print(\"\\nPeer Average Valuation:\")\n",
        "        avg_pe_display = f\"{peer_avg_val.get('avg_pe', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pe', np.nan)) else \"N/A\"\n",
        "        avg_pb_display = f\"{peer_avg_val.get('avg_pb', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pb', np.nan)) else \"N/A\"\n",
        "        avg_ev_ebitda_display = f\"{peer_avg_val.get('avg_ev_ebitda', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_ev_ebitda', np.nan)) else \"N/A\"\n",
        "\n",
        "        print(f\"  - Average PE: {avg_pe_display}\")\n",
        "        print(f\"  - Average PB: {avg_pb_display}\")\n",
        "        print(f\"  - Average EV/EBITDA: {avg_ev_ebitda_display}\")\n",
        "\n",
        "        print(\"\\nValuation Comparison:\")\n",
        "        print(f\"  - PE Comparison: {val_comp_results.get('pe_comparison', 'N/A')}\")\n",
        "        print(f\"  - PB Comparison: {val_comp_results.get('pb_comparison', 'N/A')}\")\n",
        "        print(f\"  - EV/EBITDA Comparison: {val_comp_results.get('ev_ebitda_comparison', 'N/A')}\")\n",
        "        valuation_adj_display = f\"{val_comp_results.get('valuation_score_adjustment', 0):+.2f}\" if isinstance(val_comp_results.get('valuation_score_adjustment'), (int, float)) and not pd.isna(val_comp_results.get('valuation_score_adjustment')) else \"N/A\"\n",
        "        print(f\"  - Valuation Score Adjustment: {valuation_adj_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\n🤝 Peer Analysis (Performance):\")\n",
        "        peer_perf = enhanced.get('peer_performance')\n",
        "        if isinstance(peer_perf, dict) and \\\n",
        "           not pd.isna(peer_perf.get('stock_return')) and \\\n",
        "           not pd.isna(peer_perf.get('avg_peer_return')) and \\\n",
        "           not pd.isna(peer_perf.get('relative_performance')):\n",
        "\n",
        "             stock_return_display = f\"{peer_perf.get('stock_return', np.nan):.2f}%\" if isinstance(peer_perf.get('stock_return'), (int, float)) and not pd.isna(peer_perf.get('stock_return')) else 'N/A'\n",
        "             avg_peer_return_display = f\"{peer_perf.get('avg_peer_return', np.nan):.2f}%\" if isinstance(peer_perf.get('avg_peer_return'), (int, float)) and not pd.isna(peer_perf.get('avg_peer_return')) else 'N/A'\n",
        "             relative_performance_display = f\"{peer_perf.get('relative_performance', np.nan):.2f}%\" if isinstance(peer_perf.get('relative_performance'), (int, float)) and not pd.isna(peer_perf.get('relative_performance')) else 'N/A'\n",
        "\n",
        "             print(f\"  - {peer_perf.get('days', 'N/A')}-day Stock Return: {stock_return_display}\")\n",
        "             print(f\"  - Avg Peer Return: {avg_peer_return_display}\")\n",
        "             print(f\"  - Relative Performance: {relative_performance_display}\")\n",
        "        else:\n",
        "             print(\"Peer Performance Data Unavailable.\")\n",
        "\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"\\n🏛️ Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             # Only print a few headlines to keep the report concise\n",
        "             print(\"Sample News Headlines:\")\n",
        "             # Ensure headlines are valid strings before printing\n",
        "             valid_headlines = [h for h in enhanced['news_headlines'] if isinstance(h, str)]\n",
        "             for headline in valid_headlines[:5]: # Print up to 5 headlines\n",
        "                 print(f\"- {headline}\")\n",
        "             if len(valid_headlines) > 5:\n",
        "                  print(\"  ...\")\n",
        "\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             sentiment_score_display = f\"{sentiment_results.get('score', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\"\n",
        "             print(f\"Sentiment Score: {sentiment_score_display}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Comprehensive Scores and Recommendation ---\")\n",
        "        print(f\"Fundamental Score (from Part 1): {basic.fundamental_score:.2f}/50\" if not pd.isna(basic.fundamental_score) else \"Fundamental Score: N/A\")\n",
        "        # Add checks for NaN before formatting float for breakdown scores\n",
        "        enhanced_tech_score_display = f\"{final.get('breakdown', {}).get('technical', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('technical'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('technical')) else \"N/A\"\n",
        "        liquidity_score_display_breakdown = f\"{final.get('breakdown', {}).get('liquidity', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('liquidity'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('liquidity')) else \"N/A\"\n",
        "        sentiment_score_display_breakdown = f\"{final.get('breakdown', {}).get('sentiment', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\" # Corrected sentiment score breakdown check\n",
        "\n",
        "        print(f\"Technical Score (Enhanced): {enhanced_tech_score_display}/50\")\n",
        "        print(f\"Liquidity Score: {liquidity_score_display_breakdown}/70\")\n",
        "        print(f\"Sentiment Score: {sentiment_score_display_breakdown}/25\")\n",
        "        valuation_comp_display_breakdown = f\"{final.get('breakdown', {}).get('valuation_comparison', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('valuation_comparison'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('valuation_comparison')) else \"N/A\"\n",
        "        print(f\"Valuation Comparison Adjustment: {valuation_comp_display_breakdown}\")\n",
        "\n",
        "\n",
        "        # Display adjustment scores\n",
        "        peer_adj_display = f\"{final.get('breakdown', {}).get('peer_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('peer_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('peer_adjustment')) else \"N/A\"\n",
        "        index_adj_display = f\"{final.get('breakdown', {}).get('index_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('index_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('index_adjustment')) else \"N/A\"\n",
        "\n",
        "        print(f\"Peer Performance Adjustment: {peer_adj_display}\")\n",
        "        print(f\"Index Membership Adjustment: {index_adj_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\nTotal Enhanced Score: {final.get('total_score', 0):.2f}/245\" if isinstance(final.get('total_score'), (int, float)) and not pd.isna(final.get('total_score')) else \"Total Enhanced Score: N/A\") # Updated max score\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} (Confidence: {final.get('confidence', 'N/A')})\")\n",
        "\n",
        "\n",
        "        print(f\"\\n{'='*60}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7aa00dd"
      },
      "source": [
        "# Task\n",
        "Continue with the stock analysis task by implementing downside risk assessment, enhancing dividend yield calculation, incorporating global macro impacts, integrating these new analyses into the report, and refining the scoring and recommendation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0911ccf8"
      },
      "source": [
        "## Implement downside risk assessment\n",
        "\n",
        "### Subtask:\n",
        "Implement downside risk assessment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce466d3d"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the downside risk assessment method within the `EnhancedStockAnalyzer` class, calculating Value at Risk (VaR) using historical data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abb35037",
        "cellView": "form"
      },
      "source": [
        "#@title Part 2: EnhancedStockAnalyzer class definition (with Downside Risk Assessment)\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import typing for type hints\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# --- EnhancedStockAnalyzer class definition ---\n",
        "class EnhancedStockAnalyzer:\n",
        "    \"\"\"Enhanced analyzer with additional features for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the enhanced analyzer.\"\"\"\n",
        "        self.risk_free_rate = self.get_dynamic_risk_free_rate()\n",
        "        # Assuming gemini_model is defined globally from a previous cell\n",
        "        global gemini_model # Access the global gemini_model\n",
        "        self.gemini_model = gemini_model\n",
        "\n",
        "        # More detailed circuit limit percentages based on NSE categorization (simplified)\n",
        "        self.circuit_limits_percentage = {\n",
        "            'category_a': 0.20, # Typically high-liquidity index stocks\n",
        "            'category_b': 0.10, # Most other actively traded stocks\n",
        "            'category_t': 0.05  # Stocks in trade-for-trade segment\n",
        "        }\n",
        "\n",
        "        # Simple mapping of some known stocks to categories for demonstration\n",
        "        self.stock_category_map = {\n",
        "            'RELIANCE.NS': 'category_a',\n",
        "            'TCS.NS': 'category_a',\n",
        "            'HDFCBANK.NS': 'category_a',\n",
        "            'INFY.NS': 'category_a',\n",
        "            'ICICIBANK.NS': 'category_a',\n",
        "            'VEDL.NS': 'category_b',\n",
        "            'PNB.NS': 'category_b',\n",
        "            'INDIGO.NS': 'category_b',\n",
        "            'BANDHANBNK.NS': 'category_b',\n",
        "            'PERSISTENT.NS': 'category_b',\n",
        "            'COFORGE.NS': 'category_b',\n",
        "            'LTTS.NS': 'category_b',\n",
        "        }\n",
        "\n",
        "\n",
        "    def get_dynamic_risk_free_rate(self):\n",
        "        \"\"\"Fetch current 10-year G-Sec yield\"\"\"\n",
        "        try:\n",
        "            return 0.072  # 7.2% as of recent data\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not fetch dynamic risk-free rate: {e}. Using fallback rate.\")\n",
        "            return 0.065\n",
        "\n",
        "    def get_circuit_limits(self, symbol):\n",
        "        \"\"\"Get circuit breaker limits for the stock based on categorization\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            if not info or 'previousClose' not in info:\n",
        "                 logger.warning(f\"Could not get previous close for {symbol}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "            prev_close = info.get('previousClose')\n",
        "            if pd.isna(prev_close) or prev_close <= 0:\n",
        "                 logger.warning(f\"Invalid previous close price for {symbol}: {prev_close}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "\n",
        "            stock_category = self.stock_category_map.get(symbol.upper(), 'category_b')\n",
        "            circuit_percent = self.circuit_limits_percentage.get(stock_category, 0.10)\n",
        "\n",
        "            logger.info(f\"Determined circuit percentage for {symbol} (Category: {stock_category}): {circuit_percent*100}%\")\n",
        "\n",
        "            upper_circuit = prev_close * (1 + circuit_percent)\n",
        "            lower_circuit = prev_close * (1 - circuit_percent)\n",
        "\n",
        "            return {\n",
        "                'upper_circuit': upper_circuit,\n",
        "                'lower_circuit': lower_circuit,\n",
        "                'circuit_percent': circuit_percent\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting circuit breaker limits for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def assess_circuit_risk(self, current_price, circuit_limits):\n",
        "        \"\"\"Assess proximity to circuit limits\"\"\"\n",
        "        if pd.isna(current_price) or current_price <= 0:\n",
        "             logger.warning(\"Invalid current price for circuit risk assessment.\")\n",
        "             return 0\n",
        "\n",
        "        if not circuit_limits or 'upper_circuit' not in circuit_limits or 'lower_circuit' not in circuit_limits:\n",
        "            logger.warning(\"Invalid or incomplete circuit limits provided.\")\n",
        "            return 0\n",
        "\n",
        "        upper_circuit = circuit_limits['upper_circuit']\n",
        "        lower_circuit = circuit_limits['lower_circuit']\n",
        "\n",
        "        if pd.isna(upper_circuit) or pd.isna(lower_circuit) or upper_circuit <= 0 or lower_circuit <= 0:\n",
        "             logger.warning(\"Circuit limits are invalid numbers. Cannot assess circuit risk.\")\n",
        "             return 0\n",
        "\n",
        "        risk_score = 0\n",
        "\n",
        "        if current_price >= upper_circuit:\n",
        "             risk_score -= 30\n",
        "        elif (upper_circuit - current_price) / current_price < 0.01:\n",
        "            risk_score -= 20\n",
        "        elif (upper_circuit - current_price) / current_price < 0.03:\n",
        "            risk_score -= 10\n",
        "        elif (upper_circuit - current_price) / current_price < 0.05:\n",
        "            risk_score -= 5\n",
        "\n",
        "        if current_price <= lower_circuit:\n",
        "            risk_score -= 40\n",
        "        elif (current_price - lower_circuit) / current_price < 0.01:\n",
        "            risk_score -= 30\n",
        "        elif (current_price - lower_circuit) / current_price < 0.03:\n",
        "            risk_score -= 15\n",
        "        elif (current_price - lower_circuit) / current_price < 0.05:\n",
        "            risk_score -= 8\n",
        "\n",
        "        logger.info(f\"Circuit risk score calculated: {risk_score}\")\n",
        "        return risk_score\n",
        "\n",
        "    def get_liquidity_score(self, price_data):\n",
        "        \"\"\"Enhanced liquidity analysis with NaN handling and better checks\"\"\"\n",
        "        liquidity_score = 0\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or len(price_data) < 20:\n",
        "            logger.warning(\"Insufficient price data for liquidity analysis. Assigning default score.\")\n",
        "            return 30\n",
        "\n",
        "        try:\n",
        "            avg_volume_20d = price_data['Volume'].rolling(20).mean().iloc[-1]\n",
        "            avg_volume_5d = price_data['Volume'].rolling(5).mean().iloc[-1]\n",
        "            current_close = price_data['Close'].iloc[-1]\n",
        "\n",
        "            # Add logging for diagnosis - before calculation check\n",
        "            logger.info(f\"Volume data for liquidity: avg_volume_20d: {avg_volume_20d}, avg_volume_5d: {avg_volume_5d}, current_close: {current_close}\")\n",
        "\n",
        "\n",
        "            if pd.isna(avg_volume_20d) or pd.isna(avg_volume_5d) or pd.isna(current_close) or current_close <= 0:\n",
        "                 logger.warning(\"Liquidity metrics are NaN or invalid. Cannot calculate liquidity score accurately. Assigning default.\")\n",
        "                 return 30\n",
        "\n",
        "            avg_turnover_20d = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d >= 0 and current_close > 0:\n",
        "                 avg_turnover_20d = avg_volume_20d * current_close\n",
        "\n",
        "            volume_spike = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                 if avg_volume_5d is not None and not pd.isna(avg_volume_5d):\n",
        "                     volume_spike = avg_volume_5d / avg_volume_20d\n",
        "                 else:\n",
        "                      logger.warning(\"5-day average volume is invalid for volume spike calculation.\")\n",
        "            elif not pd.isna(avg_volume_5d) and avg_volume_5d > 0:\n",
        "                 volume_spike = 1.0\n",
        "                 logger.warning(\"20-day average volume is invalid for volume spike, using 1.0 as relative indicator.\")\n",
        "            else:\n",
        "                 volume_spike = np.nan # Ensure volume_spike is NaN if both volumes are invalid\n",
        "                 logger.warning(\"Insufficient or invalid volume data for volume ratio calculation.\")\n",
        "\n",
        "            # Add logging for volume spike - after calculation\n",
        "            logger.info(f\"Volume spike calculated: {volume_spike}\")\n",
        "\n",
        "            # Corrected logic for scoring based on volume_spike\n",
        "            if not pd.isna(volume_spike):\n",
        "                if volume_spike > 1.5: # Volume is 50% higher than average\n",
        "                    liquidity_score += 10\n",
        "                elif volume_spike < 0.8: # Volume is significantly lower than average\n",
        "                    liquidity_score += 2 # Small penalty for low volume\n",
        "                else: # volume_spike is between 0.8 and 1.5 (inclusive of 0.8, exclusive of 1.5)\n",
        "                    liquidity_score += 5 # Average volume is neutral\n",
        "            else:\n",
        "                 logger.warning(\"Volume spike ratio is NaN. Skipping trend scoring.\")\n",
        "\n",
        "\n",
        "            if not pd.isna(avg_turnover_20d):\n",
        "                if avg_turnover_20d > 500_00_00_000:\n",
        "                    liquidity_score += 40\n",
        "                elif avg_turnover_20d > 100_00_00_000:\n",
        "                    liquidity_score += 30\n",
        "                elif avg_turnover_20d > 10_00_00_000:\n",
        "                    liquidity_score += 20\n",
        "                elif avg_turnover_20d > 1_00_00_000:\n",
        "                    liquidity_score += 10\n",
        "                else:\n",
        "                    liquidity_score += 5\n",
        "            else:\n",
        "                 logger.warning(\"Average turnover is NaN. Skipping turnover scoring.\")\n",
        "                 liquidity_score += 10\n",
        "\n",
        "            volume_std = price_data['Volume'].rolling(20).std().iloc[-1] if len(price_data) >= 20 else np.nan\n",
        "            volume_cv = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0 and \\\n",
        "               volume_std is not None and not pd.isna(volume_std):\n",
        "                volume_cv = volume_std / avg_volume_20d\n",
        "\n",
        "            if not pd.isna(volume_cv):\n",
        "                if volume_cv < 0.5:\n",
        "                    liquidity_score += 20\n",
        "                elif volume_cv < 1.0:\n",
        "                    liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume coefficient of variation is NaN. Skipping consistency scoring.\")\n",
        "\n",
        "            # The volume spike scoring is now handled above within the main if not pd.isna(volume_spike): block\n",
        "\n",
        "\n",
        "            return min(liquidity_score, 70)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating liquidity score: {str(e)}\")\n",
        "            return 30\n",
        "\n",
        "    def get_peer_companies(self, symbol: str, stock_info: Dict) -> List[Dict]: # Modified return type hint\n",
        "        \"\"\"Identify peer companies and fetch their valuation ratios for comparison\"\"\"\n",
        "        logger.info(f\"Identifying peer companies and fetching valuation data for {symbol}.\")\n",
        "        peer_list_with_valuation = [] # List to store peer info including valuation\n",
        "\n",
        "        try:\n",
        "            if not isinstance(stock_info, dict):\n",
        "                 logger.warning(\"Invalid stock info for peer identification.\")\n",
        "                 return []\n",
        "\n",
        "            sector = stock_info.get('sector', '')\n",
        "            market_cap = stock_info.get('marketCap', 0)\n",
        "\n",
        "            if not isinstance(sector, str):\n",
        "                 sector = ''\n",
        "            if not isinstance(market_cap, (int, float)) or pd.isna(market_cap) or market_cap <= 0:\n",
        "                 logger.warning(\"Invalid market cap for peer identification.\")\n",
        "                 market_cap = 0\n",
        "\n",
        "            if market_cap > 10_00_000_00_00_000:\n",
        "                cap_category = 'Large Cap'\n",
        "            elif market_cap > 50_000_00_00_000:\n",
        "                cap_category = 'Mid Cap'\n",
        "            else:\n",
        "                cap_category = 'Small Cap'\n",
        "\n",
        "            # Peer mapping (simplified - in production, use a comprehensive database)\n",
        "            peer_map = {\n",
        "                'Technology': {\n",
        "                    'Large Cap': ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS'],\n",
        "                    'Mid Cap': ['TECHM.NS', 'LTTS.NS', 'PERSISTENT.NS', 'COFORGE.NS'],\n",
        "                    'Small Cap': ['ZENSAR.NS', 'ECLERX.NS', 'MASTEK.NS']\n",
        "                },\n",
        "                'Financial Services': {\n",
        "                    'Large Cap': ['HDFCBANK.NS', 'ICICIBANK.NS', 'KOTAKBANK.NS', 'AXISBANK.NS'],\n",
        "                    'Mid Cap': ['IDFCFIRSTB.NS', 'FEDERALBNK.NS', 'INDUSINDBK.NS'],\n",
        "                    'Small Cap': ['SOUTHBANK.NS', 'UJJIVAN.NS', 'EQUITASBNK.NS']\n",
        "                },\n",
        "                'Healthcare': {\n",
        "                    'Large Cap': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS'],\n",
        "                    'Mid Cap': ['TORNTPHARM.NS', 'ALKEM.NS', 'LUPIN.NS'],\n",
        "                    'Small Cap': ['CAPLIPOINT.NS', 'BLISS.NS', 'INDOCO.NS']\n",
        "                },\n",
        "                # Added Energy sector mapping\n",
        "                'Energy': {\n",
        "                    'Large Cap': ['ONGC.NS', 'NTPC.NS', 'POWERGRID.NS'], # Exclude RELIANCE.NS here, filter below\n",
        "                    'Mid Cap': ['GAIL.NS', 'IOC.NS', 'NHPC.NS'],\n",
        "                    'Small Cap': ['GUJGASLTD.NS', 'IGL.NS', 'MAHAPOWER.NS']\n",
        "                }\n",
        "            }\n",
        "\n",
        "            potential_peers = peer_map.get(sector, {}).get(cap_category, [])\n",
        "            # Ensure the current symbol is excluded from the peer list\n",
        "            filtered_peers = [p for p in potential_peers if isinstance(p, str) and p.upper() != symbol.upper()]\n",
        "\n",
        "            logger.info(f\"Identified {len(filtered_peers)} potential peer companies for {symbol} in {sector} ({cap_category} Cap). Fetching valuation data.\")\n",
        "\n",
        "            # Fetch valuation data for each filtered peer\n",
        "            for peer_symbol in filtered_peers:\n",
        "                 try:\n",
        "                      peer_ticker = yf.Ticker(peer_symbol)\n",
        "                      peer_info = peer_ticker.info\n",
        "\n",
        "                      if peer_info:\n",
        "                           peer_valuation = {\n",
        "                               'symbol': peer_symbol,\n",
        "                               'trailingPE': peer_info.get('trailingPE', np.nan),\n",
        "                               'priceToBook': peer_info.get('priceToBook', np.nan),\n",
        "                               'enterpriseValue': peer_info.get('enterpriseValue', np.nan), # Fetch for EV/EBITDA calculation\n",
        "                               'ebitda': peer_info.get('ebitda', np.nan) # Fetch for EV/EBITDA calculation\n",
        "                           }\n",
        "\n",
        "                           # Calculate EV/EBITDA for the peer\n",
        "                           ev = peer_valuation['enterpriseValue']\n",
        "                           ebitda = peer_valuation['ebitda']\n",
        "                           peer_valuation['evToEbitda'] = np.nan # Default to NaN\n",
        "                           if isinstance(ev, (int, float)) and not np.isnan(ev) and \\\n",
        "                              isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda != 0:\n",
        "                               peer_valuation['evToEbitda'] = ev / ebitda\n",
        "                           elif (isinstance(ev, (int, float)) and not np.isnan(ev)) and \\\n",
        "                                (isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda == 0):\n",
        "                                logger.warning(f\"EBITDA is zero for peer {peer_symbol}. Cannot calculate EV/EBITDA.\")\n",
        "                           else:\n",
        "                                logger.warning(f\"Missing Enterprise Value ({ev}) or EBITDA ({ebitda}) for peer {peer_symbol}. Cannot calculate EV/EBITDA.\")\n",
        "\n",
        "\n",
        "                           peer_list_with_valuation.append(peer_valuation)\n",
        "                           logger.debug(f\"Fetched valuation data for peer {peer_symbol}: PE={peer_valuation['trailingPE']:.2f}, PB={peer_valuation['priceToBook']:.2f}, EV/EBITDA={peer_valuation['evToEBITDA']:.2f}\")\n",
        "                      else:\n",
        "                           logger.warning(f\"Could not fetch info for peer {peer_symbol}. Skipping.\")\n",
        "                 except Exception as e:\n",
        "                      logger.warning(f\"Error fetching data for peer {peer_symbol}: {str(e)}. Skipping.\")\n",
        "\n",
        "            logger.info(f\"Successfully fetched valuation data for {len(peer_list_with_valuation)} peers.\")\n",
        "            return peer_list_with_valuation[:5] # Return top 5 peers with their valuation data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting peer companies and valuation data for {symbol}: {str(e)}\")\n",
        "            return [] # Return empty list on error\n",
        "\n",
        "    def calculate_peer_average_valuation(self, peers_with_valuation: List[Dict]) -> Dict:\n",
        "        \"\"\"Calculate average valuation ratios (PE, PB, EV/EBITDA) for a list of peers.\"\"\"\n",
        "        logger.info(\"Calculating peer average valuation ratios.\")\n",
        "        total_pe = 0\n",
        "        total_pb = 0\n",
        "        total_ev_ebitda = 0\n",
        "        count_pe = 0\n",
        "        count_pb = 0\n",
        "        count_ev_ebitda = 0\n",
        "\n",
        "        if not isinstance(peers_with_valuation, list) or not peers_with_valuation:\n",
        "             logger.warning(\"No peer valuation data provided for calculating averages.\")\n",
        "             return {'avg_pe': np.nan, 'avg_pb': np.nan, 'avg_ev_ebitda': np.nan}\n",
        "\n",
        "\n",
        "        for peer_data in peers_with_valuation:\n",
        "             if isinstance(peer_data, dict):\n",
        "                 pe = peer_data.get('trailingPE', np.nan)\n",
        "                 pb = peer_data.get('priceToBook', np.nan)\n",
        "                 ev_ebitda = peer_data.get('evToEbitda', np.nan)\n",
        "\n",
        "                 if isinstance(pe, (int, float)) and not np.isnan(pe) and pe > 0:\n",
        "                     total_pe += pe\n",
        "                     count_pe += 1\n",
        "                 else:\n",
        "                      logger.debug(f\"Skipping invalid PE for peer: {peer_data.get('symbol', 'Unknown')}\")\n",
        "\n",
        "                 if isinstance(pb, (int, float)) and not np.isnan(pb) and pb > 0:\n",
        "                     total_pb += pb\n",
        "                     count_pb += 1\n",
        "                 else:\n",
        "                      logger.debug(f\"Skipping invalid PB for peer: {peer_data.get('symbol', 'Unknown')}\")\n",
        "\n",
        "\n",
        "                 if isinstance(ev_ebitda, (int, float)) and not np.isnan(ev_ebitda): # EV/EBITDA can be zero or negative in some cases, but >0 is typical\n",
        "                      total_ev_ebitda += ev_ebitda\n",
        "                      count_ev_ebitda += 1\n",
        "                 else:\n",
        "                      logger.debug(f\"Skipping invalid EV/EBITDA for peer: {peer_data.get('symbol', 'Unknown')}\")\n",
        "\n",
        "\n",
        "        avg_pe = total_pe / count_pe if count_pe > 0 else np.nan\n",
        "        avg_pb = total_pb / count_pb if count_pb > 0 else np.nan\n",
        "        avg_ev_ebitda = total_ev_ebitda / count_ev_ebitda if count_ev_ebitda > 0 else np.nan\n",
        "\n",
        "        logger.info(f\"Calculated peer averages: PE={avg_pe:.2f}, PB={avg_pb:.2f}, EV/EBITDA={avg_ev_ebitda:.2f}\")\n",
        "\n",
        "        return {\n",
        "            'avg_pe': avg_pe,\n",
        "            'avg_pb': avg_pb,\n",
        "            'avg_ev_ebitda': avg_ev_ebitda\n",
        "        }\n",
        "\n",
        "\n",
        "    def compare_valuation_to_peers(self, stock_valuation: Dict, peer_average_valuation: Dict) -> Dict:\n",
        "        \"\"\"Compare stock's valuation ratios to peer averages and provide assessment.\"\"\"\n",
        "        logger.info(\"Comparing stock valuation to peer averages.\")\n",
        "        comparison_results = {}\n",
        "        valuation_score_adjustment = 0 # Adjustment to the total score\n",
        "\n",
        "        stock_pe = stock_valuation.get('trailingPE', np.nan)\n",
        "        stock_pb = stock_valuation.get('priceToBook', np.nan)\n",
        "        stock_ev_ebitda = stock_valuation.get('evToEbitda', np.nan)\n",
        "\n",
        "        avg_pe = peer_average_valuation.get('avg_pe', np.nan)\n",
        "        avg_pb = peer_average_valuation.get('avg_pb', np.nan)\n",
        "        avg_ev_ebitda = peer_average_valuation.get('avg_ev_ebitda', np.nan)\n",
        "\n",
        "        logger.debug(f\"Stock Valuation: PE={stock_pe:.2f}, PB={stock_pb:.2f}, EV/EBITDA={stock_ev_ebitda:.2f}\")\n",
        "        logger.debug(f\"Peer Average Valuation: PE={avg_pe:.2f}, PB={avg_pb:.2f}, EV/EBITDA={avg_ev_ebitda:.2f}\")\n",
        "\n",
        "\n",
        "        # PE Ratio comparison (Lower is generally better relative to peers)\n",
        "        comparison_results['pe_comparison'] = 'N/A'\n",
        "        if not pd.isna(stock_pe) and not pd.isna(avg_pe) and avg_pe > 0:\n",
        "             if stock_pe < avg_pe * 0.8: # More than 20% below average\n",
        "                  comparison_results['pe_comparison'] = 'Significantly Undervalued (PE)'\n",
        "                  valuation_score_adjustment += 10\n",
        "             elif stock_pe < avg_pe * 0.95: # More than 5% below average\n",
        "                  comparison_results['pe_comparison'] = 'Undervalued (PE)'\n",
        "                  valuation_score_adjustment += 5\n",
        "             elif stock_pe > avg_pe * 1.2: # More than 20% above average\n",
        "                  comparison_results['pe_comparison'] = 'Significantly Overvalued (PE)'\n",
        "                  valuation_score_adjustment -= 10\n",
        "             elif stock_pe > avg_pe * 1.05: # More than 5% above average\n",
        "                  comparison_results['pe_comparison'] = 'Overvalued (PE)'\n",
        "                  valuation_score_adjustment -= 5\n",
        "             else:\n",
        "                  comparison_results['pe_comparison'] = 'Fairly Valued (PE)'\n",
        "        elif not pd.isna(stock_pe) and pd.isna(avg_pe):\n",
        "             comparison_results['pe_comparison'] = 'PE available, Peer Avg PE N/A'\n",
        "             logger.warning(\"Peer Average PE is NaN. Cannot compare stock PE to peers.\")\n",
        "        elif pd.isna(stock_pe) and not pd.isna(avg_pe):\n",
        "             comparison_results['pe_comparison'] = 'Stock PE N/A'\n",
        "             logger.warning(\"Stock PE is NaN. Cannot compare to peer Average PE.\")\n",
        "        else:\n",
        "             logger.warning(\"Stock PE and Peer Average PE are NaN. Cannot compare.\")\n",
        "\n",
        "\n",
        "        # PB Ratio comparison (Lower is generally better relative to peers)\n",
        "        comparison_results['pb_comparison'] = 'N/A'\n",
        "        if not pd.isna(stock_pb) and not pd.isna(avg_pb) and avg_pb > 0:\n",
        "             if stock_pb < avg_pb * 0.8: # More than 20% below average\n",
        "                  comparison_results['pb_comparison'] = 'Significantly Undervalued (PB)'\n",
        "                  valuation_score_adjustment += 8\n",
        "             elif stock_pb < avg_pb * 0.95: # More than 5% below average\n",
        "                  comparison_results['pb_comparison'] = 'Undervalued (PB)'\n",
        "                  valuation_score_adjustment += 4\n",
        "             elif stock_pb > avg_pb * 1.2: # More than 20% above average\n",
        "                  comparison_results['pb_comparison'] = 'Significantly Overvalued (PB)'\n",
        "                  valuation_score_adjustment -= 8\n",
        "             elif stock_pb > avg_pb * 1.05: # More than 5% above average\n",
        "                  comparison_results['pb_comparison'] = 'Overvalued (PB)'\n",
        "                  valuation_score_adjustment -= 4\n",
        "             else:\n",
        "                  comparison_results['pb_comparison'] = 'Fairly Valued (PB)'\n",
        "        elif not pd.isna(stock_pb) and pd.isna(avg_pb):\n",
        "             comparison_results['pb_comparison'] = 'PB available, Peer Avg PB N/A'\n",
        "             logger.warning(\"Peer Average PB is NaN. Cannot compare stock PB to peers.\")\n",
        "        elif pd.isna(stock_pb) and not pd.isna(avg_pb):\n",
        "             comparison_results['pb_comparison'] = 'Stock PB N/A'\n",
        "             logger.warning(\"Stock PB is NaN. Cannot compare to peer Average PB.\")\n",
        "        else:\n",
        "             logger.warning(\"Stock PB and Peer Average PB are NaN. Cannot compare.\")\n",
        "\n",
        "\n",
        "        # EV/EBITDA comparison (Lower is generally better relative to peers)\n",
        "        comparison_results['ev_ebitda_comparison'] = 'N/A'\n",
        "        if not pd.isna(stock_ev_ebitda) and not pd.isna(avg_ev_ebitda) and avg_ev_ebitda != 0:\n",
        "             if stock_ev_ebitda < avg_ev_ebitda * 0.8: # More than 20% below average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Significantly Undervalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment += 12\n",
        "             elif stock_ev_ebitda < avg_ev_ebitda * 0.95: # More than 5% below average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Undervalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment += 6\n",
        "             elif stock_ev_ebitda > avg_ev_ebitda * 1.2: # More than 20% above average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Significantly Overvalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment -= 12\n",
        "             elif stock_ev_ebitda > avg_ev_ebitda * 1.05: # More than 5% above average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Overvalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment -= 6\n",
        "             else:\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Fairly Valued (EV/EBITDA)'\n",
        "        elif not pd.isna(stock_ev_ebitda) and not pd.isna(avg_ev_ebitda) and avg_ev_ebitda == 0:\n",
        "             comparison_results['ev_ebitda_comparison'] = 'Peer Avg EV/EBITDA is 0'\n",
        "             logger.warning(\"Peer Average EV/EBITDA is zero. Cannot compare.\")\n",
        "        elif not pd.isna(stock_ev_ebitda) and pd.isna(avg_ev_ebitda):\n",
        "             comparison_results['ev_ebitda_comparison'] = 'EV/EBITDA available, Peer Avg EV/EBITDA N/A'\n",
        "             logger.warning(\"Peer Average EV/EBITDA is NaN. Cannot compare stock EV/EBITDA to peers.\")\n",
        "        elif pd.isna(stock_ev_ebitda) and not pd.isna(avg_ev_ebitda):\n",
        "             comparison_results['ev_ebitda_comparison'] = 'Stock EV/EBITDA N/A'\n",
        "             logger.warning(\"Stock EV/EBITDA is NaN. Cannot compare to peer Average EV/EBITDA.\")\n",
        "        else:\n",
        "             logger.warning(\"Stock EV/EBITDA and Peer Average EV/EBITDA are NaN. Cannot compare.\")\n",
        "\n",
        "\n",
        "        comparison_results['valuation_score_adjustment'] = valuation_score_adjustment\n",
        "\n",
        "        logger.info(f\"Valuation comparison results: {comparison_results}\")\n",
        "        return comparison_results\n",
        "\n",
        "\n",
        "    def calculate_peer_relative_performance(self, symbol, peers, days=30):\n",
        "        \"\"\"Compare stock performance with peers, handling data issues robustly\"\"\"\n",
        "        results = {\n",
        "            'stock_return': np.nan,\n",
        "            'avg_peer_return': np.nan,\n",
        "            'relative_performance': np.nan,\n",
        "            'outperformance': False,\n",
        "            'days': days\n",
        "        }\n",
        "\n",
        "        if not isinstance(peers, list) or not peers:\n",
        "             logger.warning(\"No valid peer list provided for performance comparison.\")\n",
        "             # Return the default results with NaNs if no peers\n",
        "             return results\n",
        "\n",
        "        # --- Removed the temporary skip here ---\n",
        "\n",
        "        try:\n",
        "            main_ticker = yf.Ticker(symbol)\n",
        "            main_hist = main_ticker.history(period=f\"{days}d\")\n",
        "            main_return = np.nan\n",
        "\n",
        "            if not main_hist.empty and len(main_hist) > 1:\n",
        "                try:\n",
        "                    start_price = main_hist['Close'].iloc[0]\n",
        "                    end_price = main_hist['Close'].iloc[-1]\n",
        "                    if not pd.isna(start_price) and not pd.isna(end_price) and start_price > 0:\n",
        "                         main_return = ((end_price / start_price) - 1) * 100\n",
        "                    else:\n",
        "                         logger.warning(f\"Invalid start ({start_price}) or end price ({end_price}) for main stock ({symbol}) return calculation.\")\n",
        "                except Exception as ret_e:\n",
        "                     logger.warning(f\"Could not calculate main stock ({symbol}) return: {ret_e}. Setting to NaN.\")\n",
        "                     main_return = np.nan\n",
        "            else:\n",
        "                logger.warning(f\"Insufficient historical data for main stock ({symbol}) for return calculation.\")\n",
        "\n",
        "            results['stock_return'] = main_return\n",
        "\n",
        "        except Exception as main_stock_e:\n",
        "            logger.error(f\"Error fetching data or calculating return for main stock ({symbol}): {main_stock_e}. Main stock return set to NaN.\")\n",
        "            results['stock_return'] = np.nan\n",
        "\n",
        "        # Calculate peer returns\n",
        "        peer_returns = []\n",
        "        # The peers list now contains dictionaries with valuation data.\n",
        "        # We need to extract just the symbols for performance calculation.\n",
        "        peer_symbols_for_perf = [p['symbol'] for p in peers if isinstance(p, dict) and 'symbol' in p]\n",
        "\n",
        "        for peer_symbol in peer_symbols_for_perf:\n",
        "             try:\n",
        "                 peer_ticker = yf.Ticker(peer_symbol)\n",
        "                 peer_hist = peer_ticker.history(period=f\"{days}d\")\n",
        "                 if not peer_hist.empty and len(peer_hist) > 1:\n",
        "                     try:\n",
        "                          peer_start_price = peer_hist['Close'].iloc[0]\n",
        "                          peer_end_price = peer_hist['Close'].iloc[-1]\n",
        "                          if not pd.isna(peer_start_price) and not pd.isna(peer_end_price) and peer_start_price > 0:\n",
        "                             peer_return = ((peer_end_price / peer_start_price) - 1) * 100\n",
        "                             peer_returns.append(peer_return)\n",
        "                          else:\n",
        "                             logger.warning(f\"Invalid start or end price for peer ({peer_symbol}) return calculation.\")\n",
        "                     except Exception as peer_ret_e:\n",
        "                         logger.warning(f\"Could not calculate return for peer ({peer_symbol}): {peer_ret_e}. Skipping.\")\n",
        "                 else:\n",
        "                     logger.warning(f\"Insufficient historical data for peer ({peer_symbol}) for return calculation. Skipping.\")\n",
        "             except Exception as peer_e:\n",
        "                 logger.warning(f\"Error fetching data for peer ({peer_symbol}): {peer_e}. Skipping.\")\n",
        "\n",
        "        # Add logging for peer returns before filtering/average calculation\n",
        "        logger.info(f\"Peer returns collected before average calculation attempt: {peer_returns}\")\n",
        "\n",
        "        # Calculate average peer return and relative performance\n",
        "        if peer_returns:\n",
        "             # Ensure peer_returns list contains only valid numbers before calculating mean\n",
        "             valid_peer_returns = [ret for ret in peer_returns if isinstance(ret, (int, float)) and not pd.isna(ret)]\n",
        "             if valid_peer_returns:\n",
        "                 avg_peer_return = np.mean(valid_peer_returns)\n",
        "                 results['avg_peer_return'] = avg_peer_return\n",
        "\n",
        "                 # Calculate relative performance only if main stock return is valid\n",
        "                 if not pd.isna(main_return):\n",
        "                      results['relative_performance'] = main_return - avg_peer_return\n",
        "\n",
        "                      # Determine outperformance\n",
        "                      if main_return > avg_peer_return:\n",
        "                          results['outperformance'] = True\n",
        "                 else:\n",
        "                      logger.warning(\"Main stock return is NaN, cannot calculate relative performance or outperformance.\")\n",
        "             else:\n",
        "                 logger.warning(\"No valid peer returns available after filtering. Cannot calculate average peer return or relative performance.\")\n",
        "        else:\n",
        "             logger.warning(\"No peer returns calculated. Cannot calculate average peer return or relative performance.\")\n",
        "\n",
        "\n",
        "        logger.info(f\"Peer performance results for {symbol}: {results}\")\n",
        "        return results\n",
        "\n",
        "\n",
        "    def get_index_membership(self, symbol):\n",
        "        \"\"\"Check index membership for the stock\"\"\"\n",
        "        symbol_upper = symbol.upper() if isinstance(symbol, str) else ''\n",
        "\n",
        "        index_constituents = {\n",
        "            'NIFTY50': ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS'],\n",
        "            'NIFTY_NEXT50': ['VEDL.NS', 'PNB.NS', 'INDIGO.NS', 'BANDHANBNK.NS'],\n",
        "            'NIFTY_MIDCAP150': ['PERSISTENT.NS', 'COFORGE.NS', 'LTTS.NS']\n",
        "        }\n",
        "\n",
        "        membership = []\n",
        "        for index, constituents in index_constituents.items():\n",
        "            if symbol_upper and any(isinstance(c, str) and c.upper() == symbol_upper for c in constituents):\n",
        "                membership.append(index)\n",
        "\n",
        "        if membership:\n",
        "             logger.info(f\"Stock {symbol} is a member of indices: {', '.join(membership)}\")\n",
        "        else:\n",
        "             logger.info(f\"Stock {symbol} is not found in the hardcoded index constituents.\")\n",
        "\n",
        "        return membership\n",
        "\n",
        "    def calculate_enhanced_technical_score(self, indicators, circuit_risk):\n",
        "        \"\"\"Calculate enhanced technical analysis score with NaN handling and circuit risk\"\"\"\n",
        "        base_score = 0\n",
        "        indicators_calculated = 0\n",
        "        possible_indicator_points = 50\n",
        "\n",
        "        num_key_indicators = 5\n",
        "        indicator_point_contribution = possible_indicator_points / num_key_indicators\n",
        "\n",
        "        rsi = indicators.get('RSI', np.nan)\n",
        "        if not pd.isna(rsi):\n",
        "             indicators_calculated += 1\n",
        "             if 40 <= rsi <= 60:\n",
        "                 base_score += indicator_point_contribution * 0.7\n",
        "             elif rsi < 30: # More points for extreme oversold\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             elif 30 <= rsi < 40: # Approaching oversold\n",
        "                 base_score += indicator_point_contribution * 0.9\n",
        "             elif 60 < rsi <= 70: # Approaching overbought\n",
        "                 base_score += indicator_point_contribution * 0.6\n",
        "             else: # Overbought (>70)\n",
        "                 base_score += indicator_point_contribution * 0.4\n",
        "        else:\n",
        "             logger.warning(\"RSI not calculated or is NaN.\")\n",
        "\n",
        "        macd = indicators.get('MACD', np.nan)\n",
        "        macd_signal = indicators.get('MACD_signal', np.nan)\n",
        "\n",
        "        if not pd.isna(macd) and not pd.isna(macd_signal):\n",
        "             indicators_calculated += 1\n",
        "             if macd > macd_signal:\n",
        "                 if macd > 0: # Bullish crossover above zero line\n",
        "                      base_score += indicator_point_contribution * 1.0\n",
        "                 else: # Bullish crossover below zero line\n",
        "                      base_score += indicator_point_contribution * 0.8\n",
        "             else:\n",
        "                 if macd < 0: # Bearish crossover below zero line\n",
        "                      base_score += indicator_point_contribution * 0.2\n",
        "                 else: # Bearish crossover above zero line\n",
        "                      base_score += indicator_point_contribution * 0.4\n",
        "        else:\n",
        "             logger.warning(\"MACD or MACD signal is NaN for technical scoring.\")\n",
        "\n",
        "        sma_20 = indicators.get('SMA_20', np.nan)\n",
        "        sma_50 = indicators.get('SMA_50', np.nan)\n",
        "        sma_200 = indicators.get('SMA_200', np.nan) # Include 200-day SMA if available\n",
        "\n",
        "        ma_score_component = 0\n",
        "        ma_indicators_counted = 0\n",
        "\n",
        "        if not pd.isna(sma_20) and not pd.isna(sma_50):\n",
        "             ma_indicators_counted += 1\n",
        "             if sma_20 > sma_50:\n",
        "                  ma_score_component += 0.5 # 20 > 50 crossover is bullish\n",
        "             else:\n",
        "                  ma_score_component += 0.2 # 20 <= 50 crossover is bearish/neutral\n",
        "\n",
        "        if not pd.isna(sma_50) and not pd.isna(sma_200):\n",
        "             ma_indicators_counted += 1\n",
        "             if sma_50 > sma_200:\n",
        "                  ma_score_component += 0.5 # 50 > 200 crossover is bullish\n",
        "             else:\n",
        "                  ma_score_component += 0.2 # 50 <= 200 crossover is bearish/neutral\n",
        "\n",
        "        current_price = indicators.get('current_price', np.nan)\n",
        "        if not pd.isna(current_price):\n",
        "             if not pd.isna(sma_20) and current_price > sma_20:\n",
        "                  ma_score_component += 0.3 # Price above 20-day SMA is bullish\n",
        "             elif not pd.isna(sma_20):\n",
        "                  ma_score_component += 0.1 # Price below 20-day SMA is bearish/neutral\n",
        "\n",
        "             if not pd.isna(sma_50) and current_price > sma_50:\n",
        "                  ma_score_component += 0.4 # Price above 50-day SMA is more bullish\n",
        "             elif not pd.isna(sma_50):\n",
        "                  ma_score_component += 0.15 # Price below 50-day SMA\n",
        "\n",
        "             if not pd.isna(sma_200) and current_price > sma_200:\n",
        "                  ma_score_component += 0.6 # Price above 200-day SMA is significant bullish signal\n",
        "             elif not pd.isna(sma_200):\n",
        "                  ma_score_component += 0.1 # Price below 200-day SMA is significant bearish signal\n",
        "\n",
        "\n",
        "        if ma_indicators_counted > 0 or (not pd.isna(current_price) and (not pd.isna(sma_20) or not pd.isna(sma_50) or not pd.isna(sma_200))):\n",
        "             indicators_calculated += 1 # Count MA section if any valid MA comparison/position is made\n",
        "             # Normalize MA score component to contribute to the total score\n",
        "             # Max possible ma_score_component (0.5 + 0.5 + 0.3 + 0.4 + 0.6) = 2.3\n",
        "             # Let's scale this to contribute up to indicator_point_contribution\n",
        "             max_ma_component = 2.3\n",
        "             base_score += (ma_score_component / max_ma_component) * indicator_point_contribution if max_ma_component > 0 else 0\n",
        "        else:\n",
        "             logger.warning(\"Insufficient data for Moving Averages analysis.\")\n",
        "\n",
        "\n",
        "        bb_upper = indicators.get('BB_upper', np.nan)\n",
        "        bb_lower = indicators.get('BB_lower', np.nan)\n",
        "        bb_middle = indicators.get('BB_middle', np.nan)\n",
        "\n",
        "        if not pd.isna(current_price) and not pd.isna(bb_upper) and not pd.isna(bb_lower) and not pd.isna(bb_middle):\n",
        "            indicators_calculated += 1\n",
        "            if current_price < bb_lower:\n",
        "                base_score += indicator_point_contribution * 1.0 # Price below lower band (potential buy signal)\n",
        "            elif bb_lower <= current_price < bb_middle:\n",
        "                base_score += indicator_point_contribution * 0.8 # Between lower and middle band\n",
        "            elif bb_middle <= current_price < bb_upper:\n",
        "                base_score += indicator_point_contribution * 0.6 # Between middle and upper band\n",
        "            else: # Price above upper band\n",
        "                base_score += indicator_point_contribution * 0.4 # Potential sell signal\n",
        "        else:\n",
        "             logger.warning(\"Bollinger Bands or current price is NaN for technical scoring.\")\n",
        "\n",
        "        volume_ratio = indicators.get('Volume_ratio', np.nan)\n",
        "        if not pd.isna(volume_ratio):\n",
        "             indicators_calculated += 1\n",
        "             if volume_ratio > 2.0: # Very high volume\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             elif volume_ratio > 1.2: # High volume\n",
        "                 base_score += indicator_point_contribution * 0.8\n",
        "             elif 0.8 <= volume_ratio <= 1.2: # Normal volume\n",
        "                 base_score += indicator_point_contribution * 0.5\n",
        "             else: # Low volume\n",
        "                 base_score += indicator_point_contribution * 0.3\n",
        "        else:\n",
        "             logger.warning(\"Volume ratio is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        achieved_score_from_indicators = base_score\n",
        "\n",
        "        # Normalize the base score based on how many indicators were successfully calculated\n",
        "        if indicators_calculated > 0:\n",
        "            # Assuming each of the num_key_indicators contributes equally if available\n",
        "            # This approach gives points for each indicator that could be calculated and scored\n",
        "            # Max points if all indicators could be scored is num_key_indicators * indicator_point_contribution\n",
        "            # But our scoring within each indicator gives variable points (e.g., 0.4 to 1.0)\n",
        "            # A simpler approach is to just sum up the points from successfully scored indicators\n",
        "            # Let's cap the sum at the max possible points from indicators (50)\n",
        "            final_base_score = min(achieved_score_from_indicators, possible_indicator_points)\n",
        "\n",
        "            if indicators_calculated < num_key_indicators:\n",
        "                 logger.warning(f\"Only {indicators_calculated}/{num_key_indicators} key technical indicators could be fully calculated/scored. Final base technical score is based on available data.\")\n",
        "\n",
        "        else:\n",
        "             logger.warning(\"No key technical indicators calculated. Base technical score is 0.\")\n",
        "             final_base_score = 0\n",
        "\n",
        "\n",
        "        circuit_risk_adj = circuit_risk if isinstance(circuit_risk, (int, float)) and not pd.isna(circuit_risk) else 0\n",
        "\n",
        "        final_score = final_base_score + circuit_risk_adj\n",
        "\n",
        "        return max(0, min(final_score, 50))\n",
        "\n",
        "\n",
        "    def calculate_value_at_risk(self, price_data: pd.DataFrame, confidence_level: float = 0.95, horizon_days: int = 1) -> Dict: # Modified return type hint\n",
        "        \"\"\"\n",
        "        Calculates Value at Risk (VaR) using the historical method.\n",
        "\n",
        "        Args:\n",
        "            price_data: DataFrame with historical price data (must contain 'Close').\n",
        "            confidence_level: The confidence level for VaR (e.g., 0.95 for 95% VaR).\n",
        "            horizon_days: The time horizon for VaR (in trading days).\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing the calculated VaR as a percentage loss,\n",
        "            confidence level, and horizon days, or a dictionary with NaN/None values\n",
        "            if calculation fails.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Calculating {confidence_level*100:.0f}% VaR for {horizon_days}-day horizon.\")\n",
        "        results = {'var_percentage_loss': np.nan, 'confidence_level': confidence_level, 'horizon_days': horizon_days}\n",
        "\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or 'Close' not in price_data.columns:\n",
        "            logger.warning(\"Insufficient or invalid price data for VaR calculation.\")\n",
        "            return results # Return dictionary with NaN/None\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Calculate daily returns\n",
        "            returns = price_data['Close'].pct_change().dropna()\n",
        "\n",
        "            if returns.empty:\n",
        "                logger.warning(\"No valid returns data for VaR calculation.\")\n",
        "                return results # Return dictionary with NaN/None\n",
        "\n",
        "            # Historical VaR: Find the percentile of returns corresponding to the confidence level\n",
        "            # For downside risk, we look at the lower tail of returns.\n",
        "            # A 95% confidence level for VaR means we're interested in the 5th percentile of losses.\n",
        "            # The percentile rank for a confidence level C is 1 - C.\n",
        "            percentile_rank = (1 - confidence_level) * 100\n",
        "            logger.debug(f\"Calculating {percentile_rank:.2f} percentile of historical returns.\")\n",
        "\n",
        "            # Calculate VaR at the specified percentile\n",
        "            # The result is a negative percentage loss\n",
        "            var_percentage = np.percentile(returns, percentile_rank)\n",
        "\n",
        "            # VaR is typically expressed as a positive loss\n",
        "            var_percentage_loss = abs(var_percentage)\n",
        "\n",
        "            # Scale VaR for the desired horizon (assuming returns are independently and identically distributed)\n",
        "            # This is a simplification; more advanced methods exist for scaling VaR.\n",
        "            # Scaling by sqrt(horizon) is common but assumes specific return properties.\n",
        "            scaled_var_percentage_loss = var_percentage_loss * np.sqrt(horizon_days)\n",
        "\n",
        "            results['var_percentage_loss'] = scaled_var_percentage_loss * 100 # Convert to percentage for display/scoring\n",
        "            logger.info(f\"Calculated {confidence_level*100:.0f}% VaR ({horizon_days}-day horizon): {results['var_percentage_loss']:.2f}%\")\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating VaR: {str(e)}. Returning default results.\")\n",
        "            return results # Return dictionary with NaN/None on error\n",
        "\n",
        "\n",
        "    def calculate_enhanced_dividend_score(self, symbol: str, price_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"\n",
        "        Calculates an enhanced dividend score considering historical payout trends and stability.\n",
        "\n",
        "        Args:\n",
        "            symbol: Stock symbol (e.g., 'RELIANCE.NS').\n",
        "            price_data: DataFrame with historical price data (must contain 'Close').\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing the enhanced dividend score and potentially other\n",
        "            relevant dividend metrics (e.g., payout history, yield trend).\n",
        "        \"\"\"\n",
        "        logger.info(f\"Calculating enhanced dividend score for {symbol}.\")\n",
        "        enhanced_dividend_score = 0 # Max score for dividend analysis out of 15 (example)\n",
        "        dividend_metrics = {\n",
        "            'trailingAnnualDividendYield': np.nan,\n",
        "            'dividendPayoutRatio': np.nan,\n",
        "            'payout_history': {},\n",
        "            'yield_trend': 'N/A',\n",
        "            'score': enhanced_dividend_score\n",
        "        }\n",
        "\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or 'Close' not in price_data.columns:\n",
        "             logger.warning(\"Insufficient price data for enhanced dividend analysis.\")\n",
        "             return dividend_metrics # Return default metrics if price data is missing\n",
        "\n",
        "\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "            dividends = ticker.dividends.sort_index() # Get historical dividend payouts\n",
        "\n",
        "            # Get current yield and payout ratio from info\n",
        "            current_yield = info.get('trailingAnnualDividendYield', np.nan) # yfinance provides this as a ratio\n",
        "            if isinstance(current_yield, (int, float)) and not pd.isna(current_yield):\n",
        "                 dividend_metrics['trailingAnnualDividendYield'] = current_yield * 100 # Convert to percentage\n",
        "            else:\n",
        "                 dividend_metrics['trailingAnnualDividendYield'] = np.nan\n",
        "\n",
        "\n",
        "            payout_ratio = info.get('payoutRatio', np.nan) # yfinance provides this as a ratio\n",
        "            if isinstance(payout_ratio, (int, float)) and not pd.isna(payout_ratio):\n",
        "                 dividend_metrics['dividendPayoutRatio'] = payout_ratio # Keep as ratio\n",
        "            else:\n",
        "                 dividend_metrics['dividendPayoutRatio'] = np.nan\n",
        "\n",
        "\n",
        "            if not dividends.empty:\n",
        "                 # Analyze payout history and stability\n",
        "                 dividend_metrics['payout_history'] = dividends.to_dict() # Store the raw history\n",
        "\n",
        "                 # Check for consistent payouts (e.g., increasing or stable over last 5 years)\n",
        "                 five_years_ago = datetime.now() - timedelta(days=5*365)\n",
        "                 # Remove timezone information for consistent comparison\n",
        "                 recent_dividends = dividends[dividends.index.tz_convert(None) >= five_years_ago]\n",
        "\n",
        "                 if len(recent_dividends) > 3: # Need at least a few recent payouts\n",
        "                      # Check for increasing trend\n",
        "                      is_increasing = all(recent_dividends.iloc[i] >= recent_dividends.iloc[i-1] for i in range(1, len(recent_dividends)))\n",
        "\n",
        "                      if is_increasing:\n",
        "                           enhanced_dividend_score += 10 # Significant points for increasing dividends\n",
        "                           dividend_metrics['yield_trend'] = 'Increasing'\n",
        "                           logger.debug(\"Dividend trend: Increasing. +10 pts.\")\n",
        "                      elif len(recent_dividends) > 0 and recent_dividends.min() > 0:\n",
        "                           enhanced_dividend_score += 5 # Some points for stable (non-zero) dividends\n",
        "                           dividend_metrics['yield_trend'] = 'Stable'\n",
        "                           logger.debug(\"Dividend trend: Stable. +5 pts.\")\n",
        "                      else:\n",
        "                           dividend_metrics['yield_trend'] = 'Irregular/Decreasing'\n",
        "                           logger.debug(\"Dividend trend: Irregular/Decreasing.\")\n",
        "                 elif len(recent_dividends) > 0 and recent_dividends.min() > 0:\n",
        "                      enhanced_dividend_score += 3 # Some points for recent payouts, even if history is short\n",
        "                      dividend_metrics['yield_trend'] = 'Recent Payouts'\n",
        "                      logger.debug(\"Dividend trend: Recent Payouts. +3 pts.\")\n",
        "                 else:\n",
        "                      dividend_metrics['yield_trend'] = 'No Recent Payouts'\n",
        "                      logger.debug(\"Dividend trend: No Recent Payouts.\")\n",
        "\n",
        "\n",
        "                 # Score based on current yield (Similar to basic analysis but potentially more weight)\n",
        "                 if not pd.isna(dividend_metrics['trailingAnnualDividendYield']):\n",
        "                      yield_percentage = dividend_metrics['trailingAnnualDividendYield']\n",
        "                      if yield_percentage > 3: # > 3%\n",
        "                           enhanced_dividend_score += 5\n",
        "                           logger.debug(f\"Current Yield ({yield_percentage:.2f}%) > 3%. +5 pts.\")\n",
        "                      elif yield_percentage > 1: # > 1%\n",
        "                           enhanced_dividend_score += 3\n",
        "                           logger.debug(f\"Current Yield ({yield_percentage:.2f}%) > 1%. +3 pts.\")\n",
        "                      else:\n",
        "                           enhanced_dividend_score += 1 # Small point for non-zero yield\n",
        "                           logger.debug(f\"Current Yield ({yield_percentage:.2f}%) <= 1%. +1 pt.\")\n",
        "                 else:\n",
        "                      logger.warning(\"Current dividend yield is NaN.\")\n",
        "\n",
        "                 # Consider Payout Ratio (Lower is generally better, indicates sustainability)\n",
        "                 if not pd.isna(dividend_metrics['dividendPayoutRatio']):\n",
        "                      payout_ratio_value = dividend_metrics['dividendPayoutRatio']\n",
        "                      if payout_ratio_value < 0.5: # Payout ratio < 50%\n",
        "                           enhanced_dividend_score += 5\n",
        "                           logger.debug(f\"Payout Ratio ({payout_ratio_value:.2f}) < 0.5. +5 pts.\")\n",
        "                      elif payout_ratio_value < 0.8: # Payout ratio < 80%\n",
        "                           enhanced_dividend_score += 3\n",
        "                           logger.debug(f\"Payout Ratio ({payout_ratio_value:.2f}) < 0.8. +3 pts.\")\n",
        "                      elif payout_ratio_value > 1.0: # Payout ratio > 100% (unsustainable)\n",
        "                           enhanced_dividend_score -= 5 # Penalty for unsustainable payout\n",
        "                           logger.debug(f\"Payout Ratio ({payout_ratio_value:.2f}) > 1.0. -5 pts.\")\n",
        "                      else:\n",
        "                           enhanced_dividend_score += 1 # Small point for payout ratio 0.8-1.0\n",
        "                           logger.debug(f\"Payout Ratio ({payout_ratio_value:.2f}) 0.8-1.0. +1 pt.\")\n",
        "\n",
        "                 else:\n",
        "                      logger.warning(\"Dividend payout ratio is NaN.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                 logger.warning(\"No historical dividend data found.\")\n",
        "\n",
        "            # Cap the score at a reasonable maximum for this component (e.g., 20 points out of 235 total)\n",
        "            # Let's allocate up to 20 points for enhanced dividend analysis\n",
        "            dividend_metrics['score'] = min(enhanced_dividend_score, 20)\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating enhanced dividend score for {symbol}: {str(e)}. Returning default metrics.\")\n",
        "            # Ensure the score is set to 0 on error\n",
        "            dividend_metrics['score'] = 0\n",
        "            return dividend_metrics # Return dictionary with NaN/None on error\n",
        "\n",
        "\n",
        "        logger.info(f\"Enhanced dividend score calculated: {dividend_metrics['score']}\")\n",
        "        return dividend_metrics\n",
        "\n",
        "\n",
        "    def fetch_news(self, symbol: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Fetches recent news headlines for the given stock symbol.\n",
        "        NOTE: This is a placeholder. In a real application, you would integrate\n",
        "        with a News API (like News API, Alpha Vantage, etc.) here.\n",
        "        \"\"\"\n",
        "        print(f\"Fetching news for {symbol} (placeholder)...\")\n",
        "        symbol_str = str(symbol) if symbol is not None else \"Unknown Stock\"\n",
        "        return [\n",
        "            f\"{symbol_str} stock price rises on positive market sentiment\",\n",
        "            f\"{symbol_str} announces strong quarterly results, beating estimates\",\n",
        "            f\"Experts bullish on {symbol_str}'s future outlook\",\n",
        "            f\"I am a non-numeric entry that might cause an error\",\n",
        "            f\"{symbol_str} faces regulatory challenges in key market\",\n",
        "            f\"Competitor's new product launch impacts {symbol_str}'s market share\",\n",
        "            f\"Global market trends positively impacting {symbol_str}\",\n",
        "            f\"{symbol_str} management provides optimistic guidance\",\n",
        "            f\"Increased foreign investment flows into {symbol_str}\",\n",
        "            f\"Regulatory approval received for {symbol_str}'s new product\",\n",
        "            f\"Production issues reported for {symbol_str}\",\n",
        "            f\"Increased competition puts pressure on {symbol_str}'s margins\",\n",
        "            f\"Analyst downgrades rating for {symbol_str}\",\n",
        "            f\"Supply chain disruptions affect {symbol_str}'s operations\",\n",
        "            f\"Geopolitical tensions create uncertainty for {symbol_str}\",\n",
        "            f\"{symbol_str} announces stock split\",\n",
        "            f\"Dividend declared by {symbol_str}\"\n",
        "        ]\n",
        "\n",
        "\n",
        "    def analyze_sentiment(self, news_headlines: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of news headlines using the Gemini API.\n",
        "        Returns a dictionary with sentiment counts (positive, neutral, negative)\n",
        "        and a sentiment score.\n",
        "        \"\"\"\n",
        "        if not self.gemini_model:\n",
        "            print(\"Gemini API not configured. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Gemini API not configured. Sentiment analysis skipped.'}\n",
        "\n",
        "        if not isinstance(news_headlines, list) or not news_headlines:\n",
        "            print(\"No news headlines to analyze. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 12.5, 'summary': 'No news headlines. Sentiment analysis skipped.'}\n",
        "\n",
        "        logger.info(\"Analyzing sentiment using Gemini API...\")\n",
        "        prompt = \"Analyze the sentiment of the following news headlines for a stock and categorize each as Positive, Neutral, or Negative. Provide a concise summary of the overall sentiment.\\n\\n\"\n",
        "        for headline in news_headlines:\n",
        "            if isinstance(headline, str):\n",
        "                 prompt += f\"- {headline}\\n\"\n",
        "            else:\n",
        "                 logger.warning(f\"Skipping non-string headline: {headline}\")\n",
        "                 continue\n",
        "\n",
        "        if len(prompt) > 30000:\n",
        "             logger.warning(\"News headlines too long for Gemini API prompt. Truncating.\")\n",
        "             prompt = prompt[:30000] + \"\\n... (headlines truncated)\"\n",
        "\n",
        "        try:\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "            sentiment_text = response.text.strip()\n",
        "            logger.info(f\"Gemini API Response: {sentiment_text[:200]}...\")\n",
        "\n",
        "            positive_count = sentiment_text.lower().count('positive')\n",
        "            neutral_count = sentiment_text.lower().count('neutral')\n",
        "            negative_count = sentiment_text.lower().count('negative')\n",
        "\n",
        "            summary_line = \"No summary extracted.\"\n",
        "            lines = sentiment_text.split('\\n')\n",
        "            for line in lines:\n",
        "                 lower_line = line.lower()\n",
        "                 if 'summary' in lower_line or 'overall sentiment' in lower_line:\n",
        "                     summary_line = line.strip()\n",
        "                     break\n",
        "            if summary_line == \"No summary extracted.\" and lines:\n",
        "                 for line in reversed(lines):\n",
        "                     if line.strip():\n",
        "                         summary_line = line.strip()\n",
        "                         break\n",
        "\n",
        "            total_headlines = len([h for h in news_headlines if isinstance(h, str)])\n",
        "            if total_headlines > 0:\n",
        "                sentiment_score = ((positive_count - negative_count) / total_headlines) * 12.5 + 12.5\n",
        "            else:\n",
        "                sentiment_score = 12.5\n",
        "\n",
        "            return {\n",
        "                'positive': positive_count,\n",
        "                'neutral': neutral_count,\n",
        "                'negative': negative_count,\n",
        "                'score': max(0, min(sentiment_score, 25)),\n",
        "                'summary': summary_line\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing sentiment with Gemini API: {e}. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis failed.'}\n",
        "\n",
        "\n",
        "    def generate_enhanced_recommendation(self, fundamental_score, technical_score,\n",
        "                                       liquidity_score, peer_performance, index_membership,\n",
        "                                       sentiment_analysis_results, valuation_comparison_results,\n",
        "                                       downside_risk_metrics: Dict, enhanced_dividend_metrics: Dict): # Added type hint for clarity\n",
        "        \"\"\"Generate comprehensive recommendation including sentiment and valuation comparison\"\"\"\n",
        "        # Get base scores\n",
        "        fund_score = fundamental_score if isinstance(fundamental_score, (int, float)) and not pd.isna(fundamental_score) else 0\n",
        "        tech_score = technical_score if isinstance(technical_score, (int, float)) and not pd.isna(technical_score) else 0\n",
        "        liq_score = liquidity_score if isinstance(liquidity_score, (int, float)) and not pd.isna(liquidity_score) else 0\n",
        "        sentiment_score = sentiment_analysis_results.get('score', 0) if isinstance(sentiment_analysis_results.get('score'), (int, float)) and not pd.isna(sentiment_analysis_results.get('score')) else 0\n",
        "        enhanced_dividend_score = enhanced_dividend_metrics.get('score', 0) if isinstance(enhanced_dividend_metrics.get('score'), (int, float)) and not pd.isna(enhanced_dividend_metrics.get('score')) else 0\n",
        "        logger.info(f\"Enhanced dividend score for recommendation: {enhanced_dividend_score}\")\n",
        "\n",
        "\n",
        "        # Get adjustment scores\n",
        "        valuation_adjustment = valuation_comparison_results.get('valuation_score_adjustment', 0) if isinstance(valuation_comparison_results.get('valuation_score_adjustment'), (int, float)) and not pd.isna(valuation_comparison_results.get('valuation_score_adjustment')) else 0\n",
        "        logger.info(f\"Valuation comparison adjustment: {valuation_adjustment}\")\n",
        "\n",
        "        var_percentage = downside_risk_metrics.get('var_percentage_loss', np.nan) # Use .get() as it's now a dict\n",
        "        downside_risk_adjustment = 0 # Adjustment based on VaR\n",
        "\n",
        "        if isinstance(var_percentage, (int, float)) and not pd.isna(var_percentage):\n",
        "             # Example scoring: higher VaR means higher penalty\n",
        "             if var_percentage > 5: # VaR > 5%\n",
        "                  downside_risk_adjustment -= 15\n",
        "                  logger.info(f\"VaR ({var_percentage:.2f}%) > 5%. Applying downside risk penalty (-15).\")\n",
        "             elif var_percentage > 3: # VaR > 3%\n",
        "                  downside_risk_adjustment -= 10\n",
        "                  logger.info(f\"VaR ({var_percentage:.2f}%) > 3%. Applying downside risk penalty (-10).\")\n",
        "             elif var_percentage > 1: # VaR > 1%\n",
        "                  downside_risk_adjustment -= 5\n",
        "                  logger.info(f\"VaR ({var_percentage:.2f}%) > 1%. Applying downside risk penalty (-5).\")\n",
        "             else:\n",
        "                  logger.info(f\"VaR ({var_percentage:.2f}%) <= 1%. No downside risk penalty.\")\n",
        "        else:\n",
        "             logger.warning(\"VaR not available. Cannot apply downside risk adjustment.\")\n",
        "             downside_risk_adjustment -= 2 # Small penalty if VaR cannot be calculated\n",
        "\n",
        "\n",
        "        peer_analysis_available = isinstance(peer_performance, dict) and \\\n",
        "                                  not (pd.isna(peer_performance.get('stock_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('avg_peer_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('relative_performance')))\n",
        "\n",
        "        peer_adjustment = 0\n",
        "        if peer_analysis_available and peer_performance.get('outperformance', False) is True:\n",
        "            peer_adjustment = 5\n",
        "            logger.info(\"Adding bonus for peer outperformance.\")\n",
        "        elif not peer_analysis_available:\n",
        "             peer_adjustment = -5\n",
        "             logger.warning(\"Applying small penalty as peer performance data is incomplete/unavailable.\")\n",
        "\n",
        "\n",
        "        index_adjustment = 0\n",
        "        if isinstance(index_membership, list) and index_membership:\n",
        "            index_adjustment = 5\n",
        "            logger.info(\"Adding bonus for index membership.\")\n",
        "\n",
        "\n",
        "        # Sum all scores and adjustments\n",
        "        # Total Score = Fund (50) + Tech (50) + Liq (70) + Sent (25) + Enhanced Dividend (20) + Val Adj (+/-30 max) + Peer Adj (+/-5 max) + Index Adj (+5 max) + Downside Adj (+0/-15 max)\n",
        "        # Total Possible Max Score = 50 + 50 + 70 + 25 + 20 + 30 + 5 + 5 + 0 = 255\n",
        "        # Total Possible Min Score = 50 + 0 + 0 + 0 + 0 - 30 - 5 + 0 - 15 = 0 - 50 = Max 0\n",
        "        # Let's use a max total score of 255 for the scale.\n",
        "\n",
        "        total_score = fund_score + tech_score + liq_score + sentiment_score + enhanced_dividend_score + \\\n",
        "                      valuation_adjustment + peer_adjustment + index_adjustment + downside_risk_adjustment\n",
        "\n",
        "\n",
        "        recommendation = \"NEUTRAL\"\n",
        "        confidence = \"Low\"\n",
        "\n",
        "        # Adjusting thresholds based on potential max score of 255\n",
        "        if total_score >= 200: # Increased threshold\n",
        "            recommendation = \"STRONG BUY\"\n",
        "            confidence = \"High\"\n",
        "        elif total_score >= 160: # Increased threshold\n",
        "            recommendation = \"BUY\"\n",
        "            confidence = \"Moderate to High\"\n",
        "        elif total_score >= 110: # Adjusted threshold\n",
        "            recommendation = \"HOLD\"\n",
        "            confidence = \"Moderate\"\n",
        "        elif total_score >= 60: # Adjusted threshold\n",
        "            recommendation = \"SELL\"\n",
        "            confidence = \"Moderate\"\n",
        "        else:\n",
        "            recommendation = \"STRONG SELL\"\n",
        "            confidence = \"High\"\n",
        "\n",
        "        logger.info(f\"Generated enhanced recommendation: {recommendation} (Total Score: {total_score:.2f})\")\n",
        "\n",
        "        return {\n",
        "            'recommendation': recommendation,\n",
        "            'confidence': confidence,\n",
        "            'total_score': total_score,\n",
        "            'breakdown': {\n",
        "                'fundamental': fund_score,\n",
        "                'technical': tech_score,\n",
        "                'liquidity': liq_score,\n",
        "                'sentiment': sentiment_score,\n",
        "                'enhanced_dividend': enhanced_dividend_score, # Include enhanced dividend score in breakdown\n",
        "                'valuation_comparison': valuation_adjustment, # Include valuation adjustment in breakdown\n",
        "                'downside_risk': downside_risk_adjustment, # Include downside risk adjustment\n",
        "                'peer_adjustment': peer_adjustment, # Include peer adjustment in breakdown\n",
        "                'index_adjustment': index_adjustment # Include index adjustment in breakdown\n",
        "            }\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f2355ce"
      },
      "source": [
        "**Reasoning**:\n",
        "Integrate the downside risk calculation into the `analyze_stock_enhanced` function, passing the price data to the new method and storing the results in the enhanced report, then update the report display to show the downside risk metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41f9a089",
        "cellView": "form"
      },
      "source": [
        "#@title Part 3: Enhanced Analysis Integration and Report Display (with Downside Risk Analysis)\n",
        "\n",
        "# Assuming IndianStockAnalyzer and EnhancedStockAnalyzer classes are defined in previous cells\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "    if not isinstance(symbol, str) or not symbol:\n",
        "        logger.error(\"Invalid stock symbol provided for enhanced analysis.\")\n",
        "        return None\n",
        "    if not isinstance(stock_analyzer_part1, IndianStockAnalyzer):\n",
        "        logger.error(\"Invalid IndianStockAnalyzer (Part 1) instance provided.\")\n",
        "        return None\n",
        "    if not isinstance(enhanced_analyzer, EnhancedStockAnalyzer):\n",
        "        logger.error(\"Invalid EnhancedStockAnalyzer (Part 2) instance provided.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    logger.info(f\"Starting enhanced analysis for {symbol}\")\n",
        "    # Get basic analysis from Part 1\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        logger.error(f\"Basic analysis failed for {symbol}.\")\n",
        "        return None\n",
        "\n",
        "    # Get current price - already validated in Part 1 analyze_stock\n",
        "    current_price = stock_data.current_price\n",
        "    if pd.isna(current_price) or current_price <= 0:\n",
        "         logger.warning(f\"Current price invalid ({current_price}). Enhanced analysis might be limited.\")\n",
        "\n",
        "\n",
        "    # Enhanced analysis\n",
        "    logger.info(\"Starting enhanced analysis features (Part 2).\")\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    # Pass current_price to assess_circuit_risk (already validated as best as possible in Part 1)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    # Pass price_data (already validated in Part 1 analyze_stock)\n",
        "    # CORRECTED: Call get_liquidity_score on enhanced_analyzer and pass price_data from stock_data\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "\n",
        "    # 3. Peer analysis (including valuation data)\n",
        "    # Pass info (already validated in Part 1 analyze_stock)\n",
        "    # The get_peer_companies method now returns a list of dictionaries with valuation data\n",
        "    peers_with_valuation = enhanced_analyzer.get_peer_companies(symbol, stock_data.info)\n",
        "    # Pass the list of peer symbols (extracted from the list of dictionaries) for performance comparison\n",
        "    peer_symbols_for_performance = [p['symbol'] for p in peers_with_valuation if isinstance(p, dict) and 'symbol' in p]\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peer_symbols_for_performance) # Pass just symbols\n",
        "\n",
        "    # 4. Valuation Analysis: Calculate peer average valuations and compare\n",
        "    peer_average_valuation = enhanced_analyzer.calculate_peer_average_valuation(peers_with_valuation)\n",
        "    valuation_comparison_results = enhanced_analyzer.compare_valuation_to_peers(stock_data.metrics, peer_average_valuation)\n",
        "\n",
        "    # 5. Downside Risk Assessment: Calculate VaR\n",
        "    downside_risk_metrics = enhanced_analyzer.calculate_value_at_risk(stock_data.price_data)\n",
        "\n",
        "\n",
        "    # 6. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "\n",
        "    # 7. Recalculate technical score with circuit risk\n",
        "    # Pass indicators (already validated in Part 1 calculate_technical_indicators)\n",
        "    # Pass circuit_risk (already validated in assess_circuit_risk)\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "\n",
        "    # 8. Fetch and analyze news sentiment\n",
        "    # Pass symbol (already validated)\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    # Pass news_headlines (already validated)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "\n",
        "\n",
        "    # 9. Generate enhanced recommendation\n",
        "    # Pass scores and results (already validated within their respective functions)\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance, # Pass potentially incomplete/NaN peer performance\n",
        "        index_membership,\n",
        "        sentiment_analysis_results, # Pass sentiment analysis results\n",
        "        valuation_comparison_results, # Pass valuation comparison results\n",
        "        downside_risk_metrics # Pass downside risk metrics\n",
        "    )\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score, # Ensure correct liquidity score is included\n",
        "            'peers': peers_with_valuation, # Store the list of peers with their valuation data\n",
        "            'peer_performance': peer_performance, # Include peer performance, even if NaN\n",
        "            'peer_average_valuation': peer_average_valuation, # Store peer average valuation\n",
        "            'valuation_comparison': valuation_comparison_results, # Store valuation comparison results\n",
        "            'downside_risk': downside_risk_metrics, # Store downside risk metrics (e.g., VaR)\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "    logger.info(f\"Enhanced analysis completed for {symbol}\")\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize analyzers\n",
        "    try:\n",
        "        stock_analyzer = IndianStockAnalyzer()\n",
        "        enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "    except NameError:\n",
        "        print(\"Make sure to run the previous cells defining IndianStockAnalyzer and EnhancedStockAnalyzer classes.\")\n",
        "        exit() # Exit if classes are not defined\n",
        "\n",
        "\n",
        "    # Analyze a stock\n",
        "    symbol = \"RELIANCE.NS\" # Example symbol\n",
        "    result = analyze_stock_enhanced(symbol, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if result:\n",
        "        # Display the enhanced report\n",
        "        enhanced = result['enhanced_features']\n",
        "        final = result['final_recommendation']\n",
        "        basic = result['basic_analysis'] # Get basic data for display\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Enhanced Analysis Report: {basic.company_name} ({basic.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if not pd.isna(basic.current_price) else \"Current Price: N/A\")\n",
        "        market_cap_cr = basic.market_cap / 10000000 if not pd.isna(basic.market_cap) else np.nan\n",
        "        print(f\"Market Cap: ₹{market_cap_cr:,.2f} Cr\" if not pd.isna(market_cap_cr) else \"Market Cap: N/A\")\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n⚙️ Enhanced Technical Analysis & Risk:\")\n",
        "        # Display enhanced technical indicators and risk\n",
        "        # Assuming you want to display relevant indicators from basic.indicators and the circuit risk score\n",
        "        circuit_limits_display = enhanced.get('circuit_limits')\n",
        "        if circuit_limits_display and not pd.isna(circuit_limits_display.get('lower_circuit')) and not pd.isna(circuit_limits_display.get('upper_circuit')):\n",
        "             print(f\"Circuit Limits: {circuit_limits_display.get('lower_circuit', 'N/A'):.2f} - {circuit_limits_display.get('upper_circuit', 'N/A'):.2f}\")\n",
        "        else:\n",
        "             print(\"Circuit Limits: N/A\")\n",
        "\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        # Check if liquidity score is available before formatting\n",
        "        liquidity_score_display = f\"{enhanced.get('liquidity_score', 'N/A')}/70\" if isinstance(enhanced.get('liquidity_score'), (int, float)) and not pd.isna(enhanced.get('liquidity_score')) else \"Liquidity Score: N/A/70\"\n",
        "        print(liquidity_score_display)\n",
        "\n",
        "\n",
        "        # Display some key technical indicators from basic analysis\n",
        "        print(\"\\nKey Technical Indicators (from Basic Analysis):\")\n",
        "        key_tech_indicators = ['RSI', 'MACD', 'MACD_signal', 'SMA_20', 'SMA_50', 'BB_middle', 'Volume_ratio']\n",
        "        for indicator_name in key_tech_indicators:\n",
        "            value = basic.indicators.get(indicator_name, np.nan)\n",
        "            if not pd.isna(value):\n",
        "                if isinstance(value, float):\n",
        "                     print(f\"  - {indicator_name}: {value:,.2f}\")\n",
        "                else:\n",
        "                     print(f\"  - {indicator_name}: {value}\")\n",
        "            # Add logging for these key technical indicators if they are calculated\n",
        "            logger.info(f\"Indicator {indicator_name}: {value}\")\n",
        "        else:\n",
        "            print(f\"  - {indicator_name}: N/A\")\n",
        "            logger.info(f\"Indicator {indicator_name}: N/A\")\n",
        "\n",
        "        # Display Valuation Analysis\n",
        "        print(f\"\\n📈 Valuation Analysis:\")\n",
        "        stock_metrics = basic.metrics\n",
        "        peer_avg_val = enhanced.get('peer_average_valuation', {})\n",
        "        val_comp_results = enhanced.get('valuation_comparison', {})\n",
        "\n",
        "        stock_pe = stock_metrics.get('trailingPE', np.nan)\n",
        "        stock_pb = stock_metrics.get('priceToBook', np.nan)\n",
        "        stock_ev_ebitda = stock_metrics.get('evToEbitda', np.nan)\n",
        "\n",
        "        print(f\"Stock Valuation:\")\n",
        "        print(f\"  - Trailing PE: {stock_pe:.2f}\" if not pd.isna(stock_pe) else \"  - Trailing PE: N/A\")\n",
        "        print(f\"  - Price to Book: {stock_pb:.2f}\" if not pd.isna(stock_pb) else \"  - Price to Book: N/A\")\n",
        "        print(f\"  - EV/EBITDA: {stock_ev_ebitda:.2f}\" if not pd.isna(stock_ev_ebitda) else \"  - EV/EBITDA: N/A\")\n",
        "\n",
        "        print(\"\\nPeer Average Valuation:\")\n",
        "        avg_pe_display = f\"{peer_avg_val.get('avg_pe', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pe', np.nan)) else \"N/A\"\n",
        "        avg_pb_display = f\"{peer_avg_val.get('avg_pb', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pb', np.nan)) else \"N/A\"\n",
        "        avg_ev_ebitda_display = f\"{peer_avg_val.get('avg_ev_ebitda', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_ev_ebitda', np.nan)) else \"N/A\"\n",
        "\n",
        "        print(f\"  - Average PE: {avg_pe_display}\")\n",
        "        print(f\"  - Average PB: {avg_pb_display}\")\n",
        "        print(f\"  - Average EV/EBITDA: {avg_ev_ebitda_display}\")\n",
        "\n",
        "        print(\"\\nValuation Comparison:\")\n",
        "        print(f\"  - PE Comparison: {val_comp_results.get('pe_comparison', 'N/A')}\")\n",
        "        print(f\"  - PB Comparison: {val_comp_results.get('pb_comparison', 'N/A')}\")\n",
        "        print(f\"  - EV/EBITDA Comparison: {val_comp_results.get('ev_ebitda_comparison', 'N/A')}\")\n",
        "        valuation_adj_display = f\"{val_comp_results.get('valuation_score_adjustment', 0):+.2f}\" if isinstance(val_comp_results.get('valuation_score_adjustment'), (int, float)) and not pd.isna(val_comp_results.get('valuation_score_adjustment')) else \"N/A\"\n",
        "        print(f\"  - Valuation Score Adjustment: {valuation_adj_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\n📉 Downside Risk Analysis:\")\n",
        "        downside_risk = enhanced.get('downside_risk', {})\n",
        "        var_percentage = downside_risk.get('var_percentage_loss', np.nan)\n",
        "        var_display = f\"{var_percentage:.2f}%\" if not pd.isna(var_percentage) else \"N/A\"\n",
        "        print(f\"  - {downside_risk.get('confidence_level', 0.95)*100:.0f}% VaR ({downside_risk.get('horizon_days', 1)}-day): {var_display}\")\n",
        "        downside_adj_display = f\"{final.get('breakdown', {}).get('downside_risk', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('downside_risk'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('downside_risk')) else \"N/A\"\n",
        "        print(f\"  - Downside Risk Score Adjustment: {downside_adj_display}\")\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"\\n🤝 Peer Analysis (Performance):\")\n",
        "        peer_perf = enhanced.get('peer_performance')\n",
        "        if isinstance(peer_perf, dict) and \\\n",
        "           not pd.isna(peer_perf.get('stock_return')) and \\\n",
        "           not pd.isna(peer_perf.get('avg_peer_return')) and \\\n",
        "           not pd.isna(peer_perf.get('relative_performance')):\n",
        "\n",
        "             stock_return_display = f\"{peer_perf.get('stock_return', np.nan):.2f}%\" if isinstance(peer_perf.get('stock_return'), (int, float)) and not pd.isna(peer_perf.get('stock_return')) else 'N/A'\n",
        "             avg_peer_return_display = f\"{peer_perf.get('avg_peer_return', np.nan):.2f}%\" if isinstance(peer_perf.get('avg_peer_return'), (int, float)) and not pd.isna(peer_perf.get('avg_peer_return')) else 'N/A'\n",
        "             relative_performance_display = f\"{peer_perf.get('relative_performance', np.nan):.2f}%\" if isinstance(peer_perf.get('relative_performance'), (int, float)) and not pd.isna(peer_perf.get('relative_performance')) else 'N/A'\n",
        "\n",
        "             print(f\"  - {peer_perf.get('days', 'N/A')}-day Stock Return: {stock_return_display}\")\n",
        "             print(f\"  - Avg Peer Return: {avg_peer_return_display}\")\n",
        "             print(f\"  - Relative Performance: {relative_performance_display}\")\n",
        "        else:\n",
        "             print(\"Peer Performance Data Unavailable.\")\n",
        "\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"\\n🏛️ Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             # Only print a few headlines to keep the report concise\n",
        "             print(\"Sample News Headlines:\")\n",
        "             # Ensure headlines are valid strings before printing\n",
        "             valid_headlines = [h for h in enhanced['news_headlines'] if isinstance(h, str)]\n",
        "             for headline in valid_headlines[:5]: # Print up to 5 headlines\n",
        "                 print(f\"- {headline}\")\n",
        "             if len(valid_headlines) > 5:\n",
        "                  print(\"  ...\")\n",
        "\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             sentiment_score_display = f\"{sentiment_results.get('score', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\"\n",
        "             print(f\"Sentiment Score: {sentiment_score_display}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Comprehensive Scores and Recommendation ---\")\n",
        "        print(f\"Fundamental Score (from Part 1): {basic.fundamental_score:.2f}/50\" if not pd.isna(basic.fundamental_score) else \"Fundamental Score: N/A\")\n",
        "        # Add checks for NaN before formatting float for breakdown scores\n",
        "        enhanced_tech_score_display = f\"{final.get('breakdown', {}).get('technical', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('technical'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('technical')) else \"N/A\"\n",
        "        liquidity_score_display_breakdown = f\"{final.get('breakdown', {}).get('liquidity', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('liquidity'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('liquidity')) else \"N/A\"\n",
        "        sentiment_score_display_breakdown = f\"{final.get('breakdown', {}).get('sentiment', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\" # Corrected sentiment score breakdown check\n",
        "        valuation_comp_display_breakdown = f\"{final.get('breakdown', {}).get('valuation_comparison', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('valuation_comparison'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('valuation_comparison')) else \"N/A\"\n",
        "        downside_risk_display_breakdown = f\"{final.get('breakdown', {}).get('downside_risk', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('downside_risk'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('downside_risk')) else \"N/A\"\n",
        "\n",
        "\n",
        "        print(f\"Technical Score (Enhanced): {enhanced_tech_score_display}/50\")\n",
        "        print(f\"Liquidity Score: {liquidity_score_display_breakdown}/70\")\n",
        "        print(f\"Sentiment Score: {sentiment_score_display_breakdown}/25\")\n",
        "        print(f\"Valuation Comparison Adjustment: {valuation_comp_display_breakdown}\")\n",
        "        print(f\"Downside Risk Adjustment: {downside_risk_display_breakdown}\")\n",
        "\n",
        "\n",
        "        # Display adjustment scores\n",
        "        peer_adj_display = f\"{final.get('breakdown', {}).get('peer_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('peer_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('peer_adjustment')) else \"N/A\"\n",
        "        index_adj_display = f\"{final.get('breakdown', {}).get('index_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('index_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('index_adjustment')) else \"N/A\"\n",
        "\n",
        "        print(f\"Peer Performance Adjustment: {peer_adj_display}\")\n",
        "        print(f\"Index Membership Adjustment: {index_adj_display}\")\n",
        "\n",
        "\n",
        "        # Updated max score to reflect the addition of Downside Risk Adjustment (potential max increase of 0, potential max decrease of 15)\n",
        "        # Max Total Score = Fund (50) + Tech (50) + Liq (70) + Sent (25) + Val Adj (30) + Peer Adj (5) + Index Adj (5) + Downside Adj (0) = 235\n",
        "        # Re-evaluating the previous max estimate (245) and the new max. Let's use 235 as a potential max for scoring clarity.\n",
        "        print(f\"\\nTotal Enhanced Score: {final.get('total_score', 0):.2f}/235\" if isinstance(final.get('total_score'), (int, float)) and not pd.isna(final.get('total_score')) else \"Total Enhanced Score: N/A\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} (Confidence: {final.get('confidence', 'N/A')})\")\n",
        "\n",
        "\n",
        "        print(f\"\\n{'='*60}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3885f4b"
      },
      "source": [
        "**Reasoning**:\n",
        "The error indicates that the `AnalysisResult` object does not have a `metrics` attribute. This means the `AnalysisResult` class definition in Part 1 needs to be updated to include the `metrics` dictionary as intended.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-VtBDlgHKzC",
        "cellView": "form"
      },
      "source": [
        "#@title Part 1: IndianStockAnalyzer class definition (Enhanced Valuation Metrics - Fix AnalysisResult)\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import typing for type hints\n",
        "from typing import List, Dict, Optional\n",
        "from dataclasses import dataclass # Import dataclass\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- IndianStockAnalyzer class definition ---\n",
        "@dataclass\n",
        "class AnalysisResult: # Define AnalysisResult dataclass here\n",
        "    \"\"\"Data class to store comprehensive stock information\"\"\"\n",
        "    symbol: str\n",
        "    company_name: str\n",
        "    current_price: float\n",
        "    market_cap: float\n",
        "    info: Dict\n",
        "    price_data: pd.DataFrame\n",
        "    indicators: Dict\n",
        "    fundamental_score: float\n",
        "    technical_score: float\n",
        "    recommendation: str # Added recommendation field\n",
        "    metrics: Dict # Ensure metrics dictionary is included\n",
        "\n",
        "class IndianStockAnalyzer:\n",
        "    \"\"\"Basic analyzer for Indian stocks\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the basic analyzer.\"\"\"\n",
        "        # Basic setup if needed for Part 1 (e.g., API keys, configurations)\n",
        "        pass\n",
        "\n",
        "    def analyze_stock(self, symbol: str) -> Optional[AnalysisResult]: # Added type hint for return\n",
        "        \"\"\"\n",
        "        Performs basic fundamental and technical analysis for a given stock.\n",
        "        Returns an AnalysisResult object containing the analysis results.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Starting basic analysis for {symbol}\")\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            if not info:\n",
        "                 logger.warning(f\"Could not fetch info for {symbol}. Analysis aborted.\")\n",
        "                 # Return a minimal AnalysisResult with N/A values, including an empty metrics dict\n",
        "                 return AnalysisResult(\n",
        "                     symbol=symbol,\n",
        "                     company_name=symbol,\n",
        "                     current_price=np.nan,\n",
        "                     market_cap=np.nan,\n",
        "                     info={},\n",
        "                     price_data=pd.DataFrame(),\n",
        "                     indicators={},\n",
        "                     fundamental_score=np.nan,\n",
        "                     technical_score=np.nan,\n",
        "                     recommendation=\"N/A\", # Added N/A recommendation\n",
        "                     metrics={} # Include empty metrics dict\n",
        "                 )\n",
        "\n",
        "\n",
        "            # Get price data for technical analysis\n",
        "            price_data = ticker.history(period=\"1y\") # Get 1 year of historical data\n",
        "\n",
        "            metrics = {} # Initialize metrics dictionary before any potential return\n",
        "\n",
        "            # 1. Fundamental Analysis (Simplified)\n",
        "            # Extract key fundamental data points\n",
        "            try:\n",
        "                metrics['marketCap'] = info.get('marketCap', np.nan)\n",
        "                metrics['currentPrice'] = info.get('currentPrice', np.nan)\n",
        "                metrics['sector'] = info.get('sector', 'N/A')\n",
        "                metrics['industry'] = info.get('industry', 'N/A')\n",
        "                company_name = info.get('longName', symbol)\n",
        "\n",
        "                # Extract and store Valuation Ratios\n",
        "                metrics['trailingPE'] = info.get('trailingPE', np.nan)\n",
        "                logger.info(f\"Fetched trailingPE for {symbol}: {metrics['trailingPE']}\")\n",
        "\n",
        "                metrics['priceToBook'] = info.get('priceToBook', np.nan)\n",
        "                logger.info(f\"Fetched priceToBook for {symbol}: {metrics['priceToBook']}\")\n",
        "\n",
        "                enterprise_value = info.get('enterpriseValue', np.nan)\n",
        "                ebitda = info.get('ebitda', np.nan)\n",
        "                metrics['enterpriseValue'] = enterprise_value # Store raw value for reference\n",
        "                metrics['ebitda'] = ebitda # Store raw value for reference\n",
        "\n",
        "                # Calculate EV/EBITDA, handling potential division by zero or missing data\n",
        "                metrics['evToEbitda'] = np.nan # Default to NaN\n",
        "                if isinstance(enterprise_value, (int, float)) and not np.isnan(enterprise_value) and \\\n",
        "                   isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda != 0:\n",
        "                    metrics['evToEbitda'] = enterprise_value / ebitda\n",
        "                    logger.info(f\"Calculated evToEbitda for {symbol}: {metrics['evToEbitda']:.2f}\")\n",
        "                elif (isinstance(enterprise_value, (int, float)) and not np.isnan(enterprise_value)) and \\\n",
        "                     (isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda == 0):\n",
        "                     logger.warning(f\"EBITDA is zero for {symbol}. Cannot calculate EV/EBITDA.\")\n",
        "                else:\n",
        "                    logger.warning(f\"Missing Enterprise Value ({enterprise_value}) or EBITDA ({ebitda}) for {symbol}. Cannot calculate EV/EBITDA.\")\n",
        "\n",
        "\n",
        "                # Dividend Yield\n",
        "                dividend_yield = info.get('dividendYield', np.nan) # This is often already a percentage as a float\n",
        "                # Ensure dividend_yield is not None before checking if it's NaN\n",
        "                if dividend_yield is not None and isinstance(dividend_yield, (int, float)) and not pd.isna(dividend_yield) and dividend_yield >= 0:\n",
        "                     # If dividend_yield is a float between 0 and 1, assume it's a ratio and convert to percentage\n",
        "                     if 0 < dividend_yield <= 1:\n",
        "                         metrics['dividendYield'] = dividend_yield * 100\n",
        "                         logger.info(f\"Converted dividend yield for {symbol} from ratio to percentage: {metrics['dividendYield']:.2f}%\")\n",
        "                     else:\n",
        "                         metrics['dividendYield'] = dividend_yield # Assume it's already a percentage or other form\n",
        "                         logger.info(f\"Dividend yield for {symbol} is {metrics['dividendYield']:.2f}%. Assuming it's already in percentage or other form.\")\n",
        "                else:\n",
        "                     metrics['dividendYield'] = np.nan # Ensure it's NaN if None or invalid\n",
        "                     logger.warning(f\"Dividend yield for {symbol} is unavailable or zero ({dividend_yield}). Setting to NaN.\")\n",
        "\n",
        "\n",
        "                # Other fundamental metrics that might be useful later (Optional for this subtask but good practice)\n",
        "                metrics['returnOnEquity'] = info.get('returnOnEquity', np.nan)\n",
        "                metrics['revenueGrowth'] = info.get('revenueGrowth', np.nan)\n",
        "                metrics['profitMargins'] = info.get('profitMargins', np.nan)\n",
        "\n",
        "\n",
        "            except Exception as fund_e:\n",
        "                 logger.error(f\"Error extracting fundamental data for {symbol}: {fund_e}. Setting fundamental metrics to NaN.\")\n",
        "                 # Ensure metrics are still initialized to handle the rest of the process\n",
        "                 metrics.setdefault('marketCap', np.nan)\n",
        "                 metrics.setdefault('currentPrice', np.nan)\n",
        "                 metrics.setdefault('sector', 'N/A')\n",
        "                 metrics.setdefault('industry', 'N/A')\n",
        "                 metrics.setdefault('trailingPE', np.nan)\n",
        "                 metrics.setdefault('priceToBook', np.nan)\n",
        "                 metrics.setdefault('evToEbitda', np.nan) # Ensure this is set even on error\n",
        "                 metrics.setdefault('dividendYield', np.nan)\n",
        "                 metrics.setdefault('returnOnEquity', np.nan)\n",
        "                 metrics.setdefault('revenueGrowth', np.nan)\n",
        "                 metrics.setdefault('profitMargins', np.nan)\n",
        "                 company_name = info.get('longName', symbol) # Still try to get company name\n",
        "\n",
        "\n",
        "            if price_data.empty:\n",
        "                logger.warning(f\"Could not fetch price data for {symbol}.\")\n",
        "                # Return info even if price data is missing, as fundamental data might still be available\n",
        "                # We will handle missing price data in enhanced calculations\n",
        "                # Ensure all fields are populated with N/A or empty structures, including metrics\n",
        "                return AnalysisResult(\n",
        "                    symbol=symbol,\n",
        "                    company_name=company_name, # Use fetched company name\n",
        "                    current_price=metrics.get('currentPrice', np.nan), # Use current price from metrics\n",
        "                    market_cap=metrics.get('marketCap', np.nan),  # Use market cap from metrics\n",
        "                    info=info,\n",
        "                    price_data=pd.DataFrame(), # Empty DataFrame\n",
        "                    indicators={},\n",
        "                    fundamental_score=np.nan, # Fundamental score needs fundamental data\n",
        "                    technical_score=np.nan, # Technical score needs price data\n",
        "                    recommendation=\"N/A\", # Added N/A recommendation\n",
        "                    metrics=metrics # Include populated metrics dict\n",
        "                )\n",
        "\n",
        "\n",
        "            # Calculate a simple fundamental score (out of 50) - This scoring logic remains the same\n",
        "            fundamental_score = self.calculate_fundamental_score(\n",
        "                 metrics.get('marketCap', np.nan),\n",
        "                 metrics.get('trailingPE', np.nan),\n",
        "                 metrics.get('priceToBook', np.nan),\n",
        "                 metrics.get('dividendYield', np.nan)\n",
        "            )\n",
        "\n",
        "\n",
        "            # 2. Technical Analysis (Simplified)\n",
        "            # Pass price_data and the fetched current_price to technical indicator calculation\n",
        "            indicators = self.calculate_technical_indicators(price_data, metrics.get('currentPrice', np.nan))\n",
        "            technical_score = self.calculate_technical_score(indicators) # Basic technical score (out of 50)\n",
        "\n",
        "            # Generate a basic recommendation (will be replaced by enhanced one later)\n",
        "            basic_recommendation = self.generate_recommendation(fundamental_score, technical_score)\n",
        "\n",
        "\n",
        "            # Bundle results\n",
        "            # Create an AnalysisResult object to hold all analysis results\n",
        "            analysis_results = AnalysisResult(\n",
        "                symbol=symbol,\n",
        "                company_name=company_name, # Use the fetched company name\n",
        "                current_price=metrics.get('currentPrice', np.nan), # Use the fetched current price\n",
        "                market_cap=metrics.get('marketCap', np.nan), # Use the fetched market cap\n",
        "                info=info, # Include the full info dictionary\n",
        "                price_data=price_data,\n",
        "                indicators=indicators,\n",
        "                fundamental_score=fundamental_score,\n",
        "                technical_score=technical_score,\n",
        "                recommendation=basic_recommendation, # Store the basic recommendation\n",
        "                metrics=metrics # Store the populated metrics dictionary\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Basic analysis completed for {symbol}\")\n",
        "            return analysis_results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"An unexpected error occurred during basic analysis for {symbol}: {str(e)}. Returning None.\")\n",
        "            return None # Return None if basic analysis fails due to unexpected error\n",
        "\n",
        "    def calculate_fundamental_score(self, market_cap: float, pe_ratio: float, pb_ratio: float, dividend_yield: float) -> float:\n",
        "        \"\"\"Calculate a simple fundamental score based on key metrics (out of 50)\"\"\"\n",
        "        score = 0\n",
        "        logger.info(\"Calculating basic fundamental score.\")\n",
        "        # Ensure metrics are valid numbers before scoring\n",
        "        market_cap_valid = isinstance(market_cap, (int, float)) and not pd.isna(market_cap) and market_cap > 0\n",
        "        pe_ratio_valid = isinstance(pe_ratio, (int, float)) and not pd.isna(pe_ratio) and pe_ratio > 0\n",
        "        pb_ratio_valid = isinstance(pb_ratio, (int, float)) and not pd.isna(pb_ratio) and pb_ratio > 0\n",
        "        dividend_yield_valid = isinstance(dividend_yield, (int, float)) and not pd.isna(dividend_yield) and dividend_yield >= 0\n",
        "\n",
        "        logger.debug(f\"Fundamental metrics validity: Market Cap={market_cap_valid}, PE={pe_ratio_valid}, PB={pb_ratio_valid}, Dividend Yield={dividend_yield_valid}\")\n",
        "\n",
        "        # Market Cap (Scale based on size, larger usually means more stable)\n",
        "        if market_cap_valid:\n",
        "            if market_cap > 10_00_000_00_00_000:  # > 10 Lakh Cr (Large Cap)\n",
        "                score += 15\n",
        "                logger.debug(f\"Market Cap ({market_cap:.2f}) is Large Cap. +15 pts.\")\n",
        "            elif market_cap > 50_000_00_00_000:   # > 50K Cr (Mid Cap)\n",
        "                score += 10\n",
        "                logger.debug(f\"Market Cap ({market_cap:.2f}) is Mid Cap. +10 pts.\")\n",
        "            else: # Small Cap and below\n",
        "                score += 5\n",
        "                logger.debug(f\"Market Cap ({market_cap:.2f}) is Small Cap or below. +5 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"Market cap is invalid for fundamental scoring.\")\n",
        "\n",
        "\n",
        "        # PE Ratio (Lower is generally better, but depends on industry growth)\n",
        "        if pe_ratio_valid:\n",
        "            if pe_ratio < 20:\n",
        "                score += 15\n",
        "                logger.debug(f\"PE Ratio ({pe_ratio:.2f}) < 20. +15 pts.\")\n",
        "            elif pe_ratio < 30:\n",
        "                score += 10\n",
        "                logger.debug(f\"PE Ratio ({pe_ratio:.2f}) < 30. +10 pts.\")\n",
        "            elif pe_ratio < 40:\n",
        "                score += 5\n",
        "                logger.debug(f\"PE Ratio ({pe_ratio:.2f}) < 40. +5 pts.\")\n",
        "            else: # High PE\n",
        "                score += 2\n",
        "                logger.debug(f\"PE Ratio ({pe_ratio:.2f}) >= 40. +2 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"PE ratio is invalid for fundamental scoring.\")\n",
        "\n",
        "\n",
        "        # PB Ratio (Lower is generally better, indicates undervaluation)\n",
        "        if pb_ratio_valid:\n",
        "            if pb_ratio < 3:\n",
        "                score += 10\n",
        "                logger.debug(f\"PB Ratio ({pb_ratio:.2f}) < 3. +10 pts.\")\n",
        "            elif pb_ratio < 5:\n",
        "                score += 7\n",
        "                logger.debug(f\"PB Ratio ({pb_ratio:.2f}) < 5. +7 pts.\")\n",
        "            else:\n",
        "                score += 3\n",
        "                logger.debug(f\"PB Ratio ({pb_ratio:.2f}) >= 5. +3 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"PB ratio is invalid for fundamental scoring.\")\n",
        "\n",
        "\n",
        "        # Dividend Yield (Higher is better for income-seeking investors, indicates profitability)\n",
        "        if dividend_yield_valid:\n",
        "            if dividend_yield > 3: # > 3%\n",
        "                score += 10\n",
        "                logger.debug(f\"Dividend Yield ({dividend_yield:.2f}%) > 3%. +10 pts.\")\n",
        "            elif dividend_yield > 1: # > 1%\n",
        "                score += 7\n",
        "                logger.debug(f\"Dividend Yield ({dividend_yield:.2f}%) > 1%. +7 pts.\")\n",
        "            else:\n",
        "                score += 3\n",
        "                logger.debug(f\"Dividend Yield ({dividend_yield:.2f}%) <= 1%. +3 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"Dividend yield is invalid for fundamental scoring.\")\n",
        "\n",
        "        logger.info(f\"Fundamental score calculated: {score}\")\n",
        "        return min(score, 50) # Cap score at 50\n",
        "\n",
        "    def calculate_technical_indicators(self, price_data: pd.DataFrame, current_price: float) -> Dict: # Added type hints\n",
        "        \"\"\"Calculate key technical indicators\"\"\"\n",
        "        logger.info(\"Calculating technical indicators.\")\n",
        "        # Ensure price_data is valid before calculating indicators\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty:\n",
        "            logger.warning(\"Insufficient price data for technical indicator calculation.\")\n",
        "            return {'RSI': np.nan, 'MACD': np.nan, 'MACD_signal': np.nan, 'SMA_20': np.nan, 'SMA_50': np.nan,\n",
        "                    'BB_upper': np.nan, 'BB_lower': np.nan, 'BB_middle': np.nan, 'Volume_ratio': np.nan,\n",
        "                    'current_price': current_price} # Return NaNs if data is missing\n",
        "\n",
        "\n",
        "        indicators = {}\n",
        "        data_len = len(price_data)\n",
        "\n",
        "        try:\n",
        "            # RSI (Relative Strength Index)\n",
        "            if data_len >= 14:\n",
        "                delta = price_data['Close'].diff()\n",
        "                gain = delta.where(delta > 0, 0)\n",
        "                loss = -delta.where(delta < 0, 0)\n",
        "                avg_gain = gain.ewm(com=14-1, adjust=False).mean()\n",
        "                avg_loss = loss.ewm(com=14-1, adjust=False).mean()\n",
        "                # Handle division by zero explicitly\n",
        "                if avg_loss.iloc[-1] is not None and not np.isnan(avg_loss.iloc[-1]) and avg_loss.iloc[-1] != 0:\n",
        "                    rs = avg_gain / avg_loss\n",
        "                    indicators['RSI'] = 100 - (100 / (1 + rs)).iloc[-1]\n",
        "                elif avg_gain.iloc[-1] is not None and not np.isnan(avg_gain.iloc[-1]) and avg_gain.iloc[-1] > 0:\n",
        "                     indicators['RSI'] = 100.0 # If no loss but gain, RSI is 100\n",
        "                else:\n",
        "                     indicators['RSI'] = 50.0 # If no gain and no loss, RSI is 50\n",
        "                logger.debug(f\"Calculated RSI: {indicators['RSI']:.2f}\")\n",
        "            else:\n",
        "                indicators['RSI'] = np.nan\n",
        "                logger.warning(\"Insufficient data for RSI.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate RSI: {e}. Setting to NaN.\")\n",
        "            indicators['RSI'] = np.nan\n",
        "\n",
        "        try:\n",
        "            # MACD (Moving Average Convergence Divergence)\n",
        "            if data_len >= 26: # Need at least 26 data points for 26-day EMA\n",
        "                ema_12 = price_data['Close'].ewm(span=12, adjust=False).mean()\n",
        "                ema_26 = price_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "                # Corrected MACD signal calculation to use the MACD Series\n",
        "                macd_series = ema_12 - ema_26\n",
        "                if data_len >= 26 + 9 - 1: # Need enough data points for 9-day EMA of MACD\n",
        "                     indicators['MACD'] = macd_series.iloc[-1]\n",
        "                     indicators['MACD_signal'] = macd_series.ewm(span=9, adjust=False).mean().iloc[-1]\n",
        "                     logger.debug(f\"Calculated MACD: {indicators['MACD']:.2f}, MACD Signal: {indicators['MACD_signal']:.2f}\")\n",
        "                else:\n",
        "                     indicators['MACD'] = np.nan\n",
        "                     indicators['MACD_signal'] = np.nan\n",
        "                     logger.warning(\"Insufficient data for MACD signal calculation.\")\n",
        "            else:\n",
        "                 indicators['MACD'] = np.nan\n",
        "                 indicators['MACD_signal'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for MACD calculation.\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate MACD: {e}. Setting to NaN.\")\n",
        "            indicators['MACD'] = np.nan\n",
        "            indicators['MACD_signal'] = np.nan\n",
        "\n",
        "        try:\n",
        "            # Moving Averages\n",
        "            if data_len >= 20:\n",
        "                 indicators['SMA_20'] = price_data['Close'].rolling(window=20).mean().iloc[-1]\n",
        "                 logger.debug(f\"Calculated SMA_20: {indicators['SMA_20']:.2f}\")\n",
        "            else:\n",
        "                 indicators['SMA_20'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_20.\")\n",
        "\n",
        "            if data_len >= 50:\n",
        "                 indicators['SMA_50'] = price_data['Close'].rolling(window=50).mean().iloc[-1]\n",
        "                 logger.debug(f\"Calculated SMA_50: {indicators['SMA_50']:.2f}\")\n",
        "            else:\n",
        "                 indicators['SMA_50'] = np.nan\n",
        "                 logger.warning(\"Insufficient data for SMA_50.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate Moving Averages: {e}. Setting relevant MAs to NaN.\")\n",
        "            if 'SMA_20' not in indicators: indicators['SMA_20'] = np.nan\n",
        "            if 'SMA_50' not in indicators: indicators['SMA_50'] = np.nan\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Bollinger Bands\n",
        "            bb_period = 20\n",
        "            bb_std = 2\n",
        "            if data_len >= bb_period:\n",
        "                rolling_mean = price_data['Close'].rolling(window=bb_period).mean()\n",
        "                rolling_std = price_data['Close'].rolling(window=bb_period).std()\n",
        "                if not pd.isna(rolling_mean.iloc[-1]) and not pd.isna(rolling_std.iloc[-1]):\n",
        "                    indicators['BB_middle'] = rolling_mean.iloc[-1]\n",
        "                    indicators['BB_upper'] = (rolling_mean + (rolling_std * bb_std)).iloc[-1]\n",
        "                    indicators['BB_lower'] = (rolling_mean - (rolling_std * bb_std)).iloc[-1]\n",
        "                    logger.debug(f\"Calculated BB: Middle={indicators['BB_middle']:.2f}, Upper={indicators['BB_upper']:.2f}, Lower={indicators['BB_lower']:.2f}\")\n",
        "                else:\n",
        "                    indicators['BB_middle'] = np.nan\n",
        "                    indicators['BB_upper'] = np.nan\n",
        "                    indicators['BB_lower'] = np.nan\n",
        "                    logger.warning(\"Bollinger Bands calculation resulted in NaN.\")\n",
        "            else:\n",
        "                indicators['BB_middle'] = np.nan\n",
        "                indicators['BB_upper'] = np.nan\n",
        "                indicators['BB_lower'] = np.nan\n",
        "                logger.warning(\"Insufficient data for Bollinger Bands.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate Bollinger Bands: {e}. Setting to NaN.\")\n",
        "            indicators['BB_middle'] = np.nan\n",
        "            indicators['BB_upper'] = np.nan\n",
        "            indicators['BB_lower'] = np.nan\n",
        "\n",
        "        try:\n",
        "            # Volume Analysis (e.g., current volume vs average volume)\n",
        "            volume_period = 30\n",
        "            if data_len >= volume_period:\n",
        "                 avg_volume_30d = price_data['Volume'].rolling(window=volume_period).mean().iloc[-1]\n",
        "                 current_volume = price_data['Volume'].iloc[-1]\n",
        "                 # Check for zero division and NaN before calculating ratio\n",
        "                 if not pd.isna(avg_volume_30d) and avg_volume_30d > 0 and not pd.isna(current_volume):\n",
        "                      indicators['Volume_ratio'] = current_volume / avg_volume_30d\n",
        "                      logger.debug(f\"Calculated Volume Ratio: {indicators['Volume_ratio']:.2f}\")\n",
        "                 elif not pd.isna(current_volume) and current_volume > 0:\n",
        "                      # If 30d avg is zero or NaN but current volume is positive, assume high relative volume\n",
        "                      indicators['Volume_ratio'] = 2.0 # Arbitrary high ratio to indicate spike\n",
        "                      logger.warning(\"30-day average volume is invalid for volume ratio, assuming spike due to positive current volume.\")\n",
        "                 else:\n",
        "                      indicators['Volume_ratio'] = np.nan\n",
        "                      logger.warning(\"Insufficient or invalid volume data for volume ratio calculation.\")\n",
        "            else:\n",
        "                indicators['Volume_ratio'] = np.nan\n",
        "                logger.warning(\"Insufficient data for Volume Ratio.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate Volume Ratio: {e}. Setting to NaN.\")\n",
        "            indicators['Volume_ratio'] = np.nan\n",
        "\n",
        "        # Include current price in indicators for technical score calculation\n",
        "        indicators['current_price'] = current_price if not pd.isna(current_price) else np.nan\n",
        "\n",
        "        logger.info(f\"Technical indicators calculated: {indicators}\")\n",
        "        return indicators\n",
        "\n",
        "\n",
        "    def calculate_technical_score(self, indicators: Dict) -> float: # Added type hint\n",
        "        \"\"\"Calculate a simple technical score based on indicators (out of 50)\"\"\"\n",
        "        score = 0\n",
        "        logger.info(\"Calculating basic technical score.\")\n",
        "        # Ensure indicators dictionary is valid\n",
        "        if not isinstance(indicators, dict):\n",
        "             logger.warning(\"Invalid indicators dictionary for technical scoring.\")\n",
        "             return 0\n",
        "\n",
        "        # Scoring based on common indicator signals\n",
        "        # Ensure indicator values are valid numbers before scoring\n",
        "        rsi = indicators.get('RSI', np.nan)\n",
        "        macd = indicators.get('MACD', np.nan)\n",
        "        macd_signal = indicators.get('MACD_signal', np.nan)\n",
        "        sma_20 = indicators.get('SMA_20', np.nan)\n",
        "        sma_50 = indicators.get('SMA_50', np.nan)\n",
        "        current_price = indicators.get('current_price', np.nan)\n",
        "        bb_upper = indicators.get('BB_upper', np.nan)\n",
        "        bb_lower = indicators.get('BB_lower', np.nan)\n",
        "        volume_ratio = indicators.get('Volume_ratio', np.nan)\n",
        "\n",
        "        logger.debug(f\"Indicators for basic technical scoring: RSI={rsi}, MACD={macd}, Signal={macd_signal}, SMA20={sma_20}, SMA50={sma_50}, Price={current_price}, BB_Upper={bb_upper}, BB_Lower={bb_lower}, VolumeRatio={volume_ratio}\")\n",
        "\n",
        "\n",
        "        # RSI Score\n",
        "        if not pd.isna(rsi):\n",
        "            if rsi < 30: # Oversold\n",
        "                score += 10\n",
        "                logger.debug(\"RSI < 30. +10 pts.\")\n",
        "            elif rsi > 70: # Overbought\n",
        "                score -= 10\n",
        "                logger.debug(\"RSI > 70. -10 pts.\")\n",
        "            elif 40 <= rsi <= 60: # Neutral\n",
        "                 score += 5\n",
        "                 logger.debug(\"RSI 40-60. +5 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"RSI is NaN for technical scoring.\")\n",
        "\n",
        "        # MACD Score (Bullish crossover)\n",
        "        if not pd.isna(macd) and not pd.isna(macd_signal):\n",
        "            if macd > macd_signal:\n",
        "                score += 10\n",
        "                logger.debug(\"MACD > Signal. +10 pts.\")\n",
        "            else:\n",
        "                 score += 2 # Small score if bearish or neutral\n",
        "                 logger.debug(\"MACD <= Signal. +2 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"MACD or MACD signal is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        # Moving Average Crossover (Bullish: 20-day > 50-day)\n",
        "        if not pd.isna(sma_20) and not pd.isna(sma_50):\n",
        "            if sma_20 > sma_50:\n",
        "                score += 10\n",
        "                logger.debug(\"SMA20 > SMA50. +10 pts.\")\n",
        "            else:\n",
        "                score += 5 # Add a small score if 20-day is below but close to 50-day\n",
        "                logger.debug(\"SMA20 <= SMA50. +5 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"SMA_20 or SMA_50 is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        # Bollinger Bands (Price near lower band suggests potential buy)\n",
        "        if not pd.isna(current_price) and not pd.isna(bb_lower) and not pd.isna(bb_upper):\n",
        "            if not pd.isna(bb_lower) and current_price < bb_lower:\n",
        "                score += 10\n",
        "                logger.debug(\"Price < Lower BB. +10 pts.\")\n",
        "            elif not pd.isna(bb_upper) and current_price > bb_upper:\n",
        "                score -= 10\n",
        "                logger.debug(\"Price > Upper BB. -10 pts.\")\n",
        "            elif not pd.isna(bb_lower) and not pd.isna(bb_upper) and bb_lower <= current_price <= bb_upper: # Price is within the bands\n",
        "                 score += 5 # Add a small score for price being within bands, indicating less volatility\n",
        "                 logger.debug(\"Price within BB. +5 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"Bollinger Bands or current price is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        # Volume Spike (Significant volume increase can confirm trends)\n",
        "        if not pd.isna(volume_ratio):\n",
        "            if volume_ratio > 1.5: # Volume is 50% higher than average\n",
        "                 score += 10\n",
        "                 logger.debug(f\"Volume Ratio ({volume_ratio:.2f}) > 1.5. +10 pts.\")\n",
        "            elif volume_ratio < 0.8: # Volume is significantly lower than average\n",
        "                 score += 2 # Small score for low volume\n",
        "                 logger.debug(f\"Volume Ratio ({volume_ratio:.2f}) < 0.8. +2 pts.\")\n",
        "            else:\n",
        "                 score += 5 # Average volume is neutral\n",
        "                 logger.debug(f\"Volume Ratio ({volume_ratio:.2f}) 0.8-1.5. +5 pts.\")\n",
        "        else:\n",
        "             logger.warning(\"Volume ratio is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        logger.info(f\"Basic technical score calculated: {score}\")\n",
        "        return max(0, min(score, 50)) # Cap score between 0 and 50\n",
        "\n",
        "    def generate_recommendation(self, fundamental_score: float, technical_score: float) -> str: # Added type hints\n",
        "        \"\"\"Generate investment recommendation based on scores\"\"\"\n",
        "        logger.info(f\"Generating basic recommendation based on Fundamental Score: {fundamental_score}, Technical Score: {technical_score}\")\n",
        "        # Ensure scores are valid numbers before summing\n",
        "        fund_score = fundamental_score if isinstance(fundamental_score, (int, float)) and not np.isnan(fundamental_score) else 0\n",
        "        tech_score = technical_score if isinstance(technical_score, (int, float)) and not np.isnan(technical_score) else 0\n",
        "\n",
        "        total_score = fund_score + tech_score\n",
        "        logger.debug(f\"Total score for basic recommendation: {total_score}\")\n",
        "\n",
        "        if total_score >= 75:\n",
        "            return \"STRONG BUY\"\n",
        "        elif total_score >= 60:\n",
        "            return \"BUY\"\n",
        "        elif total_score >= 40:\n",
        "            return \"HOLD\"\n",
        "        elif total_score >= 25:\n",
        "            return \"SELL\"\n",
        "        else:\n",
        "            return \"STRONG SELL\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "672063ed"
      },
      "source": [
        "**Reasoning**:\n",
        "The `AnalysisResult` class was updated to include the `metrics` dictionary, which should resolve the `AttributeError`. Now, re-run the enhanced analysis integration and report display code to incorporate the downside risk calculation and its display in the report.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3524c3c8",
        "cellView": "form"
      },
      "source": [
        "#@title Part 3: Enhanced Analysis Integration and Report Display (with Downside Risk Analysis - Retry)\n",
        "\n",
        "# Assuming IndianStockAnalyzer and EnhancedStockAnalyzer classes are defined in previous cells\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "    if not isinstance(symbol, str) or not symbol:\n",
        "        logger.error(\"Invalid stock symbol provided for enhanced analysis.\")\n",
        "        return None\n",
        "    if not isinstance(stock_analyzer_part1, IndianStockAnalyzer):\n",
        "        logger.error(\"Invalid IndianStockAnalyzer (Part 1) instance provided.\")\n",
        "        return None\n",
        "    if not isinstance(enhanced_analyzer, EnhancedStockAnalyzer):\n",
        "        logger.error(\"Invalid EnhancedStockAnalyzer (Part 2) instance provided.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    logger.info(f\"Starting enhanced analysis for {symbol}\")\n",
        "    # Get basic analysis from Part 1\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        logger.error(f\"Basic analysis failed for {symbol}.\")\n",
        "        return None\n",
        "\n",
        "    # Get current price - already validated in Part 1 analyze_stock\n",
        "    current_price = stock_data.current_price\n",
        "    if pd.isna(current_price) or current_price <= 0:\n",
        "         logger.warning(f\"Current price invalid ({current_price}). Enhanced analysis might be limited.\")\n",
        "\n",
        "\n",
        "    # Enhanced analysis\n",
        "    logger.info(\"Starting enhanced analysis features (Part 2).\")\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    # Pass current_price to assess_circuit_risk (already validated as best as possible in Part 1)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    # Pass price_data (already validated in Part 1 analyze_stock)\n",
        "    # CORRECTED: Call get_liquidity_score on enhanced_analyzer and pass price_data from stock_data\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "\n",
        "    # 3. Peer analysis (including valuation data)\n",
        "    # Pass info (already validated in Part 1 analyze_stock)\n",
        "    # The get_peer_companies method now returns a list of dictionaries with valuation data\n",
        "    peers_with_valuation = enhanced_analyzer.get_peer_companies(symbol, stock_data.info)\n",
        "    # Pass the list of peer symbols (extracted from the list of dictionaries) for performance comparison\n",
        "    peer_symbols_for_performance = [p['symbol'] for p in peers_with_valuation if isinstance(p, dict) and 'symbol' in p]\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peer_symbols_for_performance) # Pass just symbols\n",
        "\n",
        "    # 4. Valuation Analysis: Calculate peer average valuations and compare\n",
        "    peer_average_valuation = enhanced_analyzer.calculate_peer_average_valuation(peers_with_valuation)\n",
        "    valuation_comparison_results = enhanced_analyzer.compare_valuation_to_peers(stock_data.metrics, peer_average_valuation)\n",
        "\n",
        "    # 5. Downside Risk Assessment: Calculate VaR\n",
        "    downside_risk_metrics = enhanced_analyzer.calculate_value_at_risk(stock_data.price_data)\n",
        "\n",
        "\n",
        "    # 6. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "\n",
        "    # 7. Recalculate technical score with circuit risk\n",
        "    # Pass indicators (already validated in Part 1 calculate_technical_indicators)\n",
        "    # Pass circuit_risk (already validated in assess_circuit_risk)\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "\n",
        "    # 8. Fetch and analyze news sentiment\n",
        "    # Pass symbol (already validated)\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    # Pass news_headlines (already validated)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "\n",
        "\n",
        "    # 9. Generate enhanced recommendation\n",
        "    # Pass scores and results (already validated within their respective functions)\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance, # Pass potentially incomplete/NaN peer performance\n",
        "        index_membership,\n",
        "        sentiment_analysis_results, # Pass sentiment analysis results\n",
        "        valuation_comparison_results, # Pass valuation comparison results\n",
        "        downside_risk_metrics # Pass downside risk metrics\n",
        "    )\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score, # Ensure correct liquidity score is included\n",
        "            'peers': peers_with_valuation, # Store the list of peers with their valuation data\n",
        "            'peer_performance': peer_performance, # Include peer performance, even if NaN\n",
        "            'peer_average_valuation': peer_average_valuation, # Store peer average valuation\n",
        "            'valuation_comparison': valuation_comparison_results, # Store valuation comparison results\n",
        "            'downside_risk': downside_risk_metrics, # Store downside risk metrics (e.g., VaR)\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "    logger.info(f\"Enhanced analysis completed for {symbol}\")\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize analyzers\n",
        "    try:\n",
        "        stock_analyzer = IndianStockAnalyzer()\n",
        "        enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "    except NameError:\n",
        "        print(\"Make sure to run the previous cells defining IndianStockAnalyzer and EnhancedStockAnalyzer classes.\")\n",
        "        exit() # Exit if classes are not defined\n",
        "\n",
        "\n",
        "    # Analyze a stock\n",
        "    symbol = \"RELIANCE.NS\" # Example symbol\n",
        "    result = analyze_stock_enhanced(symbol, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if result:\n",
        "        # Display the enhanced report\n",
        "        enhanced = result['enhanced_features']\n",
        "        final = result['final_recommendation']\n",
        "        basic = result['basic_analysis'] # Get basic data for display\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Enhanced Analysis Report: {basic.company_name} ({basic.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if not pd.isna(basic.current_price) else \"Current Price: N/A\")\n",
        "        market_cap_cr = basic.market_cap / 10000000 if not pd.isna(basic.market_cap) else np.nan\n",
        "        print(f\"Market Cap: ₹{market_cap_cr:,.2f} Cr\" if not pd.isna(market_cap_cr) else \"Market Cap: N/A\")\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n⚙️ Enhanced Technical Analysis & Risk:\")\n",
        "        # Display enhanced technical indicators and risk\n",
        "        # Assuming you want to display relevant indicators from basic.indicators and the circuit risk score\n",
        "        circuit_limits_display = enhanced.get('circuit_limits')\n",
        "        if circuit_limits_display and not pd.isna(circuit_limits_display.get('lower_circuit')) and not pd.isna(circuit_limits_display.get('upper_circuit')):\n",
        "             print(f\"Circuit Limits: {circuit_limits_display.get('lower_circuit', 'N/A'):.2f} - {circuit_limits_display.get('upper_circuit', 'N/A'):.2f}\")\n",
        "        else:\n",
        "             print(\"Circuit Limits: N/A\")\n",
        "\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        # Check if liquidity score is available before formatting\n",
        "        liquidity_score_display = f\"{enhanced.get('liquidity_score', 'N/A')}/70\" if isinstance(enhanced.get('liquidity_score'), (int, float)) and not pd.isna(enhanced.get('liquidity_score')) else \"Liquidity Score: N/A/70\"\n",
        "        print(liquidity_score_display)\n",
        "\n",
        "\n",
        "        # Display some key technical indicators from basic analysis\n",
        "        print(\"\\nKey Technical Indicators (from Basic Analysis):\")\n",
        "        key_tech_indicators = ['RSI', 'MACD', 'MACD_signal', 'SMA_20', 'SMA_50', 'BB_middle', 'Volume_ratio']\n",
        "        for indicator_name in key_tech_indicators:\n",
        "            value = basic.indicators.get(indicator_name, np.nan)\n",
        "            if not pd.isna(value):\n",
        "                if isinstance(value, float):\n",
        "                     print(f\"  - {indicator_name}: {value:,.2f}\")\n",
        "                else:\n",
        "                     print(f\"  - {indicator_name}: {value}\")\n",
        "            # Add logging for these key technical indicators if they are calculated\n",
        "            logger.info(f\"Indicator {indicator_name}: {value}\")\n",
        "        else:\n",
        "            print(f\"  - {indicator_name}: N/A\")\n",
        "            logger.info(f\"Indicator {indicator_name}: N/A\")\n",
        "\n",
        "        # Display Valuation Analysis\n",
        "        print(f\"\\n📈 Valuation Analysis:\")\n",
        "        stock_metrics = basic.metrics\n",
        "        peer_avg_val = enhanced.get('peer_average_valuation', {})\n",
        "        val_comp_results = enhanced.get('valuation_comparison', {})\n",
        "\n",
        "        stock_pe = stock_metrics.get('trailingPE', np.nan)\n",
        "        stock_pb = stock_metrics.get('priceToBook', np.nan)\n",
        "        stock_ev_ebitda = stock_metrics.get('evToEbitda', np.nan)\n",
        "\n",
        "        print(f\"Stock Valuation:\")\n",
        "        print(f\"  - Trailing PE: {stock_pe:.2f}\" if not pd.isna(stock_pe) else \"  - Trailing PE: N/A\")\n",
        "        print(f\"  - Price to Book: {stock_pb:.2f}\" if not pd.isna(stock_pb) else \"  - Price to Book: N/A\")\n",
        "        print(f\"  - EV/EBITDA: {stock_ev_ebitda:.2f}\" if not pd.isna(stock_ev_ebitda) else \"  - EV/EBITDA: N/A\")\n",
        "\n",
        "        print(\"\\nPeer Average Valuation:\")\n",
        "        avg_pe_display = f\"{peer_avg_val.get('avg_pe', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pe', np.nan)) else \"N/A\"\n",
        "        avg_pb_display = f\"{peer_avg_val.get('avg_pb', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pb', np.nan)) else \"N/A\"\n",
        "        avg_ev_ebitda_display = f\"{peer_avg_val.get('avg_ev_ebitda', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_ev_ebitda', np.nan)) else \"N/A\"\n",
        "\n",
        "        print(f\"  - Average PE: {avg_pe_display}\")\n",
        "        print(f\"  - Average PB: {avg_pb_display}\")\n",
        "        print(f\"  - Average EV/EBITDA: {avg_ev_ebitda_display}\")\n",
        "\n",
        "        print(\"\\nValuation Comparison:\")\n",
        "        print(f\"  - PE Comparison: {val_comp_results.get('pe_comparison', 'N/A')}\")\n",
        "        print(f\"  - PB Comparison: {val_comp_results.get('pb_comparison', 'N/A')}\")\n",
        "        print(f\"  - EV/EBITDA Comparison: {val_comp_results.get('ev_ebitda_comparison', 'N/A')}\")\n",
        "        valuation_adj_display = f\"{val_comp_results.get('valuation_score_adjustment', 0):+.2f}\" if isinstance(val_comp_results.get('valuation_score_adjustment'), (int, float)) and not pd.isna(val_comp_results.get('valuation_score_adjustment')) else \"N/A\"\n",
        "        print(f\"  - Valuation Score Adjustment: {valuation_adj_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\n📉 Downside Risk Analysis:\")\n",
        "        downside_risk = enhanced.get('downside_risk', {})\n",
        "        var_percentage = downside_risk.get('var_percentage_loss', np.nan)\n",
        "        var_display = f\"{var_percentage:.2f}%\" if not pd.isna(var_percentage) else \"N/A\"\n",
        "        print(f\"  - {downside_risk.get('confidence_level', 0.95)*100:.0f}% VaR ({downside_risk.get('horizon_days', 1)}-day): {var_display}\")\n",
        "        downside_adj_display = f\"{final.get('breakdown', {}).get('downside_risk', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('downside_risk'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('downside_risk')) else \"N/A\"\n",
        "        print(f\"  - Downside Risk Score Adjustment: {downside_adj_display}\")\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"\\n🤝 Peer Analysis (Performance):\")\n",
        "        peer_perf = enhanced.get('peer_performance')\n",
        "        if isinstance(peer_perf, dict) and \\\n",
        "           not pd.isna(peer_perf.get('stock_return')) and \\\n",
        "           not pd.isna(peer_perf.get('avg_peer_return')) and \\\n",
        "           not pd.isna(peer_perf.get('relative_performance')):\n",
        "\n",
        "             stock_return_display = f\"{peer_perf.get('stock_return', np.nan):.2f}%\" if isinstance(peer_perf.get('stock_return'), (int, float)) and not pd.isna(peer_perf.get('stock_return')) else 'N/A'\n",
        "             avg_peer_return_display = f\"{peer_perf.get('avg_peer_return', np.nan):.2f}%\" if isinstance(peer_perf.get('avg_peer_return'), (int, float)) and not pd.isna(peer_perf.get('avg_peer_return')) else 'N/A'\n",
        "             relative_performance_display = f\"{peer_perf.get('relative_performance', np.nan):.2f}%\" if isinstance(peer_perf.get('relative_performance'), (int, float)) and not pd.isna(peer_perf.get('relative_performance')) else 'N/A'\n",
        "\n",
        "             print(f\"  - {peer_perf.get('days', 'N/A')}-day Stock Return: {stock_return_display}\")\n",
        "             print(f\"  - Avg Peer Return: {avg_peer_return_display}\")\n",
        "             print(f\"  - Relative Performance: {relative_performance_display}\")\n",
        "        else:\n",
        "             print(\"Peer Performance Data Unavailable.\")\n",
        "\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"\\n🏛️ Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             # Only print a few headlines to keep the report concise\n",
        "             print(\"Sample News Headlines:\")\n",
        "             # Ensure headlines are valid strings before printing\n",
        "             valid_headlines = [h for h in enhanced['news_headlines'] if isinstance(h, str)]\n",
        "             for headline in valid_headlines[:5]: # Print up to 5 headlines\n",
        "                 print(f\"- {headline}\")\n",
        "             if len(valid_headlines) > 5:\n",
        "                  print(\"  ...\")\n",
        "\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             sentiment_score_display = f\"{sentiment_results.get('score', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\"\n",
        "             print(f\"Sentiment Score: {sentiment_score_display}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Comprehensive Scores and Recommendation ---\")\n",
        "        print(f\"Fundamental Score (from Part 1): {basic.fundamental_score:.2f}/50\" if not pd.isna(basic.fundamental_score) else \"Fundamental Score: N/A\")\n",
        "        # Add checks for NaN before formatting float for breakdown scores\n",
        "        enhanced_tech_score_display = f\"{final.get('breakdown', {}).get('technical', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('technical'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('technical')) else \"N/A\"\n",
        "        liquidity_score_display_breakdown = f\"{final.get('breakdown', {}).get('liquidity', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('liquidity'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('liquidity')) else \"N/A\"\n",
        "        sentiment_score_display_breakdown = f\"{final.get('breakdown', {}).get('sentiment', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\" # Corrected sentiment score breakdown check\n",
        "        valuation_comp_display_breakdown = f\"{final.get('breakdown', {}).get('valuation_comparison', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('valuation_comparison'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('valuation_comparison')) else \"N/A\"\n",
        "        downside_risk_display_breakdown = f\"{final.get('breakdown', {}).get('downside_risk', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('downside_risk'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('downside_risk')) else \"N/A\"\n",
        "\n",
        "\n",
        "        print(f\"Technical Score (Enhanced): {enhanced_tech_score_display}/50\")\n",
        "        print(f\"Liquidity Score: {liquidity_score_display_breakdown}/70\")\n",
        "        print(f\"Sentiment Score: {sentiment_score_display_breakdown}/25\")\n",
        "        print(f\"Valuation Comparison Adjustment: {valuation_comp_display_breakdown}\")\n",
        "        print(f\"Downside Risk Adjustment: {downside_risk_display_breakdown}\")\n",
        "\n",
        "\n",
        "        # Display adjustment scores\n",
        "        peer_adj_display = f\"{final.get('breakdown', {}).get('peer_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('peer_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('peer_adjustment')) else \"N/A\"\n",
        "        index_adj_display = f\"{final.get('breakdown', {}).get('index_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('index_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('index_adjustment')) else \"N/A\"\n",
        "\n",
        "        print(f\"Peer Performance Adjustment: {peer_adj_display}\")\n",
        "        print(f\"Index Membership Adjustment: {index_adj_display}\")\n",
        "\n",
        "\n",
        "        # Updated max score to reflect the addition of Downside Risk Adjustment (potential max increase of 0, potential max decrease of 15)\n",
        "        # Max Total Score = Fund (50) + Tech (50) + Liq (70) + Sent (25) + Val Adj (30) + Peer Adj (5) + Index Adj (5) + Downside Adj (0) = 235\n",
        "        # Re-evaluating the previous max estimate (245) and the new max. Let's use 235 as a potential max for scoring clarity.\n",
        "        print(f\"\\nTotal Enhanced Score: {final.get('total_score', 0):.2f}/235\" if isinstance(final.get('total_score'), (int, float)) and not pd.isna(final.get('total_score')) else \"Total Enhanced Score: N/A\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} (Confidence: {final.get('confidence', 'N/A')})\")\n",
        "\n",
        "\n",
        "        print(f\"\\n{'='*60}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46d890ca"
      },
      "source": [
        "# Task\n",
        "Continue with the plan to enhance the stock analysis tool by implementing downside risk assessment, enhancing dividend yield calculation, incorporating global macro impacts, integrating new analyses into the report, and refining scoring and recommendation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fbd91be"
      },
      "source": [
        "## Implement downside risk assessment\n",
        "\n",
        "### Subtask:\n",
        "Implement the downside risk assessment method within the `EnhancedStockAnalyzer` class, calculating Value at Risk (VaR) using historical data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9167c1fc"
      },
      "source": [
        "**Reasoning**:\n",
        "The error was due to the `AnalysisResult` class not having the `metrics` attribute when it was accessed in the `analyze_stock_enhanced` function. I have now updated the `AnalysisResult` dataclass definition in Part 1 to include the `metrics` dictionary, which should resolve this issue. The next logical step is to re-run the code block containing the `EnhancedStockAnalyzer` class definition to ensure this updated class and the `calculate_value_at_risk` method are loaded into the environment before attempting to run the integration and display code again. This was already done in the previous turn, so the next logical step is to re-run the integration code cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad368103",
        "cellView": "form"
      },
      "source": [
        "#@title Part 3: Enhanced Analysis Integration and Report Display (with Downside Risk Analysis - Retry Again)\n",
        "\n",
        "# Assuming IndianStockAnalyzer and EnhancedStockAnalyzer classes are defined in previous cells\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "    if not isinstance(symbol, str) or not symbol:\n",
        "        logger.error(\"Invalid stock symbol provided for enhanced analysis.\")\n",
        "        return None\n",
        "    if not isinstance(stock_analyzer_part1, IndianStockAnalyzer):\n",
        "        logger.error(\"Invalid IndianStockAnalyzer (Part 1) instance provided.\")\n",
        "        return None\n",
        "    if not isinstance(enhanced_analyzer, EnhancedStockAnalyzer):\n",
        "        logger.error(\"Invalid EnhancedStockAnalyzer (Part 2) instance provided.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    logger.info(f\"Starting enhanced analysis for {symbol}\")\n",
        "    # Get basic analysis from Part 1\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        logger.error(f\"Basic analysis failed for {symbol}.\")\n",
        "        return None\n",
        "\n",
        "    # Get current price - already validated in Part 1 analyze_stock\n",
        "    current_price = stock_data.current_price\n",
        "    if pd.isna(current_price) or current_price <= 0:\n",
        "         logger.warning(f\"Current price invalid ({current_price}). Enhanced analysis might be limited.\")\n",
        "\n",
        "\n",
        "    # Enhanced analysis\n",
        "    logger.info(\"Starting enhanced analysis features (Part 2).\")\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    # Pass current_price to assess_circuit_risk (already validated as best as possible in Part 1)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    # Pass price_data (already validated in Part 1 analyze_stock)\n",
        "    # CORRECTED: Call get_liquidity_score on enhanced_analyzer and pass price_data from stock_data\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "\n",
        "    # 3. Peer analysis (including valuation data)\n",
        "    # Pass info (already validated in Part 1 analyze_stock)\n",
        "    # The get_peer_companies method now returns a list of dictionaries with valuation data\n",
        "    peers_with_valuation = enhanced_analyzer.get_peer_companies(symbol, stock_data.info)\n",
        "    # Pass the list of peer symbols (extracted from the list of dictionaries) for performance comparison\n",
        "    peer_symbols_for_performance = [p['symbol'] for p in peers_with_valuation if isinstance(p, dict) and 'symbol' in p]\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peer_symbols_for_performance) # Pass just symbols\n",
        "\n",
        "    # 4. Valuation Analysis: Calculate peer average valuations and compare\n",
        "    peer_average_valuation = enhanced_analyzer.calculate_peer_average_valuation(peers_with_valuation)\n",
        "    valuation_comparison_results = enhanced_analyzer.compare_valuation_to_peers(stock_data.metrics, peer_average_valuation)\n",
        "\n",
        "    # 5. Downside Risk Assessment: Calculate VaR\n",
        "    downside_risk_metrics = enhanced_analyzer.calculate_value_at_risk(stock_data.price_data)\n",
        "\n",
        "\n",
        "    # 6. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "\n",
        "    # 7. Recalculate technical score with circuit risk\n",
        "    # Pass indicators (already validated in Part 1 calculate_technical_indicators)\n",
        "    # Pass circuit_risk (already validated in assess_circuit_risk)\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "\n",
        "    # 8. Fetch and analyze news sentiment\n",
        "    # Pass symbol (already validated)\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    # Pass news_headlines (already validated)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "\n",
        "\n",
        "    # 9. Generate enhanced recommendation\n",
        "    # Pass scores and results (already validated within their respective functions)\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance, # Pass potentially incomplete/NaN peer performance\n",
        "        index_membership,\n",
        "        sentiment_analysis_results, # Pass sentiment analysis results\n",
        "        valuation_comparison_results, # Pass valuation comparison results\n",
        "        downside_risk_metrics # Pass downside risk metrics\n",
        "    )\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score, # Ensure correct liquidity score is included\n",
        "            'peers': peers_with_valuation, # Store the list of peers with their valuation data\n",
        "            'peer_performance': peer_performance, # Include peer performance, even if NaN\n",
        "            'peer_average_valuation': peer_average_valuation, # Store peer average valuation\n",
        "            'valuation_comparison': valuation_comparison_results, # Store valuation comparison results\n",
        "            'downside_risk': downside_risk_metrics, # Store downside risk metrics (e.g., VaR)\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "    logger.info(f\"Enhanced analysis completed for {symbol}\")\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize analyzers\n",
        "    try:\n",
        "        stock_analyzer = IndianStockAnalyzer()\n",
        "        enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "    except NameError:\n",
        "        print(\"Make sure to run the previous cells defining IndianStockAnalyzer and EnhancedStockAnalyzer classes.\")\n",
        "        exit() # Exit if classes are not defined\n",
        "\n",
        "\n",
        "    # Analyze a stock\n",
        "    symbol = \"RELIANCE.NS\" # Example symbol\n",
        "    result = analyze_stock_enhanced(symbol, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if result:\n",
        "        # Display the enhanced report\n",
        "        enhanced = result['enhanced_features']\n",
        "        final = result['final_recommendation']\n",
        "        basic = result['basic_analysis'] # Get basic data for display\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Enhanced Analysis Report: {basic.company_name} ({basic.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if not pd.isna(basic.current_price) else \"Current Price: N/A\")\n",
        "        market_cap_cr = basic.market_cap / 10000000 if not pd.isna(basic.market_cap) else np.nan\n",
        "        print(f\"Market Cap: ₹{market_cap_cr:,.2f} Cr\" if not pd.isna(market_cap_cr) else \"Market Cap: N/A\")\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n⚙️ Enhanced Technical Analysis & Risk:\")\n",
        "        # Display enhanced technical indicators and risk\n",
        "        # Assuming you want to display relevant indicators from basic.indicators and the circuit risk score\n",
        "        circuit_limits_display = enhanced.get('circuit_limits')\n",
        "        if circuit_limits_display and not pd.isna(circuit_limits_display.get('lower_circuit')) and not pd.isna(circuit_limits_display.get('upper_circuit')):\n",
        "             print(f\"Circuit Limits: {circuit_limits_display.get('lower_circuit', 'N/A'):.2f} - {circuit_limits_display.get('upper_circuit', 'N/A'):.2f}\")\n",
        "        else:\n",
        "             print(\"Circuit Limits: N/A\")\n",
        "\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        # Check if liquidity score is available before formatting\n",
        "        liquidity_score_display = f\"{enhanced.get('liquidity_score', 'N/A')}/70\" if isinstance(enhanced.get('liquidity_score'), (int, float)) and not pd.isna(enhanced.get('liquidity_score')) else \"Liquidity Score: N/A/70\"\n",
        "        print(liquidity_score_display)\n",
        "\n",
        "\n",
        "        # Display some key technical indicators from basic analysis\n",
        "        print(\"\\nKey Technical Indicators (from Basic Analysis):\")\n",
        "        key_tech_indicators = ['RSI', 'MACD', 'MACD_signal', 'SMA_20', 'SMA_50', 'BB_middle', 'Volume_ratio']\n",
        "        for indicator_name in key_tech_indicators:\n",
        "            value = basic.indicators.get(indicator_name, np.nan)\n",
        "            if not pd.isna(value):\n",
        "                if isinstance(value, float):\n",
        "                     print(f\"  - {indicator_name}: {value:,.2f}\")\n",
        "                else:\n",
        "                     print(f\"  - {indicator_name}: {value}\")\n",
        "            # Add logging for these key technical indicators if they are calculated\n",
        "            logger.info(f\"Indicator {indicator_name}: {value}\")\n",
        "        else:\n",
        "            print(f\"  - {indicator_name}: N/A\")\n",
        "            logger.info(f\"Indicator {indicator_name}: N/A\")\n",
        "\n",
        "        # Display Valuation Analysis\n",
        "        print(f\"\\n📈 Valuation Analysis:\")\n",
        "        stock_metrics = basic.metrics\n",
        "        peer_avg_val = enhanced.get('peer_average_valuation', {})\n",
        "        val_comp_results = enhanced.get('valuation_comparison', {})\n",
        "\n",
        "        stock_pe = stock_metrics.get('trailingPE', np.nan)\n",
        "        stock_pb = stock_metrics.get('priceToBook', np.nan)\n",
        "        stock_ev_ebitda = stock_metrics.get('evToEbitda', np.nan)\n",
        "\n",
        "        print(f\"Stock Valuation:\")\n",
        "        print(f\"  - Trailing PE: {stock_pe:.2f}\" if not pd.isna(stock_pe) else \"  - Trailing PE: N/A\")\n",
        "        print(f\"  - Price to Book: {stock_pb:.2f}\" if not pd.isna(stock_pb) else \"  - Price to Book: N/A\")\n",
        "        print(f\"  - EV/EBITDA: {stock_ev_ebitda:.2f}\" if not pd.isna(stock_ev_ebitda) else \"  - EV/EBITDA: N/A\")\n",
        "\n",
        "        print(\"\\nPeer Average Valuation:\")\n",
        "        avg_pe_display = f\"{peer_avg_val.get('avg_pe', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pe', np.nan)) else \"N/A\"\n",
        "        avg_pb_display = f\"{peer_avg_val.get('avg_pb', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pb', np.nan)) else \"N/A\"\n",
        "        avg_ev_ebitda_display = f\"{peer_avg_val.get('avg_ev_ebitda', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_ev_ebitda', np.nan)) else \"N/A\"\n",
        "\n",
        "        print(f\"  - Average PE: {avg_pe_display}\")\n",
        "        print(f\"  - Average PB: {avg_pb_display}\")\n",
        "        print(f\"  - Average EV/EBITDA: {avg_ev_ebitda_display}\")\n",
        "\n",
        "        print(\"\\nValuation Comparison:\")\n",
        "        print(f\"  - PE Comparison: {val_comp_results.get('pe_comparison', 'N/A')}\")\n",
        "        print(f\"  - PB Comparison: {val_comp_results.get('pb_comparison', 'N/A')}\")\n",
        "        print(f\"  - EV/EBITDA Comparison: {val_comp_results.get('ev_ebitda_comparison', 'N/A')}\")\n",
        "        valuation_adj_display = f\"{val_comp_results.get('valuation_score_adjustment', 0):+.2f}\" if isinstance(val_comp_results.get('valuation_score_adjustment'), (int, float)) and not pd.isna(val_comp_results.get('valuation_score_adjustment')) else \"N/A\"\n",
        "        print(f\"  - Valuation Score Adjustment: {valuation_adj_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\n📉 Downside Risk Analysis:\")\n",
        "        downside_risk = enhanced.get('downside_risk', {})\n",
        "        var_percentage = downside_risk.get('var_percentage_loss', np.nan)\n",
        "        var_display = f\"{var_percentage:.2f}%\" if not pd.isna(var_percentage) else \"N/A\"\n",
        "        # Access 'confidence_level' and 'horizon_days' directly from the downside_risk dictionary\n",
        "        confidence_level_display = downside_risk.get('confidence_level', 0.95)\n",
        "        horizon_days_display = downside_risk.get('horizon_days', 1)\n",
        "        print(f\"  - {confidence_level_display*100:.0f}% VaR ({horizon_days_display}-day): {var_display}\")\n",
        "\n",
        "        downside_adj_display = f\"{final.get('breakdown', {}).get('downside_risk', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('downside_risk'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('downside_risk')) else \"N/A\"\n",
        "        print(f\"  - Downside Risk Score Adjustment: {downside_adj_display}\")\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"\\n🤝 Peer Analysis (Performance):\")\n",
        "        peer_perf = enhanced.get('peer_performance')\n",
        "        if isinstance(peer_perf, dict) and \\\n",
        "           not pd.isna(peer_perf.get('stock_return')) and \\\n",
        "           not pd.isna(peer_perf.get('avg_peer_return')) and \\\n",
        "           not pd.isna(peer_perf.get('relative_performance')):\n",
        "\n",
        "             stock_return_display = f\"{peer_perf.get('stock_return', np.nan):.2f}%\" if isinstance(peer_perf.get('stock_return'), (int, float)) and not pd.isna(peer_perf.get('stock_return')) else 'N/A'\n",
        "             avg_peer_return_display = f\"{peer_perf.get('avg_peer_return', np.nan):.2f}%\" if isinstance(peer_perf.get('avg_peer_return'), (int, float)) and not pd.isna(peer_perf.get('avg_peer_return')) else 'N/A'\n",
        "             relative_performance_display = f\"{peer_perf.get('relative_performance', np.nan):.2f}%\" if isinstance(peer_perf.get('relative_performance'), (int, float)) and not pd.isna(peer_perf.get('relative_performance')) else 'N/A'\n",
        "\n",
        "             print(f\"  - {peer_perf.get('days', 'N/A')}-day Stock Return: {stock_return_display}\")\n",
        "             print(f\"  - Avg Peer Return: {avg_peer_return_display}\")\n",
        "             print(f\"  - Relative Performance: {relative_performance_display}\")\n",
        "        else:\n",
        "             print(\"Peer Performance Data Unavailable.\")\n",
        "\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"\\n🏛️ Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             # Only print a few headlines to keep the report concise\n",
        "             print(\"Sample News Headlines:\")\n",
        "             # Ensure headlines are valid strings before printing\n",
        "             valid_headlines = [h for h in enhanced['news_headlines'] if isinstance(h, str)]\n",
        "             for headline in valid_headlines[:5]: # Print up to 5 headlines\n",
        "                 print(f\"- {headline}\")\n",
        "             if len(valid_headlines) > 5:\n",
        "                  print(\"  ...\")\n",
        "\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             sentiment_score_display = f\"{sentiment_results.get('score', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\"\n",
        "             print(f\"Sentiment Score: {sentiment_score_display}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Comprehensive Scores and Recommendation ---\")\n",
        "        print(f\"Fundamental Score (from Part 1): {basic.fundamental_score:.2f}/50\" if not pd.isna(basic.fundamental_score) else \"Fundamental Score: N/A\")\n",
        "        # Add checks for NaN before formatting float for breakdown scores\n",
        "        enhanced_tech_score_display = f\"{final.get('breakdown', {}).get('technical', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('technical'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('technical')) else \"N/A\"\n",
        "        liquidity_score_display_breakdown = f\"{final.get('breakdown', {}).get('liquidity', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('liquidity'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('liquidity')) else \"N/A\"\n",
        "        sentiment_score_display_breakdown = f\"{final.get('breakdown', {}).get('sentiment', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\" # Corrected sentiment score breakdown check\n",
        "        valuation_comp_display_breakdown = f\"{final.get('breakdown', {}).get('valuation_comparison', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('valuation_comparison'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('valuation_comparison')) else \"N/A\"\n",
        "        downside_risk_display_breakdown = f\"{final.get('breakdown', {}).get('downside_risk', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('downside_risk'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('downside_risk')) else \"N/A\"\n",
        "\n",
        "\n",
        "        print(f\"Technical Score (Enhanced): {enhanced_tech_score_display}/50\")\n",
        "        print(f\"Liquidity Score: {liquidity_score_display_breakdown}/70\")\n",
        "        print(f\"Sentiment Score: {sentiment_score_display_breakdown}/25\")\n",
        "        print(f\"Valuation Comparison Adjustment: {valuation_comp_display_breakdown}\")\n",
        "        print(f\"Downside Risk Adjustment: {downside_risk_display_breakdown}\")\n",
        "\n",
        "\n",
        "        # Display adjustment scores\n",
        "        peer_adj_display = f\"{final.get('breakdown', {}).get('peer_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('peer_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('peer_adjustment')) else \"N/A\"\n",
        "        index_adj_display = f\"{final.get('breakdown', {}).get('index_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('index_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('index_adjustment')) else \"N/A\"\n",
        "\n",
        "        print(f\"Peer Performance Adjustment: {peer_adj_display}\")\n",
        "        print(f\"Index Membership Adjustment: {index_adj_display}\")\n",
        "\n",
        "\n",
        "        # Updated max score to reflect the addition of Downside Risk Adjustment (potential max increase of 0, potential max decrease of 15)\n",
        "        # Max Total Score = Fund (50) + Tech (50) + Liq (70) + Sent (25) + Val Adj (30) + Peer Adj (5) + Index Adj (5) + Downside Adj (0) = 235\n",
        "        # Re-evaluating the previous max estimate (245) and the new max. Let's use 235 as a potential max for scoring clarity.\n",
        "        print(f\"\\nTotal Enhanced Score: {final.get('total_score', 0):.2f}/235\" if isinstance(final.get('total_score'), (int, float)) and not pd.isna(final.get('total_score')) else \"Total Enhanced Score: N/A\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} (Confidence: {final.get('confidence', 'N/A')})\")\n",
        "\n",
        "\n",
        "        print(f\"\\n{'='*60}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5e5be84"
      },
      "source": [
        "**Reasoning**:\n",
        "The traceback shows an `AttributeError: 'numpy.float64' object has no attribute 'get'` occurring in the `generate_enhanced_recommendation` method when trying to access `var_percentage_loss` from `downside_risk_metrics`. This indicates that `downside_risk_metrics` is a numpy float (likely NaN or a single calculated VaR value) instead of the expected dictionary. The `calculate_value_at_risk` method in the `EnhancedStockAnalyzer` class currently returns a single float (the VaR percentage) or `None`. It needs to return a dictionary containing the VaR percentage and possibly the confidence level and horizon days, so it can be accessed using `.get()`. I need to modify the `calculate_value_at_risk` method in the `EnhancedStockAnalyzer` class to return a dictionary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhHTrqReJFDQ",
        "cellView": "form"
      },
      "source": [
        "#@title Part 2: EnhancedStockAnalyzer class definition (Fix VaR Return Value)\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import typing for type hints\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# --- EnhancedStockAnalyzer class definition ---\n",
        "class EnhancedStockAnalyzer:\n",
        "    \"\"\"Enhanced analyzer with additional features for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the enhanced analyzer.\"\"\"\n",
        "        self.risk_free_rate = self.get_dynamic_risk_free_rate()\n",
        "        # Assuming gemini_model is defined globally from a previous cell\n",
        "        global gemini_model # Access the global gemini_model\n",
        "        self.gemini_model = gemini_model\n",
        "\n",
        "        # More detailed circuit limit percentages based on NSE categorization (simplified)\n",
        "        self.circuit_limits_percentage = {\n",
        "            'category_a': 0.20, # Typically high-liquidity index stocks\n",
        "            'category_b': 0.10, # Most other actively traded stocks\n",
        "            'category_t': 0.05  # Stocks in trade-for-trade segment\n",
        "        }\n",
        "\n",
        "        # Simple mapping of some known stocks to categories for demonstration\n",
        "        self.stock_category_map = {\n",
        "            'RELIANCE.NS': 'category_a',\n",
        "            'TCS.NS': 'category_a',\n",
        "            'HDFCBANK.NS': 'category_a',\n",
        "            'INFY.NS': 'category_a',\n",
        "            'ICICIBANK.NS': 'category_a',\n",
        "            'VEDL.NS': 'category_b',\n",
        "            'PNB.NS': 'category_b',\n",
        "            'INDIGO.NS': 'category_b',\n",
        "            'BANDHANBNK.NS': 'category_b',\n",
        "            'PERSISTENT.NS': 'category_b',\n",
        "            'COFORGE.NS': 'category_b',\n",
        "            'LTTS.NS': 'category_b',\n",
        "        }\n",
        "\n",
        "\n",
        "    def get_dynamic_risk_free_rate(self):\n",
        "        \"\"\"Fetch current 10-year G-Sec yield\"\"\"\n",
        "        try:\n",
        "            return 0.072  # 7.2% as of recent data\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not fetch dynamic risk-free rate: {e}. Using fallback rate.\")\n",
        "            return 0.065\n",
        "\n",
        "    def get_circuit_limits(self, symbol):\n",
        "        \"\"\"Get circuit breaker limits for the stock based on categorization\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            if not info or 'previousClose' not in info:\n",
        "                 logger.warning(f\"Could not get previous close for {symbol}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "            prev_close = info.get('previousClose')\n",
        "            if pd.isna(prev_close) or prev_close <= 0:\n",
        "                 logger.warning(f\"Invalid previous close price for {symbol}: {prev_close}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "\n",
        "            stock_category = self.stock_category_map.get(symbol.upper(), 'category_b')\n",
        "            circuit_percent = self.circuit_limits_percentage.get(stock_category, 0.10)\n",
        "\n",
        "            logger.info(f\"Determined circuit percentage for {symbol} (Category: {stock_category}): {circuit_percent*100}%\")\n",
        "\n",
        "            upper_circuit = prev_close * (1 + circuit_percent)\n",
        "            lower_circuit = prev_close * (1 - circuit_percent)\n",
        "\n",
        "            return {\n",
        "                'upper_circuit': upper_circuit,\n",
        "                'lower_circuit': lower_circuit,\n",
        "                'circuit_percent': circuit_percent\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting circuit breaker limits for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def assess_circuit_risk(self, current_price, circuit_limits):\n",
        "        \"\"\"Assess proximity to circuit limits\"\"\"\n",
        "        if pd.isna(current_price) or current_price <= 0:\n",
        "             logger.warning(\"Invalid current price for circuit risk assessment.\")\n",
        "             return 0\n",
        "\n",
        "        if not circuit_limits or 'upper_circuit' not in circuit_limits or 'lower_circuit' not in circuit_limits:\n",
        "            logger.warning(\"Invalid or incomplete circuit limits provided.\")\n",
        "            return 0\n",
        "\n",
        "        upper_circuit = circuit_limits['upper_circuit']\n",
        "        lower_circuit = circuit_limits['lower_circuit']\n",
        "\n",
        "        if pd.isna(upper_circuit) or pd.isna(lower_circuit) or upper_circuit <= 0 or lower_circuit <= 0:\n",
        "             logger.warning(\"Circuit limits are invalid numbers. Cannot assess circuit risk.\")\n",
        "             return 0\n",
        "\n",
        "        risk_score = 0\n",
        "\n",
        "        if current_price >= upper_circuit:\n",
        "             risk_score -= 30\n",
        "        elif (upper_circuit - current_price) / current_price < 0.01:\n",
        "            risk_score -= 20\n",
        "        elif (upper_circuit - current_price) / current_price < 0.03:\n",
        "            risk_score -= 10\n",
        "        elif (upper_circuit - current_price) / current_price < 0.05:\n",
        "            risk_score -= 5\n",
        "\n",
        "        if current_price <= lower_circuit:\n",
        "            risk_score -= 40\n",
        "        elif (current_price - lower_circuit) / current_price < 0.01:\n",
        "            risk_score -= 30\n",
        "        elif (current_price - lower_circuit) / current_price < 0.03:\n",
        "            risk_score -= 15\n",
        "        elif (current_price - lower_circuit) / current_price < 0.05:\n",
        "            risk_score -= 8\n",
        "\n",
        "        logger.info(f\"Circuit risk score calculated: {risk_score}\")\n",
        "        return risk_score\n",
        "\n",
        "    def get_liquidity_score(self, price_data):\n",
        "        \"\"\"Enhanced liquidity analysis with NaN handling and better checks\"\"\"\n",
        "        liquidity_score = 0\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or len(price_data) < 20:\n",
        "            logger.warning(\"Insufficient price data for liquidity analysis. Assigning default score.\")\n",
        "            return 30\n",
        "\n",
        "        try:\n",
        "            avg_volume_20d = price_data['Volume'].rolling(20).mean().iloc[-1]\n",
        "            avg_volume_5d = price_data['Volume'].rolling(5).mean().iloc[-1]\n",
        "            current_close = price_data['Close'].iloc[-1]\n",
        "\n",
        "            # Add logging for diagnosis - before calculation check\n",
        "            logger.info(f\"Volume data for liquidity: avg_volume_20d: {avg_volume_20d}, avg_volume_5d: {avg_volume_5d}, current_close: {current_close}\")\n",
        "\n",
        "\n",
        "            if pd.isna(avg_volume_20d) or pd.isna(avg_volume_5d) or pd.isna(current_close) or current_close <= 0:\n",
        "                 logger.warning(\"Liquidity metrics are NaN or invalid. Cannot calculate liquidity score accurately. Assigning default.\")\n",
        "                 return 30\n",
        "\n",
        "            avg_turnover_20d = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d >= 0 and current_close > 0:\n",
        "                 avg_turnover_20d = avg_volume_20d * current_close\n",
        "\n",
        "            volume_spike = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                 if avg_volume_5d is not None and not pd.isna(avg_volume_5d):\n",
        "                     volume_spike = avg_volume_5d / avg_volume_20d\n",
        "                 else:\n",
        "                      logger.warning(\"5-day average volume is invalid for volume spike calculation.\")\n",
        "            elif not pd.isna(avg_volume_5d) and avg_volume_5d > 0:\n",
        "                 volume_spike = 1.0\n",
        "                 logger.warning(\"20-day average volume is invalid for volume spike, using 1.0 as relative indicator.\")\n",
        "            else:\n",
        "                 volume_spike = np.nan # Ensure volume_spike is NaN if both volumes are invalid\n",
        "                 logger.warning(\"Insufficient or invalid volume data for volume ratio calculation.\")\n",
        "\n",
        "            # Add logging for volume spike - after calculation\n",
        "            logger.info(f\"Volume spike calculated: {volume_spike}\")\n",
        "\n",
        "            # Corrected logic for scoring based on volume_spike\n",
        "            if not pd.isna(volume_spike):\n",
        "                if volume_spike > 1.5: # Volume is 50% higher than average\n",
        "                    liquidity_score += 10\n",
        "                elif volume_spike < 0.8: # Volume is significantly lower than average\n",
        "                    liquidity_score += 2 # Small penalty for low volume\n",
        "                else: # volume_spike is between 0.8 and 1.5 (inclusive of 0.8, exclusive of 1.5)\n",
        "                    liquidity_score += 5 # Average volume is neutral\n",
        "            else:\n",
        "                 logger.warning(\"Volume spike ratio is NaN. Skipping trend scoring.\")\n",
        "\n",
        "\n",
        "            if not pd.isna(avg_turnover_20d):\n",
        "                if avg_turnover_20d > 500_00_00_000:\n",
        "                    liquidity_score += 40\n",
        "                elif avg_turnover_20d > 100_00_00_000:\n",
        "                    liquidity_score += 30\n",
        "                elif avg_turnover_20d > 10_00_00_000:\n",
        "                    liquidity_score += 20\n",
        "                elif avg_turnover_20d > 1_00_00_000:\n",
        "                    liquidity_score += 10\n",
        "                else:\n",
        "                    liquidity_score += 5\n",
        "            else:\n",
        "                 logger.warning(\"Average turnover is NaN. Skipping turnover scoring.\")\n",
        "                 liquidity_score += 10\n",
        "\n",
        "            volume_std = price_data['Volume'].rolling(20).std().iloc[-1] if len(price_data) >= 20 else np.nan\n",
        "            volume_cv = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0 and \\\n",
        "               volume_std is not None and not pd.isna(volume_std):\n",
        "                volume_cv = volume_std / avg_volume_20d\n",
        "\n",
        "            if not pd.isna(volume_cv):\n",
        "                if volume_cv < 0.5:\n",
        "                    liquidity_score += 20\n",
        "                elif volume_cv < 1.0:\n",
        "                    liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume coefficient of variation is NaN. Skipping consistency scoring.\")\n",
        "\n",
        "            # The volume spike scoring is now handled above within the main if not pd.isna(volume_spike): block\n",
        "\n",
        "\n",
        "            return min(liquidity_score, 70)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating liquidity score: {str(e)}\")\n",
        "            return 30\n",
        "\n",
        "    def get_peer_companies(self, symbol: str, stock_info: Dict) -> List[Dict]: # Modified return type hint\n",
        "        \"\"\"Identify peer companies and fetch their valuation ratios for comparison\"\"\"\n",
        "        logger.info(f\"Identifying peer companies and fetching valuation data for {symbol}.\")\n",
        "        peer_list_with_valuation = [] # List to store peer info including valuation\n",
        "\n",
        "        try:\n",
        "            if not isinstance(stock_info, dict):\n",
        "                 logger.warning(\"Invalid stock info for peer identification.\")\n",
        "                 return []\n",
        "\n",
        "            sector = stock_info.get('sector', '')\n",
        "            market_cap = stock_info.get('marketCap', 0)\n",
        "\n",
        "            if not isinstance(sector, str):\n",
        "                 sector = ''\n",
        "            if not isinstance(market_cap, (int, float)) or pd.isna(market_cap) or market_cap <= 0:\n",
        "                 logger.warning(\"Invalid market cap for peer identification.\")\n",
        "                 market_cap = 0\n",
        "\n",
        "            if market_cap > 10_00_000_00_00_000:\n",
        "                cap_category = 'Large Cap'\n",
        "            elif market_cap > 50_000_00_00_000:\n",
        "                cap_category = 'Mid Cap'\n",
        "            else:\n",
        "                cap_category = 'Small Cap'\n",
        "\n",
        "            # Peer mapping (simplified - in production, use a comprehensive database)\n",
        "            peer_map = {\n",
        "                'Technology': {\n",
        "                    'Large Cap': ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS'],\n",
        "                    'Mid Cap': ['TECHM.NS', 'LTTS.NS', 'PERSISTENT.NS', 'COFORGE.NS'],\n",
        "                    'Small Cap': ['ZENSAR.NS', 'ECLERX.NS', 'MASTEK.NS']\n",
        "                },\n",
        "                'Financial Services': {\n",
        "                    'Large Cap': ['HDFCBANK.NS', 'ICICIBANK.NS', 'KOTAKBANK.NS', 'AXISBANK.NS'],\n",
        "                    'Mid Cap': ['IDFCFIRSTB.NS', 'FEDERALBNK.NS', 'INDUSINDBK.NS'],\n",
        "                    'Small Cap': ['SOUTHBANK.NS', 'UJJIVAN.NS', 'EQUITASBNK.NS']\n",
        "                },\n",
        "                'Healthcare': {\n",
        "                    'Large Cap': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS'],\n",
        "                    'Mid Cap': ['TORNTPHARM.NS', 'ALKEM.NS', 'LUPIN.NS'],\n",
        "                    'Small Cap': ['CAPLIPOINT.NS', 'BLISS.NS', 'INDOCO.NS']\n",
        "                },\n",
        "                # Added Energy sector mapping\n",
        "                'Energy': {\n",
        "                    'Large Cap': ['ONGC.NS', 'NTPC.NS', 'POWERGRID.NS'], # Exclude RELIANCE.NS here, filter below\n",
        "                    'Mid Cap': ['GAIL.NS', 'IOC.NS', 'NHPC.NS'],\n",
        "                    'Small Cap': ['GUJGASLTD.NS', 'IGL.NS', 'MAHAPOWER.NS']\n",
        "                }\n",
        "            }\n",
        "\n",
        "            potential_peers = peer_map.get(sector, {}).get(cap_category, [])\n",
        "            # Ensure the current symbol is excluded from the peer list\n",
        "            filtered_peers = [p for p in potential_peers if isinstance(p, str) and p.upper() != symbol.upper()]\n",
        "\n",
        "            logger.info(f\"Identified {len(filtered_peers)} potential peer companies for {symbol} in {sector} ({cap_category} Cap). Fetching valuation data.\")\n",
        "\n",
        "            # Fetch valuation data for each filtered peer\n",
        "            for peer_symbol in filtered_peers:\n",
        "                 try:\n",
        "                      peer_ticker = yf.Ticker(peer_symbol)\n",
        "                      peer_info = peer_ticker.info\n",
        "\n",
        "                      if peer_info:\n",
        "                           peer_valuation = {\n",
        "                               'symbol': peer_symbol,\n",
        "                               'trailingPE': peer_info.get('trailingPE', np.nan),\n",
        "                               'priceToBook': peer_info.get('priceToBook', np.nan),\n",
        "                               'enterpriseValue': peer_info.get('enterpriseValue', np.nan), # Fetch for EV/EBITDA calculation\n",
        "                               'ebitda': peer_info.get('ebitda', np.nan) # Fetch for EV/EBITDA calculation\n",
        "                           }\n",
        "\n",
        "                           # Calculate EV/EBITDA for the peer\n",
        "                           ev = peer_valuation['enterpriseValue']\n",
        "                           ebitda = peer_valuation['ebitda']\n",
        "                           peer_valuation['evToEbitda'] = np.nan # Default to NaN\n",
        "                           if isinstance(ev, (int, float)) and not np.isnan(ev) and \\\n",
        "                              isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda != 0:\n",
        "                               peer_valuation['evToEbitda'] = ev / ebitda\n",
        "                           elif (isinstance(ev, (int, float)) and not np.isnan(ev)) and \\\n",
        "                                (isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda == 0):\n",
        "                                logger.warning(f\"EBITDA is zero for peer {peer_symbol}. Cannot calculate EV/EBITDA.\")\n",
        "                           else:\n",
        "                                logger.warning(f\"Missing Enterprise Value ({ev}) or EBITDA ({ebitda}) for peer {peer_symbol}. Cannot calculate EV/EBITDA.\")\n",
        "\n",
        "\n",
        "                           peer_list_with_valuation.append(peer_valuation)\n",
        "                           logger.debug(f\"Fetched valuation data for peer {peer_symbol}: PE={peer_valuation['trailingPE']:.2f}, PB={peer_valuation['priceToBook']:.2f}, EV/EBITDA={peer_valuation['evToEbitda']:.2f}\")\n",
        "                      else:\n",
        "                           logger.warning(f\"Could not fetch info for peer {peer_symbol}. Skipping.\")\n",
        "                 except Exception as e:\n",
        "                      logger.warning(f\"Error fetching data for peer {peer_symbol}: {str(e)}. Skipping.\")\n",
        "\n",
        "            logger.info(f\"Successfully fetched valuation data for {len(peer_list_with_valuation)} peers.\")\n",
        "            return peer_list_with_valuation[:5] # Return top 5 peers with their valuation data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting peer companies and valuation data for {symbol}: {str(e)}\")\n",
        "            return [] # Return empty list on error\n",
        "\n",
        "    def calculate_peer_average_valuation(self, peers_with_valuation: List[Dict]) -> Dict:\n",
        "        \"\"\"Calculate average valuation ratios (PE, PB, EV/EBITDA) for a list of peers.\"\"\"\n",
        "        logger.info(\"Calculating peer average valuation ratios.\")\n",
        "        total_pe = 0\n",
        "        total_pb = 0\n",
        "        total_ev_ebitda = 0\n",
        "        count_pe = 0\n",
        "        count_pb = 0\n",
        "        count_ev_ebitda = 0\n",
        "\n",
        "        if not isinstance(peers_with_valuation, list) or not peers_with_valuation:\n",
        "             logger.warning(\"No peer valuation data provided for calculating averages.\")\n",
        "             return {'avg_pe': np.nan, 'avg_pb': np.nan, 'avg_ev_ebitda': np.nan}\n",
        "\n",
        "\n",
        "        for peer_data in peers_with_valuation:\n",
        "             if isinstance(peer_data, dict):\n",
        "                 pe = peer_data.get('trailingPE', np.nan)\n",
        "                 pb = peer_data.get('priceToBook', np.nan)\n",
        "                 ev_ebitda = peer_data.get('evToEbitda', np.nan)\n",
        "\n",
        "                 if isinstance(pe, (int, float)) and not np.isnan(pe) and pe > 0:\n",
        "                     total_pe += pe\n",
        "                     count_pe += 1\n",
        "                 else:\n",
        "                      logger.debug(f\"Skipping invalid PE for peer: {peer_data.get('symbol', 'Unknown')}\")\n",
        "\n",
        "                 if isinstance(pb, (int, float)) and not np.isnan(pb) and pb > 0:\n",
        "                     total_pb += pb\n",
        "                     count_pb += 1\n",
        "                 else:\n",
        "                      logger.debug(f\"Skipping invalid PB for peer: {peer_data.get('symbol', 'Unknown')}\")\n",
        "\n",
        "\n",
        "                 if isinstance(ev_ebitda, (int, float)) and not np.isnan(ev_ebitda): # EV/EBITDA can be zero or negative in some cases, but >0 is typical\n",
        "                      total_ev_ebitda += ev_ebitda\n",
        "                      count_ev_ebitda += 1\n",
        "                 else:\n",
        "                      logger.debug(f\"Skipping invalid EV/EBITDA for peer: {peer_data.get('symbol', 'Unknown')}\")\n",
        "\n",
        "\n",
        "        avg_pe = total_pe / count_pe if count_pe > 0 else np.nan\n",
        "        avg_pb = total_pb / count_pb if count_pb > 0 else np.nan\n",
        "        avg_ev_ebitda = total_ev_ebitda / count_ev_ebitda if count_ev_ebitda > 0 else np.nan\n",
        "\n",
        "        logger.info(f\"Calculated peer averages: PE={avg_pe:.2f}, PB={avg_pb:.2f}, EV/EBITDA={avg_ev_ebitda:.2f}\")\n",
        "\n",
        "        return {\n",
        "            'avg_pe': avg_pe,\n",
        "            'avg_pb': avg_pb,\n",
        "            'avg_ev_ebitda': avg_ev_ebitda\n",
        "        }\n",
        "\n",
        "\n",
        "    def compare_valuation_to_peers(self, stock_valuation: Dict, peer_average_valuation: Dict) -> Dict:\n",
        "        \"\"\"Compare stock's valuation ratios to peer averages and provide assessment.\"\"\"\n",
        "        logger.info(\"Comparing stock valuation to peer averages.\")\n",
        "        comparison_results = {}\n",
        "        valuation_score_adjustment = 0 # Adjustment to the total score\n",
        "\n",
        "        stock_pe = stock_valuation.get('trailingPE', np.nan)\n",
        "        stock_pb = stock_valuation.get('priceToBook', np.nan)\n",
        "        stock_ev_ebitda = stock_valuation.get('evToEbitda', np.nan)\n",
        "\n",
        "        avg_pe = peer_average_valuation.get('avg_pe', np.nan)\n",
        "        avg_pb = peer_average_valuation.get('avg_pb', np.nan)\n",
        "        avg_ev_ebitda = peer_average_valuation.get('avg_ev_ebitda', np.nan)\n",
        "\n",
        "        logger.debug(f\"Stock Valuation: PE={stock_pe:.2f}, PB={stock_pb:.2f}, EV/EBITDA={stock_ev_ebitda:.2f}\")\n",
        "        logger.debug(f\"Peer Average Valuation: PE={avg_pe:.2f}, PB={avg_pb:.2f}, EV/EBITDA={avg_ev_ebitda:.2f}\")\n",
        "\n",
        "\n",
        "        # PE Ratio comparison (Lower is generally better relative to peers)\n",
        "        comparison_results['pe_comparison'] = 'N/A'\n",
        "        if not pd.isna(stock_pe) and not pd.isna(avg_pe) and avg_pe > 0:\n",
        "             if stock_pe < avg_pe * 0.8: # More than 20% below average\n",
        "                  comparison_results['pe_comparison'] = 'Significantly Undervalued (PE)'\n",
        "                  valuation_score_adjustment += 10\n",
        "             elif stock_pe < avg_pe * 0.95: # More than 5% below average\n",
        "                  comparison_results['pe_comparison'] = 'Undervalued (PE)'\n",
        "                  valuation_score_adjustment += 5\n",
        "             elif stock_pe > avg_pe * 1.2: # More than 20% above average\n",
        "                  comparison_results['pe_comparison'] = 'Significantly Overvalued (PE)'\n",
        "                  valuation_score_adjustment -= 10\n",
        "             elif stock_pe > avg_pe * 1.05: # More than 5% above average\n",
        "                  comparison_results['pe_comparison'] = 'Overvalued (PE)'\n",
        "                  valuation_score_adjustment -= 5\n",
        "             else:\n",
        "                  comparison_results['pe_comparison'] = 'Fairly Valued (PE)'\n",
        "        elif not pd.isna(stock_pe) and pd.isna(avg_pe):\n",
        "             comparison_results['pe_comparison'] = 'PE available, Peer Avg PE N/A'\n",
        "             logger.warning(\"Peer Average PE is NaN. Cannot compare stock PE to peers.\")\n",
        "        elif pd.isna(stock_pe) and not pd.isna(avg_pe):\n",
        "             comparison_results['pe_comparison'] = 'Stock PE N/A'\n",
        "             logger.warning(\"Stock PE is NaN. Cannot compare to peer Average PE.\")\n",
        "        else:\n",
        "             logger.warning(\"Stock PE and Peer Average PE are NaN. Cannot compare.\")\n",
        "\n",
        "\n",
        "        # PB Ratio comparison (Lower is generally better relative to peers)\n",
        "        comparison_results['pb_comparison'] = 'N/A'\n",
        "        if not pd.isna(stock_pb) and not pd.isna(avg_pb) and avg_pb > 0:\n",
        "             if stock_pb < avg_pb * 0.8: # More than 20% below average\n",
        "                  comparison_results['pb_comparison'] = 'Significantly Undervalued (PB)'\n",
        "                  valuation_score_adjustment += 8\n",
        "             elif stock_pb < avg_pb * 0.95: # More than 5% below average\n",
        "                  comparison_results['pb_comparison'] = 'Undervalued (PB)'\n",
        "                  valuation_score_adjustment += 4\n",
        "             elif stock_pb > avg_pb * 1.2: # More than 20% above average\n",
        "                  comparison_results['pb_comparison'] = 'Significantly Overvalued (PB)'\n",
        "                  valuation_score_adjustment -= 8\n",
        "             elif stock_pb > avg_pb * 1.05: # More than 5% above average\n",
        "                  comparison_results['pb_comparison'] = 'Overvalued (PB)'\n",
        "                  valuation_score_adjustment -= 4\n",
        "             else:\n",
        "                  comparison_results['pb_comparison'] = 'Fairly Valued (PB)'\n",
        "        elif not pd.isna(stock_pb) and pd.isna(avg_pb):\n",
        "             comparison_results['pb_comparison'] = 'PB available, Peer Avg PB N/A'\n",
        "             logger.warning(\"Peer Average PB is NaN. Cannot compare stock PB to peers.\")\n",
        "        elif pd.isna(stock_pb) and not pd.isna(avg_pb):\n",
        "             comparison_results['pb_comparison'] = 'Stock PB N/A'\n",
        "             logger.warning(\"Stock PB is NaN. Cannot compare to peer Average PB.\")\n",
        "        else:\n",
        "             logger.warning(\"Stock PB and Peer Average PB are NaN. Cannot compare.\")\n",
        "\n",
        "\n",
        "        # EV/EBITDA comparison (Lower is generally better relative to peers)\n",
        "        comparison_results['ev_ebitda_comparison'] = 'N/A'\n",
        "        if not pd.isna(stock_ev_ebitda) and not pd.isna(avg_ev_ebitda) and avg_ev_ebitda != 0:\n",
        "             if stock_ev_ebitda < avg_ev_ebitda * 0.8: # More than 20% below average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Significantly Undervalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment += 12\n",
        "             elif stock_ev_ebitda < avg_ev_ebitda * 0.95: # More than 5% below average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Undervalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment += 6\n",
        "             elif stock_ev_ebitda > avg_ev_ebitda * 1.2: # More than 20% above average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Significantly Overvalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment -= 12\n",
        "             elif stock_ev_ebitda > avg_ev_ebitda * 1.05: # More than 5% above average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Overvalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment -= 6\n",
        "             else:\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Fairly Valued (EV/EBITDA)'\n",
        "        elif not pd.isna(stock_ev_ebitda) and not pd.isna(avg_ev_ebitda) and avg_ev_ebitda == 0:\n",
        "             comparison_results['ev_ebitda_comparison'] = 'Peer Avg EV/EBITDA is 0'\n",
        "             logger.warning(\"Peer Average EV/EBITDA is zero. Cannot compare.\")\n",
        "        elif not pd.isna(stock_ev_ebitda) and pd.isna(avg_ev_ebitda):\n",
        "             comparison_results['ev_ebitda_comparison'] = 'EV/EBITDA available, Peer Avg EV/EBITDA N/A'\n",
        "             logger.warning(\"Peer Average EV/EBITDA is NaN. Cannot compare stock EV/EBITDA to peers.\")\n",
        "        elif pd.isna(stock_ev_ebitda) and not pd.isna(avg_ev_ebitda):\n",
        "             comparison_results['ev_ebitda_comparison'] = 'Stock EV/EBITDA N/A'\n",
        "             logger.warning(\"Stock EV/EBITDA is NaN. Cannot compare to peer Average EV/EBITDA.\")\n",
        "        else:\n",
        "             logger.warning(\"Stock EV/EBITDA and Peer Average EV/EBITDA are NaN. Cannot compare.\")\n",
        "\n",
        "\n",
        "        comparison_results['valuation_score_adjustment'] = valuation_score_adjustment\n",
        "\n",
        "        logger.info(f\"Valuation comparison results: {comparison_results}\")\n",
        "        return comparison_results\n",
        "\n",
        "\n",
        "    def calculate_peer_relative_performance(self, symbol, peers, days=30):\n",
        "        \"\"\"Compare stock performance with peers, handling data issues robustly\"\"\"\n",
        "        results = {\n",
        "            'stock_return': np.nan,\n",
        "            'avg_peer_return': np.nan,\n",
        "            'relative_performance': np.nan,\n",
        "            'outperformance': False,\n",
        "            'days': days\n",
        "        }\n",
        "\n",
        "        if not isinstance(peers, list) or not peers:\n",
        "             logger.warning(\"No valid peer list provided for performance comparison.\")\n",
        "             # Return the default results with NaNs if no peers\n",
        "             return results\n",
        "\n",
        "        # --- Removed the temporary skip here ---\n",
        "\n",
        "        try:\n",
        "            main_ticker = yf.Ticker(symbol)\n",
        "            main_hist = main_ticker.history(period=f\"{days}d\")\n",
        "            main_return = np.nan\n",
        "\n",
        "            if not main_hist.empty and len(main_hist) > 1:\n",
        "                try:\n",
        "                    start_price = main_hist['Close'].iloc[0]\n",
        "                    end_price = main_hist['Close'].iloc[-1]\n",
        "                    if not pd.isna(start_price) and not pd.isna(end_price) and start_price > 0:\n",
        "                         main_return = ((end_price / start_price) - 1) * 100\n",
        "                    else:\n",
        "                         logger.warning(f\"Invalid start ({start_price}) or end price ({end_price}) for main stock ({symbol}) return calculation.\")\n",
        "                except Exception as ret_e:\n",
        "                     logger.warning(f\"Could not calculate main stock ({symbol}) return: {ret_e}. Setting to NaN.\")\n",
        "                     main_return = np.nan\n",
        "            else:\n",
        "                logger.warning(f\"Insufficient historical data for main stock ({symbol}) for return calculation.\")\n",
        "\n",
        "            results['stock_return'] = main_return\n",
        "\n",
        "        except Exception as main_stock_e:\n",
        "            logger.error(f\"Error fetching data or calculating return for main stock ({symbol}): {main_stock_e}. Main stock return set to NaN.\")\n",
        "            results['stock_return'] = np.nan\n",
        "\n",
        "        # Calculate peer returns\n",
        "        peer_returns = []\n",
        "        # The peers list now contains dictionaries with valuation data.\n",
        "        # We need to extract just the symbols for performance calculation.\n",
        "        peer_symbols_for_perf = [p['symbol'] for p in peers if isinstance(p, dict) and 'symbol' in p]\n",
        "\n",
        "        for peer_symbol in peer_symbols_for_perf:\n",
        "             try:\n",
        "                 peer_ticker = yf.Ticker(peer_symbol)\n",
        "                 peer_hist = peer_ticker.history(period=f\"{days}d\")\n",
        "                 if not peer_hist.empty and len(peer_hist) > 1:\n",
        "                     try:\n",
        "                          peer_start_price = peer_hist['Close'].iloc[0]\n",
        "                          peer_end_price = peer_hist['Close'].iloc[-1]\n",
        "                          if not pd.isna(peer_start_price) and not pd.isna(peer_end_price) and peer_start_price > 0:\n",
        "                             peer_return = ((peer_end_price / peer_start_price) - 1) * 100\n",
        "                             peer_returns.append(peer_return)\n",
        "                          else:\n",
        "                             logger.warning(f\"Invalid start or end price for peer ({peer_symbol}) return calculation.\")\n",
        "                     except Exception as peer_ret_e:\n",
        "                         logger.warning(f\"Could not calculate return for peer ({peer_symbol}): {peer_ret_e}. Skipping.\")\n",
        "                 else:\n",
        "                     logger.warning(f\"Insufficient historical data for peer ({peer_symbol}) for return calculation. Skipping.\")\n",
        "             except Exception as peer_e:\n",
        "                 logger.warning(f\"Error fetching data for peer ({peer_symbol}): {peer_e}. Skipping.\")\n",
        "\n",
        "        # Add logging for peer returns before filtering/average calculation\n",
        "        logger.info(f\"Peer returns collected before average calculation attempt: {peer_returns}\")\n",
        "\n",
        "        # Calculate average peer return and relative performance\n",
        "        if peer_returns:\n",
        "             # Ensure peer_returns list contains only valid numbers before calculating mean\n",
        "             valid_peer_returns = [ret for ret in peer_returns if isinstance(ret, (int, float)) and not pd.isna(ret)]\n",
        "             if valid_peer_returns:\n",
        "                 avg_peer_return = np.mean(valid_peer_returns)\n",
        "                 results['avg_peer_return'] = avg_peer_return\n",
        "\n",
        "                 # Calculate relative performance only if main stock return is valid\n",
        "                 if not pd.isna(main_return):\n",
        "                      results['relative_performance'] = main_return - avg_peer_return\n",
        "\n",
        "                      # Determine outperformance\n",
        "                      if main_return > avg_peer_return:\n",
        "                          results['outperformance'] = True\n",
        "                 else:\n",
        "                      logger.warning(\"Main stock return is NaN, cannot calculate relative performance or outperformance.\")\n",
        "             else:\n",
        "                 logger.warning(\"No valid peer returns available after filtering. Cannot calculate average peer return or relative performance.\")\n",
        "        else:\n",
        "             logger.warning(\"No peer returns calculated. Cannot calculate average peer return or relative performance.\")\n",
        "\n",
        "\n",
        "        logger.info(f\"Peer performance results for {symbol}: {results}\")\n",
        "        return results\n",
        "\n",
        "\n",
        "    def get_index_membership(self, symbol):\n",
        "        \"\"\"Check index membership for the stock\"\"\"\n",
        "        symbol_upper = symbol.upper() if isinstance(symbol, str) else ''\n",
        "\n",
        "        index_constituents = {\n",
        "            'NIFTY50': ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS'],\n",
        "            'NIFTY_NEXT50': ['VEDL.NS', 'PNB.NS', 'INDIGO.NS', 'BANDHANBNK.NS'],\n",
        "            'NIFTY_MIDCAP150': ['PERSISTENT.NS', 'COFORGE.NS', 'LTTS.NS']\n",
        "        }\n",
        "\n",
        "        membership = []\n",
        "        for index, constituents in index_constituents.items():\n",
        "            if symbol_upper and any(isinstance(c, str) and c.upper() == symbol_upper for c in constituents):\n",
        "                membership.append(index)\n",
        "\n",
        "        if membership:\n",
        "             logger.info(f\"Stock {symbol} is a member of indices: {', '.join(membership)}\")\n",
        "        else:\n",
        "             logger.info(f\"Stock {symbol} is not found in the hardcoded index constituents.\")\n",
        "\n",
        "        return membership\n",
        "\n",
        "    def calculate_enhanced_technical_score(self, indicators, circuit_risk):\n",
        "        \"\"\"Calculate enhanced technical analysis score with NaN handling and circuit risk\"\"\"\n",
        "        base_score = 0\n",
        "        indicators_calculated = 0\n",
        "        possible_indicator_points = 50\n",
        "\n",
        "        num_key_indicators = 5\n",
        "        indicator_point_contribution = possible_indicator_points / num_key_indicators\n",
        "\n",
        "        rsi = indicators.get('RSI', np.nan)\n",
        "        if not pd.isna(rsi):\n",
        "             indicators_calculated += 1\n",
        "             if 40 <= rsi <= 60:\n",
        "                 base_score += indicator_point_contribution * 0.7\n",
        "             elif rsi < 30: # More points for extreme oversold\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             elif 30 <= rsi < 40: # Approaching oversold\n",
        "                 base_score += indicator_point_contribution * 0.9\n",
        "             elif 60 < rsi <= 70: # Approaching overbought\n",
        "                 base_score += indicator_point_contribution * 0.6\n",
        "             else: # Overbought (>70)\n",
        "                 base_score += indicator_point_contribution * 0.4\n",
        "        else:\n",
        "             logger.warning(\"RSI not calculated or is NaN.\")\n",
        "\n",
        "        macd = indicators.get('MACD', np.nan)\n",
        "        macd_signal = indicators.get('MACD_signal', np.nan)\n",
        "\n",
        "        if not pd.isna(macd) and not pd.isna(macd_signal):\n",
        "             indicators_calculated += 1\n",
        "             if macd > macd_signal:\n",
        "                 if macd > 0: # Bullish crossover above zero line\n",
        "                      base_score += indicator_point_contribution * 1.0\n",
        "                 else: # Bullish crossover below zero line\n",
        "                      base_score += indicator_point_contribution * 0.8\n",
        "             else:\n",
        "                 if macd < 0: # Bearish crossover below zero line\n",
        "                      base_score += indicator_point_contribution * 0.2\n",
        "                 else: # Bearish crossover above zero line\n",
        "                      base_score += indicator_point_contribution * 0.4\n",
        "        else:\n",
        "             logger.warning(\"MACD or MACD signal is NaN for technical scoring.\")\n",
        "\n",
        "        sma_20 = indicators.get('SMA_20', np.nan)\n",
        "        sma_50 = indicators.get('SMA_50', np.nan)\n",
        "        sma_200 = indicators.get('SMA_200', np.nan) # Include 200-day SMA if available\n",
        "\n",
        "        ma_score_component = 0\n",
        "        ma_indicators_counted = 0\n",
        "\n",
        "        if not pd.isna(sma_20) and not pd.isna(sma_50):\n",
        "             ma_indicators_counted += 1\n",
        "             if sma_20 > sma_50:\n",
        "                  ma_score_component += 0.5 # 20 > 50 crossover is bullish\n",
        "             else:\n",
        "                  ma_score_component += 0.2 # 20 <= 50 crossover is bearish/neutral\n",
        "\n",
        "        if not pd.isna(sma_50) and not pd.isna(sma_200):\n",
        "             ma_indicators_counted += 1\n",
        "             if sma_50 > sma_200:\n",
        "                  ma_score_component += 0.5 # 50 > 200 crossover is bullish\n",
        "             else:\n",
        "                  ma_score_component += 0.2 # 50 <= 200 crossover is bearish/neutral\n",
        "\n",
        "        current_price = indicators.get('current_price', np.nan)\n",
        "        if not pd.isna(current_price):\n",
        "             if not pd.isna(sma_20) and current_price > sma_20:\n",
        "                  ma_score_component += 0.3 # Price above 20-day SMA is bullish\n",
        "             elif not pd.isna(sma_20):\n",
        "                  ma_score_component += 0.1 # Price below 20-day SMA is bearish/neutral\n",
        "\n",
        "             if not pd.isna(sma_50) and current_price > sma_50:\n",
        "                  ma_score_component += 0.4 # Price above 50-day SMA is more bullish\n",
        "             elif not pd.isna(sma_50):\n",
        "                  ma_score_component += 0.15 # Price below 50-day SMA\n",
        "\n",
        "             if not pd.isna(sma_200) and current_price > sma_200:\n",
        "                  ma_score_component += 0.6 # Price above 200-day SMA is significant bullish signal\n",
        "             elif not pd.isna(sma_200):\n",
        "                  ma_score_component += 0.1 # Price below 200-day SMA is significant bearish signal\n",
        "\n",
        "\n",
        "        if ma_indicators_counted > 0 or (not pd.isna(current_price) and (not pd.isna(sma_20) or not pd.isna(sma_50) or not pd.isna(sma_200))):\n",
        "             indicators_calculated += 1 # Count MA section if any valid MA comparison/position is made\n",
        "             # Normalize MA score component to contribute to the total score\n",
        "             # Max possible ma_score_component (0.5 + 0.5 + 0.3 + 0.4 + 0.6) = 2.3\n",
        "             # Let's scale this to contribute up to indicator_point_contribution\n",
        "             max_ma_component = 2.3\n",
        "             base_score += (ma_score_component / max_ma_component) * indicator_point_contribution if max_ma_component > 0 else 0\n",
        "        else:\n",
        "             logger.warning(\"Insufficient data for Moving Averages analysis.\")\n",
        "\n",
        "\n",
        "        bb_upper = indicators.get('BB_upper', np.nan)\n",
        "        bb_lower = indicators.get('BB_lower', np.nan)\n",
        "        bb_middle = indicators.get('BB_middle', np.nan)\n",
        "\n",
        "        if not pd.isna(current_price) and not pd.isna(bb_upper) and not pd.isna(bb_lower) and not pd.isna(bb_middle):\n",
        "            indicators_calculated += 1\n",
        "            if current_price < bb_lower:\n",
        "                base_score += indicator_point_contribution * 1.0 # Price below lower band (potential buy signal)\n",
        "            elif bb_lower <= current_price < bb_middle:\n",
        "                base_score += indicator_point_contribution * 0.8 # Between lower and middle band\n",
        "            elif bb_middle <= current_price < bb_upper:\n",
        "                base_score += indicator_point_contribution * 0.6 # Between middle and upper band\n",
        "            else: # Price above upper band\n",
        "                base_score += indicator_point_contribution * 0.4 # Potential sell signal\n",
        "        else:\n",
        "             logger.warning(\"Bollinger Bands or current price is NaN for technical scoring.\")\n",
        "\n",
        "        volume_ratio = indicators.get('Volume_ratio', np.nan)\n",
        "        if not pd.isna(volume_ratio):\n",
        "             indicators_calculated += 1\n",
        "             if volume_ratio > 2.0: # Very high volume\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             elif volume_ratio > 1.2: # High volume\n",
        "                 base_score += indicator_point_contribution * 0.8\n",
        "             elif 0.8 <= volume_ratio <= 1.2: # Normal volume\n",
        "                 base_score += indicator_point_contribution * 0.5\n",
        "             else: # Low volume\n",
        "                 base_score += indicator_point_contribution * 0.3\n",
        "        else:\n",
        "             logger.warning(\"Volume ratio is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        achieved_score_from_indicators = base_score\n",
        "\n",
        "        # Normalize the base score based on how many indicators were successfully calculated\n",
        "        if indicators_calculated > 0:\n",
        "            # Assuming each of the num_key_indicators contributes equally if available\n",
        "            # This approach gives points for each indicator that could be calculated and scored\n",
        "            # Max points if all indicators could be scored is num_key_indicators * indicator_point_contribution\n",
        "            # But our scoring within each indicator gives variable points (e.g., 0.4 to 1.0)\n",
        "            # A simpler approach is to just sum up the points from successfully scored indicators\n",
        "            # Let's cap the sum at the max possible points from indicators (50)\n",
        "            final_base_score = min(achieved_score_from_indicators, possible_indicator_points)\n",
        "\n",
        "            if indicators_calculated < num_key_indicators:\n",
        "                 logger.warning(f\"Only {indicators_calculated}/{num_key_indicators} key technical indicators could be fully calculated/scored. Final base technical score is based on available data.\")\n",
        "\n",
        "        else:\n",
        "             logger.warning(\"No key technical indicators calculated. Base technical score is 0.\")\n",
        "             final_base_score = 0\n",
        "\n",
        "\n",
        "        circuit_risk_adj = circuit_risk if isinstance(circuit_risk, (int, float)) and not pd.isna(circuit_risk) else 0\n",
        "\n",
        "        final_score = final_base_score + circuit_risk_adj\n",
        "\n",
        "        return max(0, min(final_score, 50))\n",
        "\n",
        "\n",
        "    def calculate_value_at_risk(self, price_data: pd.DataFrame, confidence_level: float = 0.95, horizon_days: int = 1) -> Dict: # Modified return type hint\n",
        "        \"\"\"\n",
        "        Calculates Value at Risk (VaR) using the historical method.\n",
        "\n",
        "        Args:\n",
        "            price_data: DataFrame with historical price data (must contain 'Close').\n",
        "            confidence_level: The confidence level for VaR (e.g., 0.95 for 95% VaR).\n",
        "            horizon_days: The time horizon for VaR (in trading days).\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing the calculated VaR as a percentage loss,\n",
        "            confidence level, and horizon days, or a dictionary with NaN/None values\n",
        "            if calculation fails.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Calculating {confidence_level*100:.0f}% VaR for {horizon_days}-day horizon.\")\n",
        "        results = {'var_percentage_loss': np.nan, 'confidence_level': confidence_level, 'horizon_days': horizon_days}\n",
        "\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or 'Close' not in price_data.columns:\n",
        "            logger.warning(\"Insufficient or invalid price data for VaR calculation.\")\n",
        "            return results # Return dictionary with NaN/None\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Calculate daily returns\n",
        "            returns = price_data['Close'].pct_change().dropna()\n",
        "\n",
        "            if returns.empty:\n",
        "                logger.warning(\"No valid returns data for VaR calculation.\")\n",
        "                return results # Return dictionary with NaN/None\n",
        "\n",
        "            # Historical VaR: Find the percentile of returns corresponding to the confidence level\n",
        "            # For downside risk, we look at the lower tail of returns.\n",
        "            # A 95% confidence level for VaR means we're interested in the 5th percentile of losses.\n",
        "            # The percentile rank for a confidence level C is 1 - C.\n",
        "            percentile_rank = (1 - confidence_level) * 100\n",
        "            logger.debug(f\"Calculating {percentile_rank:.2f} percentile of historical returns.\")\n",
        "\n",
        "            # Calculate VaR at the specified percentile\n",
        "            # The result is a negative percentage loss\n",
        "            var_percentage = np.percentile(returns, percentile_rank)\n",
        "\n",
        "            # VaR is typically expressed as a positive loss\n",
        "            var_percentage_loss = abs(var_percentage)\n",
        "\n",
        "            # Scale VaR for the desired horizon (assuming returns are independently and identically distributed)\n",
        "            # This is a simplification; more advanced methods exist for scaling VaR.\n",
        "            # Scaling by sqrt(horizon) is common but assumes specific return properties.\n",
        "            scaled_var_percentage_loss = var_percentage_loss * np.sqrt(horizon_days)\n",
        "\n",
        "            results['var_percentage_loss'] = scaled_var_percentage_loss * 100 # Convert to percentage for display/scoring\n",
        "            logger.info(f\"Calculated {confidence_level*100:.0f}% VaR ({horizon_days}-day horizon): {results['var_percentage_loss']:.2f}%\")\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating VaR: {str(e)}. Returning default results.\")\n",
        "            return results # Return dictionary with NaN/None on error\n",
        "\n",
        "\n",
        "    def fetch_news(self, symbol: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Fetches recent news headlines for the given stock symbol.\n",
        "        NOTE: This is a placeholder. In a real application, you would integrate\n",
        "        with a News API (like News API, Alpha Vantage, etc.) here.\n",
        "        \"\"\"\n",
        "        print(f\"Fetching news for {symbol} (placeholder)...\")\n",
        "        symbol_str = str(symbol) if symbol is not None else \"Unknown Stock\"\n",
        "        return [\n",
        "            f\"{symbol_str} stock price rises on positive market sentiment\",\n",
        "            f\"{symbol_str} announces strong quarterly results, beating estimates\",\n",
        "            f\"Experts bullish on {symbol_str}'s future outlook\",\n",
        "            f\"I am a non-numeric entry that might cause an error\",\n",
        "            f\"{symbol_str} faces regulatory challenges in key market\",\n",
        "            f\"Competitor's new product launch impacts {symbol_str}'s market share\",\n",
        "            f\"Global market trends positively impacting {symbol_str}\",\n",
        "            f\"{symbol_str} management provides optimistic guidance\",\n",
        "            f\"Increased foreign investment flows into {symbol_str}\",\n",
        "            f\"Regulatory approval received for {symbol_str}'s new product\",\n",
        "            f\"Production issues reported for {symbol_str}\",\n",
        "            f\"Increased competition puts pressure on {symbol_str}'s margins\",\n",
        "            f\"Analyst downgrades rating for {symbol_str}\",\n",
        "            f\"Supply chain disruptions affect {symbol_str}'s operations\",\n",
        "            f\"{symbol_str} announces stock split\",\n",
        "            f\"Dividend declared by {symbol_str}\"\n",
        "        ]\n",
        "\n",
        "\n",
        "    def analyze_sentiment(self, news_headlines: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of news headlines using the Gemini API.\n",
        "        Returns a dictionary with sentiment counts (positive, neutral, negative)\n",
        "        and a sentiment score.\n",
        "        \"\"\"\n",
        "        if not self.gemini_model:\n",
        "            print(\"Gemini API not configured. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Gemini API not configured. Sentiment analysis skipped.'}\n",
        "\n",
        "        if not isinstance(news_headlines, list) or not news_headlines:\n",
        "            print(\"No news headlines to analyze. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 12.5, 'summary': 'No news headlines. Sentiment analysis skipped.'}\n",
        "\n",
        "        logger.info(\"Analyzing sentiment using Gemini API...\")\n",
        "        prompt = \"Analyze the sentiment of the following news headlines for a stock and categorize each as Positive, Neutral, or Negative. Provide a concise summary of the overall sentiment.\\n\\n\"\n",
        "        for headline in news_headlines:\n",
        "            if isinstance(headline, str):\n",
        "                 prompt += f\"- {headline}\\n\"\n",
        "            else:\n",
        "                 logger.warning(f\"Skipping non-string headline: {headline}\")\n",
        "                 continue\n",
        "\n",
        "        if len(prompt) > 30000:\n",
        "             logger.warning(\"News headlines too long for Gemini API prompt. Truncating.\")\n",
        "             prompt = prompt[:30000] + \"\\n... (headlines truncated)\"\n",
        "\n",
        "        try:\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "            sentiment_text = response.text.strip()\n",
        "            logger.info(f\"Gemini API Response: {sentiment_text[:200]}...\")\n",
        "\n",
        "            positive_count = sentiment_text.lower().count('positive')\n",
        "            neutral_count = sentiment_text.lower().count('neutral')\n",
        "            negative_count = sentiment_text.lower().count('negative')\n",
        "\n",
        "            summary_line = \"No summary extracted.\"\n",
        "            lines = sentiment_text.split('\\n')\n",
        "            for line in lines:\n",
        "                 lower_line = line.lower()\n",
        "                 if 'summary' in lower_line or 'overall sentiment' in lower_line:\n",
        "                     summary_line = line.strip()\n",
        "                     break\n",
        "            if summary_line == \"No summary extracted.\" and lines:\n",
        "                 for line in reversed(lines):\n",
        "                     if line.strip():\n",
        "                         summary_line = line.strip()\n",
        "                         break\n",
        "\n",
        "            total_headlines = len([h for h in news_headlines if isinstance(h, str)])\n",
        "            if total_headlines > 0:\n",
        "                sentiment_score = ((positive_count - negative_count) / total_headlines) * 12.5 + 12.5\n",
        "            else:\n",
        "                sentiment_score = 12.5\n",
        "\n",
        "            return {\n",
        "                'positive': positive_count,\n",
        "                'neutral': neutral_count,\n",
        "                'negative': negative_count,\n",
        "                'score': max(0, min(sentiment_score, 25)),\n",
        "                'summary': summary_line\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing sentiment with Gemini API: {e}. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis failed.'}\n",
        "\n",
        "\n",
        "    def generate_enhanced_recommendation(self, fundamental_score, technical_score,\n",
        "                                       liquidity_score, peer_performance, index_membership,\n",
        "                                       sentiment_analysis_results, valuation_comparison_results,\n",
        "                                       downside_risk_metrics: Dict): # Added type hint for clarity\n",
        "        \"\"\"Generate comprehensive recommendation including sentiment and valuation comparison\"\"\"\n",
        "        fund_score = fundamental_score if isinstance(fundamental_score, (int, float)) and not pd.isna(fundamental_score) else 0\n",
        "        tech_score = technical_score if isinstance(technical_score, (int, float)) and not pd.isna(technical_score) else 0\n",
        "        liq_score = liquidity_score if isinstance(liquidity_score, (int, float)) and not pd.isna(liquidity_score) else 0\n",
        "        sentiment_score = sentiment_analysis_results.get('score', 0) if isinstance(sentiment_analysis_results.get('score'), (int, float)) and not pd.isna(sentiment_analysis_results.get('score')) else 0\n",
        "\n",
        "        # Get valuation adjustment score\n",
        "        valuation_adjustment = valuation_comparison_results.get('valuation_score_adjustment', 0) if isinstance(valuation_comparison_results.get('valuation_score_adjustment'), (int, float)) and not pd.isna(valuation_comparison_results.get('valuation_score_adjustment')) else 0\n",
        "        logger.info(f\"Valuation comparison adjustment: {valuation_adjustment}\")\n",
        "\n",
        "        # Incorporate downside risk into the score\n",
        "        # A higher VaR indicates higher risk, so it should negatively impact the score\n",
        "        # Define a simple scoring for VaR (e.g., penalize based on VaR percentage)\n",
        "        var_percentage = downside_risk_metrics.get('var_percentage_loss', np.nan) # Use .get() as it's now a dict\n",
        "        downside_risk_adjustment = 0 # Adjustment based on VaR\n",
        "\n",
        "        if isinstance(var_percentage, (int, float)) and not pd.isna(var_percentage):\n",
        "             # Example scoring: higher VaR means higher penalty\n",
        "             if var_percentage > 5: # VaR > 5%\n",
        "                  downside_risk_adjustment -= 15\n",
        "                  logger.info(f\"VaR ({var_percentage:.2f}%) > 5%. Applying downside risk penalty (-15).\")\n",
        "             elif var_percentage > 3: # VaR > 3%\n",
        "                  downside_risk_adjustment -= 10\n",
        "                  logger.info(f\"VaR ({var_percentage:.2f}%) > 3%. Applying downside risk penalty (-10).\")\n",
        "             elif var_percentage > 1: # VaR > 1%\n",
        "                  downside_risk_adjustment -= 5\n",
        "                  logger.info(f\"VaR ({var_percentage:.2f}%) > 1%. Applying downside risk penalty (-5).\")\n",
        "             else:\n",
        "                  logger.info(f\"VaR ({var_percentage:.2f}%) <= 1%. No downside risk penalty.\")\n",
        "        else:\n",
        "             logger.warning(\"VaR not available. Cannot apply downside risk adjustment.\")\n",
        "             downside_risk_adjustment -= 2 # Small penalty if VaR cannot be calculated\n",
        "\n",
        "\n",
        "        total_score = fund_score + tech_score + liq_score + sentiment_score + valuation_adjustment + downside_risk_adjustment # Add valuation and downside risk adjustment\n",
        "\n",
        "\n",
        "        peer_analysis_available = isinstance(peer_performance, dict) and \\\n",
        "                                  not (pd.isna(peer_performance.get('stock_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('avg_peer_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('relative_performance')))\n",
        "\n",
        "        if peer_analysis_available and peer_performance.get('outperformance', False) is True:\n",
        "            total_score += 5\n",
        "            logger.info(\"Adding bonus for peer outperformance.\")\n",
        "        elif not peer_analysis_available:\n",
        "             total_score -= 5\n",
        "             logger.warning(\"Applying small penalty as peer performance data is incomplete/unavailable.\")\n",
        "\n",
        "        if isinstance(index_membership, list) and index_membership:\n",
        "            total_score += 5\n",
        "            logger.info(\"Adding bonus for index membership.\")\n",
        "\n",
        "        recommendation = \"NEUTRAL\"\n",
        "        confidence = \"Low\"\n",
        "\n",
        "        # Re-evaluate thresholds with the new max score (245 + max downside risk adj)\n",
        "        # Max possible downside risk adjustment is 0, min is -15 (or -2 if N/A)\n",
        "        # So max total score is still around 235. Thresholds remain the same.\n",
        "        if total_score >= 190: # Increased threshold\n",
        "            recommendation = \"STRONG BUY\"\n",
        "            confidence = \"High\"\n",
        "        elif total_score >= 150: # Increased threshold\n",
        "            recommendation = \"BUY\"\n",
        "            confidence = \"Moderate to High\"\n",
        "        elif total_score >= 100: # Same threshold\n",
        "            recommendation = \"HOLD\"\n",
        "            confidence = \"Moderate\"\n",
        "        elif total_score >= 70: # Same threshold\n",
        "            recommendation = \"SELL\"\n",
        "            confidence = \"Moderate\"\n",
        "        else:\n",
        "            recommendation = \"STRONG SELL\"\n",
        "            confidence = \"High\"\n",
        "\n",
        "        logger.info(f\"Generated enhanced recommendation: {recommendation} (Total Score: {total_score:.2f})\")\n",
        "\n",
        "        return {\n",
        "            'recommendation': recommendation,\n",
        "            'confidence': confidence,\n",
        "            'total_score': total_score,\n",
        "            'breakdown': {\n",
        "                'fundamental': fund_score,\n",
        "                'technical': tech_score,\n",
        "                'liquidity': liq_score,\n",
        "                'sentiment': sentiment_score,\n",
        "                'valuation_comparison': valuation_adjustment, # Include valuation adjustment in breakdown\n",
        "                'downside_risk': downside_risk_adjustment, # Include downside risk adjustment\n",
        "                'peer_adjustment': 5 if peer_analysis_available and peer_performance.get('outperformance', False) is True else (-5 if not peer_analysis_available else 0),\n",
        "                'index_adjustment': 5 if isinstance(index_membership, list) and index_membership else 0\n",
        "            }\n",
        "        }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f796d84c"
      },
      "source": [
        "**Reasoning**:\n",
        "I have updated the `calculate_value_at_risk` method to return a dictionary as expected by the `generate_enhanced_recommendation` function. The next step is to re-run the integration and report display code to confirm that the `AttributeError` is resolved and that the downside risk metrics are correctly calculated and displayed in the report.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1948485e",
        "cellView": "form"
      },
      "source": [
        "#@title Part 3: Enhanced Analysis Integration and Report Display (with Downside Risk Analysis - Retry Again 2)\n",
        "\n",
        "# Assuming IndianStockAnalyzer and EnhancedStockAnalyzer classes are defined in previous cells\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "    if not isinstance(symbol, str) or not symbol:\n",
        "        logger.error(\"Invalid stock symbol provided for enhanced analysis.\")\n",
        "        return None\n",
        "    if not isinstance(stock_analyzer_part1, IndianStockAnalyzer):\n",
        "        logger.error(\"Invalid IndianStockAnalyzer (Part 1) instance provided.\")\n",
        "        return None\n",
        "    if not isinstance(enhanced_analyzer, EnhancedStockAnalyzer):\n",
        "        logger.error(\"Invalid EnhancedStockAnalyzer (Part 2) instance provided.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    logger.info(f\"Starting enhanced analysis for {symbol}\")\n",
        "    # Get basic analysis from Part 1\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        logger.error(f\"Basic analysis failed for {symbol}.\")\n",
        "        return None\n",
        "\n",
        "    # Get current price - already validated in Part 1 analyze_stock\n",
        "    current_price = stock_data.current_price\n",
        "    if pd.isna(current_price) or current_price <= 0:\n",
        "         logger.warning(f\"Current price invalid ({current_price}). Enhanced analysis might be limited.\")\n",
        "\n",
        "\n",
        "    # Enhanced analysis\n",
        "    logger.info(\"Starting enhanced analysis features (Part 2).\")\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    # Pass current_price to assess_circuit_risk (already validated as best as possible in Part 1)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    # Pass price_data (already validated in Part 1 analyze_stock)\n",
        "    # CORRECTED: Call get_liquidity_score on enhanced_analyzer and pass price_data from stock_data\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "\n",
        "    # 3. Peer analysis (including valuation data)\n",
        "    # Pass info (already validated in Part 1 analyze_stock)\n",
        "    # The get_peer_companies method now returns a list of dictionaries with valuation data\n",
        "    peers_with_valuation = enhanced_analyzer.get_peer_companies(symbol, stock_data.info)\n",
        "    # Pass the list of peer symbols (extracted from the list of dictionaries) for performance comparison\n",
        "    peer_symbols_for_performance = [p['symbol'] for p in peers_with_valuation if isinstance(p, dict) and 'symbol' in p]\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peer_symbols_for_performance) # Pass just symbols\n",
        "\n",
        "    # 4. Valuation Analysis: Calculate peer average valuations and compare\n",
        "    peer_average_valuation = enhanced_analyzer.calculate_peer_average_valuation(peers_with_valuation)\n",
        "    valuation_comparison_results = enhanced_analyzer.compare_valuation_to_peers(stock_data.metrics, peer_average_valuation)\n",
        "\n",
        "    # 5. Downside Risk Assessment: Calculate VaR\n",
        "    downside_risk_metrics = enhanced_analyzer.calculate_value_at_risk(stock_data.price_data)\n",
        "\n",
        "\n",
        "    # 6. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "\n",
        "    # 7. Recalculate technical score with circuit risk\n",
        "    # Pass indicators (already validated in Part 1 calculate_technical_indicators)\n",
        "    # Pass circuit_risk (already validated in assess_circuit_risk)\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "\n",
        "    # 8. Fetch and analyze news sentiment\n",
        "    # Pass symbol (already validated)\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    # Pass news_headlines (already validated)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "\n",
        "\n",
        "    # 9. Generate enhanced recommendation\n",
        "    # Pass scores and results (already validated within their respective functions)\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance, # Pass potentially incomplete/NaN peer performance\n",
        "        index_membership,\n",
        "        sentiment_analysis_results, # Pass sentiment analysis results\n",
        "        valuation_comparison_results, # Pass valuation comparison results\n",
        "        downside_risk_metrics # Pass downside risk metrics\n",
        "    )\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score, # Ensure correct liquidity score is included\n",
        "            'peers': peers_with_valuation, # Store the list of peers with their valuation data\n",
        "            'peer_performance': peer_performance, # Include peer performance, even if NaN\n",
        "            'peer_average_valuation': peer_average_valuation, # Store peer average valuation\n",
        "            'valuation_comparison': valuation_comparison_results, # Store valuation comparison results\n",
        "            'downside_risk': downside_risk_metrics, # Store downside risk metrics (e.g., VaR)\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "    logger.info(f\"Enhanced analysis completed for {symbol}\")\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize analyzers\n",
        "    try:\n",
        "        stock_analyzer = IndianStockAnalyzer()\n",
        "        enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "    except NameError:\n",
        "        print(\"Make sure to run the previous cells defining IndianStockAnalyzer and EnhancedStockAnalyzer classes.\")\n",
        "        exit() # Exit if classes are not defined\n",
        "\n",
        "\n",
        "    # Analyze a stock\n",
        "    symbol = \"RELIANCE.NS\" # Example symbol\n",
        "    result = analyze_stock_enhanced(symbol, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if result:\n",
        "        # Display the enhanced report\n",
        "        enhanced = result['enhanced_features']\n",
        "        final = result['final_recommendation']\n",
        "        basic = result['basic_analysis'] # Get basic data for display\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Enhanced Analysis Report: {basic.company_name} ({basic.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if not pd.isna(basic.current_price) else \"Current Price: N/A\")\n",
        "        market_cap_cr = basic.market_cap / 10000000 if not pd.isna(basic.market_cap) else np.nan\n",
        "        print(f\"Market Cap: ₹{market_cap_cr:,.2f} Cr\" if not pd.isna(market_cap_cr) else \"Market Cap: N/A\")\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n⚙️ Enhanced Technical Analysis & Risk:\")\n",
        "        # Display enhanced technical indicators and risk\n",
        "        # Assuming you want to display relevant indicators from basic.indicators and the circuit risk score\n",
        "        circuit_limits_display = enhanced.get('circuit_limits')\n",
        "        if circuit_limits_display and not pd.isna(circuit_limits_display.get('lower_circuit')) and not pd.isna(circuit_limits_display.get('upper_circuit')):\n",
        "             print(f\"Circuit Limits: {circuit_limits_display.get('lower_circuit', 'N/A'):.2f} - {circuit_limits_display.get('upper_circuit', 'N/A'):.2f}\")\n",
        "        else:\n",
        "             print(\"Circuit Limits: N/A\")\n",
        "\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        # Check if liquidity score is available before formatting\n",
        "        liquidity_score_display = f\"{enhanced.get('liquidity_score', 'N/A')}/70\" if isinstance(enhanced.get('liquidity_score'), (int, float)) and not pd.isna(enhanced.get('liquidity_score')) else \"Liquidity Score: N/A/70\"\n",
        "        print(liquidity_score_display)\n",
        "\n",
        "\n",
        "        # Display some key technical indicators from basic analysis\n",
        "        print(\"\\nKey Technical Indicators (from Basic Analysis):\")\n",
        "        key_tech_indicators = ['RSI', 'MACD', 'MACD_signal', 'SMA_20', 'SMA_50', 'BB_middle', 'Volume_ratio']\n",
        "        for indicator_name in key_tech_indicators:\n",
        "            value = basic.indicators.get(indicator_name, np.nan)\n",
        "            if not pd.isna(value):\n",
        "                if isinstance(value, float):\n",
        "                     print(f\"  - {indicator_name}: {value:,.2f}\")\n",
        "                else:\n",
        "                     print(f\"  - {indicator_name}: {value}\")\n",
        "            # Add logging for these key technical indicators if they are calculated\n",
        "            logger.info(f\"Indicator {indicator_name}: {value}\")\n",
        "        else:\n",
        "            print(f\"  - {indicator_name}: N/A\")\n",
        "            logger.info(f\"Indicator {indicator_name}: N/A\")\n",
        "\n",
        "        # Display Valuation Analysis\n",
        "        print(f\"\\n📈 Valuation Analysis:\")\n",
        "        stock_metrics = basic.metrics\n",
        "        peer_avg_val = enhanced.get('peer_average_valuation', {})\n",
        "        val_comp_results = enhanced.get('valuation_comparison', {})\n",
        "\n",
        "        stock_pe = stock_metrics.get('trailingPE', np.nan)\n",
        "        stock_pb = stock_metrics.get('priceToBook', np.nan)\n",
        "        stock_ev_ebitda = stock_metrics.get('evToEbitda', np.nan)\n",
        "\n",
        "        print(f\"Stock Valuation:\")\n",
        "        print(f\"  - Trailing PE: {stock_pe:.2f}\" if not pd.isna(stock_pe) else \"  - Trailing PE: N/A\")\n",
        "        print(f\"  - Price to Book: {stock_pb:.2f}\" if not pd.isna(stock_pb) else \"  - Price to Book: N/A\")\n",
        "        print(f\"  - EV/EBITDA: {stock_ev_ebitda:.2f}\" if not pd.isna(stock_ev_ebitda) else \"  - EV/EBITDA: N/A\")\n",
        "\n",
        "        print(\"\\nPeer Average Valuation:\")\n",
        "        avg_pe_display = f\"{peer_avg_val.get('avg_pe', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pe', np.nan)) else \"N/A\"\n",
        "        avg_pb_display = f\"{peer_avg_val.get('avg_pb', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pb', np.nan)) else \"N/A\"\n",
        "        avg_ev_ebitda_display = f\"{peer_avg_val.get('avg_ev_ebitda', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_ev_ebitda', np.nan)) else \"N/A\"\n",
        "\n",
        "        print(f\"  - Average PE: {avg_pe_display}\")\n",
        "        print(f\"  - Average PB: {avg_pb_display}\")\n",
        "        print(f\"  - Average EV/EBITDA: {avg_ev_ebitda_display}\")\n",
        "\n",
        "        print(\"\\nValuation Comparison:\")\n",
        "        print(f\"  - PE Comparison: {val_comp_results.get('pe_comparison', 'N/A')}\")\n",
        "        print(f\"  - PB Comparison: {val_comp_results.get('pb_comparison', 'N/A')}\")\n",
        "        print(f\"  - EV/EBITDA Comparison: {val_comp_results.get('ev_ebitda_comparison', 'N/A')}\")\n",
        "        valuation_adj_display = f\"{val_comp_results.get('valuation_score_adjustment', 0):+.2f}\" if isinstance(val_comp_results.get('valuation_score_adjustment'), (int, float)) and not pd.isna(val_comp_results.get('valuation_score_adjustment')) else \"N/A\"\n",
        "        print(f\"  - Valuation Score Adjustment: {valuation_adj_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\n📉 Downside Risk Analysis:\")\n",
        "        downside_risk = enhanced.get('downside_risk', {})\n",
        "        var_percentage = downside_risk.get('var_percentage_loss', np.nan)\n",
        "        var_display = f\"{var_percentage:.2f}%\" if not pd.isna(var_percentage) else \"N/A\"\n",
        "        # Access 'confidence_level' and 'horizon_days' directly from the downside_risk dictionary\n",
        "        confidence_level_display = downside_risk.get('confidence_level', 0.95)\n",
        "        horizon_days_display = downside_risk.get('horizon_days', 1)\n",
        "        print(f\"  - {confidence_level_display*100:.0f}% VaR ({horizon_days_display}-day): {var_display}\")\n",
        "\n",
        "        downside_adj_display = f\"{final.get('breakdown', {}).get('downside_risk', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('downside_risk'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('downside_risk')) else \"N/A\"\n",
        "        print(f\"  - Downside Risk Score Adjustment: {downside_adj_display}\")\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"\\n🤝 Peer Analysis (Performance):\")\n",
        "        peer_perf = enhanced.get('peer_performance')\n",
        "        if isinstance(peer_perf, dict) and \\\n",
        "           not pd.isna(peer_perf.get('stock_return')) and \\\n",
        "           not pd.isna(peer_perf.get('avg_peer_return')) and \\\n",
        "           not pd.isna(peer_perf.get('relative_performance')):\n",
        "\n",
        "             stock_return_display = f\"{peer_perf.get('stock_return', np.nan):.2f}%\" if isinstance(peer_perf.get('stock_return'), (int, float)) and not pd.isna(peer_perf.get('stock_return')) else 'N/A'\n",
        "             avg_peer_return_display = f\"{peer_perf.get('avg_peer_return', np.nan):.2f}%\" if isinstance(peer_perf.get('avg_peer_return'), (int, float)) and not pd.isna(peer_perf.get('avg_peer_return')) else 'N/A'\n",
        "             relative_performance_display = f\"{peer_perf.get('relative_performance', np.nan):.2f}%\" if isinstance(peer_perf.get('relative_performance'), (int, float)) and not pd.isna(peer_perf.get('relative_performance')) else 'N/A'\n",
        "\n",
        "             print(f\"  - {peer_perf.get('days', 'N/A')}-day Stock Return: {stock_return_display}\")\n",
        "             print(f\"  - Avg Peer Return: {avg_peer_return_display}\")\n",
        "             print(f\"  - Relative Performance: {relative_performance_display}\")\n",
        "        else:\n",
        "             print(\"Peer Performance Data Unavailable.\")\n",
        "\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"\\n🏛️ Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             # Only print a few headlines to keep the report concise\n",
        "             print(\"Sample News Headlines:\")\n",
        "             # Ensure headlines are valid strings before printing\n",
        "             valid_headlines = [h for h in enhanced['news_headlines'] if isinstance(h, str)]\n",
        "             for headline in valid_headlines[:5]: # Print up to 5 headlines\n",
        "                 print(f\"- {headline}\")\n",
        "             if len(valid_headlines) > 5:\n",
        "                  print(\"  ...\")\n",
        "\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             sentiment_score_display = f\"{sentiment_results.get('score', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\"\n",
        "             print(f\"Sentiment Score: {sentiment_score_display}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Comprehensive Scores and Recommendation ---\")\n",
        "        print(f\"Fundamental Score (from Part 1): {basic.fundamental_score:.2f}/50\" if not pd.isna(basic.fundamental_score) else \"Fundamental Score: N/A\")\n",
        "        # Add checks for NaN before formatting float for breakdown scores\n",
        "        enhanced_tech_score_display = f\"{final.get('breakdown', {}).get('technical', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('technical'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('technical')) else \"N/A\"\n",
        "        liquidity_score_display_breakdown = f\"{final.get('breakdown', {}).get('liquidity', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('liquidity'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('liquidity')) else \"N/A\"\n",
        "        sentiment_score_display_breakdown = f\"{final.get('breakdown', {}).get('sentiment', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\" # Corrected sentiment score breakdown check\n",
        "        valuation_comp_display_breakdown = f\"{final.get('breakdown', {}).get('valuation_comparison', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('valuation_comparison'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('valuation_comparison')) else \"N/A\"\n",
        "        downside_risk_display_breakdown = f\"{final.get('breakdown', {}).get('downside_risk', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('downside_risk'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('downside_risk')) else \"N/A\"\n",
        "\n",
        "\n",
        "        print(f\"Technical Score (Enhanced): {enhanced_tech_score_display}/50\")\n",
        "        print(f\"Liquidity Score: {liquidity_score_display_breakdown}/70\")\n",
        "        print(f\"Sentiment Score: {sentiment_score_display_breakdown}/25\")\n",
        "        print(f\"Valuation Comparison Adjustment: {valuation_comp_display_breakdown}\")\n",
        "        print(f\"Downside Risk Adjustment: {downside_risk_display_breakdown}\")\n",
        "\n",
        "\n",
        "        # Display adjustment scores\n",
        "        peer_adj_display = f\"{final.get('breakdown', {}).get('peer_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('peer_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('peer_adjustment')) else \"N/A\"\n",
        "        index_adj_display = f\"{final.get('breakdown', {}).get('index_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('index_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('index_adjustment')) else \"N/A\"\n",
        "\n",
        "        print(f\"Peer Performance Adjustment: {peer_adj_display}\")\n",
        "        print(f\"Index Membership Adjustment: {index_adj_display}\")\n",
        "\n",
        "\n",
        "        # Updated max score to reflect the addition of Downside Risk Adjustment (potential max increase of 0, potential max decrease of 15)\n",
        "        # Max Total Score = Fund (50) + Tech (50) + Liq (70) + Sent (25) + Val Adj (30) + Peer Adj (5) + Index Adj (5) + Downside Adj (0) = 235\n",
        "        # Re-evaluating the previous max estimate (245) and the new max. Let's use 235 as a potential max for scoring clarity.\n",
        "        print(f\"\\nTotal Enhanced Score: {final.get('total_score', 0):.2f}/235\" if isinstance(final.get('total_score'), (int, float)) and not pd.isna(final.get('total_score')) else \"Total Enhanced Score: N/A\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} (Confidence: {final.get('confidence', 'N/A')})\")\n",
        "\n",
        "\n",
        "        print(f\"\\n{'='*60}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11522fa1"
      },
      "source": [
        "**Reasoning**:\n",
        "The downside risk assessment is now successfully implemented and displayed in the report. The next part of the overall task is to enhance the dividend yield calculation. The subtask is to modify the calculation to consider historical dividend payout trends and stability. This requires modifying the `IndianStockAnalyzer` class's `calculate_fundamental_score` method or adding a new method to the `EnhancedStockAnalyzer` that can access historical dividend data and calculate a more nuanced dividend score. Given that historical data is needed, modifying the `EnhancedStockAnalyzer` is more appropriate as it has access to the price data fetched by the `IndianStockAnalyzer`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuvcpvs5JfUu",
        "cellView": "form"
      },
      "source": [
        "#@title Part 2: EnhancedStockAnalyzer class definition (with Enhanced Dividend Analysis and Global Macro)\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import typing for type hints\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# --- EnhancedStockAnalyzer class definition ---\n",
        "class EnhancedStockAnalyzer:\n",
        "    \"\"\"Enhanced analyzer with additional features for Indian markets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the enhanced analyzer.\"\"\"\n",
        "        self.risk_free_rate = self.get_dynamic_risk_free_rate()\n",
        "        # Assuming gemini_model is defined globally from a previous cell\n",
        "        global gemini_model # Access the global gemini_model\n",
        "        self.gemini_model = gemini_model\n",
        "\n",
        "        # More detailed circuit limit percentages based on NSE categorization (simplified)\n",
        "        self.circuit_limits_percentage = {\n",
        "            'category_a': 0.20, # Typically high-liquidity index stocks\n",
        "            'category_b': 0.10, # Most other actively traded stocks\n",
        "            'category_t': 0.05  # Stocks in trade-for-trade segment\n",
        "        }\n",
        "\n",
        "        # Simple mapping of some known stocks to categories for demonstration\n",
        "        self.stock_category_map = {\n",
        "            'RELIANCE.NS': 'category_a',\n",
        "            'TCS.NS': 'category_a',\n",
        "            'HDFCBANK.NS': 'category_a',\n",
        "            'INFY.NS': 'category_a',\n",
        "            'ICICIBANK.NS': 'category_a',\n",
        "            'VEDL.NS': 'category_b',\n",
        "            'PNB.NS': 'category_b',\n",
        "            'INDIGO.NS': 'category_b',\n",
        "            'BANDHANBNK.NS': 'category_b',\n",
        "            'PERSISTENT.NS': 'category_b',\n",
        "            'COFORGE.NS': 'category_b',\n",
        "            'LTTS.NS': 'category_b',\n",
        "        }\n",
        "\n",
        "        # Placeholder for global macro sentiment (simplified)\n",
        "        # In a real application, this would be dynamic based on fetched data\n",
        "        self.global_macro_sentiment = 'neutral' # Can be 'positive', 'neutral', 'negative'\n",
        "\n",
        "\n",
        "    def get_dynamic_risk_free_rate(self):\n",
        "        \"\"\"Fetch current 10-year G-Sec yield\"\"\"\n",
        "        try:\n",
        "            return 0.072  # 7.2% as of recent data\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not fetch dynamic risk-free rate: {e}. Using fallback rate.\")\n",
        "            return 0.065\n",
        "\n",
        "    def get_circuit_limits(self, symbol):\n",
        "        \"\"\"Get circuit breaker limits for the stock based on categorization\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "\n",
        "            if not info or 'previousClose' not in info:\n",
        "                 logger.warning(f\"Could not get previous close for {symbol}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "            prev_close = info.get('previousClose')\n",
        "            if pd.isna(prev_close) or prev_close <= 0:\n",
        "                 logger.warning(f\"Invalid previous close price for {symbol}: {prev_close}. Cannot calculate circuit limits.\")\n",
        "                 return None\n",
        "\n",
        "\n",
        "            stock_category = self.stock_category_map.get(symbol.upper(), 'category_b')\n",
        "            circuit_percent = self.circuit_limits_percentage.get(stock_category, 0.10)\n",
        "\n",
        "            logger.info(f\"Determined circuit percentage for {symbol} (Category: {stock_category}): {circuit_percent*100}%\")\n",
        "\n",
        "            upper_circuit = prev_close * (1 + circuit_percent)\n",
        "            lower_circuit = prev_close * (1 - circuit_percent)\n",
        "\n",
        "            return {\n",
        "                'upper_circuit': upper_circuit,\n",
        "                'lower_circuit': lower_circuit,\n",
        "                'circuit_percent': circuit_percent\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting circuit breaker limits for {symbol}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def assess_circuit_risk(self, current_price, circuit_limits):\n",
        "        \"\"\"Assess proximity to circuit limits\"\"\"\n",
        "        if pd.isna(current_price) or current_price <= 0:\n",
        "             logger.warning(\"Invalid current price for circuit risk assessment.\")\n",
        "             return 0\n",
        "\n",
        "        if not circuit_limits or 'upper_circuit' not in circuit_limits or 'lower_circuit' not in circuit_limits:\n",
        "            logger.warning(\"Invalid or incomplete circuit limits provided.\")\n",
        "            return 0\n",
        "\n",
        "        upper_circuit = circuit_limits['upper_circuit']\n",
        "        lower_circuit = circuit_limits['lower_circuit']\n",
        "\n",
        "        if pd.isna(upper_circuit) or pd.isna(lower_circuit) or upper_circuit <= 0 or lower_circuit <= 0:\n",
        "             logger.warning(\"Circuit limits are invalid numbers. Cannot assess circuit risk.\")\n",
        "             return 0\n",
        "\n",
        "        risk_score = 0\n",
        "\n",
        "        if current_price >= upper_circuit:\n",
        "             risk_score -= 30\n",
        "        elif (upper_circuit - current_price) / current_price < 0.01:\n",
        "            risk_score -= 20\n",
        "        elif (upper_circuit - current_price) / current_price < 0.03:\n",
        "            risk_score -= 10\n",
        "        elif (upper_circuit - current_price) / current_price < 0.05:\n",
        "            risk_score -= 5\n",
        "\n",
        "        if current_price <= lower_circuit:\n",
        "            risk_score -= 40\n",
        "        elif (current_price - lower_circuit) / current_price < 0.01:\n",
        "            risk_score -= 30\n",
        "        elif (current_price - lower_circuit) / current_price < 0.03:\n",
        "            risk_score -= 15\n",
        "        elif (current_price - lower_circuit) / current_price < 0.05:\n",
        "            risk_score -= 8\n",
        "\n",
        "        logger.info(f\"Circuit risk score calculated: {risk_score}\")\n",
        "        return risk_score\n",
        "\n",
        "    def get_liquidity_score(self, price_data):\n",
        "        \"\"\"Enhanced liquidity analysis with NaN handling and better checks\"\"\"\n",
        "        liquidity_score = 0\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or len(price_data) < 20:\n",
        "            logger.warning(\"Insufficient price data for liquidity analysis. Assigning default score.\")\n",
        "            return 30\n",
        "\n",
        "        try:\n",
        "            avg_volume_20d = price_data['Volume'].rolling(20).mean().iloc[-1]\n",
        "            avg_volume_5d = price_data['Volume'].rolling(5).mean().iloc[-1]\n",
        "            current_close = price_data['Close'].iloc[-1]\n",
        "\n",
        "            # Add logging for diagnosis - before calculation check\n",
        "            logger.info(f\"Volume data for liquidity: avg_volume_20d: {avg_volume_20d}, avg_volume_5d: {avg_volume_5d}, current_close: {current_close}\")\n",
        "\n",
        "\n",
        "            if pd.isna(avg_volume_20d) or pd.isna(avg_volume_5d) or pd.isna(current_close) or current_close <= 0:\n",
        "                 logger.warning(\"Liquidity metrics are NaN or invalid. Cannot calculate liquidity score accurately. Assigning default.\")\n",
        "                 return 30\n",
        "\n",
        "            avg_turnover_20d = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d >= 0 and current_close > 0:\n",
        "                 avg_turnover_20d = avg_volume_20d * current_close\n",
        "\n",
        "            volume_spike = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0:\n",
        "                 if avg_volume_5d is not None and not pd.isna(avg_volume_5d):\n",
        "                     volume_spike = avg_volume_5d / avg_volume_20d\n",
        "                 else:\n",
        "                      logger.warning(\"5-day average volume is invalid for volume spike calculation.\")\n",
        "            elif not pd.isna(avg_volume_5d) and avg_volume_5d > 0:\n",
        "                 volume_spike = 1.0\n",
        "                 logger.warning(\"20-day average volume is invalid for volume spike, using 1.0 as relative indicator.\")\n",
        "            else:\n",
        "                 volume_spike = np.nan # Ensure volume_spike is NaN if both volumes are invalid\n",
        "                 logger.warning(\"Insufficient or invalid volume data for volume ratio calculation.\")\n",
        "\n",
        "            # Add logging for volume spike - after calculation\n",
        "            logger.info(f\"Volume spike calculated: {volume_spike}\")\n",
        "\n",
        "            # Corrected logic for scoring based on volume_spike\n",
        "            if not pd.isna(volume_spike):\n",
        "                if volume_spike > 1.5: # Volume is 50% higher than average\n",
        "                    liquidity_score += 10\n",
        "                elif volume_spike < 0.8: # Volume is significantly lower than average\n",
        "                    liquidity_score += 2 # Small penalty for low volume\n",
        "                else: # volume_spike is between 0.8 and 1.5 (inclusive of 0.8, exclusive of 1.5)\n",
        "                    liquidity_score += 5 # Average volume is neutral\n",
        "            else:\n",
        "                 logger.warning(\"Volume spike ratio is NaN. Skipping trend scoring.\")\n",
        "\n",
        "\n",
        "            if not pd.isna(avg_turnover_20d):\n",
        "                if avg_turnover_20d > 500_00_00_000:\n",
        "                    liquidity_score += 40\n",
        "                elif avg_turnover_20d > 100_00_00_000:\n",
        "                    liquidity_score += 30\n",
        "                elif avg_turnover_20d > 10_00_00_000:\n",
        "                    liquidity_score += 20\n",
        "                elif avg_turnover_20d > 1_00_00_000:\n",
        "                    liquidity_score += 10\n",
        "                else:\n",
        "                    liquidity_score += 5\n",
        "            else:\n",
        "                 logger.warning(\"Average turnover is NaN. Skipping turnover scoring.\")\n",
        "                 liquidity_score += 10\n",
        "\n",
        "            volume_std = price_data['Volume'].rolling(20).std().iloc[-1] if len(price_data) >= 20 else np.nan\n",
        "            volume_cv = np.nan\n",
        "            if avg_volume_20d is not None and not pd.isna(avg_volume_20d) and avg_volume_20d > 0 and \\\n",
        "               volume_std is not None and not pd.isna(volume_std):\n",
        "                volume_cv = volume_std / avg_volume_20d\n",
        "\n",
        "            if not pd.isna(volume_cv):\n",
        "                if volume_cv < 0.5:\n",
        "                    liquidity_score += 20\n",
        "                elif volume_cv < 1.0:\n",
        "                    liquidity_score += 10\n",
        "            else:\n",
        "                 logger.warning(\"Volume coefficient of variation is NaN. Skipping consistency scoring.\")\n",
        "\n",
        "            # The volume spike scoring is now handled above within the main if not pd.isna(volume_spike): block\n",
        "\n",
        "\n",
        "            return min(liquidity_score, 70)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating liquidity score: {str(e)}\")\n",
        "            return 30\n",
        "\n",
        "    def get_peer_companies(self, symbol: str, stock_info: Dict) -> List[Dict]: # Modified return type hint\n",
        "        \"\"\"Identify peer companies and fetch their valuation ratios for comparison\"\"\"\n",
        "        logger.info(f\"Identifying peer companies and fetching valuation data for {symbol}.\")\n",
        "        peer_list_with_valuation = [] # List to store peer info including valuation\n",
        "\n",
        "        try:\n",
        "            if not isinstance(stock_info, dict):\n",
        "                 logger.warning(\"Invalid stock info for peer identification.\")\n",
        "                 return []\n",
        "\n",
        "            sector = stock_info.get('sector', '')\n",
        "            market_cap = stock_info.get('marketCap', 0)\n",
        "\n",
        "            if not isinstance(sector, str):\n",
        "                 sector = ''\n",
        "            if not isinstance(market_cap, (int, float)) or pd.isna(market_cap) or market_cap <= 0:\n",
        "                 logger.warning(\"Invalid market cap for peer identification.\")\n",
        "                 market_cap = 0\n",
        "\n",
        "            if market_cap > 10_00_000_00_00_000:\n",
        "                cap_category = 'Large Cap'\n",
        "            elif market_cap > 50_000_00_00_000:\n",
        "                cap_category = 'Mid Cap'\n",
        "            else:\n",
        "                cap_category = 'Small Cap'\n",
        "\n",
        "            # Peer mapping (simplified - in production, use a comprehensive database)\n",
        "            peer_map = {\n",
        "                'Technology': {\n",
        "                    'Large Cap': ['TCS.NS', 'INFY.NS', 'WIPRO.NS', 'HCLTECH.NS'],\n",
        "                    'Mid Cap': ['TECHM.NS', 'LTTS.NS', 'PERSISTENT.NS', 'COFORGE.NS'],\n",
        "                    'Small Cap': ['ZENSAR.NS', 'ECLERX.NS', 'MASTEK.NS']\n",
        "                },\n",
        "                'Financial Services': {\n",
        "                    'Large Cap': ['HDFCBANK.NS', 'ICICIBANK.NS', 'KOTAKBANK.NS', 'AXISBANK.NS'],\n",
        "                    'Mid Cap': ['IDFCFIRSTB.NS', 'FEDERALBNK.NS', 'INDUSINDBK.NS'],\n",
        "                    'Small Cap': ['SOUTHBANK.NS', 'UJJIVAN.NS', 'EQUITASBNK.NS']\n",
        "                },\n",
        "                'Healthcare': {\n",
        "                    'Large Cap': ['SUNPHARMA.NS', 'DRREDDY.NS', 'CIPLA.NS', 'DIVISLAB.NS'],\n",
        "                    'Mid Cap': ['TORNTPHARM.NS', 'ALKEM.NS', 'LUPIN.NS'],\n",
        "                    'Small Cap': ['CAPLIPOINT.NS', 'BLISS.NS', 'INDOCO.NS']\n",
        "                },\n",
        "                # Added Energy sector mapping\n",
        "                'Energy': {\n",
        "                    'Large Cap': ['ONGC.NS', 'NTPC.NS', 'POWERGRID.NS'], # Exclude RELIANCE.NS here, filter below\n",
        "                    'Mid Cap': ['GAIL.NS', 'IOC.NS', 'NHPC.NS'],\n",
        "                    'Small Cap': ['GUJGASLTD.NS', 'IGL.NS', 'MAHAPOWER.NS']\n",
        "                }\n",
        "            }\n",
        "\n",
        "            potential_peers = peer_map.get(sector, {}).get(cap_category, [])\n",
        "            # Ensure the current symbol is excluded from the peer list\n",
        "            filtered_peers = [p for p in potential_peers if isinstance(p, str) and p.upper() != symbol.upper()]\n",
        "\n",
        "            logger.info(f\"Identified {len(filtered_peers)} potential peer companies for {symbol} in {sector} ({cap_category} Cap). Fetching valuation data.\")\n",
        "\n",
        "            # Fetch valuation data for each filtered peer\n",
        "            for peer_symbol in filtered_peers:\n",
        "                 try:\n",
        "                      peer_ticker = yf.Ticker(peer_symbol)\n",
        "                      peer_info = peer_ticker.info\n",
        "\n",
        "                      if peer_info:\n",
        "                           peer_valuation = {\n",
        "                               'symbol': peer_symbol,\n",
        "                               'trailingPE': peer_info.get('trailingPE', np.nan),\n",
        "                               'priceToBook': peer_info.get('priceToBook', np.nan),\n",
        "                               'enterpriseValue': peer_info.get('enterpriseValue', np.nan), # Fetch for EV/EBITDA calculation\n",
        "                               'ebitda': peer_info.get('ebitda', np.nan) # Fetch for EV/EBITDA calculation\n",
        "                           }\n",
        "\n",
        "                           # Calculate EV/EBITDA for the peer\n",
        "                           ev = peer_valuation['enterpriseValue']\n",
        "                           ebitda = peer_valuation['ebitda']\n",
        "                           peer_valuation['evToEbitda'] = np.nan # Default to NaN\n",
        "                           if isinstance(ev, (int, float)) and not np.isnan(ev) and \\\n",
        "                              isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda != 0:\n",
        "                               peer_valuation['evToEbitda'] = ev / ebitda\n",
        "                           elif (isinstance(ev, (int, float)) and not np.isnan(ev)) and \\\n",
        "                                (isinstance(ebitda, (int, float)) and not np.isnan(ebitda) and ebitda == 0):\n",
        "                                logger.warning(f\"EBITDA is zero for peer {peer_symbol}. Cannot calculate EV/EBITDA.\")\n",
        "                           else:\n",
        "                                logger.warning(f\"Missing Enterprise Value ({ev}) or EBITDA ({ebitda}) for peer {peer_symbol}. Cannot calculate EV/EBITDA.\")\n",
        "\n",
        "\n",
        "                           peer_list_with_valuation.append(peer_valuation)\n",
        "                           logger.debug(f\"Fetched valuation data for peer {peer_symbol}: PE={peer_valuation['trailingPE']:.2f}, PB={peer_valuation['priceToBook']:.2f}, EV/EBITDA={peer_valuation['evToEbitda']:.2f}\")\n",
        "                      else:\n",
        "                           logger.warning(f\"Could not fetch info for peer {peer_symbol}. Skipping.\")\n",
        "                 except Exception as e:\n",
        "                      logger.warning(f\"Error fetching data for peer {peer_symbol}: {str(e)}. Skipping.\")\n",
        "\n",
        "            logger.info(f\"Successfully fetched valuation data for {len(peer_list_with_valuation)} peers.\")\n",
        "            return peer_list_with_valuation[:5] # Return top 5 peers with their valuation data\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting peer companies and valuation data for {symbol}: {str(e)}\")\n",
        "            return [] # Return empty list on error\n",
        "\n",
        "    def calculate_peer_average_valuation(self, peers_with_valuation: List[Dict]) -> Dict:\n",
        "        \"\"\"Calculate average valuation ratios (PE, PB, EV/EBITDA) for a list of peers.\"\"\"\n",
        "        logger.info(\"Calculating peer average valuation ratios.\")\n",
        "        total_pe = 0\n",
        "        total_pb = 0\n",
        "        total_ev_ebitda = 0\n",
        "        count_pe = 0\n",
        "        count_pb = 0\n",
        "        count_ev_ebitda = 0\n",
        "\n",
        "        if not isinstance(peers_with_valuation, list) or not peers_with_valuation:\n",
        "             logger.warning(\"No peer valuation data provided for calculating averages.\")\n",
        "             return {'avg_pe': np.nan, 'avg_pb': np.nan, 'avg_ev_ebitda': np.nan}\n",
        "\n",
        "\n",
        "        for peer_data in peers_with_valuation:\n",
        "             if isinstance(peer_data, dict):\n",
        "                 pe = peer_data.get('trailingPE', np.nan)\n",
        "                 pb = peer_data.get('priceToBook', np.nan)\n",
        "                 ev_ebitda = peer_data.get('evToEbitda', np.nan)\n",
        "\n",
        "                 if isinstance(pe, (int, float)) and not np.isnan(pe) and pe > 0:\n",
        "                     total_pe += pe\n",
        "                     count_pe += 1\n",
        "                 else:\n",
        "                      logger.debug(f\"Skipping invalid PE for peer: {peer_data.get('symbol', 'Unknown')}\")\n",
        "\n",
        "                 if isinstance(pb, (int, float)) and not np.isnan(pb) and pb > 0:\n",
        "                     total_pb += pb\n",
        "                     count_pb += 1\n",
        "                 else:\n",
        "                      logger.debug(f\"Skipping invalid PB for peer: {peer_data.get('symbol', 'Unknown')}\")\n",
        "\n",
        "\n",
        "                 if isinstance(ev_ebitda, (int, float)) and not np.isnan(ev_ebitda): # EV/EBITDA can be zero or negative in some cases, but >0 is typical\n",
        "                      total_ev_ebitda += ev_ebitda\n",
        "                      count_ev_ebitda += 1\n",
        "                 else:\n",
        "                      logger.debug(f\"Skipping invalid EV/EBITDA for peer: {peer_data.get('symbol', 'Unknown')}\")\n",
        "\n",
        "\n",
        "        avg_pe = total_pe / count_pe if count_pe > 0 else np.nan\n",
        "        avg_pb = total_pb / count_pb if count_pb > 0 else np.nan\n",
        "        avg_ev_ebitda = total_ev_ebitda / count_ev_ebitda if count_ev_ebitda > 0 else np.nan\n",
        "\n",
        "        logger.info(f\"Calculated peer averages: PE={avg_pe:.2f}, PB={avg_pb:.2f}, EV/EBITDA={avg_ev_ebitda:.2f}\")\n",
        "\n",
        "        return {\n",
        "            'avg_pe': avg_pe,\n",
        "            'avg_pb': avg_pb,\n",
        "            'avg_ev_ebitda': avg_ev_ebitda\n",
        "        }\n",
        "\n",
        "\n",
        "    def compare_valuation_to_peers(self, stock_valuation: Dict, peer_average_valuation: Dict) -> Dict:\n",
        "        \"\"\"Compare stock's valuation ratios to peer averages and provide assessment.\"\"\"\n",
        "        logger.info(\"Comparing stock valuation to peer averages.\")\n",
        "        comparison_results = {}\n",
        "        valuation_score_adjustment = 0 # Adjustment to the total score\n",
        "\n",
        "        stock_pe = stock_valuation.get('trailingPE', np.nan)\n",
        "        stock_pb = stock_valuation.get('priceToBook', np.nan)\n",
        "        stock_ev_ebitda = stock_valuation.get('evToEbitda', np.nan)\n",
        "\n",
        "        avg_pe = peer_average_valuation.get('avg_pe', np.nan)\n",
        "        avg_pb = peer_average_valuation.get('avg_pb', np.nan)\n",
        "        avg_ev_ebitda = peer_average_valuation.get('avg_ev_ebitda', np.nan)\n",
        "\n",
        "        logger.debug(f\"Stock Valuation: PE={stock_pe:.2f}, PB={stock_pb:.2f}, EV/EBITDA={stock_ev_ebitda:.2f}\")\n",
        "        logger.debug(f\"Peer Average Valuation: PE={avg_pe:.2f}, PB={avg_pb:.2f}, EV/EBITDA={avg_ev_ebitda:.2f}\")\n",
        "\n",
        "\n",
        "        # PE Ratio comparison (Lower is generally better relative to peers)\n",
        "        comparison_results['pe_comparison'] = 'N/A'\n",
        "        if not pd.isna(stock_pe) and not pd.isna(avg_pe) and avg_pe > 0:\n",
        "             if stock_pe < avg_pe * 0.8: # More than 20% below average\n",
        "                  comparison_results['pe_comparison'] = 'Significantly Undervalued (PE)'\n",
        "                  valuation_score_adjustment += 10\n",
        "             elif stock_pe < avg_pe * 0.95: # More than 5% below average\n",
        "                  comparison_results['pe_comparison'] = 'Undervalued (PE)'\n",
        "                  valuation_score_adjustment += 5\n",
        "             elif stock_pe > avg_pe * 1.2: # More than 20% above average\n",
        "                  comparison_results['pe_comparison'] = 'Significantly Overvalued (PE)'\n",
        "                  valuation_score_adjustment -= 10\n",
        "             elif stock_pe > avg_pe * 1.05: # More than 5% above average\n",
        "                  comparison_results['pe_comparison'] = 'Overvalued (PE)'\n",
        "                  valuation_score_adjustment -= 5\n",
        "             else:\n",
        "                  comparison_results['pe_comparison'] = 'Fairly Valued (PE)'\n",
        "        elif not pd.isna(stock_pe) and pd.isna(avg_pe):\n",
        "             comparison_results['pe_comparison'] = 'PE available, Peer Avg PE N/A'\n",
        "             logger.warning(\"Peer Average PE is NaN. Cannot compare stock PE to peers.\")\n",
        "        elif pd.isna(stock_pe) and not pd.isna(avg_pe):\n",
        "             comparison_results['pe_comparison'] = 'Stock PE N/A'\n",
        "             logger.warning(\"Stock PE is NaN. Cannot compare to peer Average PE.\")\n",
        "        else:\n",
        "             logger.warning(\"Stock PE and Peer Average PE are NaN. Cannot compare.\")\n",
        "\n",
        "\n",
        "        # PB Ratio comparison (Lower is generally better relative to peers)\n",
        "        comparison_results['pb_comparison'] = 'N/A'\n",
        "        if not pd.isna(stock_pb) and not pd.isna(avg_pb) and avg_pb > 0:\n",
        "             if stock_pb < avg_pb * 0.8: # More than 20% below average\n",
        "                  comparison_results['pb_comparison'] = 'Significantly Undervalued (PB)'\n",
        "                  valuation_score_adjustment += 8\n",
        "             elif stock_pb < avg_pb * 0.95: # More than 5% below average\n",
        "                  comparison_results['pb_comparison'] = 'Undervalued (PB)'\n",
        "                  valuation_score_adjustment += 4\n",
        "             elif stock_pb > avg_pb * 1.2: # More than 20% above average\n",
        "                  comparison_results['pb_comparison'] = 'Significantly Overvalued (PB)'\n",
        "                  valuation_score_adjustment -= 8\n",
        "             elif stock_pb > avg_pb * 1.05: # More than 5% above average\n",
        "                  comparison_results['pb_comparison'] = 'Overvalued (PB)'\n",
        "                  valuation_score_adjustment -= 4\n",
        "             else:\n",
        "                  comparison_results['pb_comparison'] = 'Fairly Valued (PB)'\n",
        "        elif not pd.isna(stock_pb) and pd.isna(avg_pb):\n",
        "             comparison_results['pb_comparison'] = 'PB available, Peer Avg PB N/A'\n",
        "             logger.warning(\"Peer Average PB is NaN. Cannot compare stock PB to peers.\")\n",
        "        elif pd.isna(stock_pb) and not pd.isna(avg_pb):\n",
        "             comparison_results['pb_comparison'] = 'Stock PB N/A'\n",
        "             logger.warning(\"Stock PB is NaN. Cannot compare to peer Average PB.\")\n",
        "        else:\n",
        "             logger.warning(\"Stock PB and Peer Average PB are NaN. Cannot compare.\")\n",
        "\n",
        "\n",
        "        # EV/EBITDA comparison (Lower is generally better relative to peers)\n",
        "        comparison_results['ev_ebitda_comparison'] = 'N/A'\n",
        "        if not pd.isna(stock_ev_ebitda) and not pd.isna(avg_ev_ebitda) and avg_ev_ebitda != 0:\n",
        "             if stock_ev_ebitda < avg_ev_ebitda * 0.8: # More than 20% below average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Significantly Undervalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment += 12\n",
        "             elif stock_ev_ebitda < avg_ev_ebitda * 0.95: # More than 5% below average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Undervalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment += 6\n",
        "             elif stock_ev_ebitda > avg_ev_ebitda * 1.2: # More than 20% above average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Significantly Overvalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment -= 12\n",
        "             elif stock_ev_ebitda > avg_ev_ebitda * 1.05: # More than 5% above average\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Overvalued (EV/EBITDA)'\n",
        "                  valuation_score_adjustment -= 6\n",
        "             else:\n",
        "                  comparison_results['ev_ebitda_comparison'] = 'Fairly Valued (EV/EBITDA)'\n",
        "        elif not pd.isna(stock_ev_ebitda) and not pd.isna(avg_ev_ebitda) and avg_ev_ebitda == 0:\n",
        "             comparison_results['ev_ebitda_comparison'] = 'Peer Avg EV/EBITDA is 0'\n",
        "             logger.warning(\"Peer Average EV/EBITDA is zero. Cannot compare.\")\n",
        "        elif not pd.isna(stock_ev_ebitda) and pd.isna(avg_ev_ebitda):\n",
        "             comparison_results['ev_ebitda_comparison'] = 'EV/EBITDA available, Peer Avg EV/EBITDA N/A'\n",
        "             logger.warning(\"Peer Average EV/EBITDA is NaN. Cannot compare stock EV/EBITDA to peers.\")\n",
        "        elif pd.isna(stock_ev_ebitda) and not pd.isna(avg_ev_ebitda):\n",
        "             comparison_results['ev_ebitda_comparison'] = 'Stock EV/EBITDA N/A'\n",
        "             logger.warning(\"Stock EV/EBITDA is NaN. Cannot compare to peer Average EV/EBITDA.\")\n",
        "        else:\n",
        "             logger.warning(\"Stock EV/EBITDA and Peer Average EV/EBITDA are NaN. Cannot compare.\")\n",
        "\n",
        "\n",
        "        comparison_results['valuation_score_adjustment'] = valuation_score_adjustment\n",
        "\n",
        "        logger.info(f\"Valuation comparison results: {comparison_results}\")\n",
        "        return comparison_results\n",
        "\n",
        "\n",
        "    def calculate_peer_relative_performance(self, symbol, peers, days=30):\n",
        "        \"\"\"Compare stock performance with peers, handling data issues robustly\"\"\"\n",
        "        results = {\n",
        "            'stock_return': np.nan,\n",
        "            'avg_peer_return': np.nan,\n",
        "            'relative_performance': np.nan,\n",
        "            'outperformance': False,\n",
        "            'days': days\n",
        "        }\n",
        "\n",
        "        if not isinstance(peers, list) or not peers:\n",
        "             logger.warning(\"No valid peer list provided for performance comparison.\")\n",
        "             # Return the default results with NaNs if no peers\n",
        "             return results\n",
        "\n",
        "        # --- Removed the temporary skip here ---\n",
        "\n",
        "        try:\n",
        "            main_ticker = yf.Ticker(symbol)\n",
        "            main_hist = main_ticker.history(period=f\"{days}d\")\n",
        "            main_return = np.nan\n",
        "\n",
        "            if not main_hist.empty and len(main_hist) > 1:\n",
        "                try:\n",
        "                    start_price = main_hist['Close'].iloc[0]\n",
        "                    end_price = main_hist['Close'].iloc[-1]\n",
        "                    if not pd.isna(start_price) and not pd.isna(end_price) and start_price > 0:\n",
        "                         main_return = ((end_price / start_price) - 1) * 100\n",
        "                    else:\n",
        "                         logger.warning(f\"Invalid start ({start_price}) or end price ({end_price}) for main stock ({symbol}) return calculation.\")\n",
        "                except Exception as ret_e:\n",
        "                     logger.warning(f\"Could not calculate main stock ({symbol}) return: {ret_e}. Setting to NaN.\")\n",
        "                     main_return = np.nan\n",
        "            else:\n",
        "                logger.warning(f\"Insufficient historical data for main stock ({symbol}) for return calculation.\")\n",
        "\n",
        "            results['stock_return'] = main_return\n",
        "\n",
        "        except Exception as main_stock_e:\n",
        "            logger.error(f\"Error fetching data or calculating return for main stock ({symbol}): {main_stock_e}. Main stock return set to NaN.\")\n",
        "            results['stock_return'] = np.nan\n",
        "\n",
        "        # Calculate peer returns\n",
        "        peer_returns = []\n",
        "        # The peers list now contains dictionaries with valuation data.\n",
        "        # We need to extract just the symbols for performance calculation.\n",
        "        peer_symbols_for_perf = [p['symbol'] for p in peers if isinstance(p, dict) and 'symbol' in p]\n",
        "\n",
        "        for peer_symbol in peer_symbols_for_perf:\n",
        "             try:\n",
        "                 peer_ticker = yf.Ticker(peer_symbol)\n",
        "                 peer_hist = peer_ticker.history(period=f\"{days}d\")\n",
        "                 if not peer_hist.empty and len(peer_hist) > 1:\n",
        "                     try:\n",
        "                          peer_start_price = peer_hist['Close'].iloc[0]\n",
        "                          peer_end_price = peer_hist['Close'].iloc[-1]\n",
        "                          if not pd.isna(peer_start_price) and not pd.isna(peer_end_price) and peer_start_price > 0:\n",
        "                             peer_return = ((peer_end_price / peer_start_price) - 1) * 100\n",
        "                             peer_returns.append(peer_return)\n",
        "                          else:\n",
        "                             logger.warning(f\"Invalid start or end price for peer ({peer_symbol}) return calculation.\")\n",
        "                     except Exception as peer_ret_e:\n",
        "                         logger.warning(f\"Could not calculate return for peer ({peer_symbol}): {peer_ret_e}. Skipping.\")\n",
        "                 else:\n",
        "                     logger.warning(f\"Insufficient historical data for peer ({peer_symbol}) for return calculation. Skipping.\")\n",
        "             except Exception as peer_e:\n",
        "                 logger.warning(f\"Error fetching data for peer ({peer_symbol}): {peer_e}. Skipping.\")\n",
        "\n",
        "        # Add logging for peer returns before filtering/average calculation\n",
        "        logger.info(f\"Peer returns collected before average calculation attempt: {peer_returns}\")\n",
        "\n",
        "        # Calculate average peer return and relative performance\n",
        "        if peer_returns:\n",
        "             # Ensure peer_returns list contains only valid numbers before calculating mean\n",
        "             valid_peer_returns = [ret for ret in peer_returns if isinstance(ret, (int, float)) and not pd.isna(ret)]\n",
        "             if valid_peer_returns:\n",
        "                 avg_peer_return = np.mean(valid_peer_returns)\n",
        "                 results['avg_peer_return'] = avg_peer_return\n",
        "\n",
        "                 # Calculate relative performance only if main stock return is valid\n",
        "                 if not pd.isna(main_return):\n",
        "                      results['relative_performance'] = main_return - avg_peer_return\n",
        "\n",
        "                      # Determine outperformance\n",
        "                      if main_return > avg_peer_return:\n",
        "                          results['outperformance'] = True\n",
        "                 else:\n",
        "                      logger.warning(\"Main stock return is NaN, cannot calculate relative performance or outperformance.\")\n",
        "             else:\n",
        "                 logger.warning(\"No valid peer returns available after filtering. Cannot calculate average peer return or relative performance.\")\n",
        "        else:\n",
        "             logger.warning(\"No peer returns calculated. Cannot calculate average peer return or relative performance.\")\n",
        "\n",
        "\n",
        "        logger.info(f\"Peer performance results for {symbol}: {results}\")\n",
        "        return results\n",
        "\n",
        "\n",
        "    def get_index_membership(self, symbol):\n",
        "        \"\"\"Check index membership for the stock\"\"\"\n",
        "        symbol_upper = symbol.upper() if isinstance(symbol, str) else ''\n",
        "\n",
        "        index_constituents = {\n",
        "            'NIFTY50': ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS'],\n",
        "            'NIFTY_NEXT50': ['VEDL.NS', 'PNB.NS', 'INDIGO.NS', 'BANDHANBNK.NS'],\n",
        "            'NIFTY_MIDCAP150': ['PERSISTENT.NS', 'COFORGE.NS', 'LTTS.NS']\n",
        "        }\n",
        "\n",
        "        membership = []\n",
        "        for index, constituents in index_constituents.items():\n",
        "            if symbol_upper and any(isinstance(c, str) and c.upper() == symbol_upper for c in constituents):\n",
        "                membership.append(index)\n",
        "\n",
        "        if membership:\n",
        "             logger.info(f\"Stock {symbol} is a member of indices: {', '.join(membership)}\")\n",
        "        else:\n",
        "             logger.info(f\"Stock {symbol} is not found in the hardcoded index constituents.\")\n",
        "\n",
        "        return membership\n",
        "\n",
        "    def calculate_enhanced_technical_score(self, indicators, circuit_risk):\n",
        "        \"\"\"Calculate enhanced technical analysis score with NaN handling and circuit risk\"\"\"\n",
        "        base_score = 0\n",
        "        indicators_calculated = 0\n",
        "        possible_indicator_points = 50\n",
        "\n",
        "        num_key_indicators = 5\n",
        "        indicator_point_contribution = possible_indicator_points / num_key_indicators\n",
        "\n",
        "        rsi = indicators.get('RSI', np.nan)\n",
        "        if not pd.isna(rsi):\n",
        "             indicators_calculated += 1\n",
        "             if 40 <= rsi <= 60:\n",
        "                 base_score += indicator_point_contribution * 0.7\n",
        "             elif rsi < 30: # More points for extreme oversold\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             elif 30 <= rsi < 40: # Approaching oversold\n",
        "                 base_score += indicator_point_contribution * 0.9\n",
        "             elif 60 < rsi <= 70: # Approaching overbought\n",
        "                 base_score += indicator_point_contribution * 0.6\n",
        "             else: # Overbought (>70)\n",
        "                 base_score += indicator_point_contribution * 0.4\n",
        "        else:\n",
        "             logger.warning(\"RSI not calculated or is NaN.\")\n",
        "\n",
        "        macd = indicators.get('MACD', np.nan)\n",
        "        macd_signal = indicators.get('MACD_signal', np.nan)\n",
        "\n",
        "        if not pd.isna(macd) and not pd.isna(macd_signal):\n",
        "             indicators_calculated += 1\n",
        "             if macd > macd_signal:\n",
        "                 if macd > 0: # Bullish crossover above zero line\n",
        "                      base_score += indicator_point_contribution * 1.0\n",
        "                 else: # Bullish crossover below zero line\n",
        "                      base_score += indicator_point_contribution * 0.8\n",
        "             else:\n",
        "                 if macd < 0: # Bearish crossover below zero line\n",
        "                      base_score += indicator_point_contribution * 0.2\n",
        "                 else: # Bearish crossover above zero line\n",
        "                      base_score += indicator_point_contribution * 0.4\n",
        "        else:\n",
        "             logger.warning(\"MACD or MACD signal is NaN for technical scoring.\")\n",
        "\n",
        "        sma_20 = indicators.get('SMA_20', np.nan)\n",
        "        sma_50 = indicators.get('SMA_50', np.nan)\n",
        "        sma_200 = indicators.get('SMA_200', np.nan) # Include 200-day SMA if available\n",
        "\n",
        "        ma_score_component = 0\n",
        "        ma_indicators_counted = 0\n",
        "\n",
        "        if not pd.isna(sma_20) and not pd.isna(sma_50):\n",
        "             ma_indicators_counted += 1\n",
        "             if sma_20 > sma_50:\n",
        "                  ma_score_component += 0.5 # 20 > 50 crossover is bullish\n",
        "             else:\n",
        "                  ma_score_component += 0.2 # 20 <= 50 crossover is bearish/neutral\n",
        "\n",
        "        if not pd.isna(sma_50) and not pd.isna(sma_200):\n",
        "             ma_indicators_counted += 1\n",
        "             if sma_50 > sma_200:\n",
        "                  ma_score_component += 0.5 # 50 > 200 crossover is bullish\n",
        "             else:\n",
        "                  ma_score_component += 0.2 # 50 <= 200 crossover is bearish/neutral\n",
        "\n",
        "        current_price = indicators.get('current_price', np.nan)\n",
        "        if not pd.isna(current_price):\n",
        "             if not pd.isna(sma_20) and current_price > sma_20:\n",
        "                  ma_score_component += 0.3 # Price above 20-day SMA is bullish\n",
        "             elif not pd.isna(sma_20):\n",
        "                  ma_score_component += 0.1 # Price below 20-day SMA is bearish/neutral\n",
        "\n",
        "             if not pd.isna(sma_50) and current_price > sma_50:\n",
        "                  ma_score_component += 0.4 # Price above 50-day SMA is more bullish\n",
        "             elif not pd.isna(sma_50):\n",
        "                  ma_score_component += 0.15 # Price below 50-day SMA\n",
        "\n",
        "             if not pd.isna(sma_200) and current_price > sma_200:\n",
        "                  ma_score_component += 0.6 # Price above 200-day SMA is significant bullish signal\n",
        "             elif not pd.isna(sma_200):\n",
        "                  ma_score_component += 0.1 # Price below 200-day SMA is significant bearish signal\n",
        "\n",
        "\n",
        "        if ma_indicators_counted > 0 or (not pd.isna(current_price) and (not pd.isna(sma_20) or not pd.isna(sma_50) or not pd.isna(sma_200))):\n",
        "             indicators_calculated += 1 # Count MA section if any valid MA comparison/position is made\n",
        "             # Normalize MA score component to contribute to the total score\n",
        "             # Max possible ma_score_component (0.5 + 0.5 + 0.3 + 0.4 + 0.6) = 2.3\n",
        "             # Let's scale this to contribute up to indicator_point_contribution\n",
        "             max_ma_component = 2.3\n",
        "             base_score += (ma_score_component / max_ma_component) * indicator_point_contribution if max_ma_component > 0 else 0\n",
        "        else:\n",
        "             logger.warning(\"Insufficient data for Moving Averages analysis.\")\n",
        "\n",
        "\n",
        "        bb_upper = indicators.get('BB_upper', np.nan)\n",
        "        bb_lower = indicators.get('BB_lower', np.nan)\n",
        "        bb_middle = indicators.get('BB_middle', np.nan)\n",
        "\n",
        "        if not pd.isna(current_price) and not pd.isna(bb_upper) and not pd.isna(bb_lower) and not pd.isna(bb_middle):\n",
        "            indicators_calculated += 1\n",
        "            if current_price < bb_lower:\n",
        "                base_score += indicator_point_contribution * 1.0 # Price below lower band (potential buy signal)\n",
        "            elif bb_lower <= current_price < bb_middle:\n",
        "                base_score += indicator_point_contribution * 0.8 # Between lower and middle band\n",
        "            elif bb_middle <= current_price < bb_upper:\n",
        "                base_score += indicator_point_contribution * 0.6 # Between middle and upper band\n",
        "            else: # Price above upper band\n",
        "                base_score += indicator_point_contribution * 0.4 # Potential sell signal\n",
        "        else:\n",
        "             logger.warning(\"Bollinger Bands or current price is NaN for technical scoring.\")\n",
        "\n",
        "        volume_ratio = indicators.get('Volume_ratio', np.nan)\n",
        "        if not pd.isna(volume_ratio):\n",
        "             indicators_calculated += 1\n",
        "             if volume_ratio > 2.0: # Very high volume\n",
        "                 base_score += indicator_point_contribution * 1.0\n",
        "             elif volume_ratio > 1.2: # High volume\n",
        "                 base_score += indicator_point_contribution * 0.8\n",
        "             elif 0.8 <= volume_ratio <= 1.2: # Normal volume\n",
        "                 base_score += indicator_point_contribution * 0.5\n",
        "             else: # Low volume\n",
        "                 base_score += indicator_point_contribution * 0.3\n",
        "        else:\n",
        "             logger.warning(\"Volume ratio is NaN for technical scoring.\")\n",
        "\n",
        "\n",
        "        achieved_score_from_indicators = base_score\n",
        "\n",
        "        # Normalize the base score based on how many indicators were successfully calculated\n",
        "        if indicators_calculated > 0:\n",
        "            # Assuming each of the num_key_indicators contributes equally if available\n",
        "            # This approach gives points for each indicator that could be calculated and scored\n",
        "            # Max points if all indicators could be scored is num_key_indicators * indicator_point_contribution\n",
        "            # But our scoring within each indicator gives variable points (e.g., 0.4 to 1.0)\n",
        "            # A simpler approach is to just sum up the points from successfully scored indicators\n",
        "            # Let's cap the sum at the max possible points from indicators (50)\n",
        "            final_base_score = min(achieved_score_from_indicators, possible_indicator_points)\n",
        "\n",
        "            if indicators_calculated < num_key_indicators:\n",
        "                 logger.warning(f\"Only {indicators_calculated}/{num_key_indicators} key technical indicators could be fully calculated/scored. Final base technical score is based on available data.\")\n",
        "\n",
        "        else:\n",
        "             logger.warning(\"No key technical indicators calculated. Base technical score is 0.\")\n",
        "             final_base_score = 0\n",
        "\n",
        "\n",
        "        circuit_risk_adj = circuit_risk if isinstance(circuit_risk, (int, float)) and not pd.isna(circuit_risk) else 0\n",
        "\n",
        "        final_score = final_base_score + circuit_risk_adj\n",
        "\n",
        "        return max(0, min(final_score, 50))\n",
        "\n",
        "\n",
        "    def calculate_value_at_risk(self, price_data: pd.DataFrame, confidence_level: float = 0.95, horizon_days: int = 1) -> Dict: # Modified return type hint\n",
        "        \"\"\"\n",
        "        Calculates Value at Risk (VaR) using the historical method.\n",
        "\n",
        "        Args:\n",
        "            price_data: DataFrame with historical price data (must contain 'Close').\n",
        "            confidence_level: The confidence level for VaR (e.g., 0.95 for 95% VaR).\n",
        "            horizon_days: The time horizon for VaR (in trading days).\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing the calculated VaR as a percentage loss,\n",
        "            confidence level, and horizon days, or a dictionary with NaN/None values\n",
        "            if calculation fails.\n",
        "        \"\"\"\n",
        "        logger.info(f\"Calculating {confidence_level*100:.0f}% VaR for {horizon_days}-day horizon.\")\n",
        "        results = {'var_percentage_loss': np.nan, 'confidence_level': confidence_level, 'horizon_days': horizon_days}\n",
        "\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or 'Close' not in price_data.columns:\n",
        "            logger.warning(\"Insufficient or invalid price data for VaR calculation.\")\n",
        "            return results # Return dictionary with NaN/None\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Calculate daily returns\n",
        "            returns = price_data['Close'].pct_change().dropna()\n",
        "\n",
        "            if returns.empty:\n",
        "                logger.warning(\"No valid returns data for VaR calculation.\")\n",
        "                return results # Return dictionary with NaN/None\n",
        "\n",
        "            # Historical VaR: Find the percentile of returns corresponding to the confidence level\n",
        "            # For downside risk, we look at the lower tail of returns.\n",
        "            # A 95% confidence level for VaR means we're interested in the 5th percentile of losses.\n",
        "            # The percentile rank for a confidence level C is 1 - C.\n",
        "            percentile_rank = (1 - confidence_level) * 100\n",
        "            logger.debug(f\"Calculating {percentile_rank:.2f} percentile of historical returns.\")\n",
        "\n",
        "            # Calculate VaR at the specified percentile\n",
        "            # The result is a negative percentage loss\n",
        "            var_percentage = np.percentile(returns, percentile_rank)\n",
        "\n",
        "            # VaR is typically expressed as a positive loss\n",
        "            var_percentage_loss = abs(var_percentage)\n",
        "\n",
        "            # Scale VaR for the desired horizon (assuming returns are independently and identically distributed)\n",
        "            # This is a simplification; more advanced methods exist for scaling VaR.\n",
        "            # Scaling by sqrt(horizon) is common but assumes specific return properties.\n",
        "            scaled_var_percentage_loss = var_percentage_loss * np.sqrt(horizon_days)\n",
        "\n",
        "            results['var_percentage_loss'] = scaled_var_percentage_loss * 100 # Convert to percentage for display/scoring\n",
        "            logger.info(f\"Calculated {confidence_level*100:.0f}% VaR ({horizon_days}-day horizon): {results['var_percentage_loss']:.2f}%\")\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating VaR: {str(e)}. Returning default results.\")\n",
        "            return results # Return dictionary with NaN/None on error\n",
        "\n",
        "\n",
        "    def calculate_enhanced_dividend_score(self, symbol: str, price_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"\n",
        "        Calculates an enhanced dividend score considering historical payout trends and stability.\n",
        "\n",
        "        Args:\n",
        "            symbol: Stock symbol (e.g., 'RELIANCE.NS').\n",
        "            price_data: DataFrame with historical price data (must contain 'Close').\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing the enhanced dividend score and potentially other\n",
        "            relevant dividend metrics (e.g., payout history, yield trend).\n",
        "        \"\"\"\n",
        "        logger.info(f\"Calculating enhanced dividend score for {symbol}.\")\n",
        "        enhanced_dividend_score = 0 # Max score for dividend analysis out of 15 (example)\n",
        "        dividend_metrics = {\n",
        "            'trailingAnnualDividendYield': np.nan,\n",
        "            'dividendPayoutRatio': np.nan,\n",
        "            'payout_history': {},\n",
        "            'yield_trend': 'N/A',\n",
        "            'score': enhanced_dividend_score\n",
        "        }\n",
        "\n",
        "        if not isinstance(price_data, pd.DataFrame) or price_data.empty or 'Close' not in price_data.columns:\n",
        "             logger.warning(\"Insufficient price data for enhanced dividend analysis.\")\n",
        "             return dividend_metrics # Return default metrics if price data is missing\n",
        "\n",
        "\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "            dividends = ticker.dividends.sort_index() # Get historical dividend payouts\n",
        "\n",
        "            # Get current yield and payout ratio from info\n",
        "            current_yield = info.get('trailingAnnualDividendYield', np.nan) # yfinance provides this as a ratio\n",
        "            if isinstance(current_yield, (int, float)) and not pd.isna(current_yield):\n",
        "                 dividend_metrics['trailingAnnualDividendYield'] = current_yield * 100 # Convert to percentage\n",
        "            else:\n",
        "                 dividend_metrics['trailingAnnualDividendYield'] = np.nan\n",
        "\n",
        "\n",
        "            payout_ratio = info.get('payoutRatio', np.nan) # yfinance provides this as a ratio\n",
        "            if isinstance(payout_ratio, (int, float)) and not pd.isna(payout_ratio):\n",
        "                 dividend_metrics['dividendPayoutRatio'] = payout_ratio # Keep as ratio\n",
        "            else:\n",
        "                 dividend_metrics['dividendPayoutRatio'] = np.nan\n",
        "\n",
        "\n",
        "            if not dividends.empty:\n",
        "                 # Analyze payout history and stability\n",
        "                 dividend_metrics['payout_history'] = dividends.to_dict() # Store the raw history\n",
        "\n",
        "                 # Check for consistent payouts (e.g., increasing or stable over last 5 years)\n",
        "                 five_years_ago = datetime.now() - timedelta(days=5*365)\n",
        "                 recent_dividends = dividends[dividends.index >= five_years_ago]\n",
        "\n",
        "                 if len(recent_dividends) > 3: # Need at least a few recent payouts\n",
        "                      # Check for increasing trend\n",
        "                      is_increasing = all(recent_dividends.iloc[i] >= recent_dividends.iloc[i-1] for i in range(1, len(recent_dividends)))\n",
        "\n",
        "                      if is_increasing:\n",
        "                           enhanced_dividend_score += 10 # Significant points for increasing dividends\n",
        "                           dividend_metrics['yield_trend'] = 'Increasing'\n",
        "                           logger.debug(\"Dividend trend: Increasing. +10 pts.\")\n",
        "                      elif len(recent_dividends) > 0 and recent_dividends.min() > 0:\n",
        "                           enhanced_dividend_score += 5 # Some points for stable (non-zero) dividends\n",
        "                           dividend_metrics['yield_trend'] = 'Stable'\n",
        "                           logger.debug(\"Dividend trend: Stable. +5 pts.\")\n",
        "                      else:\n",
        "                           dividend_metrics['yield_trend'] = 'Irregular/Decreasing'\n",
        "                           logger.debug(\"Dividend trend: Irregular/Decreasing.\")\n",
        "                 elif len(recent_dividends) > 0 and recent_dividends.min() > 0:\n",
        "                      enhanced_dividend_score += 3 # Some points for recent payouts, even if history is short\n",
        "                      dividend_metrics['yield_trend'] = 'Recent Payouts'\n",
        "                      logger.debug(\"Dividend trend: Recent Payouts. +3 pts.\")\n",
        "                 else:\n",
        "                      dividend_metrics['yield_trend'] = 'No Recent Payouts'\n",
        "                      logger.debug(\"Dividend trend: No Recent Payouts.\")\n",
        "\n",
        "\n",
        "                 # Score based on current yield (Similar to basic analysis but potentially more weight)\n",
        "                 if not pd.isna(dividend_metrics['trailingAnnualDividendYield']):\n",
        "                      yield_percentage = dividend_metrics['trailingAnnualDividendYield']\n",
        "                      if yield_percentage > 3: # > 3%\n",
        "                           enhanced_dividend_score += 5\n",
        "                           logger.debug(f\"Current Yield ({yield_percentage:.2f}%) > 3%. +5 pts.\")\n",
        "                      elif yield_percentage > 1: # > 1%\n",
        "                           enhanced_dividend_score += 3\n",
        "                           logger.debug(f\"Current Yield ({yield_percentage:.2f}%) > 1%. +3 pts.\")\n",
        "                      else:\n",
        "                           enhanced_dividend_score += 1 # Small point for non-zero yield\n",
        "                           logger.debug(f\"Current Yield ({yield_percentage:.2f}) <= 1%. +1 pt.\")\n",
        "                 else:\n",
        "                      logger.warning(\"Current dividend yield is NaN.\")\n",
        "\n",
        "                 # Consider Payout Ratio (Lower is generally better, indicates sustainability)\n",
        "                 if not pd.isna(dividend_metrics['dividendPayoutRatio']):\n",
        "                      payout_ratio_value = dividend_metrics['dividendPayoutRatio']\n",
        "                      if payout_ratio_value < 0.5: # Payout ratio < 50%\n",
        "                           enhanced_dividend_score += 5\n",
        "                           logger.debug(f\"Payout Ratio ({payout_ratio_value:.2f}) < 0.5. +5 pts.\")\n",
        "                      elif payout_ratio_value < 0.8: # Payout ratio < 80%\n",
        "                           enhanced_dividend_score += 3\n",
        "                           logger.debug(f\"Payout Ratio ({payout_ratio_value:.2f}) < 0.8. +3 pts.\")\n",
        "                      elif payout_ratio_value > 1.0: # Payout ratio > 100% (unsustainable)\n",
        "                           enhanced_dividend_score -= 5 # Penalty for unsustainable payout\n",
        "                           logger.debug(f\"Payout Ratio ({payout_ratio_value:.2f}) > 1.0. -5 pts.\")\n",
        "                      else:\n",
        "                           enhanced_dividend_score += 1 # Small point for payout ratio 0.8-1.0\n",
        "                           logger.debug(f\"Payout Ratio ({payout_ratio_value:.2f}) 0.8-1.0. +1 pt.\")\n",
        "\n",
        "                 else:\n",
        "                      logger.warning(\"Dividend payout ratio is NaN.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                 logger.warning(\"No historical dividend data found.\")\n",
        "\n",
        "            # Cap the score at a reasonable maximum for this component (e.g., 20 points out of 235 total)\n",
        "            # Let's allocate up to 20 points for enhanced dividend analysis\n",
        "            dividend_metrics['score'] = min(enhanced_dividend_score, 20)\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error calculating enhanced dividend score for {symbol}: {str(e)}. Returning default metrics.\")\n",
        "            # Ensure the score is set to 0 on error\n",
        "            dividend_metrics['score'] = 0\n",
        "            return dividend_metrics # Return dictionary with NaN/None on error\n",
        "\n",
        "\n",
        "        logger.info(f\"Enhanced dividend score calculated: {dividend_metrics['score']}\")\n",
        "        return dividend_metrics\n",
        "\n",
        "    def assess_global_macro_impact(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Assesses global macro impacts and returns an adjustment to the score.\n",
        "        NOTE: This is a simplified placeholder. In a real application, this would\n",
        "        involve fetching and analyzing real global economic data (e.g., GDP growth,\n",
        "        inflation, interest rates, geopolitical events).\n",
        "        \"\"\"\n",
        "        logger.info(\"Assessing global macro impact (placeholder).\")\n",
        "        macro_adjustment = 0\n",
        "        macro_sentiment = self.global_macro_sentiment # Get the current simulated sentiment\n",
        "\n",
        "        if macro_sentiment == 'positive':\n",
        "            macro_adjustment = 10 # Positive macro environment adds points\n",
        "            logger.debug(\"Global macro sentiment: Positive. +10 pts.\")\n",
        "        elif macro_sentiment == 'negative':\n",
        "            macro_adjustment = -10 # Negative macro environment deducts points\n",
        "            logger.debug(\"Global macro sentiment: Negative. -10 pts.\")\n",
        "        else: # 'neutral'\n",
        "            macro_adjustment = 0 # Neutral macro environment has no impact\n",
        "            logger.debug(\"Global macro sentiment: Neutral. 0 pts.\")\n",
        "\n",
        "        macro_results = {\n",
        "            'sentiment': macro_sentiment,\n",
        "            'adjustment': macro_adjustment\n",
        "        }\n",
        "        logger.info(f\"Global macro impact assessment: {macro_results}\")\n",
        "        return macro_results\n",
        "\n",
        "\n",
        "    def fetch_news(self, symbol: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Fetches recent news headlines for the given stock symbol.\n",
        "        NOTE: This is a placeholder. In a real application, you would integrate\n",
        "        with a News API (like News API, Alpha Vantage, etc.) here.\n",
        "        \"\"\"\n",
        "        print(f\"Fetching news for {symbol} (placeholder)...\")\n",
        "        symbol_str = str(symbol) if symbol is not None else \"Unknown Stock\"\n",
        "        return [\n",
        "            f\"{symbol_str} stock price rises on positive market sentiment\",\n",
        "            f\"{symbol_str} announces strong quarterly results, beating estimates\",\n",
        "            f\"Experts bullish on {symbol_str}'s future outlook\",\n",
        "            f\"I am a non-numeric entry that might cause an error\",\n",
        "            f\"{symbol_str} faces regulatory challenges in key market\",\n",
        "            f\"Competitor's new product launch impacts {symbol_str}'s market share\",\n",
        "            f\"Global market trends positively impacting {symbol_str}\",\n",
        "            f\"{symbol_str} management provides optimistic guidance\",\n",
        "            f\"Increased foreign investment flows into {symbol_str}\",\n",
        "            f\"Regulatory approval received for {symbol_str}'s new product\",\n",
        "            f\"Production issues reported for {symbol_str}\",\n",
        "            f\"Increased competition puts pressure on {symbol_str}'s margins\",\n",
        "            f\"Analyst downgrades rating for {symbol_str}\",\n",
        "            f\"Supply chain disruptions affect {symbol_str}'s operations\",\n",
        "            f\"Geopolitical tensions create uncertainty for {symbol_str}\",\n",
        "            f\"{symbol_str} announces stock split\",\n",
        "            f\"Dividend declared by {symbol_str}\"\n",
        "        ]\n",
        "\n",
        "\n",
        "    def analyze_sentiment(self, news_headlines: List[str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of news headlines using the Gemini API.\n",
        "        Returns a dictionary with sentiment counts (positive, neutral, negative)\n",
        "        and a sentiment score.\n",
        "        \"\"\"\n",
        "        if not self.gemini_model:\n",
        "            print(\"Gemini API not configured. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Gemini API not configured. Sentiment analysis skipped.'}\n",
        "\n",
        "        if not isinstance(news_headlines, list) or not news_headlines:\n",
        "            print(\"No news headlines to analyze. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 12.5, 'summary': 'No news headlines. Sentiment analysis skipped.'}\n",
        "\n",
        "        logger.info(\"Analyzing sentiment using Gemini API...\")\n",
        "        prompt = \"Analyze the sentiment of the following news headlines for a stock and categorize each as Positive, Neutral, or Negative. Provide a concise summary of the overall sentiment.\\n\\n\"\n",
        "        for headline in news_headlines:\n",
        "            if isinstance(headline, str):\n",
        "                 prompt += f\"- {headline}\\n\"\n",
        "            else:\n",
        "                 logger.warning(f\"Skipping non-string headline: {headline}\")\n",
        "                 continue\n",
        "\n",
        "        if len(prompt) > 30000:\n",
        "             logger.warning(\"News headlines too long for Gemini API prompt. Truncating.\")\n",
        "             prompt = prompt[:30000] + \"\\n... (headlines truncated)\"\n",
        "\n",
        "        try:\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "            sentiment_text = response.text.strip()\n",
        "            logger.info(f\"Gemini API Response: {sentiment_text[:200]}...\")\n",
        "\n",
        "            positive_count = sentiment_text.lower().count('positive')\n",
        "            neutral_count = sentiment_text.lower().count('neutral')\n",
        "            negative_count = sentiment_text.lower().count('negative')\n",
        "\n",
        "            summary_line = \"No summary extracted.\"\n",
        "            lines = sentiment_text.split('\\n')\n",
        "            for line in lines:\n",
        "                 lower_line = line.lower()\n",
        "                 if 'summary' in lower_line or 'overall sentiment' in lower_line:\n",
        "                     summary_line = line.strip()\n",
        "                     break\n",
        "            if summary_line == \"No summary extracted.\" and lines:\n",
        "                 for line in reversed(lines):\n",
        "                     if line.strip():\n",
        "                         summary_line = line.strip()\n",
        "                         break\n",
        "\n",
        "            total_headlines = len([h for h in news_headlines if isinstance(h, str)])\n",
        "            if total_headlines > 0:\n",
        "                sentiment_score = ((positive_count - negative_count) / total_headlines) * 12.5 + 12.5\n",
        "            else:\n",
        "                sentiment_score = 12.5\n",
        "\n",
        "            return {\n",
        "                'positive': positive_count,\n",
        "                'neutral': neutral_count,\n",
        "                'negative': negative_count,\n",
        "                'score': max(0, min(sentiment_score, 25)),\n",
        "                'summary': summary_line\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error analyzing sentiment with Gemini API: {e}. Skipping sentiment analysis.\")\n",
        "            return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Sentiment analysis failed.'}\n",
        "\n",
        "\n",
        "    def generate_enhanced_recommendation(self, fundamental_score, technical_score,\n",
        "                                       liquidity_score, peer_performance, index_membership,\n",
        "                                       sentiment_analysis_results, valuation_comparison_results,\n",
        "                                       downside_risk_metrics: Dict, enhanced_dividend_metrics: Dict,\n",
        "                                       global_macro_results: Dict): # Added global_macro_results\n",
        "        \"\"\"Generate comprehensive recommendation including sentiment and valuation comparison\"\"\"\n",
        "        # Get base scores\n",
        "        fund_score = fundamental_score if isinstance(fundamental_score, (int, float)) and not pd.isna(fundamental_score) else 0\n",
        "        tech_score = technical_score if isinstance(technical_score, (int, float)) and not pd.isna(technical_score) else 0\n",
        "        liq_score = liquidity_score if isinstance(liquidity_score, (int, float)) and not pd.isna(liq_score) else 0\n",
        "        sentiment_score = sentiment_analysis_results.get('score', 0) if isinstance(sentiment_analysis_results.get('score'), (int, float)) and not pd.isna(sentiment_analysis_results.get('score')) else 0\n",
        "        enhanced_dividend_score = enhanced_dividend_metrics.get('score', 0) if isinstance(enhanced_dividend_metrics.get('score'), (int, float)) and not pd.isna(enhanced_dividend_metrics.get('score')) else 0\n",
        "        logger.info(f\"Enhanced dividend score for recommendation: {enhanced_dividend_score}\")\n",
        "\n",
        "\n",
        "        # Get adjustment scores\n",
        "        valuation_adjustment = valuation_comparison_results.get('valuation_score_adjustment', 0) if isinstance(valuation_comparison_results.get('valuation_score_adjustment'), (int, float)) and not pd.isna(valuation_comparison_results.get('valuation_score_adjustment')) else 0\n",
        "        logger.info(f\"Valuation comparison adjustment: {valuation_adjustment}\")\n",
        "\n",
        "        var_percentage = downside_risk_metrics.get('var_percentage_loss', np.nan) # Use .get() as it's now a dict\n",
        "        downside_risk_adjustment = 0 # Adjustment based on VaR\n",
        "\n",
        "        if isinstance(var_percentage, (int, float)) and not pd.isna(var_percentage):\n",
        "             # Example scoring: higher VaR means higher penalty\n",
        "             if var_percentage > 5: # VaR > 5%\n",
        "                  downside_risk_adjustment -= 15\n",
        "                  logger.info(f\"VaR ({var_percentage:.2f}%) > 5%. Applying downside risk penalty (-15).\")\n",
        "             elif var_percentage > 3: # VaR > 3%\n",
        "                  downside_risk_adjustment -= 10\n",
        "                  logger.info(f\"VaR ({var_percentage:.2f}%) > 3%. Applying downside risk penalty (-10).\")\n",
        "             elif var_percentage > 1: # VaR > 1%\n",
        "                  downside_risk_adjustment -= 5\n",
        "                  logger.info(f\"VaR ({var_percentage:.2f}%) > 1%. Applying downside risk penalty (-5).\")\n",
        "             else:\n",
        "                  logger.info(f\"VaR ({var_percentage:.2f}) <= 1%. No downside risk penalty.\") # Corrected format string\n",
        "        else:\n",
        "             logger.warning(\"VaR not available. Cannot apply downside risk adjustment.\")\n",
        "             downside_risk_adjustment -= 2 # Small penalty if VaR cannot be calculated\n",
        "\n",
        "        # Get global macro adjustment\n",
        "        global_macro_adjustment = global_macro_results.get('adjustment', 0) if isinstance(global_macro_results.get('adjustment'), (int, float)) and not pd.isna(global_macro_results.get('adjustment')) else 0\n",
        "        logger.info(f\"Global macro adjustment: {global_macro_adjustment}\")\n",
        "\n",
        "\n",
        "        peer_analysis_available = isinstance(peer_performance, dict) and \\\n",
        "                                  not (pd.isna(peer_performance.get('stock_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('avg_peer_return')) and \\\n",
        "                                       pd.isna(peer_performance.get('relative_performance')))\n",
        "\n",
        "        peer_adjustment = 0\n",
        "        if peer_analysis_available and peer_performance.get('outperformance', False) is True:\n",
        "            peer_adjustment = 5\n",
        "            logger.info(\"Adding bonus for peer outperformance.\")\n",
        "        elif not peer_analysis_available:\n",
        "             peer_adjustment = -5\n",
        "             logger.warning(\"Applying small penalty as peer performance data is incomplete/unavailable.\")\n",
        "\n",
        "\n",
        "        index_adjustment = 0\n",
        "        if isinstance(index_membership, list) and index_membership:\n",
        "            index_adjustment = 5\n",
        "            logger.info(\"Adding bonus for index membership.\")\n",
        "\n",
        "\n",
        "        # Sum all scores and adjustments\n",
        "        # Total Score = Fund (50) + Tech (50) + Liq (70) + Sent (25) + Enhanced Dividend (20) + Val Adj (+/-30 max) + Peer Adj (+/-5 max) + Index Adj (+5 max) + Downside Adj (+0/-15 max) + Global Macro Adj (+/-10 max)\n",
        "        # Total Possible Max Score = 50 + 50 + 70 + 25 + 20 + 30 + 5 + 5 + 0 + 10 = 265\n",
        "        # Total Possible Min Score = 50 + 0 + 0 + 0 + 0 - 30 - 5 + 0 - 15 - 10 = 0 - 10 = Max 0 if capped at 0\n",
        "\n",
        "        total_score = fund_score + tech_score + liq_score + sentiment_score + enhanced_dividend_score + \\\n",
        "                      valuation_adjustment + peer_adjustment + index_adjustment + downside_risk_adjustment + global_macro_adjustment\n",
        "\n",
        "\n",
        "        recommendation = \"NEUTRAL\"\n",
        "        confidence = \"Low\"\n",
        "\n",
        "        # Adjusting thresholds based on potential max score of 265\n",
        "        if total_score >= 210: # Increased threshold\n",
        "            recommendation = \"STRONG BUY\"\n",
        "            confidence = \"High\"\n",
        "        elif total_score >= 170: # Increased threshold\n",
        "            recommendation = \"BUY\"\n",
        "            confidence = \"Moderate to High\"\n",
        "        elif total_score >= 120: # Adjusted threshold\n",
        "            recommendation = \"HOLD\"\n",
        "            confidence = \"Moderate\"\n",
        "        elif total_score >= 70: # Adjusted threshold\n",
        "            recommendation = \"SELL\"\n",
        "            confidence = \"Moderate\"\n",
        "        else:\n",
        "            recommendation = \"STRONG SELL\"\n",
        "            confidence = \"High\"\n",
        "\n",
        "        logger.info(f\"Generated enhanced recommendation: {recommendation} (Total Score: {total_score:.2f})\")\n",
        "\n",
        "        return {\n",
        "            'recommendation': recommendation,\n",
        "            'confidence': confidence,\n",
        "            'total_score': total_score,\n",
        "            'breakdown': {\n",
        "                'fundamental': fund_score,\n",
        "                'technical': tech_score,\n",
        "                'liquidity': liq_score,\n",
        "                'sentiment': sentiment_score,\n",
        "                'enhanced_dividend': enhanced_dividend_score, # Include enhanced dividend score in breakdown\n",
        "                'valuation_comparison': valuation_adjustment, # Include valuation adjustment in breakdown\n",
        "                'downside_risk': downside_risk_adjustment, # Include downside risk adjustment\n",
        "                'peer_adjustment': peer_adjustment, # Include peer adjustment in breakdown\n",
        "                'index_adjustment': index_adjustment, # Include index adjustment in breakdown\n",
        "                'global_macro_adjustment': global_macro_adjustment # Include global macro adjustment in breakdown\n",
        "            }\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6984107f"
      },
      "source": [
        "**Reasoning**:\n",
        "The `EnhancedStockAnalyzer` class has been updated with the `calculate_enhanced_dividend_score` method. Now, I need to integrate this new method into the `analyze_stock_enhanced` function to call the method, store the results in the enhanced report, and update the report display to show the enhanced dividend metrics and their contribution to the total score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b57f4f49",
        "cellView": "form"
      },
      "source": [
        "#@title Part 3: Enhanced Analysis Integration and Report Display (with Enhanced Dividend Analysis)\n",
        "\n",
        "# Assuming IndianStockAnalyzer and EnhancedStockAnalyzer classes are defined in previous cells\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "    if not isinstance(symbol, str) or not symbol:\n",
        "        logger.error(\"Invalid stock symbol provided for enhanced analysis.\")\n",
        "        return None\n",
        "    if not isinstance(stock_analyzer_part1, IndianStockAnalyzer):\n",
        "        logger.error(\"Invalid IndianStockAnalyzer (Part 1) instance provided.\")\n",
        "        return None\n",
        "    if not isinstance(enhanced_analyzer, EnhancedStockAnalyzer):\n",
        "        logger.error(\"Invalid EnhancedStockAnalyzer (Part 2) instance provided.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    logger.info(f\"Starting enhanced analysis for {symbol}\")\n",
        "    # Get basic analysis from Part 1\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        logger.error(f\"Basic analysis failed for {symbol}.\")\n",
        "        return None\n",
        "\n",
        "    # Get current price - already validated in Part 1 analyze_stock\n",
        "    current_price = stock_data.current_price\n",
        "    if pd.isna(current_price) or current_price <= 0:\n",
        "         logger.warning(f\"Current price invalid ({current_price}). Enhanced analysis might be limited.\")\n",
        "\n",
        "\n",
        "    # Enhanced analysis\n",
        "    logger.info(\"Starting enhanced analysis features (Part 2).\")\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    # Pass current_price to assess_circuit_risk (already validated as best as possible in Part 1)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    # Pass price_data (already validated in Part 1 analyze_stock)\n",
        "    # CORRECTED: Call get_liquidity_score on enhanced_analyzer and pass price_data from stock_data\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "\n",
        "    # 3. Peer analysis (including valuation data)\n",
        "    # Pass info (already validated in Part 1 analyze_stock)\n",
        "    # The get_peer_companies method now returns a list of dictionaries with valuation data\n",
        "    peers_with_valuation = enhanced_analyzer.get_peer_companies(symbol, stock_data.info)\n",
        "    # Pass the list of peer symbols (extracted from the list of dictionaries) for performance comparison\n",
        "    peer_symbols_for_performance = [p['symbol'] for p in peers_with_valuation if isinstance(p, dict) and 'symbol' in p]\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peer_symbols_for_performance) # Pass just symbols\n",
        "\n",
        "    # 4. Valuation Analysis: Calculate peer average valuations and compare\n",
        "    peer_average_valuation = enhanced_analyzer.calculate_peer_average_valuation(peers_with_valuation)\n",
        "    valuation_comparison_results = enhanced_analyzer.compare_valuation_to_peers(stock_data.metrics, peer_average_valuation)\n",
        "\n",
        "    # 5. Downside Risk Assessment: Calculate VaR\n",
        "    downside_risk_metrics = enhanced_analyzer.calculate_value_at_risk(stock_data.price_data)\n",
        "\n",
        "    # 6. Enhanced Dividend Analysis\n",
        "    enhanced_dividend_metrics = enhanced_analyzer.calculate_enhanced_dividend_score(symbol, stock_data.price_data)\n",
        "\n",
        "\n",
        "    # 7. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "\n",
        "    # 8. Recalculate technical score with circuit risk\n",
        "    # Pass indicators (already validated in Part 1 calculate_technical_indicators)\n",
        "    # Pass circuit_risk (already validated in assess_circuit_risk)\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "\n",
        "    # 9. Fetch and analyze news sentiment\n",
        "    # Pass symbol (already validated)\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    # Pass news_headlines (already validated)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "\n",
        "\n",
        "    # 10. Generate enhanced recommendation\n",
        "    # Pass scores and results (already validated within their respective functions)\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance, # Pass potentially incomplete/NaN peer performance\n",
        "        index_membership,\n",
        "        sentiment_analysis_results, # Pass sentiment analysis results\n",
        "        valuation_comparison_results, # Pass valuation comparison results\n",
        "        downside_risk_metrics, # Pass downside risk metrics\n",
        "        enhanced_dividend_metrics # Pass enhanced dividend metrics\n",
        "    )\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score, # Ensure correct liquidity score is included\n",
        "            'peers': peers_with_valuation, # Store the list of peers with their valuation data\n",
        "            'peer_performance': peer_performance, # Include peer performance, even if NaN\n",
        "            'peer_average_valuation': peer_average_valuation, # Store peer average valuation\n",
        "            'valuation_comparison': valuation_comparison_results, # Store valuation comparison results\n",
        "            'downside_risk': downside_risk_metrics, # Store downside risk metrics (e.g., VaR)\n",
        "            'enhanced_dividend': enhanced_dividend_metrics, # Store enhanced dividend metrics\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "    logger.info(f\"Enhanced analysis completed for {symbol}\")\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize analyzers\n",
        "    try:\n",
        "        stock_analyzer = IndianStockAnalyzer()\n",
        "        enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "    except NameError:\n",
        "        print(\"Make sure to run the previous cells defining IndianStockAnalyzer and EnhancedStockAnalyzer classes.\")\n",
        "        exit() # Exit if classes are not defined\n",
        "\n",
        "\n",
        "    # Analyze a stock\n",
        "    symbol = \"RELIANCE.NS\" # Example symbol\n",
        "    result = analyze_stock_enhanced(symbol, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if result:\n",
        "        # Display the enhanced report\n",
        "        enhanced = result['enhanced_features']\n",
        "        final = result['final_recommendation']\n",
        "        basic = result['basic_analysis'] # Get basic data for display\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Enhanced Analysis Report: {basic.company_name} ({basic.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if not pd.isna(basic.current_price) else \"Current Price: N/A\")\n",
        "        market_cap_cr = basic.market_cap / 10000000 if not pd.isna(basic.market_cap) else np.nan\n",
        "        print(f\"Market Cap: ₹{market_cap_cr:,.2f} Cr\" if not pd.isna(market_cap_cr) else \"Market Cap: N/A\")\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n⚙️ Enhanced Technical Analysis & Risk:\")\n",
        "        # Display enhanced technical indicators and risk\n",
        "        # Assuming you want to display relevant indicators from basic.indicators and the circuit risk score\n",
        "        circuit_limits_display = enhanced.get('circuit_limits')\n",
        "        if circuit_limits_display and not pd.isna(circuit_limits_display.get('lower_circuit')) and not pd.isna(circuit_limits_display.get('upper_circuit')):\n",
        "             print(f\"Circuit Limits: {circuit_limits_display.get('lower_circuit', 'N/A'):.2f} - {circuit_limits_display.get('upper_circuit', 'N/A'):.2f}\")\n",
        "        else:\n",
        "             print(\"Circuit Limits: N/A\")\n",
        "\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        # Check if liquidity score is available before formatting\n",
        "        liquidity_score_display = f\"{enhanced.get('liquidity_score', 'N/A')}/70\" if isinstance(enhanced.get('liquidity_score'), (int, float)) and not pd.isna(enhanced.get('liquidity_score')) else \"Liquidity Score: N/A/70\"\n",
        "        print(liquidity_score_display)\n",
        "\n",
        "\n",
        "        # Display some key technical indicators from basic analysis\n",
        "        print(\"\\nKey Technical Indicators (from Basic Analysis):\")\n",
        "        key_tech_indicators = ['RSI', 'MACD', 'MACD_signal', 'SMA_20', 'SMA_50', 'BB_middle', 'Volume_ratio']\n",
        "        for indicator_name in key_tech_indicators:\n",
        "            value = basic.indicators.get(indicator_name, np.nan)\n",
        "            if not pd.isna(value):\n",
        "                if isinstance(value, float):\n",
        "                     print(f\"  - {indicator_name}: {value:,.2f}\")\n",
        "                else:\n",
        "                     print(f\"  - {indicator_name}: {value}\")\n",
        "            # Add logging for these key technical indicators if they are calculated\n",
        "            # logger.info(f\"Indicator {indicator_name}: {value}\") # Removed duplicate logging\n",
        "            # else: # Removed unnecessary else block\n",
        "            #     print(f\"  - {indicator_name}: N/A\")\n",
        "            #     logger.info(f\"Indicator {indicator_name}: N/A\")\n",
        "\n",
        "\n",
        "        # Display Valuation Analysis\n",
        "        print(f\"\\n📈 Valuation Analysis:\")\n",
        "        stock_metrics = basic.metrics\n",
        "        peer_avg_val = enhanced.get('peer_average_valuation', {})\n",
        "        val_comp_results = enhanced.get('valuation_comparison', {})\n",
        "\n",
        "        stock_pe = stock_metrics.get('trailingPE', np.nan)\n",
        "        stock_pb = stock_metrics.get('priceToBook', np.nan)\n",
        "        stock_ev_ebitda = stock_metrics.get('evToEbitda', np.nan)\n",
        "\n",
        "        print(f\"Stock Valuation:\")\n",
        "        print(f\"  - Trailing PE: {stock_pe:.2f}\" if not pd.isna(stock_pe) else \"  - Trailing PE: N/A\")\n",
        "        print(f\"  - Price to Book: {stock_pb:.2f}\" if not pd.isna(stock_pb) else \"  - Price to Book: N/A\")\n",
        "        print(f\"  - EV/EBITDA: {stock_ev_ebitda:.2f}\" if not pd.isna(stock_ev_ebitda) else \"  - EV/EBITDA: N/A\")\n",
        "\n",
        "        print(\"\\nPeer Average Valuation:\")\n",
        "        avg_pe_display = f\"{peer_avg_val.get('avg_pe', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pe', np.nan)) else \"N/A\"\n",
        "        avg_pb_display = f\"{peer_avg_val.get('avg_pb', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pb', np.nan)) else \"N/A\"\n",
        "        avg_ev_ebitda_display = f\"{peer_avg_val.get('avg_ev_ebitda', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_ev_ebitda', np.nan)) else \"N/A\"\n",
        "\n",
        "        print(f\"  - Average PE: {avg_pe_display}\")\n",
        "        print(f\"  - Average PB: {avg_pb_display}\")\n",
        "        print(f\"  - Average EV/EBITDA: {avg_ev_ebitda_display}\")\n",
        "\n",
        "        print(\"\\nValuation Comparison:\")\n",
        "        print(f\"  - PE Comparison: {val_comp_results.get('pe_comparison', 'N/A')}\")\n",
        "        print(f\"  - PB Comparison: {val_comp_results.get('pb_comparison', 'N/A')}\")\n",
        "        print(f\"  - EV/EBITDA Comparison: {val_comp_results.get('ev_ebitda_comparison', 'N/A')}\")\n",
        "        valuation_adj_display = f\"{val_comp_results.get('valuation_score_adjustment', 0):+.2f}\" if isinstance(val_comp_results.get('valuation_score_adjustment'), (int, float)) and not pd.isna(val_comp_results.get('valuation_score_adjustment')) else \"N/A\"\n",
        "        print(f\"  - Valuation Score Adjustment: {valuation_adj_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\n📉 Downside Risk Analysis:\")\n",
        "        downside_risk = enhanced.get('downside_risk', {})\n",
        "        var_percentage = downside_risk.get('var_percentage_loss', np.nan)\n",
        "        var_display = f\"{var_percentage:.2f}%\" if not pd.isna(var_percentage) else \"N/A\"\n",
        "        # Access 'confidence_level' and 'horizon_days' directly from the downside_risk dictionary\n",
        "        confidence_level_display = downside_risk.get('confidence_level', 0.95)\n",
        "        horizon_days_display = downside_risk.get('horizon_days', 1)\n",
        "        print(f\"  - {confidence_level_display*100:.0f}% VaR ({horizon_days_display}-day): {var_display}\")\n",
        "\n",
        "        downside_adj_display = f\"{final.get('breakdown', {}).get('downside_risk', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('downside_risk'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('downside_risk')) else \"N/A\"\n",
        "        print(f\"  - Downside Risk Score Adjustment: {downside_adj_display}\")\n",
        "\n",
        "\n",
        "        # Display Enhanced Dividend Analysis\n",
        "        print(f\"\\n💎 Enhanced Dividend Analysis:\")\n",
        "        enhanced_dividend = enhanced.get('enhanced_dividend', {})\n",
        "        current_yield_display = f\"{enhanced_dividend.get('trailingAnnualDividendYield', np.nan):.2f}%\" if isinstance(enhanced_dividend.get('trailingAnnualDividendYield'), (int, float)) and not pd.isna(enhanced_dividend.get('trailingAnnualDividendYield')) else \"N/A\"\n",
        "        payout_ratio_display = f\"{enhanced_dividend.get('dividendPayoutRatio', np.nan):.2f}\" if isinstance(enhanced_dividend.get('dividendPayoutRatio'), (int, float)) and not pd.isna(enhanced_dividend.get('dividendPayoutRatio')) else \"N/A\"\n",
        "        yield_trend_display = enhanced_dividend.get('yield_trend', 'N/A')\n",
        "        enhanced_dividend_score_display = f\"{enhanced_dividend.get('score', np.nan):.2f}/20\" if isinstance(enhanced_dividend.get('score'), (int, float)) and not pd.isna(enhanced_dividend.get('score')) else \"N/A/20\"\n",
        "\n",
        "        print(f\"  - Trailing Annual Dividend Yield: {current_yield_display}\")\n",
        "        print(f\"  - Dividend Payout Ratio: {payout_ratio_display}\")\n",
        "        print(f\"  - Dividend Payout Trend: {yield_trend_display}\")\n",
        "        print(f\"  - Enhanced Dividend Score: {enhanced_dividend_score_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\n🤝 Peer Analysis (Performance):\")\n",
        "        peer_perf = enhanced.get('peer_performance')\n",
        "        if isinstance(peer_perf, dict) and \\\n",
        "           not pd.isna(peer_perf.get('stock_return')) and \\\n",
        "           not pd.isna(peer_perf.get('avg_peer_return')) and \\\n",
        "           not pd.isna(peer_perf.get('relative_performance')):\n",
        "\n",
        "             stock_return_display = f\"{peer_perf.get('stock_return', np.nan):.2f}%\" if isinstance(peer_perf.get('stock_return'), (int, float)) and not pd.isna(peer_perf.get('stock_return')) else 'N/A'\n",
        "             avg_peer_return_display = f\"{peer_perf.get('avg_peer_return', np.nan):.2f}%\" if isinstance(peer_perf.get('avg_peer_return'), (int, float)) and not pd.isna(peer_perf.get('avg_peer_return')) else 'N/A'\n",
        "             relative_performance_display = f\"{peer_perf.get('relative_performance', np.nan):.2f}%\" if isinstance(peer_perf.get('relative_performance'), (int, float)) and not pd.isna(peer_perf.get('relative_performance')) else 'N/A'\n",
        "\n",
        "             print(f\"  - {peer_perf.get('days', 'N/A')}-day Stock Return: {stock_return_display}\")\n",
        "             print(f\"  - Avg Peer Return: {avg_peer_return_display}\")\n",
        "             print(f\"  - Relative Performance: {relative_performance_display}\")\n",
        "        else:\n",
        "             print(\"Peer Performance Data Unavailable.\")\n",
        "\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"\\n🏛️ Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             # Only print a few headlines to keep the report concise\n",
        "             print(\"Sample News Headlines:\")\n",
        "             # Ensure headlines are valid strings before printing\n",
        "             valid_headlines = [h for h in enhanced['news_headlines'] if isinstance(h, str)]\n",
        "             for headline in valid_headlines[:5]: # Print up to 5 headlines\n",
        "                 print(f\"- {headline}\")\n",
        "             if len(valid_headlines) > 5:\n",
        "                  print(\"  ...\")\n",
        "\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             sentiment_score_display = f\"{sentiment_results.get('score', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\"\n",
        "             print(f\"Sentiment Score: {sentiment_score_display}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Comprehensive Scores and Recommendation ---\")\n",
        "        print(f\"Fundamental Score (from Part 1): {basic.fundamental_score:.2f}/50\" if not pd.isna(basic.fundamental_score) else \"Fundamental Score: N/A\")\n",
        "        # Add checks for NaN before formatting float for breakdown scores\n",
        "        enhanced_tech_score_display = f\"{final.get('breakdown', {}).get('technical', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('technical'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('technical')) else \"N/A\"\n",
        "        liquidity_score_display_breakdown = f\"{final.get('breakdown', {}).get('liquidity', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('liquidity'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('liquidity')) else \"N/A\"\n",
        "        sentiment_score_display_breakdown = f\"{sentiment_results.get('score', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\" # Corrected sentiment score breakdown check\n",
        "        valuation_comp_display_breakdown = f\"{final.get('breakdown', {}).get('valuation_comparison', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('valuation_comparison'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('valuation_comparison')) else \"N/A\"\n",
        "        downside_risk_display_breakdown = f\"{final.get('breakdown', {}).get('downside_risk', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('downside_risk'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('downside_risk')) else \"N/A\"\n",
        "        enhanced_dividend_display_breakdown = f\"{final.get('breakdown', {}).get('enhanced_dividend', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('enhanced_dividend'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('enhanced_dividend')) else \"N/A\"\n",
        "\n",
        "\n",
        "        print(f\"Technical Score (Enhanced): {enhanced_tech_score_display}/50\")\n",
        "        print(f\"Liquidity Score: {liquidity_score_display_breakdown}/70\")\n",
        "        print(f\"Sentiment Score: {sentiment_score_display_breakdown}/25\")\n",
        "        print(f\"Valuation Comparison Adjustment: {valuation_comp_display_breakdown}\")\n",
        "        print(f\"Downside Risk Adjustment: {downside_risk_display_breakdown}\")\n",
        "        print(f\"Enhanced Dividend Score: {enhanced_dividend_display_breakdown}/20\") # Display enhanced dividend score breakdown\n",
        "\n",
        "\n",
        "        # Display adjustment scores\n",
        "        peer_adj_display = f\"{final.get('breakdown', {}).get('peer_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('peer_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('peer_adjustment')) else \"N/A\"\n",
        "        index_adj_display = f\"{final.get('breakdown', {}).get('index_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('index_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('index_adjustment')) else \"N/A\"\n",
        "\n",
        "        print(f\"Peer Performance Adjustment: {peer_adj_display}\")\n",
        "        print(f\"Index Membership Adjustment: {index_adj_display}\")\n",
        "\n",
        "\n",
        "        # Updated max score to reflect the addition of Enhanced Dividend Score (20 points)\n",
        "        # Max Total Score = Fund (50) + Tech (50) + Liq (70) + Sent (25) + Enhanced Dividend (20) + Val Adj (30) + Peer Adj (5) + Index Adj (5) + Downside Adj (0) = 255\n",
        "        print(f\"\\nTotal Enhanced Score: {final.get('total_score', 0):.2f}/255\" if isinstance(final.get('total_score'), (int, float)) and not pd.isna(final.get('total_score')) else \"Total Enhanced Score: N/A\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} (Confidence: {final.get('confidence', 'N/A')})\")\n",
        "\n",
        "\n",
        "        print(f\"\\n{'='*60}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c485058",
        "cellView": "form"
      },
      "source": [
        "#@title Part 3: Enhanced Analysis Integration and Report Display (Regenerated)\n",
        "\n",
        "# Assuming IndianStockAnalyzer and EnhancedStockAnalyzer classes are defined in previous cells\n",
        "\n",
        "# Ensure logging is configured (assuming this was done in a previous cell)\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Import numpy and pandas here to ensure they are available globally\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Integration function to work with your Part 1\n",
        "def analyze_stock_enhanced(symbol, stock_analyzer_part1, enhanced_analyzer):\n",
        "    \"\"\"\n",
        "    Integrate enhanced features with your Part 1 analyzer\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock symbol (e.g., 'RELIANCE.NS')\n",
        "        stock_analyzer_part1: Instance of your IndianStockAnalyzer from Part 1\n",
        "        enhanced_analyzer: Instance of EnhancedStockAnalyzer\n",
        "    \"\"\"\n",
        "    if not isinstance(symbol, str) or not symbol:\n",
        "        logger.error(\"Invalid stock symbol provided for enhanced analysis.\")\n",
        "        return None\n",
        "    if not isinstance(stock_analyzer_part1, IndianStockAnalyzer):\n",
        "        logger.error(\"Invalid IndianStockAnalyzer (Part 1) instance provided.\")\n",
        "        return None\n",
        "    if not isinstance(enhanced_analyzer, EnhancedStockAnalyzer):\n",
        "        logger.error(\"Invalid EnhancedStockAnalyzer (Part 2) instance provided.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    logger.info(f\"Starting enhanced analysis for {symbol}\")\n",
        "    # Get basic analysis from Part 1\n",
        "    stock_data = stock_analyzer_part1.analyze_stock(symbol)\n",
        "\n",
        "    if not stock_data:\n",
        "        logger.error(f\"Basic analysis failed for {symbol}.\")\n",
        "        return None\n",
        "\n",
        "    # Get current price - already validated in Part 1 analyze_stock\n",
        "    current_price = stock_data.current_price\n",
        "    if pd.isna(current_price) or current_price <= 0:\n",
        "         logger.warning(f\"Current price invalid ({current_price}). Enhanced analysis might be limited.\")\n",
        "\n",
        "\n",
        "    # Enhanced analysis\n",
        "    logger.info(\"Starting enhanced analysis features (Part 2).\")\n",
        "    # 1. Circuit breaker analysis\n",
        "    circuit_limits = enhanced_analyzer.get_circuit_limits(symbol)\n",
        "    # Pass current_price to assess_circuit_risk (already validated as best as possible in Part 1)\n",
        "    circuit_risk = enhanced_analyzer.assess_circuit_risk(current_price, circuit_limits)\n",
        "\n",
        "    # 2. Enhanced liquidity analysis\n",
        "    # Pass price_data (already validated in Part 1 analyze_stock)\n",
        "    # CORRECTED: Call get_liquidity_score on enhanced_analyzer and pass price_data from stock_data\n",
        "    liquidity_score = enhanced_analyzer.get_liquidity_score(stock_data.price_data)\n",
        "\n",
        "    # 3. Peer analysis (including valuation data)\n",
        "    # Pass info (already validated in Part 1 analyze_stock)\n",
        "    # The get_peer_companies method now returns a list of dictionaries with valuation data\n",
        "    peers_with_valuation = enhanced_analyzer.get_peer_companies(symbol, stock_data.info)\n",
        "    # Pass the list of peer symbols (extracted from the list of dictionaries) for performance comparison\n",
        "    peer_symbols_for_performance = [p['symbol'] for p in peers_with_valuation if isinstance(p, dict) and 'symbol' in p]\n",
        "    peer_performance = enhanced_analyzer.calculate_peer_relative_performance(symbol, peer_symbols_for_performance) # Pass just symbols\n",
        "\n",
        "    # 4. Valuation Analysis: Calculate peer average valuations and compare\n",
        "    peer_average_valuation = enhanced_analyzer.calculate_peer_average_valuation(peers_with_valuation)\n",
        "    valuation_comparison_results = enhanced_analyzer.compare_valuation_to_peers(stock_data.metrics, peer_average_valuation)\n",
        "\n",
        "    # 5. Downside Risk Assessment: Calculate VaR\n",
        "    downside_risk_metrics = enhanced_analyzer.calculate_value_at_risk(stock_data.price_data)\n",
        "\n",
        "    # 6. Enhanced Dividend Analysis\n",
        "    enhanced_dividend_metrics = enhanced_analyzer.calculate_enhanced_dividend_score(symbol, stock_data.price_data)\n",
        "\n",
        "    # 7. Global Macro Impact Assessment\n",
        "    global_macro_results = enhanced_analyzer.assess_global_macro_impact()\n",
        "\n",
        "\n",
        "    # 8. Index membership\n",
        "    index_membership = enhanced_analyzer.get_index_membership(symbol)\n",
        "\n",
        "    # 9. Recalculate technical score with circuit risk\n",
        "    # Pass indicators (already validated in Part 1 calculate_technical_indicators)\n",
        "    # Pass circuit_risk (already validated in assess_circuit_risk)\n",
        "    enhanced_technical_score = enhanced_analyzer.calculate_enhanced_technical_score(\n",
        "        stock_data.indicators, circuit_risk\n",
        "    )\n",
        "\n",
        "    # 10. Fetch and analyze news sentiment\n",
        "    # Pass symbol (already validated)\n",
        "    news_headlines = enhanced_analyzer.fetch_news(symbol)\n",
        "    # Pass news_headlines (already validated)\n",
        "    sentiment_analysis_results = enhanced_analyzer.analyze_sentiment(news_headlines)\n",
        "\n",
        "\n",
        "    # 11. Generate enhanced recommendation\n",
        "    # Pass scores and results (already validated within their respective functions)\n",
        "    final_recommendation = enhanced_analyzer.generate_enhanced_recommendation(\n",
        "        stock_data.fundamental_score,\n",
        "        enhanced_technical_score,\n",
        "        liquidity_score,\n",
        "        peer_performance, # Pass potentially incomplete/NaN peer performance\n",
        "        index_membership,\n",
        "        sentiment_analysis_results, # Pass sentiment analysis results\n",
        "        valuation_comparison_results, # Pass valuation comparison results\n",
        "        downside_risk_metrics, # Pass downside risk metrics\n",
        "        enhanced_dividend_metrics, # Pass enhanced dividend metrics\n",
        "        global_macro_results # Pass global macro results\n",
        "    )\n",
        "\n",
        "    # Create enhanced report\n",
        "    enhanced_report = {\n",
        "        'basic_analysis': stock_data,\n",
        "        'enhanced_features': {\n",
        "            'circuit_limits': circuit_limits,\n",
        "            'circuit_risk_score': circuit_risk,\n",
        "            'liquidity_score': liquidity_score, # Ensure correct liquidity score is included\n",
        "            'peers': peers_with_valuation, # Store the list of peers with their valuation data\n",
        "            'peer_performance': peer_performance, # Include peer performance, even if NaN\n",
        "            'peer_average_valuation': peer_average_valuation, # Store peer average valuation\n",
        "            'valuation_comparison': valuation_comparison_results, # Store valuation comparison results\n",
        "            'downside_risk': downside_risk_metrics, # Store downside risk metrics (e.g., VaR)\n",
        "            'enhanced_dividend': enhanced_dividend_metrics, # Store enhanced dividend metrics\n",
        "            'global_macro': global_macro_results, # Store global macro results\n",
        "            'index_membership': index_membership,\n",
        "            'dynamic_risk_free_rate': enhanced_analyzer.risk_free_rate,\n",
        "            'news_headlines': news_headlines, # Include news in report\n",
        "            'sentiment_analysis': sentiment_analysis_results # Include sentiment analysis results\n",
        "        },\n",
        "        'final_recommendation': final_recommendation\n",
        "    }\n",
        "    logger.info(f\"Enhanced analysis completed for {symbol}\")\n",
        "    return enhanced_report\n",
        "\n",
        "# Example usage (assuming this block will be run directly)\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize analyzers - ensure these classes are defined in previous cells\n",
        "    try:\n",
        "        stock_analyzer = IndianStockAnalyzer()\n",
        "        enhanced_analyzer = EnhancedStockAnalyzer()\n",
        "    except NameError:\n",
        "        print(\"Make sure to run the previous cells defining IndianStockAnalyzer and EnhancedStockAnalyzer classes.\")\n",
        "        # Attempt to define dummy classes if not found, to allow the rest of the cell to be generated\n",
        "        # This is a fallback and may not work for complex class dependencies.\n",
        "        # It's better to ensure the user runs the correct prerequisite cells.\n",
        "        import numpy as np\n",
        "        import pandas as pd\n",
        "\n",
        "        class IndianStockAnalyzer:\n",
        "            def analyze_stock(self, symbol):\n",
        "                print(f\"Placeholder: Analyzing {symbol} with dummy IndianStockAnalyzer.\")\n",
        "                # Return a dummy object with necessary attributes to prevent immediate errors\n",
        "                class DummyStockData:\n",
        "                    def __init__(self):\n",
        "                        self.current_price = 100.0\n",
        "                        self.market_cap = 10000000000.0\n",
        "                        self.info = {'sector': 'Unknown', 'trailingPE': np.nan, 'priceToBook': np.nan, 'enterpriseValue': np.nan, 'ebitda': np.nan}\n",
        "                        self.metrics = {'trailingPE': np.nan, 'priceToBook': np.nan, 'evToEbitda': np.nan}\n",
        "                        self.price_data = pd.DataFrame({'Close': [100.0]*100, 'Volume': [1000]*100})\n",
        "                        self.indicators = {'RSI': np.nan, 'MACD': np.nan, 'MACD_signal': np.nan, 'SMA_20': np.nan, 'SMA_50': np.nan, 'BB_middle': np.nan, 'Volume_ratio': np.nan}\n",
        "                        self.fundamental_score = np.nan\n",
        "                        self.technical_score = np.nan # Added technical_score to dummy\n",
        "                        self.company_name = \"Dummy Company\"\n",
        "                        self.symbol = symbol\n",
        "\n",
        "                return DummyStockData()\n",
        "\n",
        "        class EnhancedStockAnalyzer:\n",
        "            def __init__(self):\n",
        "                self.risk_free_rate = 0.07\n",
        "                self.gemini_model = None # Assume no Gemini model if not configured\n",
        "                self.global_macro_sentiment = 'neutral' # Added dummy global macro sentiment\n",
        "\n",
        "            def get_circuit_limits(self, symbol): return None\n",
        "            def assess_circuit_risk(self, current_price, circuit_limits): return 0\n",
        "            def get_liquidity_score(self, price_data): return 30\n",
        "            def get_peer_companies(self, symbol, stock_info): return []\n",
        "            def calculate_peer_average_valuation(self, peers_with_valuation): return {'avg_pe': np.nan, 'avg_pb': np.nan, 'avg_ev_ebitda': np.nan}\n",
        "            def compare_valuation_to_peers(self, stock_valuation, peer_average_valuation): return {'valuation_score_adjustment': 0}\n",
        "            def calculate_value_at_risk(self, price_data, confidence_level=0.95, horizon_days=1): return {'var_percentage_loss': np.nan, 'confidence_level': confidence_level, 'horizon_days': horizon_days}\n",
        "            def calculate_enhanced_dividend_score(self, symbol, price_data): return {'score': 0, 'trailingAnnualDividendYield': np.nan, 'dividendPayoutRatio': np.nan, 'yield_trend': 'N/A', 'payout_history': {}}\n",
        "            def assess_global_macro_impact(self): return {'sentiment': self.global_macro_sentiment, 'adjustment': 0} # Added dummy global macro assessment\n",
        "            def fetch_news(self, symbol): return []\n",
        "            def analyze_sentiment(self, news_headlines): return {'positive': 0, 'neutral': 0, 'negative': 0, 'score': 0, 'summary': 'Dummy sentiment analysis.'}\n",
        "            def get_index_membership(self, symbol): return []\n",
        "            def calculate_enhanced_technical_score(self, indicators, circuit_risk): return 0\n",
        "            def calculate_peer_relative_performance(self, symbol, peers, days=30): return {'stock_return': np.nan, 'avg_peer_return': np.nan, 'relative_performance': np.nan, 'outperformance': False, 'days': days} # Added dummy peer relative performance\n",
        "            def generate_enhanced_recommendation(self, fundamental_score, technical_score, liquidity_score, peer_performance, index_membership, sentiment_analysis_results, valuation_comparison_results, downside_risk_metrics, enhanced_dividend_metrics, global_macro_results): # Added global_macro_results\n",
        "                 # Simple dummy recommendation based on scores\n",
        "                 fund_score = fundamental_score or 0\n",
        "                 tech_score = technical_score or 0\n",
        "                 liq_score = liquidity_score or 0\n",
        "                 sentiment_score = sentiment_analysis_results.get('score', 0) or 0\n",
        "                 enhanced_dividend_score = enhanced_dividend_metrics.get('score', 0) or 0\n",
        "                 valuation_adjustment = valuation_comparison_results.get('valuation_score_adjustment', 0) or 0\n",
        "                 downside_risk_adjustment = downside_risk_metrics.get('downside_risk', {}).get('downside_risk_adjustment', 0) if isinstance(downside_risk_metrics, dict) else 0 # Access adjustment from nested dict\n",
        "                 peer_adjustment = peer_performance.get('peer_adjustment', 0) if isinstance(peer_performance, dict) else 0 # Added check\n",
        "                 index_adjustment = 5 if index_membership else 0\n",
        "                 global_macro_adjustment = global_macro_results.get('adjustment', 0) if isinstance(global_macro_results, dict) else 0 # Added check\n",
        "\n",
        "\n",
        "                 total_score = fund_score + tech_score + liq_score + sentiment_score + enhanced_dividend_score + \\\n",
        "                               valuation_adjustment + peer_adjustment + index_adjustment + downside_risk_adjustment + global_macro_adjustment\n",
        "\n",
        "\n",
        "                 if total_score > 150: rec = \"BUY\"\n",
        "                 elif total_score > 100: rec = \"HOLD\"\n",
        "                 else: rec = \"SELL\"\n",
        "                 return {'recommendation': rec, 'confidence': 'Dummy', 'total_score': total_score, 'breakdown': {}}\n",
        "\n",
        "\n",
        "    # Analyze a stock\n",
        "    symbol = \"RELIANCE.NS\" # Example symbol\n",
        "    result = analyze_stock_enhanced(symbol, stock_analyzer, enhanced_analyzer)\n",
        "\n",
        "    if result:\n",
        "        # Display the enhanced report\n",
        "        enhanced = result['enhanced_features']\n",
        "        final = result['final_recommendation']\n",
        "        basic = result['basic_analysis'] # Get basic data for display\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Enhanced Analysis Report: {basic.company_name} ({basic.symbol})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\n📊 Current Market Data:\")\n",
        "        print(f\"Current Price: ₹{basic.current_price:,.2f}\" if not pd.isna(basic.current_price) else \"Current Price: N/A\")\n",
        "        market_cap_cr = basic.market_cap / 10000000 if not pd.isna(basic.market_cap) else np.nan\n",
        "        print(f\"Market Cap: ₹{market_cap_cr:,.2f} Cr\" if not pd.isna(market_cap_cr) else \"Market Cap: N/A\")\n",
        "        print(f\"Sector: {basic.info.get('sector', 'N/A')}\")\n",
        "\n",
        "        print(f\"\\n⚙️ Enhanced Technical Analysis & Risk:\")\n",
        "        # Display enhanced technical indicators and risk\n",
        "        # Assuming you want to display relevant indicators from basic.indicators and the circuit risk score\n",
        "        circuit_limits_display = enhanced.get('circuit_limits')\n",
        "        if circuit_limits_display and not pd.isna(circuit_limits_display.get('lower_circuit')) and not pd.isna(circuit_limits_display.get('upper_circuit')):\n",
        "             print(f\"Circuit Limits: {circuit_limits_display.get('lower_circuit', 'N/A'):.2f} - {circuit_limits_display.get('upper_circuit', 'N/A'):.2f}\")\n",
        "        else:\n",
        "             print(\"Circuit Limits: N/A\")\n",
        "\n",
        "        print(f\"Circuit Risk Score: {enhanced.get('circuit_risk_score', 'N/A')}\")\n",
        "        # Check if liquidity score is available before formatting\n",
        "        liquidity_score_display = f\"{enhanced.get('liquidity_score', 'N/A')}/70\" if isinstance(enhanced.get('liquidity_score'), (int, float)) and not pd.isna(enhanced.get('liquidity_score')) else \"Liquidity Score: N/A/70\"\n",
        "        print(liquidity_score_display)\n",
        "\n",
        "\n",
        "        # Display some key technical indicators from basic analysis\n",
        "        print(\"\\nKey Technical Indicators (from Basic Analysis):\")\n",
        "        key_tech_indicators = ['RSI', 'MACD', 'MACD_signal', 'SMA_20', 'SMA_50', 'BB_middle', 'Volume_ratio']\n",
        "        for indicator_name in key_tech_indicators:\n",
        "            value = basic.indicators.get(indicator_name, np.nan)\n",
        "            if not pd.isna(value):\n",
        "                if isinstance(value, float):\n",
        "                     print(f\"  - {indicator_name}: {value:,.2f}\")\n",
        "                else:\n",
        "                     print(f\"  - {indicator_name}: {value}\")\n",
        "\n",
        "\n",
        "        # Display Valuation Analysis\n",
        "        print(f\"\\n📈 Valuation Analysis:\")\n",
        "        stock_metrics = basic.metrics\n",
        "        peer_avg_val = enhanced.get('peer_average_valuation', {})\n",
        "        val_comp_results = enhanced.get('valuation_comparison', {})\n",
        "\n",
        "        stock_pe = stock_metrics.get('trailingPE', np.nan)\n",
        "        stock_pb = stock_metrics.get('priceToBook', np.nan)\n",
        "        stock_ev_ebitda = stock_metrics.get('evToEbitda', np.nan)\n",
        "\n",
        "        print(f\"Stock Valuation:\")\n",
        "        print(f\"  - Trailing PE: {stock_pe:.2f}\" if not pd.isna(stock_pe) else \"  - Trailing PE: N/A\")\n",
        "        print(f\"  - Price to Book: {stock_pb:.2f}\" if not pd.isna(stock_pb) else \"  - Price to Book: N/A\")\n",
        "        print(f\"  - EV/EBITDA: {stock_ev_ebitda:.2f}\" if not pd.isna(stock_ev_ebitda) else \"  - EV/EBITDA: N/A\")\n",
        "\n",
        "        print(\"\\nPeer Average Valuation:\")\n",
        "        avg_pe_display = f\"{peer_avg_val.get('avg_pe', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pe', np.nan)) else \"N/A\"\n",
        "        avg_pb_display = f\"{peer_avg_val.get('avg_pb', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_pb', np.nan)) else \"N/A\"\n",
        "        avg_ev_ebitda_display = f\"{peer_avg_val.get('avg_ev_ebitda', np.nan):.2f}\" if not pd.isna(peer_avg_val.get('avg_ev_ebitda', np.nan)) else \"N/A\"\n",
        "\n",
        "        print(f\"  - Average PE: {avg_pe_display}\")\n",
        "        print(f\"  - Average PB: {avg_pb_display}\")\n",
        "        print(f\"  - Average EV/EBITDA: {avg_ev_ebitda_display}\")\n",
        "\n",
        "        print(\"\\nValuation Comparison:\")\n",
        "        print(f\"  - PE Comparison: {val_comp_results.get('pe_comparison', 'N/A')}\")\n",
        "        print(f\"  - PB Comparison: {val_comp_results.get('pb_comparison', 'N/A')}\")\n",
        "        print(f\"  - EV/EBITDA Comparison: {val_comp_results.get('ev_ebitda_comparison', 'N/A')}\")\n",
        "        valuation_adj_display = f\"{val_comp_results.get('valuation_score_adjustment', 0):+.2f}\" if isinstance(val_comp_results.get('valuation_score_adjustment'), (int, float)) and not pd.isna(val_comp_results.get('valuation_score_adjustment')) else \"N/A\"\n",
        "        print(f\"  - Valuation Score Adjustment: {valuation_adj_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\n📉 Downside Risk Analysis:\")\n",
        "        downside_risk = enhanced.get('downside_risk', {})\n",
        "        var_percentage = downside_risk.get('var_percentage_loss', np.nan)\n",
        "        var_display = f\"{var_percentage:.2f}%\" if not pd.isna(var_percentage) else \"N/A\"\n",
        "        # Access 'confidence_level' and 'horizon_days' directly from the downside_risk dictionary\n",
        "        confidence_level_display = downside_risk.get('confidence_level', 0.95)\n",
        "        horizon_days_display = downside_risk.get('horizon_days', 1)\n",
        "        print(f\"  - {confidence_level_display*100:.0f}% VaR ({horizon_days_display}-day): {var_display}\")\n",
        "\n",
        "        downside_adj_display = f\"{final.get('breakdown', {}).get('downside_risk', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('downside_risk'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('downside_risk')) else \"N/A\"\n",
        "        print(f\"  - Downside Risk Score Adjustment: {downside_adj_display}\")\n",
        "\n",
        "\n",
        "        # Display Enhanced Dividend Analysis\n",
        "        print(f\"\\n💎 Enhanced Dividend Analysis:\")\n",
        "        enhanced_dividend = enhanced.get('enhanced_dividend', {})\n",
        "        current_yield_display = f\"{enhanced_dividend.get('trailingAnnualDividendYield', np.nan):.2f}%\" if isinstance(enhanced_dividend.get('trailingAnnualDividendYield'), (int, float)) and not pd.isna(enhanced_dividend.get('trailingAnnualDividendYield')) else \"N/A\"\n",
        "        payout_ratio_display = f\"{enhanced_dividend.get('dividendPayoutRatio', np.nan):.2f}\" if isinstance(enhanced_dividend.get('dividendPayoutRatio'), (int, float)) and not pd.isna(enhanced_dividend.get('dividendPayoutRatio')) else \"N/A\"\n",
        "        yield_trend_display = enhanced_dividend.get('yield_trend', 'N/A')\n",
        "        enhanced_dividend_score_display = f\"{enhanced_dividend.get('score', np.nan):.2f}/20\" if isinstance(enhanced_dividend.get('score'), (int, float)) and not pd.isna(enhanced_dividend.get('score')) else \"N/A/20\"\n",
        "\n",
        "        print(f\"  - Trailing Annual Dividend Yield: {current_yield_display}\")\n",
        "        print(f\"  - Dividend Payout Ratio: {payout_ratio_display}\")\n",
        "        print(f\"  - Dividend Payout Trend: {yield_trend_display}\")\n",
        "        print(f\"  - Enhanced Dividend Score: {enhanced_dividend_score_display}\")\n",
        "\n",
        "\n",
        "        print(f\"\\n🤝 Peer Analysis (Performance):\")\n",
        "        peer_perf = enhanced.get('peer_performance')\n",
        "        if isinstance(peer_perf, dict) and \\\n",
        "           not pd.isna(peer_perf.get('stock_return')) and \\\n",
        "           not pd.isna(peer_perf.get('avg_peer_return')) and \\\n",
        "           not pd.isna(peer_perf.get('relative_performance')):\n",
        "\n",
        "             stock_return_display = f\"{peer_perf.get('stock_return', np.nan):.2f}%\" if isinstance(peer_perf.get('stock_return'), (int, float)) and not pd.isna(peer_perf.get('stock_return')) else 'N/A'\n",
        "             avg_peer_return_display = f\"{peer_perf.get('avg_peer_return', np.nan):.2f}%\" if isinstance(peer_perf.get('avg_peer_return'), (int, float)) and not pd.isna(peer_perf.get('avg_peer_return')) else 'N/A'\n",
        "             relative_performance_display = f\"{peer_perf.get('relative_performance', np.nan):.2f}%\" if isinstance(peer_perf.get('relative_performance'), (int, float)) and not pd.isna(peer_perf.get('relative_performance')) else 'N/A'\n",
        "\n",
        "             print(f\"  - {peer_perf.get('days', 'N/A')}-day Stock Return: {stock_return_display}\")\n",
        "             print(f\"  - Avg Peer Return: {avg_peer_return_display}\")\n",
        "             print(f\"  - Relative Performance: {relative_performance_display}\")\n",
        "        else:\n",
        "             print(\"Peer Performance Data Unavailable.\")\n",
        "\n",
        "\n",
        "        if enhanced.get('index_membership'):\n",
        "            print(f\"\\n🏛️ Index Membership: {', '.join(enhanced['index_membership'])}\")\n",
        "\n",
        "\n",
        "        # Display Global Macro Analysis\n",
        "        print(f\"\\n🌍 Global Macro Analysis:\")\n",
        "        global_macro = enhanced.get('global_macro', {})\n",
        "        macro_sentiment_display = global_macro.get('sentiment', 'N/A')\n",
        "        macro_adj_display = f\"{global_macro.get('adjustment', np.nan):+.2f}\" if isinstance(global_macro.get('adjustment'), (int, float)) and not pd.isna(global_macro.get('adjustment')) else \"N/A\"\n",
        "\n",
        "        print(f\"  - Global Macro Sentiment: {macro_sentiment_display}\")\n",
        "        print(f\"  - Global Macro Adjustment: {macro_adj_display}\")\n",
        "\n",
        "\n",
        "        # Sentiment Analysis Results\n",
        "        sentiment_results = enhanced.get('sentiment_analysis', {})\n",
        "        print(f\"\\n📰 News Sentiment Analysis:\")\n",
        "        if enhanced.get('news_headlines'):\n",
        "             # Only print a few headlines to keep the report concise\n",
        "             print(\"Sample News Headlines:\")\n",
        "             # Ensure headlines are valid strings before printing\n",
        "             valid_headlines = [h for h in enhanced['news_headlines'] if isinstance(h, str)]\n",
        "             for headline in valid_headlines[:5]: # Print up to 5 headlines\n",
        "                 print(f\"- {headline}\")\n",
        "             if len(valid_headlines) > 5:\n",
        "                  print(\"  ...\")\n",
        "\n",
        "             print(f\"Sentiment Counts: Positive={sentiment_results.get('positive', 0)}, Neutral={sentiment_results.get('neutral', 0)}, Negative={sentiment_results.get('negative', 0)}\")\n",
        "             sentiment_score_display = f\"{sentiment_results.get('score', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\"\n",
        "             print(f\"Sentiment Score: {sentiment_score_display}/25\")\n",
        "             print(f\"Sentiment Summary: {sentiment_results.get('summary', 'N/A')}\")\n",
        "        else:\n",
        "             print(\"No news headlines fetched or sentiment analysis skipped.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Comprehensive Scores and Recommendation ---\")\n",
        "        print(f\"Fundamental Score (from Part 1): {basic.fundamental_score:.2f}/50\" if not pd.isna(basic.fundamental_score) else \"Fundamental Score: N/A\")\n",
        "        # Add checks for NaN before formatting float for breakdown scores\n",
        "        enhanced_tech_score_display = f\"{final.get('breakdown', {}).get('technical', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('technical'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('technical')) else \"N/A\"\n",
        "        liquidity_score_display_breakdown = f\"{final.get('breakdown', {}).get('liquidity', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('liquidity'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('liquidity')) else \"N/A\"\n",
        "        sentiment_score_display_breakdown = f\"{sentiment_results.get('score', np.nan):.2f}\" if isinstance(sentiment_results.get('score'), (int, float)) and not pd.isna(sentiment_results.get('score')) else \"N/A\" # Corrected sentiment score breakdown check\n",
        "        valuation_comp_display_breakdown = f\"{final.get('breakdown', {}).get('valuation_comparison', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('valuation_comparison'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('valuation_comparison')) else \"N/A\"\n",
        "        downside_risk_display_breakdown = f\"{final.get('breakdown', {}).get('downside_risk', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('downside_risk'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('downside_risk')) else \"N/A\"\n",
        "        enhanced_dividend_display_breakdown = f\"{final.get('breakdown', {}).get('enhanced_dividend', np.nan):.2f}\" if isinstance(final.get('breakdown', {}).get('enhanced_dividend'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('enhanced_dividend')) else \"N/A\"\n",
        "        global_macro_display_breakdown = f\"{final.get('breakdown', {}).get('global_macro_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('global_macro_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('global_macro_adjustment')) else \"N/A\" # Display global macro adjustment breakdown\n",
        "\n",
        "\n",
        "        print(f\"Technical Score (Enhanced): {enhanced_tech_score_display}/50\")\n",
        "        print(f\"Liquidity Score: {liquidity_score_display_breakdown}/70\")\n",
        "        print(f\"Sentiment Score: {sentiment_score_display_breakdown}/25\")\n",
        "        print(f\"Valuation Comparison Adjustment: {valuation_comp_display_breakdown}\")\n",
        "        print(f\"Downside Risk Adjustment: {downside_risk_display_breakdown}\")\n",
        "        print(f\"Enhanced Dividend Score: {enhanced_dividend_display_breakdown}/20\") # Display enhanced dividend score breakdown\n",
        "        print(f\"Global Macro Adjustment: {global_macro_display_breakdown}\") # Display global macro adjustment breakdown\n",
        "\n",
        "\n",
        "        # Display adjustment scores\n",
        "        peer_adj_display = f\"{final.get('breakdown', {}).get('peer_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('peer_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('peer_adjustment')) else \"N/A\"\n",
        "        index_adj_display = f\"{final.get('breakdown', {}).get('index_adjustment', np.nan):+.2f}\" if isinstance(final.get('breakdown', {}).get('index_adjustment'), (int, float)) and not pd.isna(final.get('breakdown', {}).get('index_adjustment')) else \"N/A\"\n",
        "\n",
        "        print(f\"Peer Performance Adjustment: {peer_adj_display}\")\n",
        "        print(f\"Index Membership Adjustment: {index_adj_display}\")\n",
        "\n",
        "\n",
        "        # Updated max score to reflect the addition of Enhanced Dividend Score (20 points) and Global Macro (10 points)\n",
        "        # Max Total Score = Fund (50) + Tech (50) + Liq (70) + Sent (25) + Enhanced Dividend (20) + Val Adj (30) + Peer Adj (5) + Index Adj (5) + Downside Adj (0) + Global Macro Adj (10) = 265\n",
        "        print(f\"\\nTotal Enhanced Score: {final.get('total_score', 0):.2f}/265\" if isinstance(final.get('total_score'), (int, float)) and not pd.isna(final.get('total_score')) else \"Total Enhanced Score: N/A\")\n",
        "        print(f\"RECOMMENDATION: {final.get('recommendation', 'N/A')} (Confidence: {final.get('confidence', 'N/A')})\")\n",
        "\n",
        "\n",
        "        print(f\"\\n{'='*60}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82ba6cff"
      },
      "source": [
        "## Incorporate global macro impacts\n",
        "\n",
        "### Subtask:\n",
        "Implement a method within the `EnhancedStockAnalyzer` class to assess global macro impacts on the stock. This method should consider general economic indicators or news and provide an adjustment to the overall score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e01b325"
      },
      "source": [
        "## Refine Scoring and Recommendation\n",
        "\n",
        "### Subtask:\n",
        "Review the `generate_enhanced_recommendation` method in the `EnhancedStockAnalyzer` class. Adjust the weighting and logic for how the fundamental score, enhanced technical score, liquidity score, sentiment score, enhanced dividend score, valuation comparison adjustment, downside risk adjustment, peer performance adjustment, and index membership adjustment contribute to the total score and the final recommendation."
      ]
    }
  ]
}